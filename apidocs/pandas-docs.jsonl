{"snippet": "pandas.BooleanDtype", "intent": "Extension dtype for boolean data.", "question_id": 0},
{"snippet": "pandas.BooleanDtype", "intent": "Extension dtype for boolean data.", "question_id": 1},
{"snippet": "pandas.BooleanDtype", "intent": "Extension dtype for boolean data.", "question_id": 2},
{"snippet": "Categorical.__array__()", "intent": "The numpy array interface .", "question_id": 3},
{"snippet": "Categorical.__array__(dtype=None)", "intent": "The numpy array interface . With arguments `dtype`.", "question_id": 4},
{"snippet": "Categorical.__array__()", "intent": "The numpy array interface .", "question_id": 5},
{"snippet": "Categorical.__array__(dtype=None)", "intent": "The numpy array interface . With arguments `dtype`.", "question_id": 6},
{"snippet": "Categorical.__array__()", "intent": "The numpy array interface .", "question_id": 7},
{"snippet": "Categorical.__array__(dtype=None)", "intent": "The numpy array interface . With arguments `dtype`.", "question_id": 8},
{"snippet": "Categorical.from_codes(codes)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` .", "question_id": 9},
{"snippet": "Categorical.from_codes(codes, categories=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` .", "question_id": 10},
{"snippet": "Categorical.from_codes(codes, ordered=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` . With arguments `ordered`.", "question_id": 11},
{"snippet": "Categorical.from_codes(codes, dtype=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` .", "question_id": 12},
{"snippet": "Categorical.from_codes(codes, categories=None, ordered=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` . With arguments `ordered`.", "question_id": 13},
{"snippet": "Categorical.from_codes(codes, categories=None, dtype=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` .", "question_id": 14},
{"snippet": "Categorical.from_codes(codes, ordered=None, dtype=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` . With arguments `ordered`.", "question_id": 15},
{"snippet": "Categorical.from_codes(codes, categories=None, ordered=None, dtype=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` . With arguments `ordered`.", "question_id": 16},
{"snippet": "Categorical.from_codes(codes)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` .", "question_id": 17},
{"snippet": "Categorical.from_codes(codes, categories=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` .", "question_id": 18},
{"snippet": "Categorical.from_codes(codes, ordered=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` . With arguments `ordered`.", "question_id": 19},
{"snippet": "Categorical.from_codes(codes, dtype=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` .", "question_id": 20},
{"snippet": "Categorical.from_codes(codes, categories=None, ordered=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` . With arguments `ordered`.", "question_id": 21},
{"snippet": "Categorical.from_codes(codes, categories=None, dtype=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` .", "question_id": 22},
{"snippet": "Categorical.from_codes(codes, ordered=None, dtype=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` . With arguments `ordered`.", "question_id": 23},
{"snippet": "Categorical.from_codes(codes, categories=None, ordered=None, dtype=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` . With arguments `ordered`.", "question_id": 24},
{"snippet": "Categorical.from_codes(codes)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` .", "question_id": 25},
{"snippet": "Categorical.from_codes(codes, categories=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` .", "question_id": 26},
{"snippet": "Categorical.from_codes(codes, ordered=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` . With arguments `ordered`.", "question_id": 27},
{"snippet": "Categorical.from_codes(codes, dtype=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` .", "question_id": 28},
{"snippet": "Categorical.from_codes(codes, categories=None, ordered=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` . With arguments `ordered`.", "question_id": 29},
{"snippet": "Categorical.from_codes(codes, categories=None, dtype=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` .", "question_id": 30},
{"snippet": "Categorical.from_codes(codes, ordered=None, dtype=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` . With arguments `ordered`.", "question_id": 31},
{"snippet": "Categorical.from_codes(codes, categories=None, ordered=None, dtype=None)", "intent": "Make a Categorical type from `codes` and `categories` or `dtype` . With arguments `ordered`.", "question_id": 32},
{"snippet": "pandas.Categorical(values)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) .", "question_id": 33},
{"snippet": "pandas.Categorical(values, categories=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) .", "question_id": 34},
{"snippet": "pandas.Categorical(values, ordered=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `ordered`.", "question_id": 35},
{"snippet": "pandas.Categorical(values, dtype=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `dtype`.", "question_id": 36},
{"snippet": "pandas.Categorical(values, fastpath=False)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `fastpath`.", "question_id": 37},
{"snippet": "pandas.Categorical(values, copy=True)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `copy`.", "question_id": 38},
{"snippet": "pandas.Categorical(values, categories=None, ordered=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `ordered`.", "question_id": 39},
{"snippet": "pandas.Categorical(values, categories=None, dtype=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `dtype`.", "question_id": 40},
{"snippet": "pandas.Categorical(values, categories=None, fastpath=False)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `fastpath`.", "question_id": 41},
{"snippet": "pandas.Categorical(values, categories=None, copy=True)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `copy`.", "question_id": 42},
{"snippet": "pandas.Categorical(values)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) .", "question_id": 43},
{"snippet": "pandas.Categorical(values, categories=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) .", "question_id": 44},
{"snippet": "pandas.Categorical(values, ordered=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `ordered`.", "question_id": 45},
{"snippet": "pandas.Categorical(values, dtype=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `dtype`.", "question_id": 46},
{"snippet": "pandas.Categorical(values, fastpath=False)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `fastpath`.", "question_id": 47},
{"snippet": "pandas.Categorical(values, copy=True)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `copy`.", "question_id": 48},
{"snippet": "pandas.Categorical(values, categories=None, ordered=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `ordered`.", "question_id": 49},
{"snippet": "pandas.Categorical(values, categories=None, dtype=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `dtype`.", "question_id": 50},
{"snippet": "pandas.Categorical(values, categories=None, fastpath=False)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `fastpath`.", "question_id": 51},
{"snippet": "pandas.Categorical(values, categories=None, copy=True)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `copy`.", "question_id": 52},
{"snippet": "pandas.Categorical(values)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) .", "question_id": 53},
{"snippet": "pandas.Categorical(values, categories=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) .", "question_id": 54},
{"snippet": "pandas.Categorical(values, ordered=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `ordered`.", "question_id": 55},
{"snippet": "pandas.Categorical(values, dtype=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `dtype`.", "question_id": 56},
{"snippet": "pandas.Categorical(values, fastpath=False)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `fastpath`.", "question_id": 57},
{"snippet": "pandas.Categorical(values, copy=True)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `copy`.", "question_id": 58},
{"snippet": "pandas.Categorical(values, categories=None, ordered=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `ordered`.", "question_id": 59},
{"snippet": "pandas.Categorical(values, categories=None, dtype=None)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `dtype`.", "question_id": 60},
{"snippet": "pandas.Categorical(values, categories=None, fastpath=False)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `fastpath`.", "question_id": 61},
{"snippet": "pandas.Categorical(values, categories=None, copy=True)", "intent": "Represent a categorical variable in classic R / S-plus fashion . Categoricals can only take on only a limited , and usually fixed , number of possible `values` ( `categories` ) . With arguments `copy`.", "question_id": 62},
{"snippet": "pandas.CategoricalDtype()", "intent": "Type for categorical data with the `categories` and orderedness .", "question_id": 63},
{"snippet": "pandas.CategoricalDtype(categories=None)", "intent": "Type for categorical data with the `categories` and orderedness .", "question_id": 64},
{"snippet": "pandas.CategoricalDtype(ordered=False)", "intent": "Type for categorical data with the `categories` and orderedness . With arguments `ordered`.", "question_id": 65},
{"snippet": "pandas.CategoricalDtype(categories=None, ordered=False)", "intent": "Type for categorical data with the `categories` and orderedness . With arguments `ordered`.", "question_id": 66},
{"snippet": "pandas.CategoricalDtype()", "intent": "Type for categorical data with the `categories` and orderedness .", "question_id": 67},
{"snippet": "pandas.CategoricalDtype(categories=None)", "intent": "Type for categorical data with the `categories` and orderedness .", "question_id": 68},
{"snippet": "pandas.CategoricalDtype(ordered=False)", "intent": "Type for categorical data with the `categories` and orderedness . With arguments `ordered`.", "question_id": 69},
{"snippet": "pandas.CategoricalDtype(categories=None, ordered=False)", "intent": "Type for categorical data with the `categories` and orderedness . With arguments `ordered`.", "question_id": 70},
{"snippet": "pandas.CategoricalDtype()", "intent": "Type for categorical data with the `categories` and orderedness .", "question_id": 71},
{"snippet": "pandas.CategoricalDtype(categories=None)", "intent": "Type for categorical data with the `categories` and orderedness .", "question_id": 72},
{"snippet": "pandas.CategoricalDtype(ordered=False)", "intent": "Type for categorical data with the `categories` and orderedness . With arguments `ordered`.", "question_id": 73},
{"snippet": "pandas.CategoricalDtype(categories=None, ordered=False)", "intent": "Type for categorical data with the `categories` and orderedness . With arguments `ordered`.", "question_id": 74},
{"snippet": "CategoricalIndex.add_categories(*args, **kwargs)", "intent": "Add new categories . With arguments `*args`, `**kwargs`.", "question_id": 75},
{"snippet": "CategoricalIndex.add_categories(*args, **kwargs)", "intent": "Add new categories . With arguments `*args`, `**kwargs`.", "question_id": 76},
{"snippet": "CategoricalIndex.add_categories(*args, **kwargs)", "intent": "Add new categories . With arguments `*args`, `**kwargs`.", "question_id": 77},
{"snippet": "CategoricalIndex.as_ordered(*args, **kwargs)", "intent": "Set the Categorical to be ordered . With arguments `*args`, `**kwargs`.", "question_id": 78},
{"snippet": "CategoricalIndex.as_ordered(*args, **kwargs)", "intent": "Set the Categorical to be ordered . With arguments `*args`, `**kwargs`.", "question_id": 79},
{"snippet": "CategoricalIndex.as_ordered(*args, **kwargs)", "intent": "Set the Categorical to be ordered . With arguments `*args`, `**kwargs`.", "question_id": 80},
{"snippet": "CategoricalIndex.as_unordered(*args, **kwargs)", "intent": "Set the Categorical to be unordered . With arguments `*args`, `**kwargs`.", "question_id": 81},
{"snippet": "CategoricalIndex.as_unordered(*args, **kwargs)", "intent": "Set the Categorical to be unordered . With arguments `*args`, `**kwargs`.", "question_id": 82},
{"snippet": "CategoricalIndex.as_unordered(*args, **kwargs)", "intent": "Set the Categorical to be unordered . With arguments `*args`, `**kwargs`.", "question_id": 83},
{"snippet": "CategoricalIndex.equals(other)", "intent": "Determine if two CategoricalIndex objects contain the same elements . With arguments `other`.", "question_id": 84},
{"snippet": "CategoricalIndex.equals(other)", "intent": "Determine if two CategoricalIndex objects contain the same elements . With arguments `other`.", "question_id": 85},
{"snippet": "CategoricalIndex.equals(other)", "intent": "Determine if two CategoricalIndex objects contain the same elements . With arguments `other`.", "question_id": 86},
{"snippet": "pandas.CategoricalIndex()", "intent": "Index based on an underlying Categorical .", "question_id": 87},
{"snippet": "pandas.CategoricalIndex(data=None)", "intent": "Index based on an underlying Categorical . With arguments `data`.", "question_id": 88},
{"snippet": "pandas.CategoricalIndex(categories=None)", "intent": "Index based on an underlying Categorical . CategoricalIndex , like Categorical , can only take on a limited , and usually fixed , number of possible values ( `categories` ) .", "question_id": 89},
{"snippet": "pandas.CategoricalIndex(ordered=None)", "intent": "Index based on an underlying Categorical . With arguments `ordered`.", "question_id": 90},
{"snippet": "pandas.CategoricalIndex(dtype=None)", "intent": "Index based on an underlying Categorical . With arguments `dtype`.", "question_id": 91},
{"snippet": "pandas.CategoricalIndex(copy=False)", "intent": "Index based on an underlying Categorical . With arguments `copy`.", "question_id": 92},
{"snippet": "pandas.CategoricalIndex(name=None)", "intent": "Index based on an underlying Categorical . With arguments `name`.", "question_id": 93},
{"snippet": "pandas.CategoricalIndex(data=None, categories=None)", "intent": "Index based on an underlying Categorical . CategoricalIndex , like Categorical , can only take on a limited , and usually fixed , number of possible values ( `categories` ) . With arguments `data`.", "question_id": 94},
{"snippet": "pandas.CategoricalIndex(data=None, ordered=None)", "intent": "Index based on an underlying Categorical . With arguments `data`, `ordered`.", "question_id": 95},
{"snippet": "pandas.CategoricalIndex(data=None, dtype=None)", "intent": "Index based on an underlying Categorical . With arguments `data`, `dtype`.", "question_id": 96},
{"snippet": "pandas.CategoricalIndex()", "intent": "Index based on an underlying Categorical .", "question_id": 97},
{"snippet": "pandas.CategoricalIndex(data=None)", "intent": "Index based on an underlying Categorical . With arguments `data`.", "question_id": 98},
{"snippet": "pandas.CategoricalIndex(categories=None)", "intent": "Index based on an underlying Categorical . CategoricalIndex , like Categorical , can only take on a limited , and usually fixed , number of possible values ( `categories` ) .", "question_id": 99},
{"snippet": "pandas.CategoricalIndex(ordered=None)", "intent": "Index based on an underlying Categorical . With arguments `ordered`.", "question_id": 100},
{"snippet": "pandas.CategoricalIndex(dtype=None)", "intent": "Index based on an underlying Categorical . With arguments `dtype`.", "question_id": 101},
{"snippet": "pandas.CategoricalIndex(copy=False)", "intent": "Index based on an underlying Categorical . With arguments `copy`.", "question_id": 102},
{"snippet": "pandas.CategoricalIndex(name=None)", "intent": "Index based on an underlying Categorical . With arguments `name`.", "question_id": 103},
{"snippet": "pandas.CategoricalIndex(data=None, categories=None)", "intent": "Index based on an underlying Categorical . CategoricalIndex , like Categorical , can only take on a limited , and usually fixed , number of possible values ( `categories` ) . With arguments `data`.", "question_id": 104},
{"snippet": "pandas.CategoricalIndex(data=None, ordered=None)", "intent": "Index based on an underlying Categorical . With arguments `data`, `ordered`.", "question_id": 105},
{"snippet": "pandas.CategoricalIndex(data=None, dtype=None)", "intent": "Index based on an underlying Categorical . With arguments `data`, `dtype`.", "question_id": 106},
{"snippet": "pandas.CategoricalIndex()", "intent": "Index based on an underlying Categorical .", "question_id": 107},
{"snippet": "pandas.CategoricalIndex(data=None)", "intent": "Index based on an underlying Categorical . With arguments `data`.", "question_id": 108},
{"snippet": "pandas.CategoricalIndex(categories=None)", "intent": "Index based on an underlying Categorical . CategoricalIndex , like Categorical , can only take on a limited , and usually fixed , number of possible values ( `categories` ) .", "question_id": 109},
{"snippet": "pandas.CategoricalIndex(ordered=None)", "intent": "Index based on an underlying Categorical . With arguments `ordered`.", "question_id": 110},
{"snippet": "pandas.CategoricalIndex(dtype=None)", "intent": "Index based on an underlying Categorical . With arguments `dtype`.", "question_id": 111},
{"snippet": "pandas.CategoricalIndex(copy=False)", "intent": "Index based on an underlying Categorical . With arguments `copy`.", "question_id": 112},
{"snippet": "pandas.CategoricalIndex(name=None)", "intent": "Index based on an underlying Categorical . With arguments `name`.", "question_id": 113},
{"snippet": "pandas.CategoricalIndex(data=None, categories=None)", "intent": "Index based on an underlying Categorical . CategoricalIndex , like Categorical , can only take on a limited , and usually fixed , number of possible values ( `categories` ) . With arguments `data`.", "question_id": 114},
{"snippet": "pandas.CategoricalIndex(data=None, ordered=None)", "intent": "Index based on an underlying Categorical . With arguments `data`, `ordered`.", "question_id": 115},
{"snippet": "pandas.CategoricalIndex(data=None, dtype=None)", "intent": "Index based on an underlying Categorical . With arguments `data`, `dtype`.", "question_id": 116},
{"snippet": "CategoricalIndex.map(mapper)", "intent": "Map values using input correspondence ( a dict , Series , or function ) . With arguments `mapper`.", "question_id": 117},
{"snippet": "CategoricalIndex.map(mapper)", "intent": "Map values using input correspondence ( a dict , Series , or function ) . With arguments `mapper`.", "question_id": 118},
{"snippet": "CategoricalIndex.map(mapper)", "intent": "Map values using input correspondence ( a dict , Series , or function ) . With arguments `mapper`.", "question_id": 119},
{"snippet": "CategoricalIndex.remove_categories(*args, **kwargs)", "intent": "Remove the specified categories . With arguments `*args`, `**kwargs`.", "question_id": 120},
{"snippet": "CategoricalIndex.remove_categories(*args, **kwargs)", "intent": "Remove the specified categories . With arguments `*args`, `**kwargs`.", "question_id": 121},
{"snippet": "CategoricalIndex.remove_categories(*args, **kwargs)", "intent": "Remove the specified categories . With arguments `*args`, `**kwargs`.", "question_id": 122},
{"snippet": "CategoricalIndex.remove_unused_categories(*args, **kwargs)", "intent": "Remove categories which are not used . With arguments `*args`, `**kwargs`.", "question_id": 123},
{"snippet": "CategoricalIndex.remove_unused_categories(*args, **kwargs)", "intent": "Remove categories which are not used . With arguments `*args`, `**kwargs`.", "question_id": 124},
{"snippet": "CategoricalIndex.remove_unused_categories(*args, **kwargs)", "intent": "Remove categories which are not used . With arguments `*args`, `**kwargs`.", "question_id": 125},
{"snippet": "CategoricalIndex.rename_categories(*args, **kwargs)", "intent": "Rename categories . With arguments `*args`, `**kwargs`.", "question_id": 126},
{"snippet": "CategoricalIndex.rename_categories(*args, **kwargs)", "intent": "Rename categories . With arguments `*args`, `**kwargs`.", "question_id": 127},
{"snippet": "CategoricalIndex.rename_categories(*args, **kwargs)", "intent": "Rename categories . With arguments `*args`, `**kwargs`.", "question_id": 128},
{"snippet": "CategoricalIndex.reorder_categories(*args, **kwargs)", "intent": "Reorder categories as specified in new_categories . With arguments `*args`, `**kwargs`.", "question_id": 129},
{"snippet": "CategoricalIndex.reorder_categories(*args, **kwargs)", "intent": "Reorder categories as specified in new_categories . With arguments `*args`, `**kwargs`.", "question_id": 130},
{"snippet": "CategoricalIndex.reorder_categories(*args, **kwargs)", "intent": "Reorder categories as specified in new_categories . With arguments `*args`, `**kwargs`.", "question_id": 131},
{"snippet": "CategoricalIndex.set_categories(*args, **kwargs)", "intent": "Set the categories to the specified new_categories . With arguments `*args`, `**kwargs`.", "question_id": 132},
{"snippet": "CategoricalIndex.set_categories(*args, **kwargs)", "intent": "Set the categories to the specified new_categories . With arguments `*args`, `**kwargs`.", "question_id": 133},
{"snippet": "CategoricalIndex.set_categories(*args, **kwargs)", "intent": "Set the categories to the specified new_categories . With arguments `*args`, `**kwargs`.", "question_id": 134},
{"snippet": "DataFrame.__iter__()", "intent": "Iterate over info axis .", "question_id": 135},
{"snippet": "DataFrame.__iter__()", "intent": "Iterate over info axis .", "question_id": 136},
{"snippet": "DataFrame.__iter__()", "intent": "Iterate over info axis .", "question_id": 137},
{"snippet": "DataFrame.abs()", "intent": "Return a Series/DataFrame with absolute numeric value of each element .", "question_id": 138},
{"snippet": "DataFrame.abs()", "intent": "Return a Series/DataFrame with absolute numeric value of each element .", "question_id": 139},
{"snippet": "DataFrame.abs()", "intent": "Return a Series/DataFrame with absolute numeric value of each element .", "question_id": 140},
{"snippet": "DataFrame.add(other)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) .", "question_id": 141},
{"snippet": "DataFrame.add(other, axis='columns')", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Subtract a list and Series by `axis` with operator version .", "question_id": 142},
{"snippet": "DataFrame.add(other, level=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Divide by a MultiIndex by `level` .", "question_id": 143},
{"snippet": "DataFrame.add(other, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Equivalent to dataframe + other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 144},
{"snippet": "DataFrame.add(other, axis='columns', level=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 145},
{"snippet": "DataFrame.add(other, axis='columns', fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe + other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 146},
{"snippet": "DataFrame.add(other, level=None, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Divide by a MultiIndex by `level` . Equivalent to dataframe + other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 147},
{"snippet": "DataFrame.add(other, axis='columns', level=None, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe + other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 148},
{"snippet": "DataFrame.add(other)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) .", "question_id": 149},
{"snippet": "DataFrame.add(other, axis='columns')", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Subtract a list and Series by `axis` with operator version .", "question_id": 150},
{"snippet": "DataFrame.add(other, level=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Divide by a MultiIndex by `level` .", "question_id": 151},
{"snippet": "DataFrame.add(other, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Equivalent to dataframe + other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 152},
{"snippet": "DataFrame.add(other, axis='columns', level=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 153},
{"snippet": "DataFrame.add(other, axis='columns', fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe + other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 154},
{"snippet": "DataFrame.add(other, level=None, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Divide by a MultiIndex by `level` . Equivalent to dataframe + other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 155},
{"snippet": "DataFrame.add(other, axis='columns', level=None, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe + other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 156},
{"snippet": "DataFrame.add(other)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) .", "question_id": 157},
{"snippet": "DataFrame.add(other, axis='columns')", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Subtract a list and Series by `axis` with operator version .", "question_id": 158},
{"snippet": "DataFrame.add(other, level=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Divide by a MultiIndex by `level` .", "question_id": 159},
{"snippet": "DataFrame.add(other, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Equivalent to dataframe + other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 160},
{"snippet": "DataFrame.add(other, axis='columns', level=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 161},
{"snippet": "DataFrame.add(other, axis='columns', fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe + other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 162},
{"snippet": "DataFrame.add(other, level=None, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Divide by a MultiIndex by `level` . Equivalent to dataframe + other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 163},
{"snippet": "DataFrame.add(other, axis='columns', level=None, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator add ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe + other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 164},
{"snippet": "DataFrame.add_prefix(prefix)", "intent": "Prefix labels with string `prefix` .", "question_id": 165},
{"snippet": "DataFrame.add_prefix(prefix)", "intent": "Prefix labels with string `prefix` .", "question_id": 166},
{"snippet": "DataFrame.add_prefix(prefix)", "intent": "Prefix labels with string `prefix` .", "question_id": 167},
{"snippet": "DataFrame.add_suffix(suffix)", "intent": "Suffix labels with string `suffix` .", "question_id": 168},
{"snippet": "DataFrame.add_suffix(suffix)", "intent": "Suffix labels with string `suffix` .", "question_id": 169},
{"snippet": "DataFrame.add_suffix(suffix)", "intent": "Suffix labels with string `suffix` .", "question_id": 170},
{"snippet": "DataFrame.agg(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 171},
{"snippet": "DataFrame.agg(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 172},
{"snippet": "DataFrame.agg(*args, **kwargs, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 173},
{"snippet": "DataFrame.agg(*args, **kwargs, func=None, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 174},
{"snippet": "DataFrame.agg(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 175},
{"snippet": "DataFrame.agg(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 176},
{"snippet": "DataFrame.agg(*args, **kwargs, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 177},
{"snippet": "DataFrame.agg(*args, **kwargs, func=None, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 178},
{"snippet": "DataFrame.agg(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 179},
{"snippet": "DataFrame.agg(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 180},
{"snippet": "DataFrame.agg(*args, **kwargs, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 181},
{"snippet": "DataFrame.agg(*args, **kwargs, func=None, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 182},
{"snippet": "DataFrame.aggregate(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 183},
{"snippet": "DataFrame.aggregate(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 184},
{"snippet": "DataFrame.aggregate(*args, **kwargs, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 185},
{"snippet": "DataFrame.aggregate(*args, **kwargs, func=None, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 186},
{"snippet": "DataFrame.aggregate(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 187},
{"snippet": "DataFrame.aggregate(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 188},
{"snippet": "DataFrame.aggregate(*args, **kwargs, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 189},
{"snippet": "DataFrame.aggregate(*args, **kwargs, func=None, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 190},
{"snippet": "DataFrame.aggregate(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 191},
{"snippet": "DataFrame.aggregate(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 192},
{"snippet": "DataFrame.aggregate(*args, **kwargs, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 193},
{"snippet": "DataFrame.aggregate(*args, **kwargs, func=None, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 194},
{"snippet": "DataFrame.align(other)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 195},
{"snippet": "DataFrame.align(other, join='outer')", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 196},
{"snippet": "DataFrame.align(other, axis=None)", "intent": "Align two objects on their axes with the specified `join` `method` . Join method is specified for each `axis` Index . With arguments `other`.", "question_id": 197},
{"snippet": "DataFrame.align(other, level=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `level`.", "question_id": 198},
{"snippet": "DataFrame.align(other, copy=True)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `copy`.", "question_id": 199},
{"snippet": "DataFrame.align(other, fill_value=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `fill_value`.", "question_id": 200},
{"snippet": "DataFrame.align(other, method=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 201},
{"snippet": "DataFrame.align(other, limit=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `limit`.", "question_id": 202},
{"snippet": "DataFrame.align(other, fill_axis=0)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `fill_axis`.", "question_id": 203},
{"snippet": "DataFrame.align(other, broadcast_axis=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `broadcast_axis`.", "question_id": 204},
{"snippet": "DataFrame.align(other)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 205},
{"snippet": "DataFrame.align(other, join='outer')", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 206},
{"snippet": "DataFrame.align(other, axis=None)", "intent": "Align two objects on their axes with the specified `join` `method` . Join method is specified for each `axis` Index . With arguments `other`.", "question_id": 207},
{"snippet": "DataFrame.align(other, level=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `level`.", "question_id": 208},
{"snippet": "DataFrame.align(other, copy=True)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `copy`.", "question_id": 209},
{"snippet": "DataFrame.align(other, fill_value=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `fill_value`.", "question_id": 210},
{"snippet": "DataFrame.align(other, method=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 211},
{"snippet": "DataFrame.align(other, limit=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `limit`.", "question_id": 212},
{"snippet": "DataFrame.align(other, fill_axis=0)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `fill_axis`.", "question_id": 213},
{"snippet": "DataFrame.align(other, broadcast_axis=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `broadcast_axis`.", "question_id": 214},
{"snippet": "DataFrame.align(other)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 215},
{"snippet": "DataFrame.align(other, join='outer')", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 216},
{"snippet": "DataFrame.align(other, axis=None)", "intent": "Align two objects on their axes with the specified `join` `method` . Join method is specified for each `axis` Index . With arguments `other`.", "question_id": 217},
{"snippet": "DataFrame.align(other, level=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `level`.", "question_id": 218},
{"snippet": "DataFrame.align(other, copy=True)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `copy`.", "question_id": 219},
{"snippet": "DataFrame.align(other, fill_value=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `fill_value`.", "question_id": 220},
{"snippet": "DataFrame.align(other, method=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 221},
{"snippet": "DataFrame.align(other, limit=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `limit`.", "question_id": 222},
{"snippet": "DataFrame.align(other, fill_axis=0)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `fill_axis`.", "question_id": 223},
{"snippet": "DataFrame.align(other, broadcast_axis=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `broadcast_axis`.", "question_id": 224},
{"snippet": "DataFrame.all(**kwargs)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 225},
{"snippet": "DataFrame.all(**kwargs, axis=0)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 226},
{"snippet": "DataFrame.all(**kwargs, bool_only=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 227},
{"snippet": "DataFrame.all(**kwargs, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 228},
{"snippet": "DataFrame.all(**kwargs, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 229},
{"snippet": "DataFrame.all(**kwargs, axis=0, bool_only=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 230},
{"snippet": "DataFrame.all(**kwargs, axis=0, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 231},
{"snippet": "DataFrame.all(**kwargs, axis=0, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 232},
{"snippet": "DataFrame.all(**kwargs, bool_only=None, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `skipna`.", "question_id": 233},
{"snippet": "DataFrame.all(**kwargs, bool_only=None, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `level`.", "question_id": 234},
{"snippet": "DataFrame.all(**kwargs)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 235},
{"snippet": "DataFrame.all(**kwargs, axis=0)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 236},
{"snippet": "DataFrame.all(**kwargs, bool_only=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 237},
{"snippet": "DataFrame.all(**kwargs, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 238},
{"snippet": "DataFrame.all(**kwargs, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 239},
{"snippet": "DataFrame.all(**kwargs, axis=0, bool_only=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 240},
{"snippet": "DataFrame.all(**kwargs, axis=0, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 241},
{"snippet": "DataFrame.all(**kwargs, axis=0, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 242},
{"snippet": "DataFrame.all(**kwargs, bool_only=None, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `skipna`.", "question_id": 243},
{"snippet": "DataFrame.all(**kwargs, bool_only=None, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `level`.", "question_id": 244},
{"snippet": "DataFrame.all(**kwargs)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 245},
{"snippet": "DataFrame.all(**kwargs, axis=0)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 246},
{"snippet": "DataFrame.all(**kwargs, bool_only=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 247},
{"snippet": "DataFrame.all(**kwargs, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 248},
{"snippet": "DataFrame.all(**kwargs, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 249},
{"snippet": "DataFrame.all(**kwargs, axis=0, bool_only=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 250},
{"snippet": "DataFrame.all(**kwargs, axis=0, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 251},
{"snippet": "DataFrame.all(**kwargs, axis=0, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 252},
{"snippet": "DataFrame.all(**kwargs, bool_only=None, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `skipna`.", "question_id": 253},
{"snippet": "DataFrame.all(**kwargs, bool_only=None, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `level`.", "question_id": 254},
{"snippet": "DataFrame.any(**kwargs)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 255},
{"snippet": "DataFrame.any(**kwargs, axis=0)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 256},
{"snippet": "DataFrame.any(**kwargs, bool_only=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 257},
{"snippet": "DataFrame.any(**kwargs, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 258},
{"snippet": "DataFrame.any(**kwargs, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 259},
{"snippet": "DataFrame.any(**kwargs, axis=0, bool_only=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 260},
{"snippet": "DataFrame.any(**kwargs, axis=0, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 261},
{"snippet": "DataFrame.any(**kwargs, axis=0, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 262},
{"snippet": "DataFrame.any(**kwargs, bool_only=None, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `skipna`.", "question_id": 263},
{"snippet": "DataFrame.any(**kwargs, bool_only=None, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `level`.", "question_id": 264},
{"snippet": "DataFrame.any(**kwargs)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 265},
{"snippet": "DataFrame.any(**kwargs, axis=0)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 266},
{"snippet": "DataFrame.any(**kwargs, bool_only=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 267},
{"snippet": "DataFrame.any(**kwargs, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 268},
{"snippet": "DataFrame.any(**kwargs, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 269},
{"snippet": "DataFrame.any(**kwargs, axis=0, bool_only=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 270},
{"snippet": "DataFrame.any(**kwargs, axis=0, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 271},
{"snippet": "DataFrame.any(**kwargs, axis=0, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 272},
{"snippet": "DataFrame.any(**kwargs, bool_only=None, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `skipna`.", "question_id": 273},
{"snippet": "DataFrame.any(**kwargs, bool_only=None, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `level`.", "question_id": 274},
{"snippet": "DataFrame.any(**kwargs)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 275},
{"snippet": "DataFrame.any(**kwargs, axis=0)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 276},
{"snippet": "DataFrame.any(**kwargs, bool_only=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 277},
{"snippet": "DataFrame.any(**kwargs, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 278},
{"snippet": "DataFrame.any(**kwargs, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 279},
{"snippet": "DataFrame.any(**kwargs, axis=0, bool_only=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 280},
{"snippet": "DataFrame.any(**kwargs, axis=0, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 281},
{"snippet": "DataFrame.any(**kwargs, axis=0, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 282},
{"snippet": "DataFrame.any(**kwargs, bool_only=None, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `skipna`.", "question_id": 283},
{"snippet": "DataFrame.any(**kwargs, bool_only=None, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `level`.", "question_id": 284},
{"snippet": "DataFrame.append(other)", "intent": "Append rows of `other` to the end of caller , returning a new object .", "question_id": 285},
{"snippet": "DataFrame.append(other, ignore_index=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With `ignore_index` set to True :", "question_id": 286},
{"snippet": "DataFrame.append(other, verify_integrity=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With arguments `verify_integrity`.", "question_id": 287},
{"snippet": "DataFrame.append(other, sort=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With arguments `sort`.", "question_id": 288},
{"snippet": "DataFrame.append(other, ignore_index=False, verify_integrity=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With `ignore_index` set to True : With arguments `verify_integrity`.", "question_id": 289},
{"snippet": "DataFrame.append(other, ignore_index=False, sort=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With `ignore_index` set to True : With arguments `sort`.", "question_id": 290},
{"snippet": "DataFrame.append(other, verify_integrity=False, sort=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With arguments `verify_integrity`, `sort`.", "question_id": 291},
{"snippet": "DataFrame.append(other, ignore_index=False, verify_integrity=False, sort=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With `ignore_index` set to True : With arguments `verify_integrity`, `sort`.", "question_id": 292},
{"snippet": "DataFrame.append(other)", "intent": "Append rows of `other` to the end of caller , returning a new object .", "question_id": 293},
{"snippet": "DataFrame.append(other, ignore_index=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With `ignore_index` set to True :", "question_id": 294},
{"snippet": "DataFrame.append(other, verify_integrity=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With arguments `verify_integrity`.", "question_id": 295},
{"snippet": "DataFrame.append(other, sort=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With arguments `sort`.", "question_id": 296},
{"snippet": "DataFrame.append(other, ignore_index=False, verify_integrity=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With `ignore_index` set to True : With arguments `verify_integrity`.", "question_id": 297},
{"snippet": "DataFrame.append(other, ignore_index=False, sort=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With `ignore_index` set to True : With arguments `sort`.", "question_id": 298},
{"snippet": "DataFrame.append(other, verify_integrity=False, sort=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With arguments `verify_integrity`, `sort`.", "question_id": 299},
{"snippet": "DataFrame.append(other, ignore_index=False, verify_integrity=False, sort=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With `ignore_index` set to True : With arguments `verify_integrity`, `sort`.", "question_id": 300},
{"snippet": "DataFrame.append(other)", "intent": "Append rows of `other` to the end of caller , returning a new object .", "question_id": 301},
{"snippet": "DataFrame.append(other, ignore_index=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With `ignore_index` set to True :", "question_id": 302},
{"snippet": "DataFrame.append(other, verify_integrity=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With arguments `verify_integrity`.", "question_id": 303},
{"snippet": "DataFrame.append(other, sort=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With arguments `sort`.", "question_id": 304},
{"snippet": "DataFrame.append(other, ignore_index=False, verify_integrity=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With `ignore_index` set to True : With arguments `verify_integrity`.", "question_id": 305},
{"snippet": "DataFrame.append(other, ignore_index=False, sort=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With `ignore_index` set to True : With arguments `sort`.", "question_id": 306},
{"snippet": "DataFrame.append(other, verify_integrity=False, sort=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With arguments `verify_integrity`, `sort`.", "question_id": 307},
{"snippet": "DataFrame.append(other, ignore_index=False, verify_integrity=False, sort=False)", "intent": "Append rows of `other` to the end of caller , returning a new object . With `ignore_index` set to True : With arguments `verify_integrity`, `sort`.", "question_id": 308},
{"snippet": "DataFrame.apply(func, **kwargs)", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`.", "question_id": 309},
{"snippet": "DataFrame.apply(func, **kwargs, axis=0)", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`.", "question_id": 310},
{"snippet": "DataFrame.apply(func, **kwargs, raw=False)", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `raw`.", "question_id": 311},
{"snippet": "DataFrame.apply(func, **kwargs, result_type=None)", "intent": "Apply a function along an `axis` of the DataFrame . Otherwise , it depends on the `result_type` argument . With arguments `func`, `**kwargs`.", "question_id": 312},
{"snippet": "DataFrame.apply(func, **kwargs, args=())", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `args`.", "question_id": 313},
{"snippet": "DataFrame.apply(func, **kwargs, axis=0, raw=False)", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `raw`.", "question_id": 314},
{"snippet": "DataFrame.apply(func, **kwargs, axis=0, result_type=None)", "intent": "Apply a function along an `axis` of the DataFrame . Otherwise , it depends on the `result_type` argument . With arguments `func`, `**kwargs`.", "question_id": 315},
{"snippet": "DataFrame.apply(func, **kwargs, axis=0, args=())", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `args`.", "question_id": 316},
{"snippet": "DataFrame.apply(func, **kwargs, raw=False, result_type=None)", "intent": "Apply a function along an `axis` of the DataFrame . Otherwise , it depends on the `result_type` argument . With arguments `func`, `**kwargs`, `raw`.", "question_id": 317},
{"snippet": "DataFrame.apply(func, **kwargs, raw=False, args=())", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `raw`, `args`.", "question_id": 318},
{"snippet": "DataFrame.apply(func, **kwargs)", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`.", "question_id": 319},
{"snippet": "DataFrame.apply(func, **kwargs, axis=0)", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`.", "question_id": 320},
{"snippet": "DataFrame.apply(func, **kwargs, raw=False)", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `raw`.", "question_id": 321},
{"snippet": "DataFrame.apply(func, **kwargs, result_type=None)", "intent": "Apply a function along an `axis` of the DataFrame . Otherwise , it depends on the `result_type` argument . With arguments `func`, `**kwargs`.", "question_id": 322},
{"snippet": "DataFrame.apply(func, **kwargs, args=())", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `args`.", "question_id": 323},
{"snippet": "DataFrame.apply(func, **kwargs, axis=0, raw=False)", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `raw`.", "question_id": 324},
{"snippet": "DataFrame.apply(func, **kwargs, axis=0, result_type=None)", "intent": "Apply a function along an `axis` of the DataFrame . Otherwise , it depends on the `result_type` argument . With arguments `func`, `**kwargs`.", "question_id": 325},
{"snippet": "DataFrame.apply(func, **kwargs, axis=0, args=())", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `args`.", "question_id": 326},
{"snippet": "DataFrame.apply(func, **kwargs, raw=False, result_type=None)", "intent": "Apply a function along an `axis` of the DataFrame . Otherwise , it depends on the `result_type` argument . With arguments `func`, `**kwargs`, `raw`.", "question_id": 327},
{"snippet": "DataFrame.apply(func, **kwargs, raw=False, args=())", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `raw`, `args`.", "question_id": 328},
{"snippet": "DataFrame.apply(func, **kwargs)", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`.", "question_id": 329},
{"snippet": "DataFrame.apply(func, **kwargs, axis=0)", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`.", "question_id": 330},
{"snippet": "DataFrame.apply(func, **kwargs, raw=False)", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `raw`.", "question_id": 331},
{"snippet": "DataFrame.apply(func, **kwargs, result_type=None)", "intent": "Apply a function along an `axis` of the DataFrame . Otherwise , it depends on the `result_type` argument . With arguments `func`, `**kwargs`.", "question_id": 332},
{"snippet": "DataFrame.apply(func, **kwargs, args=())", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `args`.", "question_id": 333},
{"snippet": "DataFrame.apply(func, **kwargs, axis=0, raw=False)", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `raw`.", "question_id": 334},
{"snippet": "DataFrame.apply(func, **kwargs, axis=0, result_type=None)", "intent": "Apply a function along an `axis` of the DataFrame . Otherwise , it depends on the `result_type` argument . With arguments `func`, `**kwargs`.", "question_id": 335},
{"snippet": "DataFrame.apply(func, **kwargs, axis=0, args=())", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `args`.", "question_id": 336},
{"snippet": "DataFrame.apply(func, **kwargs, raw=False, result_type=None)", "intent": "Apply a function along an `axis` of the DataFrame . Otherwise , it depends on the `result_type` argument . With arguments `func`, `**kwargs`, `raw`.", "question_id": 337},
{"snippet": "DataFrame.apply(func, **kwargs, raw=False, args=())", "intent": "Apply a function along an `axis` of the DataFrame . With arguments `func`, `**kwargs`, `raw`, `args`.", "question_id": 338},
{"snippet": "DataFrame.applymap(func, **kwargs)", "intent": "Apply a function to a Dataframe elementwise . Note that a vectorized version of `func` often exists , which will be much faster . With arguments `**kwargs`.", "question_id": 339},
{"snippet": "DataFrame.applymap(func, **kwargs, na_action=None)", "intent": "Apply a function to a Dataframe elementwise . Note that a vectorized version of `func` often exists , which will be much faster . With arguments `**kwargs`, `na_action`.", "question_id": 340},
{"snippet": "DataFrame.applymap(func, **kwargs)", "intent": "Apply a function to a Dataframe elementwise . Note that a vectorized version of `func` often exists , which will be much faster . With arguments `**kwargs`.", "question_id": 341},
{"snippet": "DataFrame.applymap(func, **kwargs, na_action=None)", "intent": "Apply a function to a Dataframe elementwise . Note that a vectorized version of `func` often exists , which will be much faster . With arguments `**kwargs`, `na_action`.", "question_id": 342},
{"snippet": "DataFrame.applymap(func, **kwargs)", "intent": "Apply a function to a Dataframe elementwise . Note that a vectorized version of `func` often exists , which will be much faster . With arguments `**kwargs`.", "question_id": 343},
{"snippet": "DataFrame.applymap(func, **kwargs, na_action=None)", "intent": "Apply a function to a Dataframe elementwise . Note that a vectorized version of `func` often exists , which will be much faster . With arguments `**kwargs`, `na_action`.", "question_id": 344},
{"snippet": "DataFrame.asfreq(freq)", "intent": "Convert time series to specified frequency . With arguments `freq`.", "question_id": 345},
{"snippet": "DataFrame.asfreq(freq, method=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`.", "question_id": 346},
{"snippet": "DataFrame.asfreq(freq, how=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`.", "question_id": 347},
{"snippet": "DataFrame.asfreq(freq, normalize=False)", "intent": "Convert time series to specified frequency . With arguments `freq`, `normalize`.", "question_id": 348},
{"snippet": "DataFrame.asfreq(freq, fill_value=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `fill_value`.", "question_id": 349},
{"snippet": "DataFrame.asfreq(freq, method=None, how=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `how`.", "question_id": 350},
{"snippet": "DataFrame.asfreq(freq, method=None, normalize=False)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `normalize`.", "question_id": 351},
{"snippet": "DataFrame.asfreq(freq, method=None, fill_value=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `fill_value`.", "question_id": 352},
{"snippet": "DataFrame.asfreq(freq, how=None, normalize=False)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`, `normalize`.", "question_id": 353},
{"snippet": "DataFrame.asfreq(freq, how=None, fill_value=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`, `fill_value`.", "question_id": 354},
{"snippet": "DataFrame.asfreq(freq)", "intent": "Convert time series to specified frequency . With arguments `freq`.", "question_id": 355},
{"snippet": "DataFrame.asfreq(freq, method=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`.", "question_id": 356},
{"snippet": "DataFrame.asfreq(freq, how=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`.", "question_id": 357},
{"snippet": "DataFrame.asfreq(freq, normalize=False)", "intent": "Convert time series to specified frequency . With arguments `freq`, `normalize`.", "question_id": 358},
{"snippet": "DataFrame.asfreq(freq, fill_value=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `fill_value`.", "question_id": 359},
{"snippet": "DataFrame.asfreq(freq, method=None, how=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `how`.", "question_id": 360},
{"snippet": "DataFrame.asfreq(freq, method=None, normalize=False)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `normalize`.", "question_id": 361},
{"snippet": "DataFrame.asfreq(freq, method=None, fill_value=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `fill_value`.", "question_id": 362},
{"snippet": "DataFrame.asfreq(freq, how=None, normalize=False)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`, `normalize`.", "question_id": 363},
{"snippet": "DataFrame.asfreq(freq, how=None, fill_value=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`, `fill_value`.", "question_id": 364},
{"snippet": "DataFrame.asfreq(freq)", "intent": "Convert time series to specified frequency . With arguments `freq`.", "question_id": 365},
{"snippet": "DataFrame.asfreq(freq, method=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`.", "question_id": 366},
{"snippet": "DataFrame.asfreq(freq, how=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`.", "question_id": 367},
{"snippet": "DataFrame.asfreq(freq, normalize=False)", "intent": "Convert time series to specified frequency . With arguments `freq`, `normalize`.", "question_id": 368},
{"snippet": "DataFrame.asfreq(freq, fill_value=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `fill_value`.", "question_id": 369},
{"snippet": "DataFrame.asfreq(freq, method=None, how=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `how`.", "question_id": 370},
{"snippet": "DataFrame.asfreq(freq, method=None, normalize=False)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `normalize`.", "question_id": 371},
{"snippet": "DataFrame.asfreq(freq, method=None, fill_value=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `fill_value`.", "question_id": 372},
{"snippet": "DataFrame.asfreq(freq, how=None, normalize=False)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`, `normalize`.", "question_id": 373},
{"snippet": "DataFrame.asfreq(freq, how=None, fill_value=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`, `fill_value`.", "question_id": 374},
{"snippet": "DataFrame.asof(where)", "intent": "Return the last row ( s ) without any NaNs before `where` .", "question_id": 375},
{"snippet": "DataFrame.asof(where, subset=None)", "intent": "Return the last row ( s ) without any NaNs before `where` . In case of a DataFrame , the last row without NaN considering only the `subset` of columns ( if not None )", "question_id": 376},
{"snippet": "DataFrame.asof(where)", "intent": "Return the last row ( s ) without any NaNs before `where` .", "question_id": 377},
{"snippet": "DataFrame.asof(where, subset=None)", "intent": "Return the last row ( s ) without any NaNs before `where` . In case of a DataFrame , the last row without NaN considering only the `subset` of columns ( if not None )", "question_id": 378},
{"snippet": "DataFrame.asof(where)", "intent": "Return the last row ( s ) without any NaNs before `where` .", "question_id": 379},
{"snippet": "DataFrame.asof(where, subset=None)", "intent": "Return the last row ( s ) without any NaNs before `where` . In case of a DataFrame , the last row without NaN considering only the `subset` of columns ( if not None )", "question_id": 380},
{"snippet": "DataFrame.assign(**kwargs)", "intent": "Assign new columns to a DataFrame . With arguments `**kwargs`.", "question_id": 381},
{"snippet": "DataFrame.assign(**kwargs)", "intent": "Assign new columns to a DataFrame . With arguments `**kwargs`.", "question_id": 382},
{"snippet": "DataFrame.assign(**kwargs)", "intent": "Assign new columns to a DataFrame . With arguments `**kwargs`.", "question_id": 383},
{"snippet": "DataFrame.astype(dtype)", "intent": "Cast a pandas object to a specified `dtype` dtype .", "question_id": 384},
{"snippet": "DataFrame.astype(dtype, copy=True)", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `copy`.", "question_id": 385},
{"snippet": "DataFrame.astype(dtype, errors='raise')", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `errors`.", "question_id": 386},
{"snippet": "DataFrame.astype(dtype, copy=True, errors='raise')", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `copy`, `errors`.", "question_id": 387},
{"snippet": "DataFrame.astype(dtype)", "intent": "Cast a pandas object to a specified `dtype` dtype .", "question_id": 388},
{"snippet": "DataFrame.astype(dtype, copy=True)", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `copy`.", "question_id": 389},
{"snippet": "DataFrame.astype(dtype, errors='raise')", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `errors`.", "question_id": 390},
{"snippet": "DataFrame.astype(dtype, copy=True, errors='raise')", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `copy`, `errors`.", "question_id": 391},
{"snippet": "DataFrame.astype(dtype)", "intent": "Cast a pandas object to a specified `dtype` dtype .", "question_id": 392},
{"snippet": "DataFrame.astype(dtype, copy=True)", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `copy`.", "question_id": 393},
{"snippet": "DataFrame.astype(dtype, errors='raise')", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `errors`.", "question_id": 394},
{"snippet": "DataFrame.astype(dtype, copy=True, errors='raise')", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `copy`, `errors`.", "question_id": 395},
{"snippet": "DataFrame.at_time(time)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) .", "question_id": 396},
{"snippet": "DataFrame.at_time(time, asof=False)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `asof`.", "question_id": 397},
{"snippet": "DataFrame.at_time(time, axis=None)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `axis`.", "question_id": 398},
{"snippet": "DataFrame.at_time(time, asof=False, axis=None)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `asof`, `axis`.", "question_id": 399},
{"snippet": "DataFrame.at_time(time)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) .", "question_id": 400},
{"snippet": "DataFrame.at_time(time, asof=False)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `asof`.", "question_id": 401},
{"snippet": "DataFrame.at_time(time, axis=None)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `axis`.", "question_id": 402},
{"snippet": "DataFrame.at_time(time, asof=False, axis=None)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `asof`, `axis`.", "question_id": 403},
{"snippet": "DataFrame.at_time(time)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) .", "question_id": 404},
{"snippet": "DataFrame.at_time(time, asof=False)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `asof`.", "question_id": 405},
{"snippet": "DataFrame.at_time(time, axis=None)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `axis`.", "question_id": 406},
{"snippet": "DataFrame.at_time(time, asof=False, axis=None)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `asof`, `axis`.", "question_id": 407},
{"snippet": "DataFrame.backfill()", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' .", "question_id": 408},
{"snippet": "DataFrame.backfill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`.", "question_id": 409},
{"snippet": "DataFrame.backfill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`.", "question_id": 410},
{"snippet": "DataFrame.backfill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `limit`.", "question_id": 411},
{"snippet": "DataFrame.backfill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `downcast`.", "question_id": 412},
{"snippet": "DataFrame.backfill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `inplace`.", "question_id": 413},
{"snippet": "DataFrame.backfill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `limit`.", "question_id": 414},
{"snippet": "DataFrame.backfill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `downcast`.", "question_id": 415},
{"snippet": "DataFrame.backfill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `limit`.", "question_id": 416},
{"snippet": "DataFrame.backfill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `downcast`.", "question_id": 417},
{"snippet": "DataFrame.backfill()", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' .", "question_id": 418},
{"snippet": "DataFrame.backfill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`.", "question_id": 419},
{"snippet": "DataFrame.backfill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`.", "question_id": 420},
{"snippet": "DataFrame.backfill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `limit`.", "question_id": 421},
{"snippet": "DataFrame.backfill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `downcast`.", "question_id": 422},
{"snippet": "DataFrame.backfill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `inplace`.", "question_id": 423},
{"snippet": "DataFrame.backfill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `limit`.", "question_id": 424},
{"snippet": "DataFrame.backfill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `downcast`.", "question_id": 425},
{"snippet": "DataFrame.backfill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `limit`.", "question_id": 426},
{"snippet": "DataFrame.backfill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `downcast`.", "question_id": 427},
{"snippet": "DataFrame.backfill()", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' .", "question_id": 428},
{"snippet": "DataFrame.backfill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`.", "question_id": 429},
{"snippet": "DataFrame.backfill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`.", "question_id": 430},
{"snippet": "DataFrame.backfill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `limit`.", "question_id": 431},
{"snippet": "DataFrame.backfill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `downcast`.", "question_id": 432},
{"snippet": "DataFrame.backfill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `inplace`.", "question_id": 433},
{"snippet": "DataFrame.backfill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `limit`.", "question_id": 434},
{"snippet": "DataFrame.backfill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `downcast`.", "question_id": 435},
{"snippet": "DataFrame.backfill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `limit`.", "question_id": 436},
{"snippet": "DataFrame.backfill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `downcast`.", "question_id": 437},
{"snippet": "DataFrame.between_time(start_time, end_time)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times .", "question_id": 438},
{"snippet": "DataFrame.between_time(start_time, end_time, include_start=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`.", "question_id": 439},
{"snippet": "DataFrame.between_time(start_time, end_time, include_end=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_end`.", "question_id": 440},
{"snippet": "DataFrame.between_time(start_time, end_time, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `axis`.", "question_id": 441},
{"snippet": "DataFrame.between_time(start_time, end_time, include_start=True, include_end=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `include_end`.", "question_id": 442},
{"snippet": "DataFrame.between_time(start_time, end_time, include_start=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `axis`.", "question_id": 443},
{"snippet": "DataFrame.between_time(start_time, end_time, include_end=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_end`, `axis`.", "question_id": 444},
{"snippet": "DataFrame.between_time(start_time, end_time, include_start=True, include_end=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `include_end`, `axis`.", "question_id": 445},
{"snippet": "DataFrame.between_time(start_time, end_time)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times .", "question_id": 446},
{"snippet": "DataFrame.between_time(start_time, end_time, include_start=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`.", "question_id": 447},
{"snippet": "DataFrame.between_time(start_time, end_time, include_end=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_end`.", "question_id": 448},
{"snippet": "DataFrame.between_time(start_time, end_time, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `axis`.", "question_id": 449},
{"snippet": "DataFrame.between_time(start_time, end_time, include_start=True, include_end=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `include_end`.", "question_id": 450},
{"snippet": "DataFrame.between_time(start_time, end_time, include_start=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `axis`.", "question_id": 451},
{"snippet": "DataFrame.between_time(start_time, end_time, include_end=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_end`, `axis`.", "question_id": 452},
{"snippet": "DataFrame.between_time(start_time, end_time, include_start=True, include_end=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `include_end`, `axis`.", "question_id": 453},
{"snippet": "DataFrame.between_time(start_time, end_time)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times .", "question_id": 454},
{"snippet": "DataFrame.between_time(start_time, end_time, include_start=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`.", "question_id": 455},
{"snippet": "DataFrame.between_time(start_time, end_time, include_end=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_end`.", "question_id": 456},
{"snippet": "DataFrame.between_time(start_time, end_time, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `axis`.", "question_id": 457},
{"snippet": "DataFrame.between_time(start_time, end_time, include_start=True, include_end=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `include_end`.", "question_id": 458},
{"snippet": "DataFrame.between_time(start_time, end_time, include_start=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `axis`.", "question_id": 459},
{"snippet": "DataFrame.between_time(start_time, end_time, include_end=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_end`, `axis`.", "question_id": 460},
{"snippet": "DataFrame.between_time(start_time, end_time, include_start=True, include_end=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `include_end`, `axis`.", "question_id": 461},
{"snippet": "DataFrame.bfill()", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' .", "question_id": 462},
{"snippet": "DataFrame.bfill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`.", "question_id": 463},
{"snippet": "DataFrame.bfill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`.", "question_id": 464},
{"snippet": "DataFrame.bfill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `limit`.", "question_id": 465},
{"snippet": "DataFrame.bfill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `downcast`.", "question_id": 466},
{"snippet": "DataFrame.bfill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `inplace`.", "question_id": 467},
{"snippet": "DataFrame.bfill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `limit`.", "question_id": 468},
{"snippet": "DataFrame.bfill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `downcast`.", "question_id": 469},
{"snippet": "DataFrame.bfill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `limit`.", "question_id": 470},
{"snippet": "DataFrame.bfill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `downcast`.", "question_id": 471},
{"snippet": "DataFrame.bfill()", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' .", "question_id": 472},
{"snippet": "DataFrame.bfill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`.", "question_id": 473},
{"snippet": "DataFrame.bfill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`.", "question_id": 474},
{"snippet": "DataFrame.bfill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `limit`.", "question_id": 475},
{"snippet": "DataFrame.bfill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `downcast`.", "question_id": 476},
{"snippet": "DataFrame.bfill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `inplace`.", "question_id": 477},
{"snippet": "DataFrame.bfill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `limit`.", "question_id": 478},
{"snippet": "DataFrame.bfill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `downcast`.", "question_id": 479},
{"snippet": "DataFrame.bfill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `limit`.", "question_id": 480},
{"snippet": "DataFrame.bfill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `downcast`.", "question_id": 481},
{"snippet": "DataFrame.bfill()", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' .", "question_id": 482},
{"snippet": "DataFrame.bfill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`.", "question_id": 483},
{"snippet": "DataFrame.bfill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`.", "question_id": 484},
{"snippet": "DataFrame.bfill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `limit`.", "question_id": 485},
{"snippet": "DataFrame.bfill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `downcast`.", "question_id": 486},
{"snippet": "DataFrame.bfill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `inplace`.", "question_id": 487},
{"snippet": "DataFrame.bfill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `limit`.", "question_id": 488},
{"snippet": "DataFrame.bfill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `downcast`.", "question_id": 489},
{"snippet": "DataFrame.bfill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `limit`.", "question_id": 490},
{"snippet": "DataFrame.bfill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `downcast`.", "question_id": 491},
{"snippet": "DataFrame.bool()", "intent": "Return the bool of a single element Series or DataFrame .", "question_id": 492},
{"snippet": "DataFrame.bool()", "intent": "Return the bool of a single element Series or DataFrame .", "question_id": 493},
{"snippet": "DataFrame.bool()", "intent": "Return the bool of a single element Series or DataFrame .", "question_id": 494},
{"snippet": "DataFrame.boxplot(**kwargs)", "intent": "Make a box plot from DataFrame columns . With arguments `**kwargs`.", "question_id": 495},
{"snippet": "DataFrame.boxplot(**kwargs, column=None)", "intent": "Make a box plot from DataFrame columns . Boxplots can be created for every `column` in the dataframe by df.boxplot ( ) or indicating the columns to be used : With arguments `**kwargs`.", "question_id": 496},
{"snippet": "DataFrame.boxplot(**kwargs, by=None)", "intent": "Make a box plot from DataFrame columns . Make a box-and-whisker plot from DataFrame columns , optionally grouped `by` some other columns . With arguments `**kwargs`.", "question_id": 497},
{"snippet": "DataFrame.boxplot(**kwargs, ax=None)", "intent": "Make a box plot from DataFrame columns . With arguments `**kwargs`, `ax`.", "question_id": 498},
{"snippet": "DataFrame.boxplot(**kwargs, fontsize=None)", "intent": "Make a box plot from DataFrame columns . rot=45 ) or changing the `fontsize` ( i.e . With arguments `**kwargs`.", "question_id": 499},
{"snippet": "DataFrame.boxplot(**kwargs, rot=0)", "intent": "Make a box plot from DataFrame columns . With arguments `**kwargs`, `rot`.", "question_id": 500},
{"snippet": "DataFrame.boxplot(**kwargs, grid=True)", "intent": "Make a box plot from DataFrame columns . Additional formatting can be done to the boxplot , like suppressing the `grid` ( grid=False ) , rotating the labels in the x-axis ( i.e . With arguments `**kwargs`.", "question_id": 501},
{"snippet": "DataFrame.boxplot(**kwargs, figsize=None)", "intent": "Make a box plot from DataFrame columns . With arguments `**kwargs`, `figsize`.", "question_id": 502},
{"snippet": "DataFrame.boxplot(**kwargs, layout=None)", "intent": "Make a box plot from DataFrame columns . The `layout` of boxplot can be adjusted giving a tuple to layout : With arguments `**kwargs`.", "question_id": 503},
{"snippet": "DataFrame.boxplot(**kwargs, return_type=None)", "intent": "Make a box plot from DataFrame columns . The return type depends on the `return_type` parameter : With arguments `**kwargs`.", "question_id": 504},
{"snippet": "DataFrame.boxplot(**kwargs)", "intent": "Make a box plot from DataFrame columns . With arguments `**kwargs`.", "question_id": 505},
{"snippet": "DataFrame.boxplot(**kwargs, column=None)", "intent": "Make a box plot from DataFrame columns . Boxplots can be created for every `column` in the dataframe by df.boxplot ( ) or indicating the columns to be used : With arguments `**kwargs`.", "question_id": 506},
{"snippet": "DataFrame.boxplot(**kwargs, by=None)", "intent": "Make a box plot from DataFrame columns . Make a box-and-whisker plot from DataFrame columns , optionally grouped `by` some other columns . With arguments `**kwargs`.", "question_id": 507},
{"snippet": "DataFrame.boxplot(**kwargs, ax=None)", "intent": "Make a box plot from DataFrame columns . With arguments `**kwargs`, `ax`.", "question_id": 508},
{"snippet": "DataFrame.boxplot(**kwargs, fontsize=None)", "intent": "Make a box plot from DataFrame columns . rot=45 ) or changing the `fontsize` ( i.e . With arguments `**kwargs`.", "question_id": 509},
{"snippet": "DataFrame.boxplot(**kwargs, rot=0)", "intent": "Make a box plot from DataFrame columns . With arguments `**kwargs`, `rot`.", "question_id": 510},
{"snippet": "DataFrame.boxplot(**kwargs, grid=True)", "intent": "Make a box plot from DataFrame columns . Additional formatting can be done to the boxplot , like suppressing the `grid` ( grid=False ) , rotating the labels in the x-axis ( i.e . With arguments `**kwargs`.", "question_id": 511},
{"snippet": "DataFrame.boxplot(**kwargs, figsize=None)", "intent": "Make a box plot from DataFrame columns . With arguments `**kwargs`, `figsize`.", "question_id": 512},
{"snippet": "DataFrame.boxplot(**kwargs, layout=None)", "intent": "Make a box plot from DataFrame columns . The `layout` of boxplot can be adjusted giving a tuple to layout : With arguments `**kwargs`.", "question_id": 513},
{"snippet": "DataFrame.boxplot(**kwargs, return_type=None)", "intent": "Make a box plot from DataFrame columns . The return type depends on the `return_type` parameter : With arguments `**kwargs`.", "question_id": 514},
{"snippet": "DataFrame.boxplot(**kwargs)", "intent": "Make a box plot from DataFrame columns . With arguments `**kwargs`.", "question_id": 515},
{"snippet": "DataFrame.boxplot(**kwargs, column=None)", "intent": "Make a box plot from DataFrame columns . Boxplots can be created for every `column` in the dataframe by df.boxplot ( ) or indicating the columns to be used : With arguments `**kwargs`.", "question_id": 516},
{"snippet": "DataFrame.boxplot(**kwargs, by=None)", "intent": "Make a box plot from DataFrame columns . Make a box-and-whisker plot from DataFrame columns , optionally grouped `by` some other columns . With arguments `**kwargs`.", "question_id": 517},
{"snippet": "DataFrame.boxplot(**kwargs, ax=None)", "intent": "Make a box plot from DataFrame columns . With arguments `**kwargs`, `ax`.", "question_id": 518},
{"snippet": "DataFrame.boxplot(**kwargs, fontsize=None)", "intent": "Make a box plot from DataFrame columns . rot=45 ) or changing the `fontsize` ( i.e . With arguments `**kwargs`.", "question_id": 519},
{"snippet": "DataFrame.boxplot(**kwargs, rot=0)", "intent": "Make a box plot from DataFrame columns . With arguments `**kwargs`, `rot`.", "question_id": 520},
{"snippet": "DataFrame.boxplot(**kwargs, grid=True)", "intent": "Make a box plot from DataFrame columns . Additional formatting can be done to the boxplot , like suppressing the `grid` ( grid=False ) , rotating the labels in the x-axis ( i.e . With arguments `**kwargs`.", "question_id": 521},
{"snippet": "DataFrame.boxplot(**kwargs, figsize=None)", "intent": "Make a box plot from DataFrame columns . With arguments `**kwargs`, `figsize`.", "question_id": 522},
{"snippet": "DataFrame.boxplot(**kwargs, layout=None)", "intent": "Make a box plot from DataFrame columns . The `layout` of boxplot can be adjusted giving a tuple to layout : With arguments `**kwargs`.", "question_id": 523},
{"snippet": "DataFrame.boxplot(**kwargs, return_type=None)", "intent": "Make a box plot from DataFrame columns . The return type depends on the `return_type` parameter : With arguments `**kwargs`.", "question_id": 524},
{"snippet": "DataFrame.clip(*args, **kwargs)", "intent": "Trim values at input threshold ( s ) . With arguments `*args`, `**kwargs`.", "question_id": 525},
{"snippet": "DataFrame.clip(*args, **kwargs, lower=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 526},
{"snippet": "DataFrame.clip(*args, **kwargs, upper=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 527},
{"snippet": "DataFrame.clip(*args, **kwargs, axis=None)", "intent": "Trim values at input threshold ( s ) . Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 528},
{"snippet": "DataFrame.clip(*args, **kwargs, inplace=False)", "intent": "Trim values at input threshold ( s ) . With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 529},
{"snippet": "DataFrame.clip(*args, **kwargs, lower=None, upper=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 530},
{"snippet": "DataFrame.clip(*args, **kwargs, lower=None, axis=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 531},
{"snippet": "DataFrame.clip(*args, **kwargs, lower=None, inplace=False)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 532},
{"snippet": "DataFrame.clip(*args, **kwargs, upper=None, axis=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 533},
{"snippet": "DataFrame.clip(*args, **kwargs, upper=None, inplace=False)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 534},
{"snippet": "DataFrame.clip(*args, **kwargs)", "intent": "Trim values at input threshold ( s ) . With arguments `*args`, `**kwargs`.", "question_id": 535},
{"snippet": "DataFrame.clip(*args, **kwargs, lower=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 536},
{"snippet": "DataFrame.clip(*args, **kwargs, upper=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 537},
{"snippet": "DataFrame.clip(*args, **kwargs, axis=None)", "intent": "Trim values at input threshold ( s ) . Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 538},
{"snippet": "DataFrame.clip(*args, **kwargs, inplace=False)", "intent": "Trim values at input threshold ( s ) . With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 539},
{"snippet": "DataFrame.clip(*args, **kwargs, lower=None, upper=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 540},
{"snippet": "DataFrame.clip(*args, **kwargs, lower=None, axis=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 541},
{"snippet": "DataFrame.clip(*args, **kwargs, lower=None, inplace=False)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 542},
{"snippet": "DataFrame.clip(*args, **kwargs, upper=None, axis=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 543},
{"snippet": "DataFrame.clip(*args, **kwargs, upper=None, inplace=False)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 544},
{"snippet": "DataFrame.clip(*args, **kwargs)", "intent": "Trim values at input threshold ( s ) . With arguments `*args`, `**kwargs`.", "question_id": 545},
{"snippet": "DataFrame.clip(*args, **kwargs, lower=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 546},
{"snippet": "DataFrame.clip(*args, **kwargs, upper=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 547},
{"snippet": "DataFrame.clip(*args, **kwargs, axis=None)", "intent": "Trim values at input threshold ( s ) . Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 548},
{"snippet": "DataFrame.clip(*args, **kwargs, inplace=False)", "intent": "Trim values at input threshold ( s ) . With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 549},
{"snippet": "DataFrame.clip(*args, **kwargs, lower=None, upper=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 550},
{"snippet": "DataFrame.clip(*args, **kwargs, lower=None, axis=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 551},
{"snippet": "DataFrame.clip(*args, **kwargs, lower=None, inplace=False)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 552},
{"snippet": "DataFrame.clip(*args, **kwargs, upper=None, axis=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 553},
{"snippet": "DataFrame.clip(*args, **kwargs, upper=None, inplace=False)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 554},
{"snippet": "DataFrame.columns", "intent": "The column labels of the DataFrame.", "question_id": 555},
{"snippet": "DataFrame.columns", "intent": "The column labels of the DataFrame.", "question_id": 556},
{"snippet": "DataFrame.columns", "intent": "The column labels of the DataFrame.", "question_id": 557},
{"snippet": "DataFrame.combine(other, func)", "intent": "Perform column-wise combine with another DataFrame . Combines a DataFrame with `other` DataFrame using `func` to element-wise combine columns .", "question_id": 558},
{"snippet": "DataFrame.combine(other, func, fill_value=None)", "intent": "Perform column-wise combine with another DataFrame . Combines a DataFrame with `other` DataFrame using `func` to element-wise combine columns . Using `fill_value` fills Nones prior to passing the column to the merge function .", "question_id": 559},
{"snippet": "DataFrame.combine(other, func, overwrite=True)", "intent": "Perform column-wise combine with another DataFrame . Combines a DataFrame with `other` DataFrame using `func` to element-wise combine columns . Example that demonstrates the use of `overwrite` and behavior when the axis differ between the dataframes .", "question_id": 560},
{"snippet": "DataFrame.combine(other, func, fill_value=None, overwrite=True)", "intent": "Perform column-wise combine with another DataFrame . Combines a DataFrame with `other` DataFrame using `func` to element-wise combine columns . Using `fill_value` fills Nones prior to passing the column to the merge function . Example that demonstrates the use of `overwrite` and behavior when the axis differ between the dataframes .", "question_id": 561},
{"snippet": "DataFrame.combine(other, func)", "intent": "Perform column-wise combine with another DataFrame . Combines a DataFrame with `other` DataFrame using `func` to element-wise combine columns .", "question_id": 562},
{"snippet": "DataFrame.combine(other, func, fill_value=None)", "intent": "Perform column-wise combine with another DataFrame . Combines a DataFrame with `other` DataFrame using `func` to element-wise combine columns . Using `fill_value` fills Nones prior to passing the column to the merge function .", "question_id": 563},
{"snippet": "DataFrame.combine(other, func, overwrite=True)", "intent": "Perform column-wise combine with another DataFrame . Combines a DataFrame with `other` DataFrame using `func` to element-wise combine columns . Example that demonstrates the use of `overwrite` and behavior when the axis differ between the dataframes .", "question_id": 564},
{"snippet": "DataFrame.combine(other, func, fill_value=None, overwrite=True)", "intent": "Perform column-wise combine with another DataFrame . Combines a DataFrame with `other` DataFrame using `func` to element-wise combine columns . Using `fill_value` fills Nones prior to passing the column to the merge function . Example that demonstrates the use of `overwrite` and behavior when the axis differ between the dataframes .", "question_id": 565},
{"snippet": "DataFrame.combine(other, func)", "intent": "Perform column-wise combine with another DataFrame . Combines a DataFrame with `other` DataFrame using `func` to element-wise combine columns .", "question_id": 566},
{"snippet": "DataFrame.combine(other, func, fill_value=None)", "intent": "Perform column-wise combine with another DataFrame . Combines a DataFrame with `other` DataFrame using `func` to element-wise combine columns . Using `fill_value` fills Nones prior to passing the column to the merge function .", "question_id": 567},
{"snippet": "DataFrame.combine(other, func, overwrite=True)", "intent": "Perform column-wise combine with another DataFrame . Combines a DataFrame with `other` DataFrame using `func` to element-wise combine columns . Example that demonstrates the use of `overwrite` and behavior when the axis differ between the dataframes .", "question_id": 568},
{"snippet": "DataFrame.combine(other, func, fill_value=None, overwrite=True)", "intent": "Perform column-wise combine with another DataFrame . Combines a DataFrame with `other` DataFrame using `func` to element-wise combine columns . Using `fill_value` fills Nones prior to passing the column to the merge function . Example that demonstrates the use of `overwrite` and behavior when the axis differ between the dataframes .", "question_id": 569},
{"snippet": "DataFrame.combine_first(other)", "intent": "Update null elements with value in the same location in `other` .", "question_id": 570},
{"snippet": "DataFrame.combine_first(other)", "intent": "Update null elements with value in the same location in `other` .", "question_id": 571},
{"snippet": "DataFrame.combine_first(other)", "intent": "Update null elements with value in the same location in `other` .", "question_id": 572},
{"snippet": "DataFrame.compare(other)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`.", "question_id": 573},
{"snippet": "DataFrame.compare(other, align_axis=1)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `align_axis`.", "question_id": 574},
{"snippet": "DataFrame.compare(other, keep_shape=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `keep_shape`.", "question_id": 575},
{"snippet": "DataFrame.compare(other, keep_equal=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `keep_equal`.", "question_id": 576},
{"snippet": "DataFrame.compare(other, align_axis=1, keep_shape=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `align_axis`, `keep_shape`.", "question_id": 577},
{"snippet": "DataFrame.compare(other, align_axis=1, keep_equal=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `align_axis`, `keep_equal`.", "question_id": 578},
{"snippet": "DataFrame.compare(other, keep_shape=False, keep_equal=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `keep_shape`, `keep_equal`.", "question_id": 579},
{"snippet": "DataFrame.compare(other, align_axis=1, keep_shape=False, keep_equal=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `align_axis`, `keep_shape`, `keep_equal`.", "question_id": 580},
{"snippet": "DataFrame.compare(other)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`.", "question_id": 581},
{"snippet": "DataFrame.compare(other, align_axis=1)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `align_axis`.", "question_id": 582},
{"snippet": "DataFrame.compare(other, keep_shape=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `keep_shape`.", "question_id": 583},
{"snippet": "DataFrame.compare(other, keep_equal=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `keep_equal`.", "question_id": 584},
{"snippet": "DataFrame.compare(other, align_axis=1, keep_shape=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `align_axis`, `keep_shape`.", "question_id": 585},
{"snippet": "DataFrame.compare(other, align_axis=1, keep_equal=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `align_axis`, `keep_equal`.", "question_id": 586},
{"snippet": "DataFrame.compare(other, keep_shape=False, keep_equal=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `keep_shape`, `keep_equal`.", "question_id": 587},
{"snippet": "DataFrame.compare(other, align_axis=1, keep_shape=False, keep_equal=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `align_axis`, `keep_shape`, `keep_equal`.", "question_id": 588},
{"snippet": "DataFrame.compare(other)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`.", "question_id": 589},
{"snippet": "DataFrame.compare(other, align_axis=1)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `align_axis`.", "question_id": 590},
{"snippet": "DataFrame.compare(other, keep_shape=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `keep_shape`.", "question_id": 591},
{"snippet": "DataFrame.compare(other, keep_equal=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `keep_equal`.", "question_id": 592},
{"snippet": "DataFrame.compare(other, align_axis=1, keep_shape=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `align_axis`, `keep_shape`.", "question_id": 593},
{"snippet": "DataFrame.compare(other, align_axis=1, keep_equal=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `align_axis`, `keep_equal`.", "question_id": 594},
{"snippet": "DataFrame.compare(other, keep_shape=False, keep_equal=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `keep_shape`, `keep_equal`.", "question_id": 595},
{"snippet": "DataFrame.compare(other, align_axis=1, keep_shape=False, keep_equal=False)", "intent": "Compare to another DataFrame and show the differences . With arguments `other`, `align_axis`, `keep_shape`, `keep_equal`.", "question_id": 596},
{"snippet": "DataFrame.convert_dtypes()", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA .", "question_id": 597},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction .", "question_id": 598},
{"snippet": "DataFrame.convert_dtypes(convert_string=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 599},
{"snippet": "DataFrame.convert_dtypes(convert_integer=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 600},
{"snippet": "DataFrame.convert_dtypes(convert_boolean=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 601},
{"snippet": "DataFrame.convert_dtypes(convert_floating=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . With arguments `convert_floating`.", "question_id": 602},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True, convert_string=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 603},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True, convert_integer=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 604},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True, convert_boolean=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 605},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True, convert_floating=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . With arguments `convert_floating`.", "question_id": 606},
{"snippet": "DataFrame.convert_dtypes()", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA .", "question_id": 607},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction .", "question_id": 608},
{"snippet": "DataFrame.convert_dtypes(convert_string=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 609},
{"snippet": "DataFrame.convert_dtypes(convert_integer=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 610},
{"snippet": "DataFrame.convert_dtypes(convert_boolean=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 611},
{"snippet": "DataFrame.convert_dtypes(convert_floating=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . With arguments `convert_floating`.", "question_id": 612},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True, convert_string=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 613},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True, convert_integer=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 614},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True, convert_boolean=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 615},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True, convert_floating=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . With arguments `convert_floating`.", "question_id": 616},
{"snippet": "DataFrame.convert_dtypes()", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA .", "question_id": 617},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction .", "question_id": 618},
{"snippet": "DataFrame.convert_dtypes(convert_string=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 619},
{"snippet": "DataFrame.convert_dtypes(convert_integer=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 620},
{"snippet": "DataFrame.convert_dtypes(convert_boolean=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 621},
{"snippet": "DataFrame.convert_dtypes(convert_floating=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . With arguments `convert_floating`.", "question_id": 622},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True, convert_string=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 623},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True, convert_integer=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 624},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True, convert_boolean=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 625},
{"snippet": "DataFrame.convert_dtypes(infer_objects=True, convert_floating=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . With arguments `convert_floating`.", "question_id": 626},
{"snippet": "DataFrame.copy()", "intent": "Make a copy of this object \u2019 s indices and data .", "question_id": 627},
{"snippet": "DataFrame.copy(deep=True)", "intent": "Make a copy of this object \u2019 s indices and data . Shallow copy versus default ( `deep` ) copy :", "question_id": 628},
{"snippet": "DataFrame.copy()", "intent": "Make a copy of this object \u2019 s indices and data .", "question_id": 629},
{"snippet": "DataFrame.copy(deep=True)", "intent": "Make a copy of this object \u2019 s indices and data . Shallow copy versus default ( `deep` ) copy :", "question_id": 630},
{"snippet": "DataFrame.copy()", "intent": "Make a copy of this object \u2019 s indices and data .", "question_id": 631},
{"snippet": "DataFrame.copy(deep=True)", "intent": "Make a copy of this object \u2019 s indices and data . Shallow copy versus default ( `deep` ) copy :", "question_id": 632},
{"snippet": "DataFrame.corr()", "intent": "Compute pairwise correlation of columns , excluding NA/null values .", "question_id": 633},
{"snippet": "DataFrame.corr(method='pearson')", "intent": "Compute pairwise correlation of columns , excluding NA/null values . With arguments `method`.", "question_id": 634},
{"snippet": "DataFrame.corr(min_periods=1)", "intent": "Compute pairwise correlation of columns , excluding NA/null values . With arguments `min_periods`.", "question_id": 635},
{"snippet": "DataFrame.corr(method='pearson', min_periods=1)", "intent": "Compute pairwise correlation of columns , excluding NA/null values . With arguments `method`, `min_periods`.", "question_id": 636},
{"snippet": "DataFrame.corr()", "intent": "Compute pairwise correlation of columns , excluding NA/null values .", "question_id": 637},
{"snippet": "DataFrame.corr(method='pearson')", "intent": "Compute pairwise correlation of columns , excluding NA/null values . With arguments `method`.", "question_id": 638},
{"snippet": "DataFrame.corr(min_periods=1)", "intent": "Compute pairwise correlation of columns , excluding NA/null values . With arguments `min_periods`.", "question_id": 639},
{"snippet": "DataFrame.corr(method='pearson', min_periods=1)", "intent": "Compute pairwise correlation of columns , excluding NA/null values . With arguments `method`, `min_periods`.", "question_id": 640},
{"snippet": "DataFrame.corr()", "intent": "Compute pairwise correlation of columns , excluding NA/null values .", "question_id": 641},
{"snippet": "DataFrame.corr(method='pearson')", "intent": "Compute pairwise correlation of columns , excluding NA/null values . With arguments `method`.", "question_id": 642},
{"snippet": "DataFrame.corr(min_periods=1)", "intent": "Compute pairwise correlation of columns , excluding NA/null values . With arguments `min_periods`.", "question_id": 643},
{"snippet": "DataFrame.corr(method='pearson', min_periods=1)", "intent": "Compute pairwise correlation of columns , excluding NA/null values . With arguments `method`, `min_periods`.", "question_id": 644},
{"snippet": "DataFrame.corrwith(other)", "intent": "Compute pairwise correlation . With arguments `other`.", "question_id": 645},
{"snippet": "DataFrame.corrwith(other, axis=0)", "intent": "Compute pairwise correlation . With arguments `other`, `axis`.", "question_id": 646},
{"snippet": "DataFrame.corrwith(other, drop=False)", "intent": "Compute pairwise correlation . With arguments `other`, `drop`.", "question_id": 647},
{"snippet": "DataFrame.corrwith(other, method='pearson')", "intent": "Compute pairwise correlation . With arguments `other`, `method`.", "question_id": 648},
{"snippet": "DataFrame.corrwith(other, axis=0, drop=False)", "intent": "Compute pairwise correlation . With arguments `other`, `axis`, `drop`.", "question_id": 649},
{"snippet": "DataFrame.corrwith(other, axis=0, method='pearson')", "intent": "Compute pairwise correlation . With arguments `other`, `axis`, `method`.", "question_id": 650},
{"snippet": "DataFrame.corrwith(other, drop=False, method='pearson')", "intent": "Compute pairwise correlation . With arguments `other`, `drop`, `method`.", "question_id": 651},
{"snippet": "DataFrame.corrwith(other, axis=0, drop=False, method='pearson')", "intent": "Compute pairwise correlation . With arguments `other`, `axis`, `drop`, `method`.", "question_id": 652},
{"snippet": "DataFrame.corrwith(other)", "intent": "Compute pairwise correlation . With arguments `other`.", "question_id": 653},
{"snippet": "DataFrame.corrwith(other, axis=0)", "intent": "Compute pairwise correlation . With arguments `other`, `axis`.", "question_id": 654},
{"snippet": "DataFrame.corrwith(other, drop=False)", "intent": "Compute pairwise correlation . With arguments `other`, `drop`.", "question_id": 655},
{"snippet": "DataFrame.corrwith(other, method='pearson')", "intent": "Compute pairwise correlation . With arguments `other`, `method`.", "question_id": 656},
{"snippet": "DataFrame.corrwith(other, axis=0, drop=False)", "intent": "Compute pairwise correlation . With arguments `other`, `axis`, `drop`.", "question_id": 657},
{"snippet": "DataFrame.corrwith(other, axis=0, method='pearson')", "intent": "Compute pairwise correlation . With arguments `other`, `axis`, `method`.", "question_id": 658},
{"snippet": "DataFrame.corrwith(other, drop=False, method='pearson')", "intent": "Compute pairwise correlation . With arguments `other`, `drop`, `method`.", "question_id": 659},
{"snippet": "DataFrame.corrwith(other, axis=0, drop=False, method='pearson')", "intent": "Compute pairwise correlation . With arguments `other`, `axis`, `drop`, `method`.", "question_id": 660},
{"snippet": "DataFrame.corrwith(other)", "intent": "Compute pairwise correlation . With arguments `other`.", "question_id": 661},
{"snippet": "DataFrame.corrwith(other, axis=0)", "intent": "Compute pairwise correlation . With arguments `other`, `axis`.", "question_id": 662},
{"snippet": "DataFrame.corrwith(other, drop=False)", "intent": "Compute pairwise correlation . With arguments `other`, `drop`.", "question_id": 663},
{"snippet": "DataFrame.corrwith(other, method='pearson')", "intent": "Compute pairwise correlation . With arguments `other`, `method`.", "question_id": 664},
{"snippet": "DataFrame.corrwith(other, axis=0, drop=False)", "intent": "Compute pairwise correlation . With arguments `other`, `axis`, `drop`.", "question_id": 665},
{"snippet": "DataFrame.corrwith(other, axis=0, method='pearson')", "intent": "Compute pairwise correlation . With arguments `other`, `axis`, `method`.", "question_id": 666},
{"snippet": "DataFrame.corrwith(other, drop=False, method='pearson')", "intent": "Compute pairwise correlation . With arguments `other`, `drop`, `method`.", "question_id": 667},
{"snippet": "DataFrame.corrwith(other, axis=0, drop=False, method='pearson')", "intent": "Compute pairwise correlation . With arguments `other`, `axis`, `drop`, `method`.", "question_id": 668},
{"snippet": "DataFrame.count()", "intent": "Count non-NA cells for each column or row .", "question_id": 669},
{"snippet": "DataFrame.count(axis=0)", "intent": "Count non-NA cells for each column or row . With arguments `axis`.", "question_id": 670},
{"snippet": "DataFrame.count(level=None)", "intent": "Count non-NA cells for each column or row . With arguments `level`.", "question_id": 671},
{"snippet": "DataFrame.count(numeric_only=False)", "intent": "Count non-NA cells for each column or row . With arguments `numeric_only`.", "question_id": 672},
{"snippet": "DataFrame.count(axis=0, level=None)", "intent": "Count non-NA cells for each column or row . With arguments `axis`, `level`.", "question_id": 673},
{"snippet": "DataFrame.count(axis=0, numeric_only=False)", "intent": "Count non-NA cells for each column or row . With arguments `axis`, `numeric_only`.", "question_id": 674},
{"snippet": "DataFrame.count(level=None, numeric_only=False)", "intent": "Count non-NA cells for each column or row . With arguments `level`, `numeric_only`.", "question_id": 675},
{"snippet": "DataFrame.count(axis=0, level=None, numeric_only=False)", "intent": "Count non-NA cells for each column or row . With arguments `axis`, `level`, `numeric_only`.", "question_id": 676},
{"snippet": "DataFrame.count()", "intent": "Count non-NA cells for each column or row .", "question_id": 677},
{"snippet": "DataFrame.count(axis=0)", "intent": "Count non-NA cells for each column or row . With arguments `axis`.", "question_id": 678},
{"snippet": "DataFrame.count(level=None)", "intent": "Count non-NA cells for each column or row . With arguments `level`.", "question_id": 679},
{"snippet": "DataFrame.count(numeric_only=False)", "intent": "Count non-NA cells for each column or row . With arguments `numeric_only`.", "question_id": 680},
{"snippet": "DataFrame.count(axis=0, level=None)", "intent": "Count non-NA cells for each column or row . With arguments `axis`, `level`.", "question_id": 681},
{"snippet": "DataFrame.count(axis=0, numeric_only=False)", "intent": "Count non-NA cells for each column or row . With arguments `axis`, `numeric_only`.", "question_id": 682},
{"snippet": "DataFrame.count(level=None, numeric_only=False)", "intent": "Count non-NA cells for each column or row . With arguments `level`, `numeric_only`.", "question_id": 683},
{"snippet": "DataFrame.count(axis=0, level=None, numeric_only=False)", "intent": "Count non-NA cells for each column or row . With arguments `axis`, `level`, `numeric_only`.", "question_id": 684},
{"snippet": "DataFrame.count()", "intent": "Count non-NA cells for each column or row .", "question_id": 685},
{"snippet": "DataFrame.count(axis=0)", "intent": "Count non-NA cells for each column or row . With arguments `axis`.", "question_id": 686},
{"snippet": "DataFrame.count(level=None)", "intent": "Count non-NA cells for each column or row . With arguments `level`.", "question_id": 687},
{"snippet": "DataFrame.count(numeric_only=False)", "intent": "Count non-NA cells for each column or row . With arguments `numeric_only`.", "question_id": 688},
{"snippet": "DataFrame.count(axis=0, level=None)", "intent": "Count non-NA cells for each column or row . With arguments `axis`, `level`.", "question_id": 689},
{"snippet": "DataFrame.count(axis=0, numeric_only=False)", "intent": "Count non-NA cells for each column or row . With arguments `axis`, `numeric_only`.", "question_id": 690},
{"snippet": "DataFrame.count(level=None, numeric_only=False)", "intent": "Count non-NA cells for each column or row . With arguments `level`, `numeric_only`.", "question_id": 691},
{"snippet": "DataFrame.count(axis=0, level=None, numeric_only=False)", "intent": "Count non-NA cells for each column or row . With arguments `axis`, `level`, `numeric_only`.", "question_id": 692},
{"snippet": "DataFrame.cov()", "intent": "Compute pairwise covariance of columns , excluding NA/null values .", "question_id": 693},
{"snippet": "DataFrame.cov(min_periods=None)", "intent": "Compute pairwise covariance of columns , excluding NA/null values . This method also supports an optional `min_periods` keyword that specifies the required minimum number of non-NA observations for each column pair in order to have a valid result :", "question_id": 694},
{"snippet": "DataFrame.cov(ddof=1)", "intent": "Compute pairwise covariance of columns , excluding NA/null values . With arguments `ddof`.", "question_id": 695},
{"snippet": "DataFrame.cov(min_periods=None, ddof=1)", "intent": "Compute pairwise covariance of columns , excluding NA/null values . This method also supports an optional `min_periods` keyword that specifies the required minimum number of non-NA observations for each column pair in order to have a valid result : With arguments `ddof`.", "question_id": 696},
{"snippet": "DataFrame.cov()", "intent": "Compute pairwise covariance of columns , excluding NA/null values .", "question_id": 697},
{"snippet": "DataFrame.cov(min_periods=None)", "intent": "Compute pairwise covariance of columns , excluding NA/null values . This method also supports an optional `min_periods` keyword that specifies the required minimum number of non-NA observations for each column pair in order to have a valid result :", "question_id": 698},
{"snippet": "DataFrame.cov(ddof=1)", "intent": "Compute pairwise covariance of columns , excluding NA/null values . With arguments `ddof`.", "question_id": 699},
{"snippet": "DataFrame.cov(min_periods=None, ddof=1)", "intent": "Compute pairwise covariance of columns , excluding NA/null values . This method also supports an optional `min_periods` keyword that specifies the required minimum number of non-NA observations for each column pair in order to have a valid result : With arguments `ddof`.", "question_id": 700},
{"snippet": "DataFrame.cov()", "intent": "Compute pairwise covariance of columns , excluding NA/null values .", "question_id": 701},
{"snippet": "DataFrame.cov(min_periods=None)", "intent": "Compute pairwise covariance of columns , excluding NA/null values . This method also supports an optional `min_periods` keyword that specifies the required minimum number of non-NA observations for each column pair in order to have a valid result :", "question_id": 702},
{"snippet": "DataFrame.cov(ddof=1)", "intent": "Compute pairwise covariance of columns , excluding NA/null values . With arguments `ddof`.", "question_id": 703},
{"snippet": "DataFrame.cov(min_periods=None, ddof=1)", "intent": "Compute pairwise covariance of columns , excluding NA/null values . This method also supports an optional `min_periods` keyword that specifies the required minimum number of non-NA observations for each column pair in order to have a valid result : With arguments `ddof`.", "question_id": 704},
{"snippet": "DataFrame.cummax(*args, **kwargs)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 705},
{"snippet": "DataFrame.cummax(*args, **kwargs, axis=None)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 706},
{"snippet": "DataFrame.cummax(*args, **kwargs, skipna=True)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 707},
{"snippet": "DataFrame.cummax(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 708},
{"snippet": "DataFrame.cummax(*args, **kwargs)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 709},
{"snippet": "DataFrame.cummax(*args, **kwargs, axis=None)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 710},
{"snippet": "DataFrame.cummax(*args, **kwargs, skipna=True)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 711},
{"snippet": "DataFrame.cummax(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 712},
{"snippet": "DataFrame.cummax(*args, **kwargs)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 713},
{"snippet": "DataFrame.cummax(*args, **kwargs, axis=None)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 714},
{"snippet": "DataFrame.cummax(*args, **kwargs, skipna=True)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 715},
{"snippet": "DataFrame.cummax(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 716},
{"snippet": "DataFrame.cummin(*args, **kwargs)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 717},
{"snippet": "DataFrame.cummin(*args, **kwargs, axis=None)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 718},
{"snippet": "DataFrame.cummin(*args, **kwargs, skipna=True)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 719},
{"snippet": "DataFrame.cummin(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 720},
{"snippet": "DataFrame.cummin(*args, **kwargs)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 721},
{"snippet": "DataFrame.cummin(*args, **kwargs, axis=None)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 722},
{"snippet": "DataFrame.cummin(*args, **kwargs, skipna=True)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 723},
{"snippet": "DataFrame.cummin(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 724},
{"snippet": "DataFrame.cummin(*args, **kwargs)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 725},
{"snippet": "DataFrame.cummin(*args, **kwargs, axis=None)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 726},
{"snippet": "DataFrame.cummin(*args, **kwargs, skipna=True)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 727},
{"snippet": "DataFrame.cummin(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 728},
{"snippet": "DataFrame.cumprod(*args, **kwargs)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 729},
{"snippet": "DataFrame.cumprod(*args, **kwargs, axis=None)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 730},
{"snippet": "DataFrame.cumprod(*args, **kwargs, skipna=True)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 731},
{"snippet": "DataFrame.cumprod(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 732},
{"snippet": "DataFrame.cumprod(*args, **kwargs)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 733},
{"snippet": "DataFrame.cumprod(*args, **kwargs, axis=None)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 734},
{"snippet": "DataFrame.cumprod(*args, **kwargs, skipna=True)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 735},
{"snippet": "DataFrame.cumprod(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 736},
{"snippet": "DataFrame.cumprod(*args, **kwargs)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 737},
{"snippet": "DataFrame.cumprod(*args, **kwargs, axis=None)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 738},
{"snippet": "DataFrame.cumprod(*args, **kwargs, skipna=True)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 739},
{"snippet": "DataFrame.cumprod(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 740},
{"snippet": "DataFrame.cumsum(*args, **kwargs)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 741},
{"snippet": "DataFrame.cumsum(*args, **kwargs, axis=None)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 742},
{"snippet": "DataFrame.cumsum(*args, **kwargs, skipna=True)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 743},
{"snippet": "DataFrame.cumsum(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 744},
{"snippet": "DataFrame.cumsum(*args, **kwargs)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 745},
{"snippet": "DataFrame.cumsum(*args, **kwargs, axis=None)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 746},
{"snippet": "DataFrame.cumsum(*args, **kwargs, skipna=True)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 747},
{"snippet": "DataFrame.cumsum(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 748},
{"snippet": "DataFrame.cumsum(*args, **kwargs)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 749},
{"snippet": "DataFrame.cumsum(*args, **kwargs, axis=None)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 750},
{"snippet": "DataFrame.cumsum(*args, **kwargs, skipna=True)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 751},
{"snippet": "DataFrame.cumsum(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 752},
{"snippet": "DataFrame.describe()", "intent": "Generate descriptive statistics .", "question_id": 753},
{"snippet": "DataFrame.describe(percentiles=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` .", "question_id": 754},
{"snippet": "DataFrame.describe(include=None)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values .", "question_id": 755},
{"snippet": "DataFrame.describe(exclude=None)", "intent": "Generate descriptive statistics . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 756},
{"snippet": "DataFrame.describe(datetime_is_numeric=False)", "intent": "Generate descriptive statistics . With arguments `datetime_is_numeric`.", "question_id": 757},
{"snippet": "DataFrame.describe(percentiles=None, include=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values .", "question_id": 758},
{"snippet": "DataFrame.describe(percentiles=None, exclude=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 759},
{"snippet": "DataFrame.describe(percentiles=None, datetime_is_numeric=False)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . With arguments `datetime_is_numeric`.", "question_id": 760},
{"snippet": "DataFrame.describe(include=None, exclude=None)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 761},
{"snippet": "DataFrame.describe(include=None, datetime_is_numeric=False)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values . With arguments `datetime_is_numeric`.", "question_id": 762},
{"snippet": "DataFrame.describe()", "intent": "Generate descriptive statistics .", "question_id": 763},
{"snippet": "DataFrame.describe(percentiles=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` .", "question_id": 764},
{"snippet": "DataFrame.describe(include=None)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values .", "question_id": 765},
{"snippet": "DataFrame.describe(exclude=None)", "intent": "Generate descriptive statistics . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 766},
{"snippet": "DataFrame.describe(datetime_is_numeric=False)", "intent": "Generate descriptive statistics . With arguments `datetime_is_numeric`.", "question_id": 767},
{"snippet": "DataFrame.describe(percentiles=None, include=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values .", "question_id": 768},
{"snippet": "DataFrame.describe(percentiles=None, exclude=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 769},
{"snippet": "DataFrame.describe(percentiles=None, datetime_is_numeric=False)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . With arguments `datetime_is_numeric`.", "question_id": 770},
{"snippet": "DataFrame.describe(include=None, exclude=None)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 771},
{"snippet": "DataFrame.describe(include=None, datetime_is_numeric=False)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values . With arguments `datetime_is_numeric`.", "question_id": 772},
{"snippet": "DataFrame.describe()", "intent": "Generate descriptive statistics .", "question_id": 773},
{"snippet": "DataFrame.describe(percentiles=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` .", "question_id": 774},
{"snippet": "DataFrame.describe(include=None)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values .", "question_id": 775},
{"snippet": "DataFrame.describe(exclude=None)", "intent": "Generate descriptive statistics . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 776},
{"snippet": "DataFrame.describe(datetime_is_numeric=False)", "intent": "Generate descriptive statistics . With arguments `datetime_is_numeric`.", "question_id": 777},
{"snippet": "DataFrame.describe(percentiles=None, include=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values .", "question_id": 778},
{"snippet": "DataFrame.describe(percentiles=None, exclude=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 779},
{"snippet": "DataFrame.describe(percentiles=None, datetime_is_numeric=False)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . With arguments `datetime_is_numeric`.", "question_id": 780},
{"snippet": "DataFrame.describe(include=None, exclude=None)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 781},
{"snippet": "DataFrame.describe(include=None, datetime_is_numeric=False)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values . With arguments `datetime_is_numeric`.", "question_id": 782},
{"snippet": "DataFrame.diff()", "intent": "First discrete difference of element .", "question_id": 783},
{"snippet": "DataFrame.diff(periods=1)", "intent": "First discrete difference of element . With arguments `periods`.", "question_id": 784},
{"snippet": "DataFrame.diff(axis=0)", "intent": "First discrete difference of element . With arguments `axis`.", "question_id": 785},
{"snippet": "DataFrame.diff(periods=1, axis=0)", "intent": "First discrete difference of element . With arguments `periods`, `axis`.", "question_id": 786},
{"snippet": "DataFrame.diff()", "intent": "First discrete difference of element .", "question_id": 787},
{"snippet": "DataFrame.diff(periods=1)", "intent": "First discrete difference of element . With arguments `periods`.", "question_id": 788},
{"snippet": "DataFrame.diff(axis=0)", "intent": "First discrete difference of element . With arguments `axis`.", "question_id": 789},
{"snippet": "DataFrame.diff(periods=1, axis=0)", "intent": "First discrete difference of element . With arguments `periods`, `axis`.", "question_id": 790},
{"snippet": "DataFrame.diff()", "intent": "First discrete difference of element .", "question_id": 791},
{"snippet": "DataFrame.diff(periods=1)", "intent": "First discrete difference of element . With arguments `periods`.", "question_id": 792},
{"snippet": "DataFrame.diff(axis=0)", "intent": "First discrete difference of element . With arguments `axis`.", "question_id": 793},
{"snippet": "DataFrame.diff(periods=1, axis=0)", "intent": "First discrete difference of element . With arguments `periods`, `axis`.", "question_id": 794},
{"snippet": "DataFrame.div(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) .", "question_id": 795},
{"snippet": "DataFrame.div(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 796},
{"snippet": "DataFrame.div(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` .", "question_id": 797},
{"snippet": "DataFrame.div(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 798},
{"snippet": "DataFrame.div(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 799},
{"snippet": "DataFrame.div(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 800},
{"snippet": "DataFrame.div(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 801},
{"snippet": "DataFrame.div(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 802},
{"snippet": "DataFrame.div(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) .", "question_id": 803},
{"snippet": "DataFrame.div(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 804},
{"snippet": "DataFrame.div(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` .", "question_id": 805},
{"snippet": "DataFrame.div(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 806},
{"snippet": "DataFrame.div(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 807},
{"snippet": "DataFrame.div(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 808},
{"snippet": "DataFrame.div(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 809},
{"snippet": "DataFrame.div(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 810},
{"snippet": "DataFrame.div(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) .", "question_id": 811},
{"snippet": "DataFrame.div(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 812},
{"snippet": "DataFrame.div(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` .", "question_id": 813},
{"snippet": "DataFrame.div(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 814},
{"snippet": "DataFrame.div(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 815},
{"snippet": "DataFrame.div(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 816},
{"snippet": "DataFrame.div(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 817},
{"snippet": "DataFrame.div(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 818},
{"snippet": "DataFrame.divide(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) .", "question_id": 819},
{"snippet": "DataFrame.divide(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 820},
{"snippet": "DataFrame.divide(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` .", "question_id": 821},
{"snippet": "DataFrame.divide(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 822},
{"snippet": "DataFrame.divide(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 823},
{"snippet": "DataFrame.divide(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 824},
{"snippet": "DataFrame.divide(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 825},
{"snippet": "DataFrame.divide(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 826},
{"snippet": "DataFrame.divide(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) .", "question_id": 827},
{"snippet": "DataFrame.divide(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 828},
{"snippet": "DataFrame.divide(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` .", "question_id": 829},
{"snippet": "DataFrame.divide(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 830},
{"snippet": "DataFrame.divide(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 831},
{"snippet": "DataFrame.divide(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 832},
{"snippet": "DataFrame.divide(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 833},
{"snippet": "DataFrame.divide(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 834},
{"snippet": "DataFrame.divide(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) .", "question_id": 835},
{"snippet": "DataFrame.divide(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 836},
{"snippet": "DataFrame.divide(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` .", "question_id": 837},
{"snippet": "DataFrame.divide(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 838},
{"snippet": "DataFrame.divide(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 839},
{"snippet": "DataFrame.divide(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 840},
{"snippet": "DataFrame.divide(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 841},
{"snippet": "DataFrame.divide(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 842},
{"snippet": "DataFrame.dot(other)", "intent": "Compute the matrix multiplication between the DataFrame and `other` .", "question_id": 843},
{"snippet": "DataFrame.dot(other)", "intent": "Compute the matrix multiplication between the DataFrame and `other` .", "question_id": 844},
{"snippet": "DataFrame.dot(other)", "intent": "Compute the matrix multiplication between the DataFrame and `other` .", "question_id": 845},
{"snippet": "DataFrame.drop()", "intent": "Drop specified `labels` from rows or `columns` .", "question_id": 846},
{"snippet": "DataFrame.drop(labels=None)", "intent": "Drop specified `labels` from rows or `columns` .", "question_id": 847},
{"snippet": "DataFrame.drop(axis=0)", "intent": "Drop specified `labels` from rows or `columns` . Remove rows or columns by specifying label names and corresponding `axis` , or by specifying directly `index` or column names .", "question_id": 848},
{"snippet": "DataFrame.drop(index=None)", "intent": "Drop specified `labels` from rows or `columns` . Remove rows or columns by specifying label names and corresponding `axis` , or by specifying directly `index` or column names .", "question_id": 849},
{"snippet": "DataFrame.drop(columns=None)", "intent": "Drop specified `labels` from rows or `columns` .", "question_id": 850},
{"snippet": "DataFrame.drop(level=None)", "intent": "Drop specified `labels` from rows or `columns` . When using a multi-index , labels on different levels can be removed by specifying the `level` .", "question_id": 851},
{"snippet": "DataFrame.drop(inplace=False)", "intent": "Drop specified `labels` from rows or `columns` . With arguments `inplace`.", "question_id": 852},
{"snippet": "DataFrame.drop(errors='raise')", "intent": "Drop specified `labels` from rows or `columns` . With arguments `errors`.", "question_id": 853},
{"snippet": "DataFrame.drop(labels=None, axis=0)", "intent": "Drop specified `labels` from rows or `columns` . Remove rows or columns by specifying label names and corresponding `axis` , or by specifying directly `index` or column names .", "question_id": 854},
{"snippet": "DataFrame.drop(labels=None, index=None)", "intent": "Drop specified `labels` from rows or `columns` . Remove rows or columns by specifying label names and corresponding `axis` , or by specifying directly `index` or column names .", "question_id": 855},
{"snippet": "DataFrame.drop()", "intent": "Drop specified `labels` from rows or `columns` .", "question_id": 856},
{"snippet": "DataFrame.drop(labels=None)", "intent": "Drop specified `labels` from rows or `columns` .", "question_id": 857},
{"snippet": "DataFrame.drop(axis=0)", "intent": "Drop specified `labels` from rows or `columns` . Remove rows or columns by specifying label names and corresponding `axis` , or by specifying directly `index` or column names .", "question_id": 858},
{"snippet": "DataFrame.drop(index=None)", "intent": "Drop specified `labels` from rows or `columns` . Remove rows or columns by specifying label names and corresponding `axis` , or by specifying directly `index` or column names .", "question_id": 859},
{"snippet": "DataFrame.drop(columns=None)", "intent": "Drop specified `labels` from rows or `columns` .", "question_id": 860},
{"snippet": "DataFrame.drop(level=None)", "intent": "Drop specified `labels` from rows or `columns` . When using a multi-index , labels on different levels can be removed by specifying the `level` .", "question_id": 861},
{"snippet": "DataFrame.drop(inplace=False)", "intent": "Drop specified `labels` from rows or `columns` . With arguments `inplace`.", "question_id": 862},
{"snippet": "DataFrame.drop(errors='raise')", "intent": "Drop specified `labels` from rows or `columns` . With arguments `errors`.", "question_id": 863},
{"snippet": "DataFrame.drop(labels=None, axis=0)", "intent": "Drop specified `labels` from rows or `columns` . Remove rows or columns by specifying label names and corresponding `axis` , or by specifying directly `index` or column names .", "question_id": 864},
{"snippet": "DataFrame.drop(labels=None, index=None)", "intent": "Drop specified `labels` from rows or `columns` . Remove rows or columns by specifying label names and corresponding `axis` , or by specifying directly `index` or column names .", "question_id": 865},
{"snippet": "DataFrame.drop()", "intent": "Drop specified `labels` from rows or `columns` .", "question_id": 866},
{"snippet": "DataFrame.drop(labels=None)", "intent": "Drop specified `labels` from rows or `columns` .", "question_id": 867},
{"snippet": "DataFrame.drop(axis=0)", "intent": "Drop specified `labels` from rows or `columns` . Remove rows or columns by specifying label names and corresponding `axis` , or by specifying directly `index` or column names .", "question_id": 868},
{"snippet": "DataFrame.drop(index=None)", "intent": "Drop specified `labels` from rows or `columns` . Remove rows or columns by specifying label names and corresponding `axis` , or by specifying directly `index` or column names .", "question_id": 869},
{"snippet": "DataFrame.drop(columns=None)", "intent": "Drop specified `labels` from rows or `columns` .", "question_id": 870},
{"snippet": "DataFrame.drop(level=None)", "intent": "Drop specified `labels` from rows or `columns` . When using a multi-index , labels on different levels can be removed by specifying the `level` .", "question_id": 871},
{"snippet": "DataFrame.drop(inplace=False)", "intent": "Drop specified `labels` from rows or `columns` . With arguments `inplace`.", "question_id": 872},
{"snippet": "DataFrame.drop(errors='raise')", "intent": "Drop specified `labels` from rows or `columns` . With arguments `errors`.", "question_id": 873},
{"snippet": "DataFrame.drop(labels=None, axis=0)", "intent": "Drop specified `labels` from rows or `columns` . Remove rows or columns by specifying label names and corresponding `axis` , or by specifying directly `index` or column names .", "question_id": 874},
{"snippet": "DataFrame.drop(labels=None, index=None)", "intent": "Drop specified `labels` from rows or `columns` . Remove rows or columns by specifying label names and corresponding `axis` , or by specifying directly `index` or column names .", "question_id": 875},
{"snippet": "DataFrame.drop_duplicates()", "intent": "Return DataFrame with duplicate rows removed .", "question_id": 876},
{"snippet": "DataFrame.drop_duplicates(subset=None)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates on specific column ( s ) , use `subset` .", "question_id": 877},
{"snippet": "DataFrame.drop_duplicates(keep='first')", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates and `keep` last occurrences , use keep .", "question_id": 878},
{"snippet": "DataFrame.drop_duplicates(inplace=False)", "intent": "Return DataFrame with duplicate rows removed . With arguments `inplace`.", "question_id": 879},
{"snippet": "DataFrame.drop_duplicates(ignore_index=False)", "intent": "Return DataFrame with duplicate rows removed . With arguments `ignore_index`.", "question_id": 880},
{"snippet": "DataFrame.drop_duplicates(subset=None, keep='first')", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates on specific column ( s ) , use `subset` . To remove duplicates and `keep` last occurrences , use keep .", "question_id": 881},
{"snippet": "DataFrame.drop_duplicates(subset=None, inplace=False)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates on specific column ( s ) , use `subset` . With arguments `inplace`.", "question_id": 882},
{"snippet": "DataFrame.drop_duplicates(subset=None, ignore_index=False)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates on specific column ( s ) , use `subset` . With arguments `ignore_index`.", "question_id": 883},
{"snippet": "DataFrame.drop_duplicates(keep='first', inplace=False)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates and `keep` last occurrences , use keep . With arguments `inplace`.", "question_id": 884},
{"snippet": "DataFrame.drop_duplicates(keep='first', ignore_index=False)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates and `keep` last occurrences , use keep . With arguments `ignore_index`.", "question_id": 885},
{"snippet": "DataFrame.drop_duplicates()", "intent": "Return DataFrame with duplicate rows removed .", "question_id": 886},
{"snippet": "DataFrame.drop_duplicates(subset=None)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates on specific column ( s ) , use `subset` .", "question_id": 887},
{"snippet": "DataFrame.drop_duplicates(keep='first')", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates and `keep` last occurrences , use keep .", "question_id": 888},
{"snippet": "DataFrame.drop_duplicates(inplace=False)", "intent": "Return DataFrame with duplicate rows removed . With arguments `inplace`.", "question_id": 889},
{"snippet": "DataFrame.drop_duplicates(ignore_index=False)", "intent": "Return DataFrame with duplicate rows removed . With arguments `ignore_index`.", "question_id": 890},
{"snippet": "DataFrame.drop_duplicates(subset=None, keep='first')", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates on specific column ( s ) , use `subset` . To remove duplicates and `keep` last occurrences , use keep .", "question_id": 891},
{"snippet": "DataFrame.drop_duplicates(subset=None, inplace=False)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates on specific column ( s ) , use `subset` . With arguments `inplace`.", "question_id": 892},
{"snippet": "DataFrame.drop_duplicates(subset=None, ignore_index=False)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates on specific column ( s ) , use `subset` . With arguments `ignore_index`.", "question_id": 893},
{"snippet": "DataFrame.drop_duplicates(keep='first', inplace=False)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates and `keep` last occurrences , use keep . With arguments `inplace`.", "question_id": 894},
{"snippet": "DataFrame.drop_duplicates(keep='first', ignore_index=False)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates and `keep` last occurrences , use keep . With arguments `ignore_index`.", "question_id": 895},
{"snippet": "DataFrame.drop_duplicates()", "intent": "Return DataFrame with duplicate rows removed .", "question_id": 896},
{"snippet": "DataFrame.drop_duplicates(subset=None)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates on specific column ( s ) , use `subset` .", "question_id": 897},
{"snippet": "DataFrame.drop_duplicates(keep='first')", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates and `keep` last occurrences , use keep .", "question_id": 898},
{"snippet": "DataFrame.drop_duplicates(inplace=False)", "intent": "Return DataFrame with duplicate rows removed . With arguments `inplace`.", "question_id": 899},
{"snippet": "DataFrame.drop_duplicates(ignore_index=False)", "intent": "Return DataFrame with duplicate rows removed . With arguments `ignore_index`.", "question_id": 900},
{"snippet": "DataFrame.drop_duplicates(subset=None, keep='first')", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates on specific column ( s ) , use `subset` . To remove duplicates and `keep` last occurrences , use keep .", "question_id": 901},
{"snippet": "DataFrame.drop_duplicates(subset=None, inplace=False)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates on specific column ( s ) , use `subset` . With arguments `inplace`.", "question_id": 902},
{"snippet": "DataFrame.drop_duplicates(subset=None, ignore_index=False)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates on specific column ( s ) , use `subset` . With arguments `ignore_index`.", "question_id": 903},
{"snippet": "DataFrame.drop_duplicates(keep='first', inplace=False)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates and `keep` last occurrences , use keep . With arguments `inplace`.", "question_id": 904},
{"snippet": "DataFrame.drop_duplicates(keep='first', ignore_index=False)", "intent": "Return DataFrame with duplicate rows removed . To remove duplicates and `keep` last occurrences , use keep . With arguments `ignore_index`.", "question_id": 905},
{"snippet": "DataFrame.droplevel(level)", "intent": "Return Series/DataFrame with requested index / column `level` ( s ) removed .", "question_id": 906},
{"snippet": "DataFrame.droplevel(level, axis=0)", "intent": "Return Series/DataFrame with requested index / column `level` ( s ) removed . With arguments `axis`.", "question_id": 907},
{"snippet": "DataFrame.droplevel(level)", "intent": "Return Series/DataFrame with requested index / column `level` ( s ) removed .", "question_id": 908},
{"snippet": "DataFrame.droplevel(level, axis=0)", "intent": "Return Series/DataFrame with requested index / column `level` ( s ) removed . With arguments `axis`.", "question_id": 909},
{"snippet": "DataFrame.droplevel(level)", "intent": "Return Series/DataFrame with requested index / column `level` ( s ) removed .", "question_id": 910},
{"snippet": "DataFrame.droplevel(level, axis=0)", "intent": "Return Series/DataFrame with requested index / column `level` ( s ) removed . With arguments `axis`.", "question_id": 911},
{"snippet": "DataFrame.dropna()", "intent": "Remove missing values .", "question_id": 912},
{"snippet": "DataFrame.dropna(axis=0)", "intent": "Remove missing values . With arguments `axis`.", "question_id": 913},
{"snippet": "DataFrame.dropna(how='any')", "intent": "Remove missing values . See the User Guide for more on which values are considered missing , and `how` to work with missing data .", "question_id": 914},
{"snippet": "DataFrame.dropna(thresh=None)", "intent": "Remove missing values . With arguments `thresh`.", "question_id": 915},
{"snippet": "DataFrame.dropna(subset=None)", "intent": "Remove missing values . With arguments `subset`.", "question_id": 916},
{"snippet": "DataFrame.dropna(inplace=False)", "intent": "Remove missing values . With arguments `inplace`.", "question_id": 917},
{"snippet": "DataFrame.dropna(axis=0, how='any')", "intent": "Remove missing values . See the User Guide for more on which values are considered missing , and `how` to work with missing data . With arguments `axis`.", "question_id": 918},
{"snippet": "DataFrame.dropna(axis=0, thresh=None)", "intent": "Remove missing values . With arguments `axis`, `thresh`.", "question_id": 919},
{"snippet": "DataFrame.dropna(axis=0, subset=None)", "intent": "Remove missing values . With arguments `axis`, `subset`.", "question_id": 920},
{"snippet": "DataFrame.dropna(axis=0, inplace=False)", "intent": "Remove missing values . With arguments `axis`, `inplace`.", "question_id": 921},
{"snippet": "DataFrame.dropna()", "intent": "Remove missing values .", "question_id": 922},
{"snippet": "DataFrame.dropna(axis=0)", "intent": "Remove missing values . With arguments `axis`.", "question_id": 923},
{"snippet": "DataFrame.dropna(how='any')", "intent": "Remove missing values . See the User Guide for more on which values are considered missing , and `how` to work with missing data .", "question_id": 924},
{"snippet": "DataFrame.dropna(thresh=None)", "intent": "Remove missing values . With arguments `thresh`.", "question_id": 925},
{"snippet": "DataFrame.dropna(subset=None)", "intent": "Remove missing values . With arguments `subset`.", "question_id": 926},
{"snippet": "DataFrame.dropna(inplace=False)", "intent": "Remove missing values . With arguments `inplace`.", "question_id": 927},
{"snippet": "DataFrame.dropna(axis=0, how='any')", "intent": "Remove missing values . See the User Guide for more on which values are considered missing , and `how` to work with missing data . With arguments `axis`.", "question_id": 928},
{"snippet": "DataFrame.dropna(axis=0, thresh=None)", "intent": "Remove missing values . With arguments `axis`, `thresh`.", "question_id": 929},
{"snippet": "DataFrame.dropna(axis=0, subset=None)", "intent": "Remove missing values . With arguments `axis`, `subset`.", "question_id": 930},
{"snippet": "DataFrame.dropna(axis=0, inplace=False)", "intent": "Remove missing values . With arguments `axis`, `inplace`.", "question_id": 931},
{"snippet": "DataFrame.dropna()", "intent": "Remove missing values .", "question_id": 932},
{"snippet": "DataFrame.dropna(axis=0)", "intent": "Remove missing values . With arguments `axis`.", "question_id": 933},
{"snippet": "DataFrame.dropna(how='any')", "intent": "Remove missing values . See the User Guide for more on which values are considered missing , and `how` to work with missing data .", "question_id": 934},
{"snippet": "DataFrame.dropna(thresh=None)", "intent": "Remove missing values . With arguments `thresh`.", "question_id": 935},
{"snippet": "DataFrame.dropna(subset=None)", "intent": "Remove missing values . With arguments `subset`.", "question_id": 936},
{"snippet": "DataFrame.dropna(inplace=False)", "intent": "Remove missing values . With arguments `inplace`.", "question_id": 937},
{"snippet": "DataFrame.dropna(axis=0, how='any')", "intent": "Remove missing values . See the User Guide for more on which values are considered missing , and `how` to work with missing data . With arguments `axis`.", "question_id": 938},
{"snippet": "DataFrame.dropna(axis=0, thresh=None)", "intent": "Remove missing values . With arguments `axis`, `thresh`.", "question_id": 939},
{"snippet": "DataFrame.dropna(axis=0, subset=None)", "intent": "Remove missing values . With arguments `axis`, `subset`.", "question_id": 940},
{"snippet": "DataFrame.dropna(axis=0, inplace=False)", "intent": "Remove missing values . With arguments `axis`, `inplace`.", "question_id": 941},
{"snippet": "DataFrame.duplicated()", "intent": "Return boolean Series denoting duplicate rows .", "question_id": 942},
{"snippet": "DataFrame.duplicated(subset=None)", "intent": "Return boolean Series denoting duplicate rows . To find duplicates on specific column ( s ) , use `subset` .", "question_id": 943},
{"snippet": "DataFrame.duplicated(keep='first')", "intent": "Return boolean Series denoting duplicate rows . By setting `keep` on False , all duplicates are True .", "question_id": 944},
{"snippet": "DataFrame.duplicated(subset=None, keep='first')", "intent": "Return boolean Series denoting duplicate rows . To find duplicates on specific column ( s ) , use `subset` . By setting `keep` on False , all duplicates are True .", "question_id": 945},
{"snippet": "DataFrame.duplicated()", "intent": "Return boolean Series denoting duplicate rows .", "question_id": 946},
{"snippet": "DataFrame.duplicated(subset=None)", "intent": "Return boolean Series denoting duplicate rows . To find duplicates on specific column ( s ) , use `subset` .", "question_id": 947},
{"snippet": "DataFrame.duplicated(keep='first')", "intent": "Return boolean Series denoting duplicate rows . By setting `keep` on False , all duplicates are True .", "question_id": 948},
{"snippet": "DataFrame.duplicated(subset=None, keep='first')", "intent": "Return boolean Series denoting duplicate rows . To find duplicates on specific column ( s ) , use `subset` . By setting `keep` on False , all duplicates are True .", "question_id": 949},
{"snippet": "DataFrame.duplicated()", "intent": "Return boolean Series denoting duplicate rows .", "question_id": 950},
{"snippet": "DataFrame.duplicated(subset=None)", "intent": "Return boolean Series denoting duplicate rows . To find duplicates on specific column ( s ) , use `subset` .", "question_id": 951},
{"snippet": "DataFrame.duplicated(keep='first')", "intent": "Return boolean Series denoting duplicate rows . By setting `keep` on False , all duplicates are True .", "question_id": 952},
{"snippet": "DataFrame.duplicated(subset=None, keep='first')", "intent": "Return boolean Series denoting duplicate rows . To find duplicates on specific column ( s ) , use `subset` . By setting `keep` on False , all duplicates are True .", "question_id": 953},
{"snippet": "DataFrame.eq(other)", "intent": "Get Equal to of dataframe and `other` , element-wise ( binary operator eq ) .", "question_id": 954},
{"snippet": "DataFrame.eq(other, axis='columns')", "intent": "Get Equal to of dataframe and `other` , element-wise ( binary operator eq ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 955},
{"snippet": "DataFrame.eq(other, level=None)", "intent": "Get Equal to of dataframe and `other` , element-wise ( binary operator eq ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 956},
{"snippet": "DataFrame.eq(other, axis='columns', level=None)", "intent": "Get Equal to of dataframe and `other` , element-wise ( binary operator eq ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 957},
{"snippet": "DataFrame.eq(other)", "intent": "Get Equal to of dataframe and `other` , element-wise ( binary operator eq ) .", "question_id": 958},
{"snippet": "DataFrame.eq(other, axis='columns')", "intent": "Get Equal to of dataframe and `other` , element-wise ( binary operator eq ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 959},
{"snippet": "DataFrame.eq(other, level=None)", "intent": "Get Equal to of dataframe and `other` , element-wise ( binary operator eq ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 960},
{"snippet": "DataFrame.eq(other, axis='columns', level=None)", "intent": "Get Equal to of dataframe and `other` , element-wise ( binary operator eq ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 961},
{"snippet": "DataFrame.eq(other)", "intent": "Get Equal to of dataframe and `other` , element-wise ( binary operator eq ) .", "question_id": 962},
{"snippet": "DataFrame.eq(other, axis='columns')", "intent": "Get Equal to of dataframe and `other` , element-wise ( binary operator eq ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 963},
{"snippet": "DataFrame.eq(other, level=None)", "intent": "Get Equal to of dataframe and `other` , element-wise ( binary operator eq ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 964},
{"snippet": "DataFrame.eq(other, axis='columns', level=None)", "intent": "Get Equal to of dataframe and `other` , element-wise ( binary operator eq ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 965},
{"snippet": "DataFrame.equals(other)", "intent": "Test whether two objects contain the same elements . This function allows two Series or DataFrames to be compared against each `other` to see if they have the same shape and elements .", "question_id": 966},
{"snippet": "DataFrame.equals(other)", "intent": "Test whether two objects contain the same elements . This function allows two Series or DataFrames to be compared against each `other` to see if they have the same shape and elements .", "question_id": 967},
{"snippet": "DataFrame.equals(other)", "intent": "Test whether two objects contain the same elements . This function allows two Series or DataFrames to be compared against each `other` to see if they have the same shape and elements .", "question_id": 968},
{"snippet": "DataFrame.eval(expr, **kwargs)", "intent": "Evaluate a string describing operations on DataFrame columns . With arguments `expr`, `**kwargs`.", "question_id": 969},
{"snippet": "DataFrame.eval(expr, **kwargs, inplace=False)", "intent": "Evaluate a string describing operations on DataFrame columns . With arguments `expr`, `**kwargs`, `inplace`.", "question_id": 970},
{"snippet": "DataFrame.eval(expr, **kwargs)", "intent": "Evaluate a string describing operations on DataFrame columns . With arguments `expr`, `**kwargs`.", "question_id": 971},
{"snippet": "DataFrame.eval(expr, **kwargs, inplace=False)", "intent": "Evaluate a string describing operations on DataFrame columns . With arguments `expr`, `**kwargs`, `inplace`.", "question_id": 972},
{"snippet": "DataFrame.eval(expr, **kwargs)", "intent": "Evaluate a string describing operations on DataFrame columns . With arguments `expr`, `**kwargs`.", "question_id": 973},
{"snippet": "DataFrame.eval(expr, **kwargs, inplace=False)", "intent": "Evaluate a string describing operations on DataFrame columns . With arguments `expr`, `**kwargs`, `inplace`.", "question_id": 974},
{"snippet": "DataFrame.ewm()", "intent": "Provide exponential weighted ( EW ) functions .", "question_id": 975},
{"snippet": "DataFrame.ewm(com=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 976},
{"snippet": "DataFrame.ewm(span=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 977},
{"snippet": "DataFrame.ewm(halflife=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 978},
{"snippet": "DataFrame.ewm(alpha=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 979},
{"snippet": "DataFrame.ewm(min_periods=0)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `min_periods`.", "question_id": 980},
{"snippet": "DataFrame.ewm(adjust=True)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `adjust`.", "question_id": 981},
{"snippet": "DataFrame.ewm(ignore_na=False)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `ignore_na`.", "question_id": 982},
{"snippet": "DataFrame.ewm(axis=0)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `axis`.", "question_id": 983},
{"snippet": "DataFrame.ewm(times=None)", "intent": "Provide exponential weighted ( EW ) functions . Specifying `times` with a timedelta halflife when computing mean .", "question_id": 984},
{"snippet": "DataFrame.ewm()", "intent": "Provide exponential weighted ( EW ) functions .", "question_id": 985},
{"snippet": "DataFrame.ewm(com=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 986},
{"snippet": "DataFrame.ewm(span=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 987},
{"snippet": "DataFrame.ewm(halflife=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 988},
{"snippet": "DataFrame.ewm(alpha=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 989},
{"snippet": "DataFrame.ewm(min_periods=0)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `min_periods`.", "question_id": 990},
{"snippet": "DataFrame.ewm(adjust=True)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `adjust`.", "question_id": 991},
{"snippet": "DataFrame.ewm(ignore_na=False)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `ignore_na`.", "question_id": 992},
{"snippet": "DataFrame.ewm(axis=0)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `axis`.", "question_id": 993},
{"snippet": "DataFrame.ewm(times=None)", "intent": "Provide exponential weighted ( EW ) functions . Specifying `times` with a timedelta halflife when computing mean .", "question_id": 994},
{"snippet": "DataFrame.ewm()", "intent": "Provide exponential weighted ( EW ) functions .", "question_id": 995},
{"snippet": "DataFrame.ewm(com=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 996},
{"snippet": "DataFrame.ewm(span=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 997},
{"snippet": "DataFrame.ewm(halflife=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 998},
{"snippet": "DataFrame.ewm(alpha=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 999},
{"snippet": "DataFrame.ewm(min_periods=0)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `min_periods`.", "question_id": 1000},
{"snippet": "DataFrame.ewm(adjust=True)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `adjust`.", "question_id": 1001},
{"snippet": "DataFrame.ewm(ignore_na=False)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `ignore_na`.", "question_id": 1002},
{"snippet": "DataFrame.ewm(axis=0)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `axis`.", "question_id": 1003},
{"snippet": "DataFrame.ewm(times=None)", "intent": "Provide exponential weighted ( EW ) functions . Specifying `times` with a timedelta halflife when computing mean .", "question_id": 1004},
{"snippet": "DataFrame.expanding()", "intent": "Provide expanding transformations .", "question_id": 1005},
{"snippet": "DataFrame.expanding(min_periods=1)", "intent": "Provide expanding transformations . With arguments `min_periods`.", "question_id": 1006},
{"snippet": "DataFrame.expanding(center=None)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True .", "question_id": 1007},
{"snippet": "DataFrame.expanding(axis=0)", "intent": "Provide expanding transformations . With arguments `axis`.", "question_id": 1008},
{"snippet": "DataFrame.expanding(method='single')", "intent": "Provide expanding transformations . With arguments `method`.", "question_id": 1009},
{"snippet": "DataFrame.expanding(min_periods=1, center=None)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `min_periods`.", "question_id": 1010},
{"snippet": "DataFrame.expanding(min_periods=1, axis=0)", "intent": "Provide expanding transformations . With arguments `min_periods`, `axis`.", "question_id": 1011},
{"snippet": "DataFrame.expanding(min_periods=1, method='single')", "intent": "Provide expanding transformations . With arguments `min_periods`, `method`.", "question_id": 1012},
{"snippet": "DataFrame.expanding(center=None, axis=0)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `axis`.", "question_id": 1013},
{"snippet": "DataFrame.expanding(center=None, method='single')", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `method`.", "question_id": 1014},
{"snippet": "DataFrame.expanding()", "intent": "Provide expanding transformations .", "question_id": 1015},
{"snippet": "DataFrame.expanding(min_periods=1)", "intent": "Provide expanding transformations . With arguments `min_periods`.", "question_id": 1016},
{"snippet": "DataFrame.expanding(center=None)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True .", "question_id": 1017},
{"snippet": "DataFrame.expanding(axis=0)", "intent": "Provide expanding transformations . With arguments `axis`.", "question_id": 1018},
{"snippet": "DataFrame.expanding(method='single')", "intent": "Provide expanding transformations . With arguments `method`.", "question_id": 1019},
{"snippet": "DataFrame.expanding(min_periods=1, center=None)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `min_periods`.", "question_id": 1020},
{"snippet": "DataFrame.expanding(min_periods=1, axis=0)", "intent": "Provide expanding transformations . With arguments `min_periods`, `axis`.", "question_id": 1021},
{"snippet": "DataFrame.expanding(min_periods=1, method='single')", "intent": "Provide expanding transformations . With arguments `min_periods`, `method`.", "question_id": 1022},
{"snippet": "DataFrame.expanding(center=None, axis=0)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `axis`.", "question_id": 1023},
{"snippet": "DataFrame.expanding(center=None, method='single')", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `method`.", "question_id": 1024},
{"snippet": "DataFrame.expanding()", "intent": "Provide expanding transformations .", "question_id": 1025},
{"snippet": "DataFrame.expanding(min_periods=1)", "intent": "Provide expanding transformations . With arguments `min_periods`.", "question_id": 1026},
{"snippet": "DataFrame.expanding(center=None)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True .", "question_id": 1027},
{"snippet": "DataFrame.expanding(axis=0)", "intent": "Provide expanding transformations . With arguments `axis`.", "question_id": 1028},
{"snippet": "DataFrame.expanding(method='single')", "intent": "Provide expanding transformations . With arguments `method`.", "question_id": 1029},
{"snippet": "DataFrame.expanding(min_periods=1, center=None)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `min_periods`.", "question_id": 1030},
{"snippet": "DataFrame.expanding(min_periods=1, axis=0)", "intent": "Provide expanding transformations . With arguments `min_periods`, `axis`.", "question_id": 1031},
{"snippet": "DataFrame.expanding(min_periods=1, method='single')", "intent": "Provide expanding transformations . With arguments `min_periods`, `method`.", "question_id": 1032},
{"snippet": "DataFrame.expanding(center=None, axis=0)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `axis`.", "question_id": 1033},
{"snippet": "DataFrame.expanding(center=None, method='single')", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `method`.", "question_id": 1034},
{"snippet": "DataFrame.explode(column)", "intent": "Transform each element of a list-like to a row , replicating index values . With arguments `column`.", "question_id": 1035},
{"snippet": "DataFrame.explode(column, ignore_index=False)", "intent": "Transform each element of a list-like to a row , replicating index values . With arguments `column`, `ignore_index`.", "question_id": 1036},
{"snippet": "DataFrame.explode(column)", "intent": "Transform each element of a list-like to a row , replicating index values . With arguments `column`.", "question_id": 1037},
{"snippet": "DataFrame.explode(column, ignore_index=False)", "intent": "Transform each element of a list-like to a row , replicating index values . With arguments `column`, `ignore_index`.", "question_id": 1038},
{"snippet": "DataFrame.explode(column)", "intent": "Transform each element of a list-like to a row , replicating index values . With arguments `column`.", "question_id": 1039},
{"snippet": "DataFrame.explode(column, ignore_index=False)", "intent": "Transform each element of a list-like to a row , replicating index values . With arguments `column`, `ignore_index`.", "question_id": 1040},
{"snippet": "DataFrame.ffill()", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' .", "question_id": 1041},
{"snippet": "DataFrame.ffill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`.", "question_id": 1042},
{"snippet": "DataFrame.ffill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`.", "question_id": 1043},
{"snippet": "DataFrame.ffill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `limit`.", "question_id": 1044},
{"snippet": "DataFrame.ffill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `downcast`.", "question_id": 1045},
{"snippet": "DataFrame.ffill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `inplace`.", "question_id": 1046},
{"snippet": "DataFrame.ffill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `limit`.", "question_id": 1047},
{"snippet": "DataFrame.ffill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `downcast`.", "question_id": 1048},
{"snippet": "DataFrame.ffill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `limit`.", "question_id": 1049},
{"snippet": "DataFrame.ffill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `downcast`.", "question_id": 1050},
{"snippet": "DataFrame.ffill()", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' .", "question_id": 1051},
{"snippet": "DataFrame.ffill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`.", "question_id": 1052},
{"snippet": "DataFrame.ffill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`.", "question_id": 1053},
{"snippet": "DataFrame.ffill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `limit`.", "question_id": 1054},
{"snippet": "DataFrame.ffill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `downcast`.", "question_id": 1055},
{"snippet": "DataFrame.ffill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `inplace`.", "question_id": 1056},
{"snippet": "DataFrame.ffill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `limit`.", "question_id": 1057},
{"snippet": "DataFrame.ffill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `downcast`.", "question_id": 1058},
{"snippet": "DataFrame.ffill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `limit`.", "question_id": 1059},
{"snippet": "DataFrame.ffill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `downcast`.", "question_id": 1060},
{"snippet": "DataFrame.ffill()", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' .", "question_id": 1061},
{"snippet": "DataFrame.ffill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`.", "question_id": 1062},
{"snippet": "DataFrame.ffill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`.", "question_id": 1063},
{"snippet": "DataFrame.ffill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `limit`.", "question_id": 1064},
{"snippet": "DataFrame.ffill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `downcast`.", "question_id": 1065},
{"snippet": "DataFrame.ffill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `inplace`.", "question_id": 1066},
{"snippet": "DataFrame.ffill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `limit`.", "question_id": 1067},
{"snippet": "DataFrame.ffill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `downcast`.", "question_id": 1068},
{"snippet": "DataFrame.ffill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `limit`.", "question_id": 1069},
{"snippet": "DataFrame.ffill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `downcast`.", "question_id": 1070},
{"snippet": "DataFrame.fillna()", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 1071},
{"snippet": "DataFrame.fillna(value=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 1072},
{"snippet": "DataFrame.fillna(method=None)", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 1073},
{"snippet": "DataFrame.fillna(axis=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `axis`.", "question_id": 1074},
{"snippet": "DataFrame.fillna(inplace=False)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `inplace`.", "question_id": 1075},
{"snippet": "DataFrame.fillna(limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `limit`.", "question_id": 1076},
{"snippet": "DataFrame.fillna(downcast=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `downcast`.", "question_id": 1077},
{"snippet": "DataFrame.fillna(value=None, method=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 1078},
{"snippet": "DataFrame.fillna(value=None, axis=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `axis`.", "question_id": 1079},
{"snippet": "DataFrame.fillna(value=None, inplace=False)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `inplace`.", "question_id": 1080},
{"snippet": "DataFrame.fillna()", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 1081},
{"snippet": "DataFrame.fillna(value=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 1082},
{"snippet": "DataFrame.fillna(method=None)", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 1083},
{"snippet": "DataFrame.fillna(axis=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `axis`.", "question_id": 1084},
{"snippet": "DataFrame.fillna(inplace=False)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `inplace`.", "question_id": 1085},
{"snippet": "DataFrame.fillna(limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `limit`.", "question_id": 1086},
{"snippet": "DataFrame.fillna(downcast=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `downcast`.", "question_id": 1087},
{"snippet": "DataFrame.fillna(value=None, method=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 1088},
{"snippet": "DataFrame.fillna(value=None, axis=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `axis`.", "question_id": 1089},
{"snippet": "DataFrame.fillna(value=None, inplace=False)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `inplace`.", "question_id": 1090},
{"snippet": "DataFrame.fillna()", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 1091},
{"snippet": "DataFrame.fillna(value=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 1092},
{"snippet": "DataFrame.fillna(method=None)", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 1093},
{"snippet": "DataFrame.fillna(axis=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `axis`.", "question_id": 1094},
{"snippet": "DataFrame.fillna(inplace=False)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `inplace`.", "question_id": 1095},
{"snippet": "DataFrame.fillna(limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `limit`.", "question_id": 1096},
{"snippet": "DataFrame.fillna(downcast=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `downcast`.", "question_id": 1097},
{"snippet": "DataFrame.fillna(value=None, method=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 1098},
{"snippet": "DataFrame.fillna(value=None, axis=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `axis`.", "question_id": 1099},
{"snippet": "DataFrame.fillna(value=None, inplace=False)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `inplace`.", "question_id": 1100},
{"snippet": "DataFrame.filter()", "intent": "Subset the dataframe rows or columns according to the specified index labels .", "question_id": 1101},
{"snippet": "DataFrame.filter(items=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1102},
{"snippet": "DataFrame.filter(like=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1103},
{"snippet": "DataFrame.filter(regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1104},
{"snippet": "DataFrame.filter(axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 1105},
{"snippet": "DataFrame.filter(items=None, like=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1106},
{"snippet": "DataFrame.filter(items=None, regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1107},
{"snippet": "DataFrame.filter(items=None, axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 1108},
{"snippet": "DataFrame.filter(like=None, regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1109},
{"snippet": "DataFrame.filter(like=None, axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 1110},
{"snippet": "DataFrame.filter()", "intent": "Subset the dataframe rows or columns according to the specified index labels .", "question_id": 1111},
{"snippet": "DataFrame.filter(items=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1112},
{"snippet": "DataFrame.filter(like=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1113},
{"snippet": "DataFrame.filter(regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1114},
{"snippet": "DataFrame.filter(axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 1115},
{"snippet": "DataFrame.filter(items=None, like=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1116},
{"snippet": "DataFrame.filter(items=None, regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1117},
{"snippet": "DataFrame.filter(items=None, axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 1118},
{"snippet": "DataFrame.filter(like=None, regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1119},
{"snippet": "DataFrame.filter(like=None, axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 1120},
{"snippet": "DataFrame.filter()", "intent": "Subset the dataframe rows or columns according to the specified index labels .", "question_id": 1121},
{"snippet": "DataFrame.filter(items=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1122},
{"snippet": "DataFrame.filter(like=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1123},
{"snippet": "DataFrame.filter(regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1124},
{"snippet": "DataFrame.filter(axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 1125},
{"snippet": "DataFrame.filter(items=None, like=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1126},
{"snippet": "DataFrame.filter(items=None, regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1127},
{"snippet": "DataFrame.filter(items=None, axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 1128},
{"snippet": "DataFrame.filter(like=None, regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 1129},
{"snippet": "DataFrame.filter(like=None, axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 1130},
{"snippet": "DataFrame.first(offset)", "intent": "Select initial periods of time series data based on a date `offset` .", "question_id": 1131},
{"snippet": "DataFrame.first(offset)", "intent": "Select initial periods of time series data based on a date `offset` .", "question_id": 1132},
{"snippet": "DataFrame.first(offset)", "intent": "Select initial periods of time series data based on a date `offset` .", "question_id": 1133},
{"snippet": "DataFrame.first_valid_index()", "intent": "Return index for first non-NA value or None , if no NA value is found .", "question_id": 1134},
{"snippet": "DataFrame.first_valid_index()", "intent": "Return index for first non-NA value or None , if no NA value is found .", "question_id": 1135},
{"snippet": "DataFrame.first_valid_index()", "intent": "Return index for first non-NA value or None , if no NA value is found .", "question_id": 1136},
{"snippet": "DataFrame.floordiv(other)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) .", "question_id": 1137},
{"snippet": "DataFrame.floordiv(other, axis='columns')", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 1138},
{"snippet": "DataFrame.floordiv(other, level=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Divide by a MultiIndex by `level` .", "question_id": 1139},
{"snippet": "DataFrame.floordiv(other, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Equivalent to dataframe // other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1140},
{"snippet": "DataFrame.floordiv(other, axis='columns', level=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 1141},
{"snippet": "DataFrame.floordiv(other, axis='columns', fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe // other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1142},
{"snippet": "DataFrame.floordiv(other, level=None, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Divide by a MultiIndex by `level` . Equivalent to dataframe // other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1143},
{"snippet": "DataFrame.floordiv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe // other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1144},
{"snippet": "DataFrame.floordiv(other)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) .", "question_id": 1145},
{"snippet": "DataFrame.floordiv(other, axis='columns')", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 1146},
{"snippet": "DataFrame.floordiv(other, level=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Divide by a MultiIndex by `level` .", "question_id": 1147},
{"snippet": "DataFrame.floordiv(other, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Equivalent to dataframe // other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1148},
{"snippet": "DataFrame.floordiv(other, axis='columns', level=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 1149},
{"snippet": "DataFrame.floordiv(other, axis='columns', fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe // other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1150},
{"snippet": "DataFrame.floordiv(other, level=None, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Divide by a MultiIndex by `level` . Equivalent to dataframe // other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1151},
{"snippet": "DataFrame.floordiv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe // other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1152},
{"snippet": "DataFrame.floordiv(other)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) .", "question_id": 1153},
{"snippet": "DataFrame.floordiv(other, axis='columns')", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 1154},
{"snippet": "DataFrame.floordiv(other, level=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Divide by a MultiIndex by `level` .", "question_id": 1155},
{"snippet": "DataFrame.floordiv(other, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Equivalent to dataframe // other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1156},
{"snippet": "DataFrame.floordiv(other, axis='columns', level=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 1157},
{"snippet": "DataFrame.floordiv(other, axis='columns', fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe // other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1158},
{"snippet": "DataFrame.floordiv(other, level=None, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Divide by a MultiIndex by `level` . Equivalent to dataframe // other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1159},
{"snippet": "DataFrame.floordiv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator floordiv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe // other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1160},
{"snippet": "DataFrame.from_dict(data)", "intent": "Construct DataFrame from dict of array-like or dicts . With arguments `data`.", "question_id": 1161},
{"snippet": "DataFrame.from_dict(data, orient='columns')", "intent": "Construct DataFrame from dict of array-like or dicts . With arguments `data`, `orient`.", "question_id": 1162},
{"snippet": "DataFrame.from_dict(data, dtype=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`.", "question_id": 1163},
{"snippet": "DataFrame.from_dict(data, columns=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`.", "question_id": 1164},
{"snippet": "DataFrame.from_dict(data, orient='columns', dtype=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`, `orient`.", "question_id": 1165},
{"snippet": "DataFrame.from_dict(data, orient='columns', columns=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`, `orient`.", "question_id": 1166},
{"snippet": "DataFrame.from_dict(data, dtype=None, columns=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`.", "question_id": 1167},
{"snippet": "DataFrame.from_dict(data, orient='columns', dtype=None, columns=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`, `orient`.", "question_id": 1168},
{"snippet": "DataFrame.from_dict(data)", "intent": "Construct DataFrame from dict of array-like or dicts . With arguments `data`.", "question_id": 1169},
{"snippet": "DataFrame.from_dict(data, orient='columns')", "intent": "Construct DataFrame from dict of array-like or dicts . With arguments `data`, `orient`.", "question_id": 1170},
{"snippet": "DataFrame.from_dict(data, dtype=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`.", "question_id": 1171},
{"snippet": "DataFrame.from_dict(data, columns=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`.", "question_id": 1172},
{"snippet": "DataFrame.from_dict(data, orient='columns', dtype=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`, `orient`.", "question_id": 1173},
{"snippet": "DataFrame.from_dict(data, orient='columns', columns=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`, `orient`.", "question_id": 1174},
{"snippet": "DataFrame.from_dict(data, dtype=None, columns=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`.", "question_id": 1175},
{"snippet": "DataFrame.from_dict(data, orient='columns', dtype=None, columns=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`, `orient`.", "question_id": 1176},
{"snippet": "DataFrame.from_dict(data)", "intent": "Construct DataFrame from dict of array-like or dicts . With arguments `data`.", "question_id": 1177},
{"snippet": "DataFrame.from_dict(data, orient='columns')", "intent": "Construct DataFrame from dict of array-like or dicts . With arguments `data`, `orient`.", "question_id": 1178},
{"snippet": "DataFrame.from_dict(data, dtype=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`.", "question_id": 1179},
{"snippet": "DataFrame.from_dict(data, columns=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`.", "question_id": 1180},
{"snippet": "DataFrame.from_dict(data, orient='columns', dtype=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`, `orient`.", "question_id": 1181},
{"snippet": "DataFrame.from_dict(data, orient='columns', columns=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`, `orient`.", "question_id": 1182},
{"snippet": "DataFrame.from_dict(data, dtype=None, columns=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`.", "question_id": 1183},
{"snippet": "DataFrame.from_dict(data, orient='columns', dtype=None, columns=None)", "intent": "Construct DataFrame from dict of array-like or dicts . Creates DataFrame object from dictionary by `columns` or by index allowing `dtype` specification . With arguments `data`, `orient`.", "question_id": 1184},
{"snippet": "DataFrame.from_records(data)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`.", "question_id": 1185},
{"snippet": "DataFrame.from_records(data, index=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `index`.", "question_id": 1186},
{"snippet": "DataFrame.from_records(data, exclude=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `exclude`.", "question_id": 1187},
{"snippet": "DataFrame.from_records(data, columns=None)", "intent": "Convert structured or record ndarray to DataFrame . Data can be provided as a list of tuples with corresponding `columns` : With arguments `data`.", "question_id": 1188},
{"snippet": "DataFrame.from_records(data, coerce_float=False)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `coerce_float`.", "question_id": 1189},
{"snippet": "DataFrame.from_records(data, nrows=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `nrows`.", "question_id": 1190},
{"snippet": "DataFrame.from_records(data, index=None, exclude=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `index`, `exclude`.", "question_id": 1191},
{"snippet": "DataFrame.from_records(data, index=None, columns=None)", "intent": "Convert structured or record ndarray to DataFrame . Data can be provided as a list of tuples with corresponding `columns` : With arguments `data`, `index`.", "question_id": 1192},
{"snippet": "DataFrame.from_records(data, index=None, coerce_float=False)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `index`, `coerce_float`.", "question_id": 1193},
{"snippet": "DataFrame.from_records(data, index=None, nrows=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `index`, `nrows`.", "question_id": 1194},
{"snippet": "DataFrame.from_records(data)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`.", "question_id": 1195},
{"snippet": "DataFrame.from_records(data, index=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `index`.", "question_id": 1196},
{"snippet": "DataFrame.from_records(data, exclude=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `exclude`.", "question_id": 1197},
{"snippet": "DataFrame.from_records(data, columns=None)", "intent": "Convert structured or record ndarray to DataFrame . Data can be provided as a list of tuples with corresponding `columns` : With arguments `data`.", "question_id": 1198},
{"snippet": "DataFrame.from_records(data, coerce_float=False)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `coerce_float`.", "question_id": 1199},
{"snippet": "DataFrame.from_records(data, nrows=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `nrows`.", "question_id": 1200},
{"snippet": "DataFrame.from_records(data, index=None, exclude=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `index`, `exclude`.", "question_id": 1201},
{"snippet": "DataFrame.from_records(data, index=None, columns=None)", "intent": "Convert structured or record ndarray to DataFrame . Data can be provided as a list of tuples with corresponding `columns` : With arguments `data`, `index`.", "question_id": 1202},
{"snippet": "DataFrame.from_records(data, index=None, coerce_float=False)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `index`, `coerce_float`.", "question_id": 1203},
{"snippet": "DataFrame.from_records(data, index=None, nrows=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `index`, `nrows`.", "question_id": 1204},
{"snippet": "DataFrame.from_records(data)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`.", "question_id": 1205},
{"snippet": "DataFrame.from_records(data, index=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `index`.", "question_id": 1206},
{"snippet": "DataFrame.from_records(data, exclude=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `exclude`.", "question_id": 1207},
{"snippet": "DataFrame.from_records(data, columns=None)", "intent": "Convert structured or record ndarray to DataFrame . Data can be provided as a list of tuples with corresponding `columns` : With arguments `data`.", "question_id": 1208},
{"snippet": "DataFrame.from_records(data, coerce_float=False)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `coerce_float`.", "question_id": 1209},
{"snippet": "DataFrame.from_records(data, nrows=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `nrows`.", "question_id": 1210},
{"snippet": "DataFrame.from_records(data, index=None, exclude=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `index`, `exclude`.", "question_id": 1211},
{"snippet": "DataFrame.from_records(data, index=None, columns=None)", "intent": "Convert structured or record ndarray to DataFrame . Data can be provided as a list of tuples with corresponding `columns` : With arguments `data`, `index`.", "question_id": 1212},
{"snippet": "DataFrame.from_records(data, index=None, coerce_float=False)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `index`, `coerce_float`.", "question_id": 1213},
{"snippet": "DataFrame.from_records(data, index=None, nrows=None)", "intent": "Convert structured or record ndarray to DataFrame . With arguments `data`, `index`, `nrows`.", "question_id": 1214},
{"snippet": "DataFrame.ge(other)", "intent": "Get Greater than or equal to of dataframe and `other` , element-wise ( binary operator ge ) .", "question_id": 1215},
{"snippet": "DataFrame.ge(other, axis='columns')", "intent": "Get Greater than or equal to of dataframe and `other` , element-wise ( binary operator ge ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1216},
{"snippet": "DataFrame.ge(other, level=None)", "intent": "Get Greater than or equal to of dataframe and `other` , element-wise ( binary operator ge ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1217},
{"snippet": "DataFrame.ge(other, axis='columns', level=None)", "intent": "Get Greater than or equal to of dataframe and `other` , element-wise ( binary operator ge ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1218},
{"snippet": "DataFrame.ge(other)", "intent": "Get Greater than or equal to of dataframe and `other` , element-wise ( binary operator ge ) .", "question_id": 1219},
{"snippet": "DataFrame.ge(other, axis='columns')", "intent": "Get Greater than or equal to of dataframe and `other` , element-wise ( binary operator ge ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1220},
{"snippet": "DataFrame.ge(other, level=None)", "intent": "Get Greater than or equal to of dataframe and `other` , element-wise ( binary operator ge ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1221},
{"snippet": "DataFrame.ge(other, axis='columns', level=None)", "intent": "Get Greater than or equal to of dataframe and `other` , element-wise ( binary operator ge ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1222},
{"snippet": "DataFrame.ge(other)", "intent": "Get Greater than or equal to of dataframe and `other` , element-wise ( binary operator ge ) .", "question_id": 1223},
{"snippet": "DataFrame.ge(other, axis='columns')", "intent": "Get Greater than or equal to of dataframe and `other` , element-wise ( binary operator ge ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1224},
{"snippet": "DataFrame.ge(other, level=None)", "intent": "Get Greater than or equal to of dataframe and `other` , element-wise ( binary operator ge ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1225},
{"snippet": "DataFrame.ge(other, axis='columns', level=None)", "intent": "Get Greater than or equal to of dataframe and `other` , element-wise ( binary operator ge ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1226},
{"snippet": "DataFrame.get(key)", "intent": "Get item from object for given `key` ( ex : DataFrame column ) .", "question_id": 1227},
{"snippet": "DataFrame.get(key, default=None)", "intent": "Get item from object for given `key` ( ex : DataFrame column ) . Returns `default` value if not found .", "question_id": 1228},
{"snippet": "DataFrame.get(key)", "intent": "Get item from object for given `key` ( ex : DataFrame column ) .", "question_id": 1229},
{"snippet": "DataFrame.get(key, default=None)", "intent": "Get item from object for given `key` ( ex : DataFrame column ) . Returns `default` value if not found .", "question_id": 1230},
{"snippet": "DataFrame.get(key)", "intent": "Get item from object for given `key` ( ex : DataFrame column ) .", "question_id": 1231},
{"snippet": "DataFrame.get(key, default=None)", "intent": "Get item from object for given `key` ( ex : DataFrame column ) . Returns `default` value if not found .", "question_id": 1232},
{"snippet": "DataFrame.groupby()", "intent": "Group DataFrame using a mapper or `by` a Series of columns .", "question_id": 1233},
{"snippet": "DataFrame.groupby(by=None)", "intent": "Group DataFrame using a mapper or `by` a Series of columns .", "question_id": 1234},
{"snippet": "DataFrame.groupby(axis=0)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `axis`.", "question_id": 1235},
{"snippet": "DataFrame.groupby(level=None)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . We can groupby different levels of a hierarchical index using the `level` parameter :", "question_id": 1236},
{"snippet": "DataFrame.groupby(as_index=True)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `as_index`.", "question_id": 1237},
{"snippet": "DataFrame.groupby(sort=True)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `sort`.", "question_id": 1238},
{"snippet": "DataFrame.groupby(group_keys=True)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `group_keys`.", "question_id": 1239},
{"snippet": "DataFrame.groupby(squeeze=NoDefault.no_default)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `squeeze`.", "question_id": 1240},
{"snippet": "DataFrame.groupby(observed=False)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `observed`.", "question_id": 1241},
{"snippet": "DataFrame.groupby(dropna=True)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . We can also choose to include NA in group keys or not by setting `dropna` parameter , the default setting is True :", "question_id": 1242},
{"snippet": "DataFrame.groupby()", "intent": "Group DataFrame using a mapper or `by` a Series of columns .", "question_id": 1243},
{"snippet": "DataFrame.groupby(by=None)", "intent": "Group DataFrame using a mapper or `by` a Series of columns .", "question_id": 1244},
{"snippet": "DataFrame.groupby(axis=0)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `axis`.", "question_id": 1245},
{"snippet": "DataFrame.groupby(level=None)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . We can groupby different levels of a hierarchical index using the `level` parameter :", "question_id": 1246},
{"snippet": "DataFrame.groupby(as_index=True)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `as_index`.", "question_id": 1247},
{"snippet": "DataFrame.groupby(sort=True)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `sort`.", "question_id": 1248},
{"snippet": "DataFrame.groupby(group_keys=True)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `group_keys`.", "question_id": 1249},
{"snippet": "DataFrame.groupby(squeeze=NoDefault.no_default)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `squeeze`.", "question_id": 1250},
{"snippet": "DataFrame.groupby(observed=False)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `observed`.", "question_id": 1251},
{"snippet": "DataFrame.groupby(dropna=True)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . We can also choose to include NA in group keys or not by setting `dropna` parameter , the default setting is True :", "question_id": 1252},
{"snippet": "DataFrame.groupby()", "intent": "Group DataFrame using a mapper or `by` a Series of columns .", "question_id": 1253},
{"snippet": "DataFrame.groupby(by=None)", "intent": "Group DataFrame using a mapper or `by` a Series of columns .", "question_id": 1254},
{"snippet": "DataFrame.groupby(axis=0)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `axis`.", "question_id": 1255},
{"snippet": "DataFrame.groupby(level=None)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . We can groupby different levels of a hierarchical index using the `level` parameter :", "question_id": 1256},
{"snippet": "DataFrame.groupby(as_index=True)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `as_index`.", "question_id": 1257},
{"snippet": "DataFrame.groupby(sort=True)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `sort`.", "question_id": 1258},
{"snippet": "DataFrame.groupby(group_keys=True)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `group_keys`.", "question_id": 1259},
{"snippet": "DataFrame.groupby(squeeze=NoDefault.no_default)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `squeeze`.", "question_id": 1260},
{"snippet": "DataFrame.groupby(observed=False)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . With arguments `observed`.", "question_id": 1261},
{"snippet": "DataFrame.groupby(dropna=True)", "intent": "Group DataFrame using a mapper or `by` a Series of columns . We can also choose to include NA in group keys or not by setting `dropna` parameter , the default setting is True :", "question_id": 1262},
{"snippet": "DataFrame.gt(other)", "intent": "Get Greater than of dataframe and `other` , element-wise ( binary operator gt ) .", "question_id": 1263},
{"snippet": "DataFrame.gt(other, axis='columns')", "intent": "Get Greater than of dataframe and `other` , element-wise ( binary operator gt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1264},
{"snippet": "DataFrame.gt(other, level=None)", "intent": "Get Greater than of dataframe and `other` , element-wise ( binary operator gt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1265},
{"snippet": "DataFrame.gt(other, axis='columns', level=None)", "intent": "Get Greater than of dataframe and `other` , element-wise ( binary operator gt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1266},
{"snippet": "DataFrame.gt(other)", "intent": "Get Greater than of dataframe and `other` , element-wise ( binary operator gt ) .", "question_id": 1267},
{"snippet": "DataFrame.gt(other, axis='columns')", "intent": "Get Greater than of dataframe and `other` , element-wise ( binary operator gt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1268},
{"snippet": "DataFrame.gt(other, level=None)", "intent": "Get Greater than of dataframe and `other` , element-wise ( binary operator gt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1269},
{"snippet": "DataFrame.gt(other, axis='columns', level=None)", "intent": "Get Greater than of dataframe and `other` , element-wise ( binary operator gt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1270},
{"snippet": "DataFrame.gt(other)", "intent": "Get Greater than of dataframe and `other` , element-wise ( binary operator gt ) .", "question_id": 1271},
{"snippet": "DataFrame.gt(other, axis='columns')", "intent": "Get Greater than of dataframe and `other` , element-wise ( binary operator gt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1272},
{"snippet": "DataFrame.gt(other, level=None)", "intent": "Get Greater than of dataframe and `other` , element-wise ( binary operator gt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1273},
{"snippet": "DataFrame.gt(other, axis='columns', level=None)", "intent": "Get Greater than of dataframe and `other` , element-wise ( binary operator gt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1274},
{"snippet": "DataFrame.head()", "intent": "Return the first `n` rows .", "question_id": 1275},
{"snippet": "DataFrame.head(n=5)", "intent": "Return the first `n` rows .", "question_id": 1276},
{"snippet": "DataFrame.head()", "intent": "Return the first `n` rows .", "question_id": 1277},
{"snippet": "DataFrame.head(n=5)", "intent": "Return the first `n` rows .", "question_id": 1278},
{"snippet": "DataFrame.head()", "intent": "Return the first `n` rows .", "question_id": 1279},
{"snippet": "DataFrame.head(n=5)", "intent": "Return the first `n` rows .", "question_id": 1280},
{"snippet": "DataFrame.hist(**kwargs)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`.", "question_id": 1281},
{"snippet": "DataFrame.hist(**kwargs, column=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . This function calls matplotlib.pyplot.hist ( ) , on each series in the DataFrame , resulting in one histogram per `column` . With arguments `**kwargs`.", "question_id": 1282},
{"snippet": "DataFrame.hist(**kwargs, by=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `by`.", "question_id": 1283},
{"snippet": "DataFrame.hist(**kwargs, grid=True)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `grid`.", "question_id": 1284},
{"snippet": "DataFrame.hist(**kwargs, xlabelsize=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `xlabelsize`.", "question_id": 1285},
{"snippet": "DataFrame.hist(**kwargs, xrot=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `xrot`.", "question_id": 1286},
{"snippet": "DataFrame.hist(**kwargs, ylabelsize=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `ylabelsize`.", "question_id": 1287},
{"snippet": "DataFrame.hist(**kwargs, yrot=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `yrot`.", "question_id": 1288},
{"snippet": "DataFrame.hist(**kwargs, ax=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `ax`.", "question_id": 1289},
{"snippet": "DataFrame.hist(**kwargs, sharex=False)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `sharex`.", "question_id": 1290},
{"snippet": "DataFrame.hist(**kwargs)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`.", "question_id": 1291},
{"snippet": "DataFrame.hist(**kwargs, column=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . This function calls matplotlib.pyplot.hist ( ) , on each series in the DataFrame , resulting in one histogram per `column` . With arguments `**kwargs`.", "question_id": 1292},
{"snippet": "DataFrame.hist(**kwargs, by=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `by`.", "question_id": 1293},
{"snippet": "DataFrame.hist(**kwargs, grid=True)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `grid`.", "question_id": 1294},
{"snippet": "DataFrame.hist(**kwargs, xlabelsize=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `xlabelsize`.", "question_id": 1295},
{"snippet": "DataFrame.hist(**kwargs, xrot=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `xrot`.", "question_id": 1296},
{"snippet": "DataFrame.hist(**kwargs, ylabelsize=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `ylabelsize`.", "question_id": 1297},
{"snippet": "DataFrame.hist(**kwargs, yrot=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `yrot`.", "question_id": 1298},
{"snippet": "DataFrame.hist(**kwargs, ax=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `ax`.", "question_id": 1299},
{"snippet": "DataFrame.hist(**kwargs, sharex=False)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `sharex`.", "question_id": 1300},
{"snippet": "DataFrame.hist(**kwargs)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`.", "question_id": 1301},
{"snippet": "DataFrame.hist(**kwargs, column=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . This function calls matplotlib.pyplot.hist ( ) , on each series in the DataFrame , resulting in one histogram per `column` . With arguments `**kwargs`.", "question_id": 1302},
{"snippet": "DataFrame.hist(**kwargs, by=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `by`.", "question_id": 1303},
{"snippet": "DataFrame.hist(**kwargs, grid=True)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `grid`.", "question_id": 1304},
{"snippet": "DataFrame.hist(**kwargs, xlabelsize=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `xlabelsize`.", "question_id": 1305},
{"snippet": "DataFrame.hist(**kwargs, xrot=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `xrot`.", "question_id": 1306},
{"snippet": "DataFrame.hist(**kwargs, ylabelsize=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `ylabelsize`.", "question_id": 1307},
{"snippet": "DataFrame.hist(**kwargs, yrot=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `yrot`.", "question_id": 1308},
{"snippet": "DataFrame.hist(**kwargs, ax=None)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `ax`.", "question_id": 1309},
{"snippet": "DataFrame.hist(**kwargs, sharex=False)", "intent": "Make a histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `sharex`.", "question_id": 1310},
{"snippet": "pandas.DataFrame()", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` .", "question_id": 1311},
{"snippet": "pandas.DataFrame(data=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` .", "question_id": 1312},
{"snippet": "pandas.DataFrame(index=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . With arguments `index`.", "question_id": 1313},
{"snippet": "pandas.DataFrame(columns=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . Data structure also contains labeled axes ( rows and `columns` ) .", "question_id": 1314},
{"snippet": "pandas.DataFrame(dtype=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . Notice that the inferred `dtype` is int64 .", "question_id": 1315},
{"snippet": "pandas.DataFrame(copy=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . With arguments `copy`.", "question_id": 1316},
{"snippet": "pandas.DataFrame(data=None, index=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . With arguments `index`.", "question_id": 1317},
{"snippet": "pandas.DataFrame(data=None, columns=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . Data structure also contains labeled axes ( rows and `columns` ) .", "question_id": 1318},
{"snippet": "pandas.DataFrame(data=None, dtype=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . Notice that the inferred `dtype` is int64 .", "question_id": 1319},
{"snippet": "pandas.DataFrame(data=None, copy=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . With arguments `copy`.", "question_id": 1320},
{"snippet": "pandas.DataFrame()", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` .", "question_id": 1321},
{"snippet": "pandas.DataFrame(data=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` .", "question_id": 1322},
{"snippet": "pandas.DataFrame(index=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . With arguments `index`.", "question_id": 1323},
{"snippet": "pandas.DataFrame(columns=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . Data structure also contains labeled axes ( rows and `columns` ) .", "question_id": 1324},
{"snippet": "pandas.DataFrame(dtype=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . Notice that the inferred `dtype` is int64 .", "question_id": 1325},
{"snippet": "pandas.DataFrame(copy=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . With arguments `copy`.", "question_id": 1326},
{"snippet": "pandas.DataFrame(data=None, index=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . With arguments `index`.", "question_id": 1327},
{"snippet": "pandas.DataFrame(data=None, columns=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . Data structure also contains labeled axes ( rows and `columns` ) .", "question_id": 1328},
{"snippet": "pandas.DataFrame(data=None, dtype=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . Notice that the inferred `dtype` is int64 .", "question_id": 1329},
{"snippet": "pandas.DataFrame(data=None, copy=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . With arguments `copy`.", "question_id": 1330},
{"snippet": "pandas.DataFrame()", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` .", "question_id": 1331},
{"snippet": "pandas.DataFrame(data=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` .", "question_id": 1332},
{"snippet": "pandas.DataFrame(index=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . With arguments `index`.", "question_id": 1333},
{"snippet": "pandas.DataFrame(columns=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . Data structure also contains labeled axes ( rows and `columns` ) .", "question_id": 1334},
{"snippet": "pandas.DataFrame(dtype=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . Notice that the inferred `dtype` is int64 .", "question_id": 1335},
{"snippet": "pandas.DataFrame(copy=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . With arguments `copy`.", "question_id": 1336},
{"snippet": "pandas.DataFrame(data=None, index=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . With arguments `index`.", "question_id": 1337},
{"snippet": "pandas.DataFrame(data=None, columns=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . Data structure also contains labeled axes ( rows and `columns` ) .", "question_id": 1338},
{"snippet": "pandas.DataFrame(data=None, dtype=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . Notice that the inferred `dtype` is int64 .", "question_id": 1339},
{"snippet": "pandas.DataFrame(data=None, copy=None)", "intent": "Two-dimensional , size-mutable , potentially heterogeneous tabular `data` . With arguments `copy`.", "question_id": 1340},
{"snippet": "DataFrame.idxmax()", "intent": "Return index of first occurrence of maximum over requested `axis` .", "question_id": 1341},
{"snippet": "DataFrame.idxmax(axis=0)", "intent": "Return index of first occurrence of maximum over requested `axis` .", "question_id": 1342},
{"snippet": "DataFrame.idxmax(skipna=True)", "intent": "Return index of first occurrence of maximum over requested `axis` . With arguments `skipna`.", "question_id": 1343},
{"snippet": "DataFrame.idxmax(axis=0, skipna=True)", "intent": "Return index of first occurrence of maximum over requested `axis` . With arguments `skipna`.", "question_id": 1344},
{"snippet": "DataFrame.idxmax()", "intent": "Return index of first occurrence of maximum over requested `axis` .", "question_id": 1345},
{"snippet": "DataFrame.idxmax(axis=0)", "intent": "Return index of first occurrence of maximum over requested `axis` .", "question_id": 1346},
{"snippet": "DataFrame.idxmax(skipna=True)", "intent": "Return index of first occurrence of maximum over requested `axis` . With arguments `skipna`.", "question_id": 1347},
{"snippet": "DataFrame.idxmax(axis=0, skipna=True)", "intent": "Return index of first occurrence of maximum over requested `axis` . With arguments `skipna`.", "question_id": 1348},
{"snippet": "DataFrame.idxmax()", "intent": "Return index of first occurrence of maximum over requested `axis` .", "question_id": 1349},
{"snippet": "DataFrame.idxmax(axis=0)", "intent": "Return index of first occurrence of maximum over requested `axis` .", "question_id": 1350},
{"snippet": "DataFrame.idxmax(skipna=True)", "intent": "Return index of first occurrence of maximum over requested `axis` . With arguments `skipna`.", "question_id": 1351},
{"snippet": "DataFrame.idxmax(axis=0, skipna=True)", "intent": "Return index of first occurrence of maximum over requested `axis` . With arguments `skipna`.", "question_id": 1352},
{"snippet": "DataFrame.idxmin()", "intent": "Return index of first occurrence of minimum over requested `axis` .", "question_id": 1353},
{"snippet": "DataFrame.idxmin(axis=0)", "intent": "Return index of first occurrence of minimum over requested `axis` .", "question_id": 1354},
{"snippet": "DataFrame.idxmin(skipna=True)", "intent": "Return index of first occurrence of minimum over requested `axis` . With arguments `skipna`.", "question_id": 1355},
{"snippet": "DataFrame.idxmin(axis=0, skipna=True)", "intent": "Return index of first occurrence of minimum over requested `axis` . With arguments `skipna`.", "question_id": 1356},
{"snippet": "DataFrame.idxmin()", "intent": "Return index of first occurrence of minimum over requested `axis` .", "question_id": 1357},
{"snippet": "DataFrame.idxmin(axis=0)", "intent": "Return index of first occurrence of minimum over requested `axis` .", "question_id": 1358},
{"snippet": "DataFrame.idxmin(skipna=True)", "intent": "Return index of first occurrence of minimum over requested `axis` . With arguments `skipna`.", "question_id": 1359},
{"snippet": "DataFrame.idxmin(axis=0, skipna=True)", "intent": "Return index of first occurrence of minimum over requested `axis` . With arguments `skipna`.", "question_id": 1360},
{"snippet": "DataFrame.idxmin()", "intent": "Return index of first occurrence of minimum over requested `axis` .", "question_id": 1361},
{"snippet": "DataFrame.idxmin(axis=0)", "intent": "Return index of first occurrence of minimum over requested `axis` .", "question_id": 1362},
{"snippet": "DataFrame.idxmin(skipna=True)", "intent": "Return index of first occurrence of minimum over requested `axis` . With arguments `skipna`.", "question_id": 1363},
{"snippet": "DataFrame.idxmin(axis=0, skipna=True)", "intent": "Return index of first occurrence of minimum over requested `axis` . With arguments `skipna`.", "question_id": 1364},
{"snippet": "DataFrame.index", "intent": "The index (row labels) of the DataFrame.", "question_id": 1365},
{"snippet": "DataFrame.index", "intent": "The index (row labels) of the DataFrame.", "question_id": 1366},
{"snippet": "DataFrame.index", "intent": "The index (row labels) of the DataFrame.", "question_id": 1367},
{"snippet": "DataFrame.infer_objects()", "intent": "Attempt to infer better dtypes for object columns .", "question_id": 1368},
{"snippet": "DataFrame.infer_objects()", "intent": "Attempt to infer better dtypes for object columns .", "question_id": 1369},
{"snippet": "DataFrame.infer_objects()", "intent": "Attempt to infer better dtypes for object columns .", "question_id": 1370},
{"snippet": "DataFrame.info()", "intent": "Print a concise summary of a DataFrame .", "question_id": 1371},
{"snippet": "DataFrame.info(verbose=None)", "intent": "Print a concise summary of a DataFrame . With arguments `verbose`.", "question_id": 1372},
{"snippet": "DataFrame.info(buf=None)", "intent": "Print a concise summary of a DataFrame . With arguments `buf`.", "question_id": 1373},
{"snippet": "DataFrame.info(max_cols=None)", "intent": "Print a concise summary of a DataFrame . With arguments `max_cols`.", "question_id": 1374},
{"snippet": "DataFrame.info(memory_usage=None)", "intent": "Print a concise summary of a DataFrame . The `memory_usage` parameter allows deep introspection mode , specially useful for big DataFrames and fine-tune memory optimization :", "question_id": 1375},
{"snippet": "DataFrame.info(show_counts=None)", "intent": "Print a concise summary of a DataFrame . With arguments `show_counts`.", "question_id": 1376},
{"snippet": "DataFrame.info(null_counts=None)", "intent": "Print a concise summary of a DataFrame . With arguments `null_counts`.", "question_id": 1377},
{"snippet": "DataFrame.info(verbose=None, buf=None)", "intent": "Print a concise summary of a DataFrame . With arguments `verbose`, `buf`.", "question_id": 1378},
{"snippet": "DataFrame.info(verbose=None, max_cols=None)", "intent": "Print a concise summary of a DataFrame . With arguments `verbose`, `max_cols`.", "question_id": 1379},
{"snippet": "DataFrame.info(verbose=None, memory_usage=None)", "intent": "Print a concise summary of a DataFrame . The `memory_usage` parameter allows deep introspection mode , specially useful for big DataFrames and fine-tune memory optimization : With arguments `verbose`.", "question_id": 1380},
{"snippet": "DataFrame.info()", "intent": "Print a concise summary of a DataFrame .", "question_id": 1381},
{"snippet": "DataFrame.info(verbose=None)", "intent": "Print a concise summary of a DataFrame . With arguments `verbose`.", "question_id": 1382},
{"snippet": "DataFrame.info(buf=None)", "intent": "Print a concise summary of a DataFrame . With arguments `buf`.", "question_id": 1383},
{"snippet": "DataFrame.info(max_cols=None)", "intent": "Print a concise summary of a DataFrame . With arguments `max_cols`.", "question_id": 1384},
{"snippet": "DataFrame.info(memory_usage=None)", "intent": "Print a concise summary of a DataFrame . The `memory_usage` parameter allows deep introspection mode , specially useful for big DataFrames and fine-tune memory optimization :", "question_id": 1385},
{"snippet": "DataFrame.info(show_counts=None)", "intent": "Print a concise summary of a DataFrame . With arguments `show_counts`.", "question_id": 1386},
{"snippet": "DataFrame.info(null_counts=None)", "intent": "Print a concise summary of a DataFrame . With arguments `null_counts`.", "question_id": 1387},
{"snippet": "DataFrame.info(verbose=None, buf=None)", "intent": "Print a concise summary of a DataFrame . With arguments `verbose`, `buf`.", "question_id": 1388},
{"snippet": "DataFrame.info(verbose=None, max_cols=None)", "intent": "Print a concise summary of a DataFrame . With arguments `verbose`, `max_cols`.", "question_id": 1389},
{"snippet": "DataFrame.info(verbose=None, memory_usage=None)", "intent": "Print a concise summary of a DataFrame . The `memory_usage` parameter allows deep introspection mode , specially useful for big DataFrames and fine-tune memory optimization : With arguments `verbose`.", "question_id": 1390},
{"snippet": "DataFrame.info()", "intent": "Print a concise summary of a DataFrame .", "question_id": 1391},
{"snippet": "DataFrame.info(verbose=None)", "intent": "Print a concise summary of a DataFrame . With arguments `verbose`.", "question_id": 1392},
{"snippet": "DataFrame.info(buf=None)", "intent": "Print a concise summary of a DataFrame . With arguments `buf`.", "question_id": 1393},
{"snippet": "DataFrame.info(max_cols=None)", "intent": "Print a concise summary of a DataFrame . With arguments `max_cols`.", "question_id": 1394},
{"snippet": "DataFrame.info(memory_usage=None)", "intent": "Print a concise summary of a DataFrame . The `memory_usage` parameter allows deep introspection mode , specially useful for big DataFrames and fine-tune memory optimization :", "question_id": 1395},
{"snippet": "DataFrame.info(show_counts=None)", "intent": "Print a concise summary of a DataFrame . With arguments `show_counts`.", "question_id": 1396},
{"snippet": "DataFrame.info(null_counts=None)", "intent": "Print a concise summary of a DataFrame . With arguments `null_counts`.", "question_id": 1397},
{"snippet": "DataFrame.info(verbose=None, buf=None)", "intent": "Print a concise summary of a DataFrame . With arguments `verbose`, `buf`.", "question_id": 1398},
{"snippet": "DataFrame.info(verbose=None, max_cols=None)", "intent": "Print a concise summary of a DataFrame . With arguments `verbose`, `max_cols`.", "question_id": 1399},
{"snippet": "DataFrame.info(verbose=None, memory_usage=None)", "intent": "Print a concise summary of a DataFrame . The `memory_usage` parameter allows deep introspection mode , specially useful for big DataFrames and fine-tune memory optimization : With arguments `verbose`.", "question_id": 1400},
{"snippet": "DataFrame.insert(loc, column, value)", "intent": "Insert `column` into DataFrame at specified location . Notice that pandas uses index alignment in case of `value` from type Series : With arguments `loc`.", "question_id": 1401},
{"snippet": "DataFrame.insert(loc, column, value, allow_duplicates=False)", "intent": "Insert `column` into DataFrame at specified location . Notice that pandas uses index alignment in case of `value` from type Series : Raises a ValueError if column is already contained in the DataFrame , unless `allow_duplicates` is set to True . With arguments `loc`.", "question_id": 1402},
{"snippet": "DataFrame.insert(loc, column, value)", "intent": "Insert `column` into DataFrame at specified location . Notice that pandas uses index alignment in case of `value` from type Series : With arguments `loc`.", "question_id": 1403},
{"snippet": "DataFrame.insert(loc, column, value, allow_duplicates=False)", "intent": "Insert `column` into DataFrame at specified location . Notice that pandas uses index alignment in case of `value` from type Series : Raises a ValueError if column is already contained in the DataFrame , unless `allow_duplicates` is set to True . With arguments `loc`.", "question_id": 1404},
{"snippet": "DataFrame.insert(loc, column, value)", "intent": "Insert `column` into DataFrame at specified location . Notice that pandas uses index alignment in case of `value` from type Series : With arguments `loc`.", "question_id": 1405},
{"snippet": "DataFrame.insert(loc, column, value, allow_duplicates=False)", "intent": "Insert `column` into DataFrame at specified location . Notice that pandas uses index alignment in case of `value` from type Series : Raises a ValueError if column is already contained in the DataFrame , unless `allow_duplicates` is set to True . With arguments `loc`.", "question_id": 1406},
{"snippet": "DataFrame.interpolate(**kwargs)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 1407},
{"snippet": "DataFrame.interpolate(**kwargs, method='linear')", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 1408},
{"snippet": "DataFrame.interpolate(**kwargs, axis=0)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 1409},
{"snippet": "DataFrame.interpolate(**kwargs, limit=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 1410},
{"snippet": "DataFrame.interpolate(**kwargs, inplace=False)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `inplace`.", "question_id": 1411},
{"snippet": "DataFrame.interpolate(**kwargs, limit_direction=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit_direction`.", "question_id": 1412},
{"snippet": "DataFrame.interpolate(**kwargs, limit_area=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit_area`.", "question_id": 1413},
{"snippet": "DataFrame.interpolate(**kwargs, downcast=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `downcast`.", "question_id": 1414},
{"snippet": "DataFrame.interpolate(**kwargs, method='linear', axis=0)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 1415},
{"snippet": "DataFrame.interpolate(**kwargs, method='linear', limit=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 1416},
{"snippet": "DataFrame.interpolate(**kwargs)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 1417},
{"snippet": "DataFrame.interpolate(**kwargs, method='linear')", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 1418},
{"snippet": "DataFrame.interpolate(**kwargs, axis=0)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 1419},
{"snippet": "DataFrame.interpolate(**kwargs, limit=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 1420},
{"snippet": "DataFrame.interpolate(**kwargs, inplace=False)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `inplace`.", "question_id": 1421},
{"snippet": "DataFrame.interpolate(**kwargs, limit_direction=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit_direction`.", "question_id": 1422},
{"snippet": "DataFrame.interpolate(**kwargs, limit_area=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit_area`.", "question_id": 1423},
{"snippet": "DataFrame.interpolate(**kwargs, downcast=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `downcast`.", "question_id": 1424},
{"snippet": "DataFrame.interpolate(**kwargs, method='linear', axis=0)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 1425},
{"snippet": "DataFrame.interpolate(**kwargs, method='linear', limit=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 1426},
{"snippet": "DataFrame.interpolate(**kwargs)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 1427},
{"snippet": "DataFrame.interpolate(**kwargs, method='linear')", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 1428},
{"snippet": "DataFrame.interpolate(**kwargs, axis=0)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 1429},
{"snippet": "DataFrame.interpolate(**kwargs, limit=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 1430},
{"snippet": "DataFrame.interpolate(**kwargs, inplace=False)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `inplace`.", "question_id": 1431},
{"snippet": "DataFrame.interpolate(**kwargs, limit_direction=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit_direction`.", "question_id": 1432},
{"snippet": "DataFrame.interpolate(**kwargs, limit_area=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit_area`.", "question_id": 1433},
{"snippet": "DataFrame.interpolate(**kwargs, downcast=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `downcast`.", "question_id": 1434},
{"snippet": "DataFrame.interpolate(**kwargs, method='linear', axis=0)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 1435},
{"snippet": "DataFrame.interpolate(**kwargs, method='linear', limit=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 1436},
{"snippet": "DataFrame.isin(values)", "intent": "Whether each element in the DataFrame is contained in `values` .", "question_id": 1437},
{"snippet": "DataFrame.isin(values)", "intent": "Whether each element in the DataFrame is contained in `values` .", "question_id": 1438},
{"snippet": "DataFrame.isin(values)", "intent": "Whether each element in the DataFrame is contained in `values` .", "question_id": 1439},
{"snippet": "DataFrame.isna()", "intent": "Detect missing values .", "question_id": 1440},
{"snippet": "DataFrame.isna()", "intent": "Detect missing values .", "question_id": 1441},
{"snippet": "DataFrame.isna()", "intent": "Detect missing values .", "question_id": 1442},
{"snippet": "DataFrame.isnull()", "intent": "Detect missing values .", "question_id": 1443},
{"snippet": "DataFrame.isnull()", "intent": "Detect missing values .", "question_id": 1444},
{"snippet": "DataFrame.isnull()", "intent": "Detect missing values .", "question_id": 1445},
{"snippet": "DataFrame.items()", "intent": "Iterate over ( column name , Series ) pairs .", "question_id": 1446},
{"snippet": "DataFrame.items()", "intent": "Iterate over ( column name , Series ) pairs .", "question_id": 1447},
{"snippet": "DataFrame.items()", "intent": "Iterate over ( column name , Series ) pairs .", "question_id": 1448},
{"snippet": "DataFrame.iteritems()", "intent": "Iterate over ( column name , Series ) pairs .", "question_id": 1449},
{"snippet": "DataFrame.iteritems()", "intent": "Iterate over ( column name , Series ) pairs .", "question_id": 1450},
{"snippet": "DataFrame.iteritems()", "intent": "Iterate over ( column name , Series ) pairs .", "question_id": 1451},
{"snippet": "DataFrame.iterrows()", "intent": "Iterate over DataFrame rows as ( index , Series ) pairs .", "question_id": 1452},
{"snippet": "DataFrame.iterrows()", "intent": "Iterate over DataFrame rows as ( index , Series ) pairs .", "question_id": 1453},
{"snippet": "DataFrame.iterrows()", "intent": "Iterate over DataFrame rows as ( index , Series ) pairs .", "question_id": 1454},
{"snippet": "DataFrame.itertuples()", "intent": "Iterate over DataFrame rows as namedtuples .", "question_id": 1455},
{"snippet": "DataFrame.itertuples(index=True)", "intent": "Iterate over DataFrame rows as namedtuples . By setting the `index` parameter to False we can remove the index as the first element of the tuple :", "question_id": 1456},
{"snippet": "DataFrame.itertuples(name='Pandas')", "intent": "Iterate over DataFrame rows as namedtuples . With the `name` parameter set we set a custom name for the yielded namedtuples :", "question_id": 1457},
{"snippet": "DataFrame.itertuples(index=True, name='Pandas')", "intent": "Iterate over DataFrame rows as namedtuples . By setting the `index` parameter to False we can remove the index as the first element of the tuple : With the `name` parameter set we set a custom name for the yielded namedtuples :", "question_id": 1458},
{"snippet": "DataFrame.itertuples()", "intent": "Iterate over DataFrame rows as namedtuples .", "question_id": 1459},
{"snippet": "DataFrame.itertuples(index=True)", "intent": "Iterate over DataFrame rows as namedtuples . By setting the `index` parameter to False we can remove the index as the first element of the tuple :", "question_id": 1460},
{"snippet": "DataFrame.itertuples(name='Pandas')", "intent": "Iterate over DataFrame rows as namedtuples . With the `name` parameter set we set a custom name for the yielded namedtuples :", "question_id": 1461},
{"snippet": "DataFrame.itertuples(index=True, name='Pandas')", "intent": "Iterate over DataFrame rows as namedtuples . By setting the `index` parameter to False we can remove the index as the first element of the tuple : With the `name` parameter set we set a custom name for the yielded namedtuples :", "question_id": 1462},
{"snippet": "DataFrame.itertuples()", "intent": "Iterate over DataFrame rows as namedtuples .", "question_id": 1463},
{"snippet": "DataFrame.itertuples(index=True)", "intent": "Iterate over DataFrame rows as namedtuples . By setting the `index` parameter to False we can remove the index as the first element of the tuple :", "question_id": 1464},
{"snippet": "DataFrame.itertuples(name='Pandas')", "intent": "Iterate over DataFrame rows as namedtuples . With the `name` parameter set we set a custom name for the yielded namedtuples :", "question_id": 1465},
{"snippet": "DataFrame.itertuples(index=True, name='Pandas')", "intent": "Iterate over DataFrame rows as namedtuples . By setting the `index` parameter to False we can remove the index as the first element of the tuple : With the `name` parameter set we set a custom name for the yielded namedtuples :", "question_id": 1466},
{"snippet": "DataFrame.join(other)", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column .", "question_id": 1467},
{"snippet": "DataFrame.join(other, on=None)", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column .", "question_id": 1468},
{"snippet": "DataFrame.join(other, how='left')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . With arguments `how`.", "question_id": 1469},
{"snippet": "DataFrame.join(other, lsuffix='')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . Parameters on , `lsuffix` , and `rsuffix` are not supported when passing a list of DataFrame objects .", "question_id": 1470},
{"snippet": "DataFrame.join(other, rsuffix='')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . Parameters on , `lsuffix` , and `rsuffix` are not supported when passing a list of DataFrame objects .", "question_id": 1471},
{"snippet": "DataFrame.join(other, sort=False)", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . With arguments `sort`.", "question_id": 1472},
{"snippet": "DataFrame.join(other, on=None, how='left')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . With arguments `how`.", "question_id": 1473},
{"snippet": "DataFrame.join(other, on=None, lsuffix='')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . Parameters on , `lsuffix` , and `rsuffix` are not supported when passing a list of DataFrame objects .", "question_id": 1474},
{"snippet": "DataFrame.join(other, on=None, rsuffix='')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . Parameters on , `lsuffix` , and `rsuffix` are not supported when passing a list of DataFrame objects .", "question_id": 1475},
{"snippet": "DataFrame.join(other, on=None, sort=False)", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . With arguments `sort`.", "question_id": 1476},
{"snippet": "DataFrame.join(other)", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column .", "question_id": 1477},
{"snippet": "DataFrame.join(other, on=None)", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column .", "question_id": 1478},
{"snippet": "DataFrame.join(other, how='left')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . With arguments `how`.", "question_id": 1479},
{"snippet": "DataFrame.join(other, lsuffix='')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . Parameters on , `lsuffix` , and `rsuffix` are not supported when passing a list of DataFrame objects .", "question_id": 1480},
{"snippet": "DataFrame.join(other, rsuffix='')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . Parameters on , `lsuffix` , and `rsuffix` are not supported when passing a list of DataFrame objects .", "question_id": 1481},
{"snippet": "DataFrame.join(other, sort=False)", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . With arguments `sort`.", "question_id": 1482},
{"snippet": "DataFrame.join(other, on=None, how='left')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . With arguments `how`.", "question_id": 1483},
{"snippet": "DataFrame.join(other, on=None, lsuffix='')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . Parameters on , `lsuffix` , and `rsuffix` are not supported when passing a list of DataFrame objects .", "question_id": 1484},
{"snippet": "DataFrame.join(other, on=None, rsuffix='')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . Parameters on , `lsuffix` , and `rsuffix` are not supported when passing a list of DataFrame objects .", "question_id": 1485},
{"snippet": "DataFrame.join(other, on=None, sort=False)", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . With arguments `sort`.", "question_id": 1486},
{"snippet": "DataFrame.join(other)", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column .", "question_id": 1487},
{"snippet": "DataFrame.join(other, on=None)", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column .", "question_id": 1488},
{"snippet": "DataFrame.join(other, how='left')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . With arguments `how`.", "question_id": 1489},
{"snippet": "DataFrame.join(other, lsuffix='')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . Parameters on , `lsuffix` , and `rsuffix` are not supported when passing a list of DataFrame objects .", "question_id": 1490},
{"snippet": "DataFrame.join(other, rsuffix='')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . Parameters on , `lsuffix` , and `rsuffix` are not supported when passing a list of DataFrame objects .", "question_id": 1491},
{"snippet": "DataFrame.join(other, sort=False)", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . With arguments `sort`.", "question_id": 1492},
{"snippet": "DataFrame.join(other, on=None, how='left')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . With arguments `how`.", "question_id": 1493},
{"snippet": "DataFrame.join(other, on=None, lsuffix='')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . Parameters on , `lsuffix` , and `rsuffix` are not supported when passing a list of DataFrame objects .", "question_id": 1494},
{"snippet": "DataFrame.join(other, on=None, rsuffix='')", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . Parameters on , `lsuffix` , and `rsuffix` are not supported when passing a list of DataFrame objects .", "question_id": 1495},
{"snippet": "DataFrame.join(other, on=None, sort=False)", "intent": "Join columns of another DataFrame . Join columns with `other` DataFrame either `on` index or on a key column . With arguments `sort`.", "question_id": 1496},
{"snippet": "DataFrame.keys()", "intent": "Get the \u2018 info axis \u2019 ( see Indexing for more ) .", "question_id": 1497},
{"snippet": "DataFrame.keys()", "intent": "Get the \u2018 info axis \u2019 ( see Indexing for more ) .", "question_id": 1498},
{"snippet": "DataFrame.keys()", "intent": "Get the \u2018 info axis \u2019 ( see Indexing for more ) .", "question_id": 1499},
{"snippet": "DataFrame.kurt(**kwargs)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 1500},
{"snippet": "DataFrame.kurt(**kwargs, axis=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 1501},
{"snippet": "DataFrame.kurt(**kwargs, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1502},
{"snippet": "DataFrame.kurt(**kwargs, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1503},
{"snippet": "DataFrame.kurt(**kwargs, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1504},
{"snippet": "DataFrame.kurt(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1505},
{"snippet": "DataFrame.kurt(**kwargs, axis=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1506},
{"snippet": "DataFrame.kurt(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1507},
{"snippet": "DataFrame.kurt(**kwargs, skipna=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1508},
{"snippet": "DataFrame.kurt(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1509},
{"snippet": "DataFrame.kurt(**kwargs)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 1510},
{"snippet": "DataFrame.kurt(**kwargs, axis=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 1511},
{"snippet": "DataFrame.kurt(**kwargs, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1512},
{"snippet": "DataFrame.kurt(**kwargs, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1513},
{"snippet": "DataFrame.kurt(**kwargs, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1514},
{"snippet": "DataFrame.kurt(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1515},
{"snippet": "DataFrame.kurt(**kwargs, axis=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1516},
{"snippet": "DataFrame.kurt(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1517},
{"snippet": "DataFrame.kurt(**kwargs, skipna=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1518},
{"snippet": "DataFrame.kurt(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1519},
{"snippet": "DataFrame.kurt(**kwargs)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 1520},
{"snippet": "DataFrame.kurt(**kwargs, axis=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 1521},
{"snippet": "DataFrame.kurt(**kwargs, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1522},
{"snippet": "DataFrame.kurt(**kwargs, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1523},
{"snippet": "DataFrame.kurt(**kwargs, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1524},
{"snippet": "DataFrame.kurt(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1525},
{"snippet": "DataFrame.kurt(**kwargs, axis=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1526},
{"snippet": "DataFrame.kurt(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1527},
{"snippet": "DataFrame.kurt(**kwargs, skipna=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1528},
{"snippet": "DataFrame.kurt(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1529},
{"snippet": "DataFrame.kurtosis(**kwargs)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 1530},
{"snippet": "DataFrame.kurtosis(**kwargs, axis=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 1531},
{"snippet": "DataFrame.kurtosis(**kwargs, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1532},
{"snippet": "DataFrame.kurtosis(**kwargs, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1533},
{"snippet": "DataFrame.kurtosis(**kwargs, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1534},
{"snippet": "DataFrame.kurtosis(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1535},
{"snippet": "DataFrame.kurtosis(**kwargs, axis=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1536},
{"snippet": "DataFrame.kurtosis(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1537},
{"snippet": "DataFrame.kurtosis(**kwargs, skipna=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1538},
{"snippet": "DataFrame.kurtosis(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1539},
{"snippet": "DataFrame.kurtosis(**kwargs)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 1540},
{"snippet": "DataFrame.kurtosis(**kwargs, axis=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 1541},
{"snippet": "DataFrame.kurtosis(**kwargs, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1542},
{"snippet": "DataFrame.kurtosis(**kwargs, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1543},
{"snippet": "DataFrame.kurtosis(**kwargs, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1544},
{"snippet": "DataFrame.kurtosis(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1545},
{"snippet": "DataFrame.kurtosis(**kwargs, axis=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1546},
{"snippet": "DataFrame.kurtosis(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1547},
{"snippet": "DataFrame.kurtosis(**kwargs, skipna=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1548},
{"snippet": "DataFrame.kurtosis(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1549},
{"snippet": "DataFrame.kurtosis(**kwargs)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 1550},
{"snippet": "DataFrame.kurtosis(**kwargs, axis=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 1551},
{"snippet": "DataFrame.kurtosis(**kwargs, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1552},
{"snippet": "DataFrame.kurtosis(**kwargs, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1553},
{"snippet": "DataFrame.kurtosis(**kwargs, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1554},
{"snippet": "DataFrame.kurtosis(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1555},
{"snippet": "DataFrame.kurtosis(**kwargs, axis=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1556},
{"snippet": "DataFrame.kurtosis(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1557},
{"snippet": "DataFrame.kurtosis(**kwargs, skipna=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1558},
{"snippet": "DataFrame.kurtosis(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1559},
{"snippet": "DataFrame.last(offset)", "intent": "Select final periods of time series data based on a date `offset` .", "question_id": 1560},
{"snippet": "DataFrame.last(offset)", "intent": "Select final periods of time series data based on a date `offset` .", "question_id": 1561},
{"snippet": "DataFrame.last(offset)", "intent": "Select final periods of time series data based on a date `offset` .", "question_id": 1562},
{"snippet": "DataFrame.last_valid_index()", "intent": "Return index for last non-NA value or None , if no NA value is found .", "question_id": 1563},
{"snippet": "DataFrame.last_valid_index()", "intent": "Return index for last non-NA value or None , if no NA value is found .", "question_id": 1564},
{"snippet": "DataFrame.last_valid_index()", "intent": "Return index for last non-NA value or None , if no NA value is found .", "question_id": 1565},
{"snippet": "DataFrame.le(other)", "intent": "Get Less than or equal to of dataframe and `other` , element-wise ( binary operator le ) .", "question_id": 1566},
{"snippet": "DataFrame.le(other, axis='columns')", "intent": "Get Less than or equal to of dataframe and `other` , element-wise ( binary operator le ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1567},
{"snippet": "DataFrame.le(other, level=None)", "intent": "Get Less than or equal to of dataframe and `other` , element-wise ( binary operator le ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1568},
{"snippet": "DataFrame.le(other, axis='columns', level=None)", "intent": "Get Less than or equal to of dataframe and `other` , element-wise ( binary operator le ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1569},
{"snippet": "DataFrame.le(other)", "intent": "Get Less than or equal to of dataframe and `other` , element-wise ( binary operator le ) .", "question_id": 1570},
{"snippet": "DataFrame.le(other, axis='columns')", "intent": "Get Less than or equal to of dataframe and `other` , element-wise ( binary operator le ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1571},
{"snippet": "DataFrame.le(other, level=None)", "intent": "Get Less than or equal to of dataframe and `other` , element-wise ( binary operator le ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1572},
{"snippet": "DataFrame.le(other, axis='columns', level=None)", "intent": "Get Less than or equal to of dataframe and `other` , element-wise ( binary operator le ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1573},
{"snippet": "DataFrame.le(other)", "intent": "Get Less than or equal to of dataframe and `other` , element-wise ( binary operator le ) .", "question_id": 1574},
{"snippet": "DataFrame.le(other, axis='columns')", "intent": "Get Less than or equal to of dataframe and `other` , element-wise ( binary operator le ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1575},
{"snippet": "DataFrame.le(other, level=None)", "intent": "Get Less than or equal to of dataframe and `other` , element-wise ( binary operator le ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1576},
{"snippet": "DataFrame.le(other, axis='columns', level=None)", "intent": "Get Less than or equal to of dataframe and `other` , element-wise ( binary operator le ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1577},
{"snippet": "DataFrame.lookup(row_labels, col_labels)", "intent": "Label-based \u201c fancy indexing \u201d function for DataFrame . With arguments `row_labels`, `col_labels`.", "question_id": 1578},
{"snippet": "DataFrame.lookup(row_labels, col_labels)", "intent": "Label-based \u201c fancy indexing \u201d function for DataFrame . With arguments `row_labels`, `col_labels`.", "question_id": 1579},
{"snippet": "DataFrame.lookup(row_labels, col_labels)", "intent": "Label-based \u201c fancy indexing \u201d function for DataFrame . With arguments `row_labels`, `col_labels`.", "question_id": 1580},
{"snippet": "DataFrame.lt(other)", "intent": "Get Less than of dataframe and `other` , element-wise ( binary operator lt ) .", "question_id": 1581},
{"snippet": "DataFrame.lt(other, axis='columns')", "intent": "Get Less than of dataframe and `other` , element-wise ( binary operator lt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1582},
{"snippet": "DataFrame.lt(other, level=None)", "intent": "Get Less than of dataframe and `other` , element-wise ( binary operator lt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1583},
{"snippet": "DataFrame.lt(other, axis='columns', level=None)", "intent": "Get Less than of dataframe and `other` , element-wise ( binary operator lt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1584},
{"snippet": "DataFrame.lt(other)", "intent": "Get Less than of dataframe and `other` , element-wise ( binary operator lt ) .", "question_id": 1585},
{"snippet": "DataFrame.lt(other, axis='columns')", "intent": "Get Less than of dataframe and `other` , element-wise ( binary operator lt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1586},
{"snippet": "DataFrame.lt(other, level=None)", "intent": "Get Less than of dataframe and `other` , element-wise ( binary operator lt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1587},
{"snippet": "DataFrame.lt(other, axis='columns', level=None)", "intent": "Get Less than of dataframe and `other` , element-wise ( binary operator lt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1588},
{"snippet": "DataFrame.lt(other)", "intent": "Get Less than of dataframe and `other` , element-wise ( binary operator lt ) .", "question_id": 1589},
{"snippet": "DataFrame.lt(other, axis='columns')", "intent": "Get Less than of dataframe and `other` , element-wise ( binary operator lt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1590},
{"snippet": "DataFrame.lt(other, level=None)", "intent": "Get Less than of dataframe and `other` , element-wise ( binary operator lt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1591},
{"snippet": "DataFrame.lt(other, axis='columns', level=None)", "intent": "Get Less than of dataframe and `other` , element-wise ( binary operator lt ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1592},
{"snippet": "DataFrame.mad()", "intent": "Return the mean absolute deviation of the values over the requested `axis` .", "question_id": 1593},
{"snippet": "DataFrame.mad(axis=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` .", "question_id": 1594},
{"snippet": "DataFrame.mad(skipna=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`.", "question_id": 1595},
{"snippet": "DataFrame.mad(level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `level`.", "question_id": 1596},
{"snippet": "DataFrame.mad(axis=None, skipna=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`.", "question_id": 1597},
{"snippet": "DataFrame.mad(axis=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `level`.", "question_id": 1598},
{"snippet": "DataFrame.mad(skipna=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`, `level`.", "question_id": 1599},
{"snippet": "DataFrame.mad(axis=None, skipna=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`, `level`.", "question_id": 1600},
{"snippet": "DataFrame.mad()", "intent": "Return the mean absolute deviation of the values over the requested `axis` .", "question_id": 1601},
{"snippet": "DataFrame.mad(axis=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` .", "question_id": 1602},
{"snippet": "DataFrame.mad(skipna=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`.", "question_id": 1603},
{"snippet": "DataFrame.mad(level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `level`.", "question_id": 1604},
{"snippet": "DataFrame.mad(axis=None, skipna=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`.", "question_id": 1605},
{"snippet": "DataFrame.mad(axis=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `level`.", "question_id": 1606},
{"snippet": "DataFrame.mad(skipna=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`, `level`.", "question_id": 1607},
{"snippet": "DataFrame.mad(axis=None, skipna=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`, `level`.", "question_id": 1608},
{"snippet": "DataFrame.mad()", "intent": "Return the mean absolute deviation of the values over the requested `axis` .", "question_id": 1609},
{"snippet": "DataFrame.mad(axis=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` .", "question_id": 1610},
{"snippet": "DataFrame.mad(skipna=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`.", "question_id": 1611},
{"snippet": "DataFrame.mad(level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `level`.", "question_id": 1612},
{"snippet": "DataFrame.mad(axis=None, skipna=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`.", "question_id": 1613},
{"snippet": "DataFrame.mad(axis=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `level`.", "question_id": 1614},
{"snippet": "DataFrame.mad(skipna=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`, `level`.", "question_id": 1615},
{"snippet": "DataFrame.mad(axis=None, skipna=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`, `level`.", "question_id": 1616},
{"snippet": "DataFrame.mask(cond)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 1617},
{"snippet": "DataFrame.mask(cond, other=nan)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 1618},
{"snippet": "DataFrame.mask(cond, inplace=False)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 1619},
{"snippet": "DataFrame.mask(cond, axis=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 1620},
{"snippet": "DataFrame.mask(cond, level=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 1621},
{"snippet": "DataFrame.mask(cond, errors='raise')", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `errors`.", "question_id": 1622},
{"snippet": "DataFrame.mask(cond, try_cast=NoDefault.no_default)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `try_cast`.", "question_id": 1623},
{"snippet": "DataFrame.mask(cond, other=nan, inplace=False)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 1624},
{"snippet": "DataFrame.mask(cond, other=nan, axis=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 1625},
{"snippet": "DataFrame.mask(cond, other=nan, level=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 1626},
{"snippet": "DataFrame.mask(cond)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 1627},
{"snippet": "DataFrame.mask(cond, other=nan)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 1628},
{"snippet": "DataFrame.mask(cond, inplace=False)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 1629},
{"snippet": "DataFrame.mask(cond, axis=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 1630},
{"snippet": "DataFrame.mask(cond, level=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 1631},
{"snippet": "DataFrame.mask(cond, errors='raise')", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `errors`.", "question_id": 1632},
{"snippet": "DataFrame.mask(cond, try_cast=NoDefault.no_default)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `try_cast`.", "question_id": 1633},
{"snippet": "DataFrame.mask(cond, other=nan, inplace=False)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 1634},
{"snippet": "DataFrame.mask(cond, other=nan, axis=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 1635},
{"snippet": "DataFrame.mask(cond, other=nan, level=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 1636},
{"snippet": "DataFrame.mask(cond)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 1637},
{"snippet": "DataFrame.mask(cond, other=nan)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 1638},
{"snippet": "DataFrame.mask(cond, inplace=False)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 1639},
{"snippet": "DataFrame.mask(cond, axis=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 1640},
{"snippet": "DataFrame.mask(cond, level=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 1641},
{"snippet": "DataFrame.mask(cond, errors='raise')", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `errors`.", "question_id": 1642},
{"snippet": "DataFrame.mask(cond, try_cast=NoDefault.no_default)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `try_cast`.", "question_id": 1643},
{"snippet": "DataFrame.mask(cond, other=nan, inplace=False)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 1644},
{"snippet": "DataFrame.mask(cond, other=nan, axis=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 1645},
{"snippet": "DataFrame.mask(cond, other=nan, level=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 1646},
{"snippet": "DataFrame.max(**kwargs)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1647},
{"snippet": "DataFrame.max(**kwargs, axis=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1648},
{"snippet": "DataFrame.max(**kwargs, skipna=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1649},
{"snippet": "DataFrame.max(**kwargs, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1650},
{"snippet": "DataFrame.max(**kwargs, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1651},
{"snippet": "DataFrame.max(**kwargs, axis=None, skipna=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1652},
{"snippet": "DataFrame.max(**kwargs, axis=None, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1653},
{"snippet": "DataFrame.max(**kwargs, axis=None, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1654},
{"snippet": "DataFrame.max(**kwargs, skipna=None, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1655},
{"snippet": "DataFrame.max(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1656},
{"snippet": "DataFrame.max(**kwargs)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1657},
{"snippet": "DataFrame.max(**kwargs, axis=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1658},
{"snippet": "DataFrame.max(**kwargs, skipna=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1659},
{"snippet": "DataFrame.max(**kwargs, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1660},
{"snippet": "DataFrame.max(**kwargs, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1661},
{"snippet": "DataFrame.max(**kwargs, axis=None, skipna=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1662},
{"snippet": "DataFrame.max(**kwargs, axis=None, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1663},
{"snippet": "DataFrame.max(**kwargs, axis=None, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1664},
{"snippet": "DataFrame.max(**kwargs, skipna=None, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1665},
{"snippet": "DataFrame.max(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1666},
{"snippet": "DataFrame.max(**kwargs)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1667},
{"snippet": "DataFrame.max(**kwargs, axis=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1668},
{"snippet": "DataFrame.max(**kwargs, skipna=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1669},
{"snippet": "DataFrame.max(**kwargs, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1670},
{"snippet": "DataFrame.max(**kwargs, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1671},
{"snippet": "DataFrame.max(**kwargs, axis=None, skipna=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1672},
{"snippet": "DataFrame.max(**kwargs, axis=None, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1673},
{"snippet": "DataFrame.max(**kwargs, axis=None, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1674},
{"snippet": "DataFrame.max(**kwargs, skipna=None, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1675},
{"snippet": "DataFrame.max(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1676},
{"snippet": "DataFrame.mean(**kwargs)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1677},
{"snippet": "DataFrame.mean(**kwargs, axis=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1678},
{"snippet": "DataFrame.mean(**kwargs, skipna=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1679},
{"snippet": "DataFrame.mean(**kwargs, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1680},
{"snippet": "DataFrame.mean(**kwargs, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1681},
{"snippet": "DataFrame.mean(**kwargs, axis=None, skipna=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1682},
{"snippet": "DataFrame.mean(**kwargs, axis=None, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1683},
{"snippet": "DataFrame.mean(**kwargs, axis=None, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1684},
{"snippet": "DataFrame.mean(**kwargs, skipna=None, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1685},
{"snippet": "DataFrame.mean(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1686},
{"snippet": "DataFrame.mean(**kwargs)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1687},
{"snippet": "DataFrame.mean(**kwargs, axis=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1688},
{"snippet": "DataFrame.mean(**kwargs, skipna=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1689},
{"snippet": "DataFrame.mean(**kwargs, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1690},
{"snippet": "DataFrame.mean(**kwargs, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1691},
{"snippet": "DataFrame.mean(**kwargs, axis=None, skipna=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1692},
{"snippet": "DataFrame.mean(**kwargs, axis=None, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1693},
{"snippet": "DataFrame.mean(**kwargs, axis=None, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1694},
{"snippet": "DataFrame.mean(**kwargs, skipna=None, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1695},
{"snippet": "DataFrame.mean(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1696},
{"snippet": "DataFrame.mean(**kwargs)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1697},
{"snippet": "DataFrame.mean(**kwargs, axis=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1698},
{"snippet": "DataFrame.mean(**kwargs, skipna=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1699},
{"snippet": "DataFrame.mean(**kwargs, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1700},
{"snippet": "DataFrame.mean(**kwargs, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1701},
{"snippet": "DataFrame.mean(**kwargs, axis=None, skipna=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1702},
{"snippet": "DataFrame.mean(**kwargs, axis=None, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1703},
{"snippet": "DataFrame.mean(**kwargs, axis=None, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1704},
{"snippet": "DataFrame.mean(**kwargs, skipna=None, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1705},
{"snippet": "DataFrame.mean(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1706},
{"snippet": "DataFrame.median(**kwargs)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1707},
{"snippet": "DataFrame.median(**kwargs, axis=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1708},
{"snippet": "DataFrame.median(**kwargs, skipna=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1709},
{"snippet": "DataFrame.median(**kwargs, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1710},
{"snippet": "DataFrame.median(**kwargs, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1711},
{"snippet": "DataFrame.median(**kwargs, axis=None, skipna=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1712},
{"snippet": "DataFrame.median(**kwargs, axis=None, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1713},
{"snippet": "DataFrame.median(**kwargs, axis=None, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1714},
{"snippet": "DataFrame.median(**kwargs, skipna=None, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1715},
{"snippet": "DataFrame.median(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1716},
{"snippet": "DataFrame.median(**kwargs)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1717},
{"snippet": "DataFrame.median(**kwargs, axis=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1718},
{"snippet": "DataFrame.median(**kwargs, skipna=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1719},
{"snippet": "DataFrame.median(**kwargs, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1720},
{"snippet": "DataFrame.median(**kwargs, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1721},
{"snippet": "DataFrame.median(**kwargs, axis=None, skipna=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1722},
{"snippet": "DataFrame.median(**kwargs, axis=None, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1723},
{"snippet": "DataFrame.median(**kwargs, axis=None, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1724},
{"snippet": "DataFrame.median(**kwargs, skipna=None, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1725},
{"snippet": "DataFrame.median(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1726},
{"snippet": "DataFrame.median(**kwargs)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1727},
{"snippet": "DataFrame.median(**kwargs, axis=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1728},
{"snippet": "DataFrame.median(**kwargs, skipna=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1729},
{"snippet": "DataFrame.median(**kwargs, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1730},
{"snippet": "DataFrame.median(**kwargs, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1731},
{"snippet": "DataFrame.median(**kwargs, axis=None, skipna=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1732},
{"snippet": "DataFrame.median(**kwargs, axis=None, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1733},
{"snippet": "DataFrame.median(**kwargs, axis=None, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1734},
{"snippet": "DataFrame.median(**kwargs, skipna=None, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1735},
{"snippet": "DataFrame.median(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1736},
{"snippet": "DataFrame.melt()", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set .", "question_id": 1737},
{"snippet": "DataFrame.melt(id_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 .", "question_id": 1738},
{"snippet": "DataFrame.melt(value_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 .", "question_id": 1739},
{"snippet": "DataFrame.melt(var_name=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `var_name`.", "question_id": 1740},
{"snippet": "DataFrame.melt(value_name='value')", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `value_name`.", "question_id": 1741},
{"snippet": "DataFrame.melt(col_level=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `col_level`.", "question_id": 1742},
{"snippet": "DataFrame.melt(ignore_index=True)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `ignore_index`.", "question_id": 1743},
{"snippet": "DataFrame.melt(id_vars=None, value_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 .", "question_id": 1744},
{"snippet": "DataFrame.melt(id_vars=None, var_name=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `var_name`.", "question_id": 1745},
{"snippet": "DataFrame.melt(id_vars=None, value_name='value')", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `value_name`.", "question_id": 1746},
{"snippet": "DataFrame.melt()", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set .", "question_id": 1747},
{"snippet": "DataFrame.melt(id_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 .", "question_id": 1748},
{"snippet": "DataFrame.melt(value_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 .", "question_id": 1749},
{"snippet": "DataFrame.melt(var_name=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `var_name`.", "question_id": 1750},
{"snippet": "DataFrame.melt(value_name='value')", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `value_name`.", "question_id": 1751},
{"snippet": "DataFrame.melt(col_level=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `col_level`.", "question_id": 1752},
{"snippet": "DataFrame.melt(ignore_index=True)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `ignore_index`.", "question_id": 1753},
{"snippet": "DataFrame.melt(id_vars=None, value_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 .", "question_id": 1754},
{"snippet": "DataFrame.melt(id_vars=None, var_name=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `var_name`.", "question_id": 1755},
{"snippet": "DataFrame.melt(id_vars=None, value_name='value')", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `value_name`.", "question_id": 1756},
{"snippet": "DataFrame.melt()", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set .", "question_id": 1757},
{"snippet": "DataFrame.melt(id_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 .", "question_id": 1758},
{"snippet": "DataFrame.melt(value_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 .", "question_id": 1759},
{"snippet": "DataFrame.melt(var_name=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `var_name`.", "question_id": 1760},
{"snippet": "DataFrame.melt(value_name='value')", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `value_name`.", "question_id": 1761},
{"snippet": "DataFrame.melt(col_level=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `col_level`.", "question_id": 1762},
{"snippet": "DataFrame.melt(ignore_index=True)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `ignore_index`.", "question_id": 1763},
{"snippet": "DataFrame.melt(id_vars=None, value_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 .", "question_id": 1764},
{"snippet": "DataFrame.melt(id_vars=None, var_name=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `var_name`.", "question_id": 1765},
{"snippet": "DataFrame.melt(id_vars=None, value_name='value')", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `value_name`.", "question_id": 1766},
{"snippet": "DataFrame.memory_usage()", "intent": "Return the memory usage of each column in bytes .", "question_id": 1767},
{"snippet": "DataFrame.memory_usage(index=True)", "intent": "Return the memory usage of each column in bytes . The memory usage can optionally include the contribution of the `index` and elements of object dtype .", "question_id": 1768},
{"snippet": "DataFrame.memory_usage(deep=False)", "intent": "Return the memory usage of each column in bytes . With arguments `deep`.", "question_id": 1769},
{"snippet": "DataFrame.memory_usage(index=True, deep=False)", "intent": "Return the memory usage of each column in bytes . The memory usage can optionally include the contribution of the `index` and elements of object dtype . With arguments `deep`.", "question_id": 1770},
{"snippet": "DataFrame.memory_usage()", "intent": "Return the memory usage of each column in bytes .", "question_id": 1771},
{"snippet": "DataFrame.memory_usage(index=True)", "intent": "Return the memory usage of each column in bytes . The memory usage can optionally include the contribution of the `index` and elements of object dtype .", "question_id": 1772},
{"snippet": "DataFrame.memory_usage(deep=False)", "intent": "Return the memory usage of each column in bytes . With arguments `deep`.", "question_id": 1773},
{"snippet": "DataFrame.memory_usage(index=True, deep=False)", "intent": "Return the memory usage of each column in bytes . The memory usage can optionally include the contribution of the `index` and elements of object dtype . With arguments `deep`.", "question_id": 1774},
{"snippet": "DataFrame.memory_usage()", "intent": "Return the memory usage of each column in bytes .", "question_id": 1775},
{"snippet": "DataFrame.memory_usage(index=True)", "intent": "Return the memory usage of each column in bytes . The memory usage can optionally include the contribution of the `index` and elements of object dtype .", "question_id": 1776},
{"snippet": "DataFrame.memory_usage(deep=False)", "intent": "Return the memory usage of each column in bytes . With arguments `deep`.", "question_id": 1777},
{"snippet": "DataFrame.memory_usage(index=True, deep=False)", "intent": "Return the memory usage of each column in bytes . The memory usage can optionally include the contribution of the `index` and elements of object dtype . With arguments `deep`.", "question_id": 1778},
{"snippet": "DataFrame.merge(right, '_y'))", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`.", "question_id": 1779},
{"snippet": "DataFrame.merge(right, '_y'), how='inner')", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `how`.", "question_id": 1780},
{"snippet": "DataFrame.merge(right, '_y'), on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . The join is done `on` columns or indexes . With arguments `'_y')`.", "question_id": 1781},
{"snippet": "DataFrame.merge(right, '_y'), left_on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . Support for specifying index levels as the on , `left_on` , and `right_on` parameters was added in version 0.23.0 Support for merging named Series objects was added in version 0.24.0 With arguments `'_y')`.", "question_id": 1782},
{"snippet": "DataFrame.merge(right, '_y'), right_on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . Support for specifying index levels as the on , `left_on` , and `right_on` parameters was added in version 0.23.0 Support for merging named Series objects was added in version 0.24.0 With arguments `'_y')`.", "question_id": 1783},
{"snippet": "DataFrame.merge(right, '_y'), left_index=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `left_index`.", "question_id": 1784},
{"snippet": "DataFrame.merge(right, '_y'), right_index=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `right_index`.", "question_id": 1785},
{"snippet": "DataFrame.merge(right, '_y'), sort=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `sort`.", "question_id": 1786},
{"snippet": "DataFrame.merge(right, '_y'), suffixes=('_x')", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . The value columns have the default `suffixes` , _x and _y , appended . With arguments `'_y')`.", "question_id": 1787},
{"snippet": "DataFrame.merge(right, '_y'), copy=True)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `copy`.", "question_id": 1788},
{"snippet": "DataFrame.merge(right, '_y'))", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`.", "question_id": 1789},
{"snippet": "DataFrame.merge(right, '_y'), how='inner')", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `how`.", "question_id": 1790},
{"snippet": "DataFrame.merge(right, '_y'), on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . The join is done `on` columns or indexes . With arguments `'_y')`.", "question_id": 1791},
{"snippet": "DataFrame.merge(right, '_y'), left_on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . Support for specifying index levels as the on , `left_on` , and `right_on` parameters was added in version 0.23.0 Support for merging named Series objects was added in version 0.24.0 With arguments `'_y')`.", "question_id": 1792},
{"snippet": "DataFrame.merge(right, '_y'), right_on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . Support for specifying index levels as the on , `left_on` , and `right_on` parameters was added in version 0.23.0 Support for merging named Series objects was added in version 0.24.0 With arguments `'_y')`.", "question_id": 1793},
{"snippet": "DataFrame.merge(right, '_y'), left_index=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `left_index`.", "question_id": 1794},
{"snippet": "DataFrame.merge(right, '_y'), right_index=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `right_index`.", "question_id": 1795},
{"snippet": "DataFrame.merge(right, '_y'), sort=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `sort`.", "question_id": 1796},
{"snippet": "DataFrame.merge(right, '_y'), suffixes=('_x')", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . The value columns have the default `suffixes` , _x and _y , appended . With arguments `'_y')`.", "question_id": 1797},
{"snippet": "DataFrame.merge(right, '_y'), copy=True)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `copy`.", "question_id": 1798},
{"snippet": "DataFrame.merge(right, '_y'))", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`.", "question_id": 1799},
{"snippet": "DataFrame.merge(right, '_y'), how='inner')", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `how`.", "question_id": 1800},
{"snippet": "DataFrame.merge(right, '_y'), on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . The join is done `on` columns or indexes . With arguments `'_y')`.", "question_id": 1801},
{"snippet": "DataFrame.merge(right, '_y'), left_on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . Support for specifying index levels as the on , `left_on` , and `right_on` parameters was added in version 0.23.0 Support for merging named Series objects was added in version 0.24.0 With arguments `'_y')`.", "question_id": 1802},
{"snippet": "DataFrame.merge(right, '_y'), right_on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . Support for specifying index levels as the on , `left_on` , and `right_on` parameters was added in version 0.23.0 Support for merging named Series objects was added in version 0.24.0 With arguments `'_y')`.", "question_id": 1803},
{"snippet": "DataFrame.merge(right, '_y'), left_index=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `left_index`.", "question_id": 1804},
{"snippet": "DataFrame.merge(right, '_y'), right_index=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `right_index`.", "question_id": 1805},
{"snippet": "DataFrame.merge(right, '_y'), sort=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `sort`.", "question_id": 1806},
{"snippet": "DataFrame.merge(right, '_y'), suffixes=('_x')", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . The value columns have the default `suffixes` , _x and _y , appended . With arguments `'_y')`.", "question_id": 1807},
{"snippet": "DataFrame.merge(right, '_y'), copy=True)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified left and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `copy`.", "question_id": 1808},
{"snippet": "DataFrame.min(**kwargs)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1809},
{"snippet": "DataFrame.min(**kwargs, axis=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1810},
{"snippet": "DataFrame.min(**kwargs, skipna=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1811},
{"snippet": "DataFrame.min(**kwargs, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1812},
{"snippet": "DataFrame.min(**kwargs, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1813},
{"snippet": "DataFrame.min(**kwargs, axis=None, skipna=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1814},
{"snippet": "DataFrame.min(**kwargs, axis=None, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1815},
{"snippet": "DataFrame.min(**kwargs, axis=None, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1816},
{"snippet": "DataFrame.min(**kwargs, skipna=None, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1817},
{"snippet": "DataFrame.min(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1818},
{"snippet": "DataFrame.min(**kwargs)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1819},
{"snippet": "DataFrame.min(**kwargs, axis=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1820},
{"snippet": "DataFrame.min(**kwargs, skipna=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1821},
{"snippet": "DataFrame.min(**kwargs, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1822},
{"snippet": "DataFrame.min(**kwargs, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1823},
{"snippet": "DataFrame.min(**kwargs, axis=None, skipna=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1824},
{"snippet": "DataFrame.min(**kwargs, axis=None, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1825},
{"snippet": "DataFrame.min(**kwargs, axis=None, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1826},
{"snippet": "DataFrame.min(**kwargs, skipna=None, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1827},
{"snippet": "DataFrame.min(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1828},
{"snippet": "DataFrame.min(**kwargs)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1829},
{"snippet": "DataFrame.min(**kwargs, axis=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 1830},
{"snippet": "DataFrame.min(**kwargs, skipna=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1831},
{"snippet": "DataFrame.min(**kwargs, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1832},
{"snippet": "DataFrame.min(**kwargs, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1833},
{"snippet": "DataFrame.min(**kwargs, axis=None, skipna=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 1834},
{"snippet": "DataFrame.min(**kwargs, axis=None, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 1835},
{"snippet": "DataFrame.min(**kwargs, axis=None, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 1836},
{"snippet": "DataFrame.min(**kwargs, skipna=None, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 1837},
{"snippet": "DataFrame.min(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 1838},
{"snippet": "DataFrame.mod(other)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) .", "question_id": 1839},
{"snippet": "DataFrame.mod(other, axis='columns')", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Subtract a list and Series by `axis` with operator version .", "question_id": 1840},
{"snippet": "DataFrame.mod(other, level=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Divide by a MultiIndex by `level` .", "question_id": 1841},
{"snippet": "DataFrame.mod(other, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Equivalent to dataframe % other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1842},
{"snippet": "DataFrame.mod(other, axis='columns', level=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 1843},
{"snippet": "DataFrame.mod(other, axis='columns', fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe % other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1844},
{"snippet": "DataFrame.mod(other, level=None, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Divide by a MultiIndex by `level` . Equivalent to dataframe % other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1845},
{"snippet": "DataFrame.mod(other, axis='columns', level=None, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe % other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1846},
{"snippet": "DataFrame.mod(other)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) .", "question_id": 1847},
{"snippet": "DataFrame.mod(other, axis='columns')", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Subtract a list and Series by `axis` with operator version .", "question_id": 1848},
{"snippet": "DataFrame.mod(other, level=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Divide by a MultiIndex by `level` .", "question_id": 1849},
{"snippet": "DataFrame.mod(other, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Equivalent to dataframe % other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1850},
{"snippet": "DataFrame.mod(other, axis='columns', level=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 1851},
{"snippet": "DataFrame.mod(other, axis='columns', fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe % other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1852},
{"snippet": "DataFrame.mod(other, level=None, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Divide by a MultiIndex by `level` . Equivalent to dataframe % other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1853},
{"snippet": "DataFrame.mod(other, axis='columns', level=None, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe % other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1854},
{"snippet": "DataFrame.mod(other)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) .", "question_id": 1855},
{"snippet": "DataFrame.mod(other, axis='columns')", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Subtract a list and Series by `axis` with operator version .", "question_id": 1856},
{"snippet": "DataFrame.mod(other, level=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Divide by a MultiIndex by `level` .", "question_id": 1857},
{"snippet": "DataFrame.mod(other, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Equivalent to dataframe % other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1858},
{"snippet": "DataFrame.mod(other, axis='columns', level=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 1859},
{"snippet": "DataFrame.mod(other, axis='columns', fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe % other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1860},
{"snippet": "DataFrame.mod(other, level=None, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Divide by a MultiIndex by `level` . Equivalent to dataframe % other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1861},
{"snippet": "DataFrame.mod(other, axis='columns', level=None, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator mod ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe % other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1862},
{"snippet": "DataFrame.mode()", "intent": "Get the mode ( s ) of each element along the selected `axis` .", "question_id": 1863},
{"snippet": "DataFrame.mode(axis=0)", "intent": "Get the mode ( s ) of each element along the selected `axis` .", "question_id": 1864},
{"snippet": "DataFrame.mode(numeric_only=False)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `numeric_only`.", "question_id": 1865},
{"snippet": "DataFrame.mode(dropna=True)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `dropna`.", "question_id": 1866},
{"snippet": "DataFrame.mode(axis=0, numeric_only=False)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `numeric_only`.", "question_id": 1867},
{"snippet": "DataFrame.mode(axis=0, dropna=True)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `dropna`.", "question_id": 1868},
{"snippet": "DataFrame.mode(numeric_only=False, dropna=True)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `numeric_only`, `dropna`.", "question_id": 1869},
{"snippet": "DataFrame.mode(axis=0, numeric_only=False, dropna=True)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `numeric_only`, `dropna`.", "question_id": 1870},
{"snippet": "DataFrame.mode()", "intent": "Get the mode ( s ) of each element along the selected `axis` .", "question_id": 1871},
{"snippet": "DataFrame.mode(axis=0)", "intent": "Get the mode ( s ) of each element along the selected `axis` .", "question_id": 1872},
{"snippet": "DataFrame.mode(numeric_only=False)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `numeric_only`.", "question_id": 1873},
{"snippet": "DataFrame.mode(dropna=True)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `dropna`.", "question_id": 1874},
{"snippet": "DataFrame.mode(axis=0, numeric_only=False)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `numeric_only`.", "question_id": 1875},
{"snippet": "DataFrame.mode(axis=0, dropna=True)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `dropna`.", "question_id": 1876},
{"snippet": "DataFrame.mode(numeric_only=False, dropna=True)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `numeric_only`, `dropna`.", "question_id": 1877},
{"snippet": "DataFrame.mode(axis=0, numeric_only=False, dropna=True)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `numeric_only`, `dropna`.", "question_id": 1878},
{"snippet": "DataFrame.mode()", "intent": "Get the mode ( s ) of each element along the selected `axis` .", "question_id": 1879},
{"snippet": "DataFrame.mode(axis=0)", "intent": "Get the mode ( s ) of each element along the selected `axis` .", "question_id": 1880},
{"snippet": "DataFrame.mode(numeric_only=False)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `numeric_only`.", "question_id": 1881},
{"snippet": "DataFrame.mode(dropna=True)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `dropna`.", "question_id": 1882},
{"snippet": "DataFrame.mode(axis=0, numeric_only=False)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `numeric_only`.", "question_id": 1883},
{"snippet": "DataFrame.mode(axis=0, dropna=True)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `dropna`.", "question_id": 1884},
{"snippet": "DataFrame.mode(numeric_only=False, dropna=True)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `numeric_only`, `dropna`.", "question_id": 1885},
{"snippet": "DataFrame.mode(axis=0, numeric_only=False, dropna=True)", "intent": "Get the mode ( s ) of each element along the selected `axis` . With arguments `numeric_only`, `dropna`.", "question_id": 1886},
{"snippet": "DataFrame.mul(other)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) .", "question_id": 1887},
{"snippet": "DataFrame.mul(other, axis='columns')", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version .", "question_id": 1888},
{"snippet": "DataFrame.mul(other, level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Divide by a MultiIndex by `level` .", "question_id": 1889},
{"snippet": "DataFrame.mul(other, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1890},
{"snippet": "DataFrame.mul(other, axis='columns', level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 1891},
{"snippet": "DataFrame.mul(other, axis='columns', fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1892},
{"snippet": "DataFrame.mul(other, level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Divide by a MultiIndex by `level` . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1893},
{"snippet": "DataFrame.mul(other, axis='columns', level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1894},
{"snippet": "DataFrame.mul(other)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) .", "question_id": 1895},
{"snippet": "DataFrame.mul(other, axis='columns')", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version .", "question_id": 1896},
{"snippet": "DataFrame.mul(other, level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Divide by a MultiIndex by `level` .", "question_id": 1897},
{"snippet": "DataFrame.mul(other, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1898},
{"snippet": "DataFrame.mul(other, axis='columns', level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 1899},
{"snippet": "DataFrame.mul(other, axis='columns', fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1900},
{"snippet": "DataFrame.mul(other, level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Divide by a MultiIndex by `level` . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1901},
{"snippet": "DataFrame.mul(other, axis='columns', level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1902},
{"snippet": "DataFrame.mul(other)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) .", "question_id": 1903},
{"snippet": "DataFrame.mul(other, axis='columns')", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version .", "question_id": 1904},
{"snippet": "DataFrame.mul(other, level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Divide by a MultiIndex by `level` .", "question_id": 1905},
{"snippet": "DataFrame.mul(other, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1906},
{"snippet": "DataFrame.mul(other, axis='columns', level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 1907},
{"snippet": "DataFrame.mul(other, axis='columns', fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1908},
{"snippet": "DataFrame.mul(other, level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Divide by a MultiIndex by `level` . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1909},
{"snippet": "DataFrame.mul(other, axis='columns', level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1910},
{"snippet": "DataFrame.multiply(other)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) .", "question_id": 1911},
{"snippet": "DataFrame.multiply(other, axis='columns')", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version .", "question_id": 1912},
{"snippet": "DataFrame.multiply(other, level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Divide by a MultiIndex by `level` .", "question_id": 1913},
{"snippet": "DataFrame.multiply(other, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1914},
{"snippet": "DataFrame.multiply(other, axis='columns', level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 1915},
{"snippet": "DataFrame.multiply(other, axis='columns', fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1916},
{"snippet": "DataFrame.multiply(other, level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Divide by a MultiIndex by `level` . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1917},
{"snippet": "DataFrame.multiply(other, axis='columns', level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1918},
{"snippet": "DataFrame.multiply(other)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) .", "question_id": 1919},
{"snippet": "DataFrame.multiply(other, axis='columns')", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version .", "question_id": 1920},
{"snippet": "DataFrame.multiply(other, level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Divide by a MultiIndex by `level` .", "question_id": 1921},
{"snippet": "DataFrame.multiply(other, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1922},
{"snippet": "DataFrame.multiply(other, axis='columns', level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 1923},
{"snippet": "DataFrame.multiply(other, axis='columns', fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1924},
{"snippet": "DataFrame.multiply(other, level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Divide by a MultiIndex by `level` . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1925},
{"snippet": "DataFrame.multiply(other, axis='columns', level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1926},
{"snippet": "DataFrame.multiply(other)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) .", "question_id": 1927},
{"snippet": "DataFrame.multiply(other, axis='columns')", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version .", "question_id": 1928},
{"snippet": "DataFrame.multiply(other, level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Divide by a MultiIndex by `level` .", "question_id": 1929},
{"snippet": "DataFrame.multiply(other, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1930},
{"snippet": "DataFrame.multiply(other, axis='columns', level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 1931},
{"snippet": "DataFrame.multiply(other, axis='columns', fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1932},
{"snippet": "DataFrame.multiply(other, level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Divide by a MultiIndex by `level` . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1933},
{"snippet": "DataFrame.multiply(other, axis='columns', level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator mul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 1934},
{"snippet": "DataFrame.ne(other)", "intent": "Get Not equal to of dataframe and `other` , element-wise ( binary operator ne ) .", "question_id": 1935},
{"snippet": "DataFrame.ne(other, axis='columns')", "intent": "Get Not equal to of dataframe and `other` , element-wise ( binary operator ne ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1936},
{"snippet": "DataFrame.ne(other, level=None)", "intent": "Get Not equal to of dataframe and `other` , element-wise ( binary operator ne ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1937},
{"snippet": "DataFrame.ne(other, axis='columns', level=None)", "intent": "Get Not equal to of dataframe and `other` , element-wise ( binary operator ne ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1938},
{"snippet": "DataFrame.ne(other)", "intent": "Get Not equal to of dataframe and `other` , element-wise ( binary operator ne ) .", "question_id": 1939},
{"snippet": "DataFrame.ne(other, axis='columns')", "intent": "Get Not equal to of dataframe and `other` , element-wise ( binary operator ne ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1940},
{"snippet": "DataFrame.ne(other, level=None)", "intent": "Get Not equal to of dataframe and `other` , element-wise ( binary operator ne ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1941},
{"snippet": "DataFrame.ne(other, axis='columns', level=None)", "intent": "Get Not equal to of dataframe and `other` , element-wise ( binary operator ne ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1942},
{"snippet": "DataFrame.ne(other)", "intent": "Get Not equal to of dataframe and `other` , element-wise ( binary operator ne ) .", "question_id": 1943},
{"snippet": "DataFrame.ne(other, axis='columns')", "intent": "Get Not equal to of dataframe and `other` , element-wise ( binary operator ne ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1944},
{"snippet": "DataFrame.ne(other, level=None)", "intent": "Get Not equal to of dataframe and `other` , element-wise ( binary operator ne ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1945},
{"snippet": "DataFrame.ne(other, axis='columns', level=None)", "intent": "Get Not equal to of dataframe and `other` , element-wise ( binary operator ne ) . Equivalent to == , ! = , < = , < , > = , > with support to choose `axis` ( rows or columns ) and `level` for comparison .", "question_id": 1946},
{"snippet": "DataFrame.nlargest(n, columns)", "intent": "Return the first `n` rows ordered by `columns` in descending order .", "question_id": 1947},
{"snippet": "DataFrame.nlargest(n, columns, keep='first')", "intent": "Return the first `n` rows ordered by `columns` in descending order . With arguments `keep`.", "question_id": 1948},
{"snippet": "DataFrame.nlargest(n, columns)", "intent": "Return the first `n` rows ordered by `columns` in descending order .", "question_id": 1949},
{"snippet": "DataFrame.nlargest(n, columns, keep='first')", "intent": "Return the first `n` rows ordered by `columns` in descending order . With arguments `keep`.", "question_id": 1950},
{"snippet": "DataFrame.nlargest(n, columns)", "intent": "Return the first `n` rows ordered by `columns` in descending order .", "question_id": 1951},
{"snippet": "DataFrame.nlargest(n, columns, keep='first')", "intent": "Return the first `n` rows ordered by `columns` in descending order . With arguments `keep`.", "question_id": 1952},
{"snippet": "DataFrame.notna()", "intent": "Detect existing ( non-missing ) values .", "question_id": 1953},
{"snippet": "DataFrame.notna()", "intent": "Detect existing ( non-missing ) values .", "question_id": 1954},
{"snippet": "DataFrame.notna()", "intent": "Detect existing ( non-missing ) values .", "question_id": 1955},
{"snippet": "DataFrame.notnull()", "intent": "Detect existing ( non-missing ) values .", "question_id": 1956},
{"snippet": "DataFrame.notnull()", "intent": "Detect existing ( non-missing ) values .", "question_id": 1957},
{"snippet": "DataFrame.notnull()", "intent": "Detect existing ( non-missing ) values .", "question_id": 1958},
{"snippet": "DataFrame.nsmallest(n, columns)", "intent": "Return the first `n` rows ordered by `columns` in ascending order .", "question_id": 1959},
{"snippet": "DataFrame.nsmallest(n, columns, keep='first')", "intent": "Return the first `n` rows ordered by `columns` in ascending order . With arguments `keep`.", "question_id": 1960},
{"snippet": "DataFrame.nsmallest(n, columns)", "intent": "Return the first `n` rows ordered by `columns` in ascending order .", "question_id": 1961},
{"snippet": "DataFrame.nsmallest(n, columns, keep='first')", "intent": "Return the first `n` rows ordered by `columns` in ascending order . With arguments `keep`.", "question_id": 1962},
{"snippet": "DataFrame.nsmallest(n, columns)", "intent": "Return the first `n` rows ordered by `columns` in ascending order .", "question_id": 1963},
{"snippet": "DataFrame.nsmallest(n, columns, keep='first')", "intent": "Return the first `n` rows ordered by `columns` in ascending order . With arguments `keep`.", "question_id": 1964},
{"snippet": "DataFrame.nunique()", "intent": "Count number of distinct elements in specified `axis` .", "question_id": 1965},
{"snippet": "DataFrame.nunique(axis=0)", "intent": "Count number of distinct elements in specified `axis` .", "question_id": 1966},
{"snippet": "DataFrame.nunique(dropna=True)", "intent": "Count number of distinct elements in specified `axis` . With arguments `dropna`.", "question_id": 1967},
{"snippet": "DataFrame.nunique(axis=0, dropna=True)", "intent": "Count number of distinct elements in specified `axis` . With arguments `dropna`.", "question_id": 1968},
{"snippet": "DataFrame.nunique()", "intent": "Count number of distinct elements in specified `axis` .", "question_id": 1969},
{"snippet": "DataFrame.nunique(axis=0)", "intent": "Count number of distinct elements in specified `axis` .", "question_id": 1970},
{"snippet": "DataFrame.nunique(dropna=True)", "intent": "Count number of distinct elements in specified `axis` . With arguments `dropna`.", "question_id": 1971},
{"snippet": "DataFrame.nunique(axis=0, dropna=True)", "intent": "Count number of distinct elements in specified `axis` . With arguments `dropna`.", "question_id": 1972},
{"snippet": "DataFrame.nunique()", "intent": "Count number of distinct elements in specified `axis` .", "question_id": 1973},
{"snippet": "DataFrame.nunique(axis=0)", "intent": "Count number of distinct elements in specified `axis` .", "question_id": 1974},
{"snippet": "DataFrame.nunique(dropna=True)", "intent": "Count number of distinct elements in specified `axis` . With arguments `dropna`.", "question_id": 1975},
{"snippet": "DataFrame.nunique(axis=0, dropna=True)", "intent": "Count number of distinct elements in specified `axis` . With arguments `dropna`.", "question_id": 1976},
{"snippet": "DataFrame.pad()", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' .", "question_id": 1977},
{"snippet": "DataFrame.pad(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`.", "question_id": 1978},
{"snippet": "DataFrame.pad(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`.", "question_id": 1979},
{"snippet": "DataFrame.pad(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `limit`.", "question_id": 1980},
{"snippet": "DataFrame.pad(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `downcast`.", "question_id": 1981},
{"snippet": "DataFrame.pad(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `inplace`.", "question_id": 1982},
{"snippet": "DataFrame.pad(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `limit`.", "question_id": 1983},
{"snippet": "DataFrame.pad(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `downcast`.", "question_id": 1984},
{"snippet": "DataFrame.pad(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `limit`.", "question_id": 1985},
{"snippet": "DataFrame.pad(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `downcast`.", "question_id": 1986},
{"snippet": "DataFrame.pad()", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' .", "question_id": 1987},
{"snippet": "DataFrame.pad(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`.", "question_id": 1988},
{"snippet": "DataFrame.pad(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`.", "question_id": 1989},
{"snippet": "DataFrame.pad(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `limit`.", "question_id": 1990},
{"snippet": "DataFrame.pad(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `downcast`.", "question_id": 1991},
{"snippet": "DataFrame.pad(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `inplace`.", "question_id": 1992},
{"snippet": "DataFrame.pad(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `limit`.", "question_id": 1993},
{"snippet": "DataFrame.pad(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `downcast`.", "question_id": 1994},
{"snippet": "DataFrame.pad(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `limit`.", "question_id": 1995},
{"snippet": "DataFrame.pad(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `downcast`.", "question_id": 1996},
{"snippet": "DataFrame.pad()", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' .", "question_id": 1997},
{"snippet": "DataFrame.pad(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`.", "question_id": 1998},
{"snippet": "DataFrame.pad(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`.", "question_id": 1999},
{"snippet": "DataFrame.pad(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `limit`.", "question_id": 2000},
{"snippet": "DataFrame.pad(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `downcast`.", "question_id": 2001},
{"snippet": "DataFrame.pad(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `inplace`.", "question_id": 2002},
{"snippet": "DataFrame.pad(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `limit`.", "question_id": 2003},
{"snippet": "DataFrame.pad(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `downcast`.", "question_id": 2004},
{"snippet": "DataFrame.pad(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `limit`.", "question_id": 2005},
{"snippet": "DataFrame.pad(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `downcast`.", "question_id": 2006},
{"snippet": "DataFrame.pct_change(**kwargs)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`.", "question_id": 2007},
{"snippet": "DataFrame.pct_change(**kwargs, periods=1)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`.", "question_id": 2008},
{"snippet": "DataFrame.pct_change(**kwargs, fill_method='pad')", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`.", "question_id": 2009},
{"snippet": "DataFrame.pct_change(**kwargs, limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `limit`.", "question_id": 2010},
{"snippet": "DataFrame.pct_change(**kwargs, freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `freq`.", "question_id": 2011},
{"snippet": "DataFrame.pct_change(**kwargs, periods=1, fill_method='pad')", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `fill_method`.", "question_id": 2012},
{"snippet": "DataFrame.pct_change(**kwargs, periods=1, limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `limit`.", "question_id": 2013},
{"snippet": "DataFrame.pct_change(**kwargs, periods=1, freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `freq`.", "question_id": 2014},
{"snippet": "DataFrame.pct_change(**kwargs, fill_method='pad', limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`, `limit`.", "question_id": 2015},
{"snippet": "DataFrame.pct_change(**kwargs, fill_method='pad', freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`, `freq`.", "question_id": 2016},
{"snippet": "DataFrame.pct_change(**kwargs)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`.", "question_id": 2017},
{"snippet": "DataFrame.pct_change(**kwargs, periods=1)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`.", "question_id": 2018},
{"snippet": "DataFrame.pct_change(**kwargs, fill_method='pad')", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`.", "question_id": 2019},
{"snippet": "DataFrame.pct_change(**kwargs, limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `limit`.", "question_id": 2020},
{"snippet": "DataFrame.pct_change(**kwargs, freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `freq`.", "question_id": 2021},
{"snippet": "DataFrame.pct_change(**kwargs, periods=1, fill_method='pad')", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `fill_method`.", "question_id": 2022},
{"snippet": "DataFrame.pct_change(**kwargs, periods=1, limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `limit`.", "question_id": 2023},
{"snippet": "DataFrame.pct_change(**kwargs, periods=1, freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `freq`.", "question_id": 2024},
{"snippet": "DataFrame.pct_change(**kwargs, fill_method='pad', limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`, `limit`.", "question_id": 2025},
{"snippet": "DataFrame.pct_change(**kwargs, fill_method='pad', freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`, `freq`.", "question_id": 2026},
{"snippet": "DataFrame.pct_change(**kwargs)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`.", "question_id": 2027},
{"snippet": "DataFrame.pct_change(**kwargs, periods=1)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`.", "question_id": 2028},
{"snippet": "DataFrame.pct_change(**kwargs, fill_method='pad')", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`.", "question_id": 2029},
{"snippet": "DataFrame.pct_change(**kwargs, limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `limit`.", "question_id": 2030},
{"snippet": "DataFrame.pct_change(**kwargs, freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `freq`.", "question_id": 2031},
{"snippet": "DataFrame.pct_change(**kwargs, periods=1, fill_method='pad')", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `fill_method`.", "question_id": 2032},
{"snippet": "DataFrame.pct_change(**kwargs, periods=1, limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `limit`.", "question_id": 2033},
{"snippet": "DataFrame.pct_change(**kwargs, periods=1, freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `freq`.", "question_id": 2034},
{"snippet": "DataFrame.pct_change(**kwargs, fill_method='pad', limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`, `limit`.", "question_id": 2035},
{"snippet": "DataFrame.pct_change(**kwargs, fill_method='pad', freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`, `freq`.", "question_id": 2036},
{"snippet": "DataFrame.pipe(func, *args, **kwargs)", "intent": "Apply `func` ( self , * args , * * kwargs ) . With arguments `*args`, `**kwargs`.", "question_id": 2037},
{"snippet": "DataFrame.pipe(func, *args, **kwargs)", "intent": "Apply `func` ( self , * args , * * kwargs ) . With arguments `*args`, `**kwargs`.", "question_id": 2038},
{"snippet": "DataFrame.pipe(func, *args, **kwargs)", "intent": "Apply `func` ( self , * args , * * kwargs ) . With arguments `*args`, `**kwargs`.", "question_id": 2039},
{"snippet": "DataFrame.pivot()", "intent": "Return reshaped DataFrame organized by given `index` / column `values` .", "question_id": 2040},
{"snippet": "DataFrame.pivot(index=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` .", "question_id": 2041},
{"snippet": "DataFrame.pivot(columns=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 2042},
{"snippet": "DataFrame.pivot(values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` .", "question_id": 2043},
{"snippet": "DataFrame.pivot(index=None, columns=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 2044},
{"snippet": "DataFrame.pivot(index=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` .", "question_id": 2045},
{"snippet": "DataFrame.pivot(columns=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 2046},
{"snippet": "DataFrame.pivot(index=None, columns=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 2047},
{"snippet": "DataFrame.pivot()", "intent": "Return reshaped DataFrame organized by given `index` / column `values` .", "question_id": 2048},
{"snippet": "DataFrame.pivot(index=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` .", "question_id": 2049},
{"snippet": "DataFrame.pivot(columns=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 2050},
{"snippet": "DataFrame.pivot(values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` .", "question_id": 2051},
{"snippet": "DataFrame.pivot(index=None, columns=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 2052},
{"snippet": "DataFrame.pivot(index=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` .", "question_id": 2053},
{"snippet": "DataFrame.pivot(columns=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 2054},
{"snippet": "DataFrame.pivot(index=None, columns=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 2055},
{"snippet": "DataFrame.pivot()", "intent": "Return reshaped DataFrame organized by given `index` / column `values` .", "question_id": 2056},
{"snippet": "DataFrame.pivot(index=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` .", "question_id": 2057},
{"snippet": "DataFrame.pivot(columns=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 2058},
{"snippet": "DataFrame.pivot(values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` .", "question_id": 2059},
{"snippet": "DataFrame.pivot(index=None, columns=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 2060},
{"snippet": "DataFrame.pivot(index=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` .", "question_id": 2061},
{"snippet": "DataFrame.pivot(columns=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 2062},
{"snippet": "DataFrame.pivot(index=None, columns=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 2063},
{"snippet": "DataFrame.pivot_table()", "intent": "Create a spreadsheet-style pivot table as a DataFrame .", "question_id": 2064},
{"snippet": "DataFrame.pivot_table(values=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . This first example aggregates `values` by taking the sum .", "question_id": 2065},
{"snippet": "DataFrame.pivot_table(index=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . The levels in the pivot table will be stored in MultiIndex objects ( hierarchical indexes ) on the `index` and `columns` of the result DataFrame .", "question_id": 2066},
{"snippet": "DataFrame.pivot_table(columns=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . The levels in the pivot table will be stored in MultiIndex objects ( hierarchical indexes ) on the `index` and `columns` of the result DataFrame .", "question_id": 2067},
{"snippet": "DataFrame.pivot_table(aggfunc='mean')", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `aggfunc`.", "question_id": 2068},
{"snippet": "DataFrame.pivot_table(fill_value=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . We can also fill missing values using the `fill_value` parameter .", "question_id": 2069},
{"snippet": "DataFrame.pivot_table(margins=False)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `margins`.", "question_id": 2070},
{"snippet": "DataFrame.pivot_table(dropna=True)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `dropna`.", "question_id": 2071},
{"snippet": "DataFrame.pivot_table(margins_name='All')", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `margins_name`.", "question_id": 2072},
{"snippet": "DataFrame.pivot_table(observed=False)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `observed`.", "question_id": 2073},
{"snippet": "DataFrame.pivot_table()", "intent": "Create a spreadsheet-style pivot table as a DataFrame .", "question_id": 2074},
{"snippet": "DataFrame.pivot_table(values=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . This first example aggregates `values` by taking the sum .", "question_id": 2075},
{"snippet": "DataFrame.pivot_table(index=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . The levels in the pivot table will be stored in MultiIndex objects ( hierarchical indexes ) on the `index` and `columns` of the result DataFrame .", "question_id": 2076},
{"snippet": "DataFrame.pivot_table(columns=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . The levels in the pivot table will be stored in MultiIndex objects ( hierarchical indexes ) on the `index` and `columns` of the result DataFrame .", "question_id": 2077},
{"snippet": "DataFrame.pivot_table(aggfunc='mean')", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `aggfunc`.", "question_id": 2078},
{"snippet": "DataFrame.pivot_table(fill_value=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . We can also fill missing values using the `fill_value` parameter .", "question_id": 2079},
{"snippet": "DataFrame.pivot_table(margins=False)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `margins`.", "question_id": 2080},
{"snippet": "DataFrame.pivot_table(dropna=True)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `dropna`.", "question_id": 2081},
{"snippet": "DataFrame.pivot_table(margins_name='All')", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `margins_name`.", "question_id": 2082},
{"snippet": "DataFrame.pivot_table(observed=False)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `observed`.", "question_id": 2083},
{"snippet": "DataFrame.pivot_table()", "intent": "Create a spreadsheet-style pivot table as a DataFrame .", "question_id": 2084},
{"snippet": "DataFrame.pivot_table(values=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . This first example aggregates `values` by taking the sum .", "question_id": 2085},
{"snippet": "DataFrame.pivot_table(index=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . The levels in the pivot table will be stored in MultiIndex objects ( hierarchical indexes ) on the `index` and `columns` of the result DataFrame .", "question_id": 2086},
{"snippet": "DataFrame.pivot_table(columns=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . The levels in the pivot table will be stored in MultiIndex objects ( hierarchical indexes ) on the `index` and `columns` of the result DataFrame .", "question_id": 2087},
{"snippet": "DataFrame.pivot_table(aggfunc='mean')", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `aggfunc`.", "question_id": 2088},
{"snippet": "DataFrame.pivot_table(fill_value=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . We can also fill missing values using the `fill_value` parameter .", "question_id": 2089},
{"snippet": "DataFrame.pivot_table(margins=False)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `margins`.", "question_id": 2090},
{"snippet": "DataFrame.pivot_table(dropna=True)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `dropna`.", "question_id": 2091},
{"snippet": "DataFrame.pivot_table(margins_name='All')", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `margins_name`.", "question_id": 2092},
{"snippet": "DataFrame.pivot_table(observed=False)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `observed`.", "question_id": 2093},
{"snippet": "DataFrame.plot.area(**kwargs)", "intent": "Draw a stacked area plot . With arguments `**kwargs`.", "question_id": 2094},
{"snippet": "DataFrame.plot.area(**kwargs, x=None)", "intent": "Draw a stacked area plot . Draw with a different `x` : With arguments `**kwargs`.", "question_id": 2095},
{"snippet": "DataFrame.plot.area(**kwargs, y=None)", "intent": "Draw a stacked area plot . With arguments `**kwargs`, `y`.", "question_id": 2096},
{"snippet": "DataFrame.plot.area(**kwargs, x=None, y=None)", "intent": "Draw a stacked area plot . Draw with a different `x` : With arguments `**kwargs`, `y`.", "question_id": 2097},
{"snippet": "DataFrame.plot.area(**kwargs)", "intent": "Draw a stacked area plot . With arguments `**kwargs`.", "question_id": 2098},
{"snippet": "DataFrame.plot.area(**kwargs, x=None)", "intent": "Draw a stacked area plot . Draw with a different `x` : With arguments `**kwargs`.", "question_id": 2099},
{"snippet": "DataFrame.plot.area(**kwargs, y=None)", "intent": "Draw a stacked area plot . With arguments `**kwargs`, `y`.", "question_id": 2100},
{"snippet": "DataFrame.plot.area(**kwargs, x=None, y=None)", "intent": "Draw a stacked area plot . Draw with a different `x` : With arguments `**kwargs`, `y`.", "question_id": 2101},
{"snippet": "DataFrame.plot.area(**kwargs)", "intent": "Draw a stacked area plot . With arguments `**kwargs`.", "question_id": 2102},
{"snippet": "DataFrame.plot.area(**kwargs, x=None)", "intent": "Draw a stacked area plot . Draw with a different `x` : With arguments `**kwargs`.", "question_id": 2103},
{"snippet": "DataFrame.plot.area(**kwargs, y=None)", "intent": "Draw a stacked area plot . With arguments `**kwargs`, `y`.", "question_id": 2104},
{"snippet": "DataFrame.plot.area(**kwargs, x=None, y=None)", "intent": "Draw a stacked area plot . Draw with a different `x` : With arguments `**kwargs`, `y`.", "question_id": 2105},
{"snippet": "DataFrame.plot.bar(**kwargs)", "intent": "Vertical bar plot . With arguments `**kwargs`.", "question_id": 2106},
{"snippet": "DataFrame.plot.bar(**kwargs, x=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `x`.", "question_id": 2107},
{"snippet": "DataFrame.plot.bar(**kwargs, y=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `y`.", "question_id": 2108},
{"snippet": "DataFrame.plot.bar(**kwargs, x=None, y=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `x`, `y`.", "question_id": 2109},
{"snippet": "DataFrame.plot.bar(**kwargs)", "intent": "Vertical bar plot . With arguments `**kwargs`.", "question_id": 2110},
{"snippet": "DataFrame.plot.bar(**kwargs, x=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `x`.", "question_id": 2111},
{"snippet": "DataFrame.plot.bar(**kwargs, y=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `y`.", "question_id": 2112},
{"snippet": "DataFrame.plot.bar(**kwargs, x=None, y=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `x`, `y`.", "question_id": 2113},
{"snippet": "DataFrame.plot.bar(**kwargs)", "intent": "Vertical bar plot . With arguments `**kwargs`.", "question_id": 2114},
{"snippet": "DataFrame.plot.bar(**kwargs, x=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `x`.", "question_id": 2115},
{"snippet": "DataFrame.plot.bar(**kwargs, y=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `y`.", "question_id": 2116},
{"snippet": "DataFrame.plot.bar(**kwargs, x=None, y=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `x`, `y`.", "question_id": 2117},
{"snippet": "DataFrame.plot.barh(**kwargs)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`.", "question_id": 2118},
{"snippet": "DataFrame.plot.barh(**kwargs, x=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `x`.", "question_id": 2119},
{"snippet": "DataFrame.plot.barh(**kwargs, y=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `y`.", "question_id": 2120},
{"snippet": "DataFrame.plot.barh(**kwargs, x=None, y=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `x`, `y`.", "question_id": 2121},
{"snippet": "DataFrame.plot.barh(**kwargs)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`.", "question_id": 2122},
{"snippet": "DataFrame.plot.barh(**kwargs, x=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `x`.", "question_id": 2123},
{"snippet": "DataFrame.plot.barh(**kwargs, y=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `y`.", "question_id": 2124},
{"snippet": "DataFrame.plot.barh(**kwargs, x=None, y=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `x`, `y`.", "question_id": 2125},
{"snippet": "DataFrame.plot.barh(**kwargs)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`.", "question_id": 2126},
{"snippet": "DataFrame.plot.barh(**kwargs, x=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `x`.", "question_id": 2127},
{"snippet": "DataFrame.plot.barh(**kwargs, y=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `y`.", "question_id": 2128},
{"snippet": "DataFrame.plot.barh(**kwargs, x=None, y=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `x`, `y`.", "question_id": 2129},
{"snippet": "DataFrame.plot.box(**kwargs)", "intent": "Make a box plot of the DataFrame columns . With arguments `**kwargs`.", "question_id": 2130},
{"snippet": "DataFrame.plot.box(**kwargs, by=None)", "intent": "Make a box plot of the DataFrame columns . The position of the whiskers is set `by` default to 1.5 * IQR ( IQR = Q3 - Q1 ) from the edges of the box . With arguments `**kwargs`.", "question_id": 2131},
{"snippet": "DataFrame.plot.box(**kwargs)", "intent": "Make a box plot of the DataFrame columns . With arguments `**kwargs`.", "question_id": 2132},
{"snippet": "DataFrame.plot.box(**kwargs, by=None)", "intent": "Make a box plot of the DataFrame columns . The position of the whiskers is set `by` default to 1.5 * IQR ( IQR = Q3 - Q1 ) from the edges of the box . With arguments `**kwargs`.", "question_id": 2133},
{"snippet": "DataFrame.plot.box(**kwargs)", "intent": "Make a box plot of the DataFrame columns . With arguments `**kwargs`.", "question_id": 2134},
{"snippet": "DataFrame.plot.box(**kwargs, by=None)", "intent": "Make a box plot of the DataFrame columns . The position of the whiskers is set `by` default to 1.5 * IQR ( IQR = Q3 - Q1 ) from the edges of the box . With arguments `**kwargs`.", "question_id": 2135},
{"snippet": "DataFrame.plot.density(**kwargs)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`.", "question_id": 2136},
{"snippet": "DataFrame.plot.density(**kwargs, bw_method=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`, `bw_method`.", "question_id": 2137},
{"snippet": "DataFrame.plot.density(**kwargs, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`.", "question_id": 2138},
{"snippet": "DataFrame.plot.density(**kwargs, bw_method=None, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`, `bw_method`.", "question_id": 2139},
{"snippet": "DataFrame.plot.density(**kwargs)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`.", "question_id": 2140},
{"snippet": "DataFrame.plot.density(**kwargs, bw_method=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`, `bw_method`.", "question_id": 2141},
{"snippet": "DataFrame.plot.density(**kwargs, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`.", "question_id": 2142},
{"snippet": "DataFrame.plot.density(**kwargs, bw_method=None, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`, `bw_method`.", "question_id": 2143},
{"snippet": "DataFrame.plot.density(**kwargs)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`.", "question_id": 2144},
{"snippet": "DataFrame.plot.density(**kwargs, bw_method=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`, `bw_method`.", "question_id": 2145},
{"snippet": "DataFrame.plot.density(**kwargs, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`.", "question_id": 2146},
{"snippet": "DataFrame.plot.density(**kwargs, bw_method=None, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`, `bw_method`.", "question_id": 2147},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . With arguments `**kwargs`.", "question_id": 2148},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, C=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . If `C` is None ( the default ) , this is a histogram of the number of occurrences of the observations at ( x [ i ] , y [ i ] ) . With arguments `**kwargs`.", "question_id": 2149},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, reduce_C_function=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . These values are accumulated for each hexagonal bin and then reduced according to `reduce_C_function` , having as default the NumPy \u2019 s mean function ( numpy.mean ( ) ) . With arguments `**kwargs`.", "question_id": 2150},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, gridsize=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . With arguments `**kwargs`, `gridsize`.", "question_id": 2151},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, C=None, reduce_C_function=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . If `C` is None ( the default ) , this is a histogram of the number of occurrences of the observations at ( x [ i ] , y [ i ] ) . These values are accumulated for each hexagonal bin and then reduced according to `reduce_C_function` , having as default the NumPy \u2019 s mean function ( numpy.mean ( ) ) . With arguments `**kwargs`.", "question_id": 2152},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, C=None, gridsize=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . If `C` is None ( the default ) , this is a histogram of the number of occurrences of the observations at ( x [ i ] , y [ i ] ) . With arguments `**kwargs`, `gridsize`.", "question_id": 2153},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, reduce_C_function=None, gridsize=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . These values are accumulated for each hexagonal bin and then reduced according to `reduce_C_function` , having as default the NumPy \u2019 s mean function ( numpy.mean ( ) ) . With arguments `**kwargs`, `gridsize`.", "question_id": 2154},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, C=None, reduce_C_function=None, gridsize=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . If `C` is None ( the default ) , this is a histogram of the number of occurrences of the observations at ( x [ i ] , y [ i ] ) . These values are accumulated for each hexagonal bin and then reduced according to `reduce_C_function` , having as default the NumPy \u2019 s mean function ( numpy.mean ( ) ) . With arguments `**kwargs`, `gridsize`.", "question_id": 2155},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . With arguments `**kwargs`.", "question_id": 2156},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, C=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . If `C` is None ( the default ) , this is a histogram of the number of occurrences of the observations at ( x [ i ] , y [ i ] ) . With arguments `**kwargs`.", "question_id": 2157},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, reduce_C_function=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . These values are accumulated for each hexagonal bin and then reduced according to `reduce_C_function` , having as default the NumPy \u2019 s mean function ( numpy.mean ( ) ) . With arguments `**kwargs`.", "question_id": 2158},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, gridsize=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . With arguments `**kwargs`, `gridsize`.", "question_id": 2159},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, C=None, reduce_C_function=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . If `C` is None ( the default ) , this is a histogram of the number of occurrences of the observations at ( x [ i ] , y [ i ] ) . These values are accumulated for each hexagonal bin and then reduced according to `reduce_C_function` , having as default the NumPy \u2019 s mean function ( numpy.mean ( ) ) . With arguments `**kwargs`.", "question_id": 2160},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, C=None, gridsize=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . If `C` is None ( the default ) , this is a histogram of the number of occurrences of the observations at ( x [ i ] , y [ i ] ) . With arguments `**kwargs`, `gridsize`.", "question_id": 2161},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, reduce_C_function=None, gridsize=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . These values are accumulated for each hexagonal bin and then reduced according to `reduce_C_function` , having as default the NumPy \u2019 s mean function ( numpy.mean ( ) ) . With arguments `**kwargs`, `gridsize`.", "question_id": 2162},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, C=None, reduce_C_function=None, gridsize=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . If `C` is None ( the default ) , this is a histogram of the number of occurrences of the observations at ( x [ i ] , y [ i ] ) . These values are accumulated for each hexagonal bin and then reduced according to `reduce_C_function` , having as default the NumPy \u2019 s mean function ( numpy.mean ( ) ) . With arguments `**kwargs`, `gridsize`.", "question_id": 2163},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . With arguments `**kwargs`.", "question_id": 2164},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, C=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . If `C` is None ( the default ) , this is a histogram of the number of occurrences of the observations at ( x [ i ] , y [ i ] ) . With arguments `**kwargs`.", "question_id": 2165},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, reduce_C_function=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . These values are accumulated for each hexagonal bin and then reduced according to `reduce_C_function` , having as default the NumPy \u2019 s mean function ( numpy.mean ( ) ) . With arguments `**kwargs`.", "question_id": 2166},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, gridsize=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . With arguments `**kwargs`, `gridsize`.", "question_id": 2167},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, C=None, reduce_C_function=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . If `C` is None ( the default ) , this is a histogram of the number of occurrences of the observations at ( x [ i ] , y [ i ] ) . These values are accumulated for each hexagonal bin and then reduced according to `reduce_C_function` , having as default the NumPy \u2019 s mean function ( numpy.mean ( ) ) . With arguments `**kwargs`.", "question_id": 2168},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, C=None, gridsize=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . If `C` is None ( the default ) , this is a histogram of the number of occurrences of the observations at ( x [ i ] , y [ i ] ) . With arguments `**kwargs`, `gridsize`.", "question_id": 2169},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, reduce_C_function=None, gridsize=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . These values are accumulated for each hexagonal bin and then reduced according to `reduce_C_function` , having as default the NumPy \u2019 s mean function ( numpy.mean ( ) ) . With arguments `**kwargs`, `gridsize`.", "question_id": 2170},
{"snippet": "DataFrame.plot.hexbin(x, y, **kwargs, C=None, reduce_C_function=None, gridsize=None)", "intent": "Generate a hexagonal binning plot . Generate a hexagonal binning plot of `x` versus `y` . If `C` is None ( the default ) , this is a histogram of the number of occurrences of the observations at ( x [ i ] , y [ i ] ) . These values are accumulated for each hexagonal bin and then reduced according to `reduce_C_function` , having as default the NumPy \u2019 s mean function ( numpy.mean ( ) ) . With arguments `**kwargs`, `gridsize`.", "question_id": 2171},
{"snippet": "DataFrame.plot.hist(**kwargs)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`.", "question_id": 2172},
{"snippet": "DataFrame.plot.hist(**kwargs, by=None)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `by`.", "question_id": 2173},
{"snippet": "DataFrame.plot.hist(**kwargs, bins=10)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . This function groups the values of all given Series in the DataFrame into `bins` and draws all bins in one matplotlib.axes.Axes . With arguments `**kwargs`.", "question_id": 2174},
{"snippet": "DataFrame.plot.hist(**kwargs, by=None, bins=10)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . This function groups the values of all given Series in the DataFrame into `bins` and draws all bins in one matplotlib.axes.Axes . With arguments `**kwargs`, `by`.", "question_id": 2175},
{"snippet": "DataFrame.plot.hist(**kwargs)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`.", "question_id": 2176},
{"snippet": "DataFrame.plot.hist(**kwargs, by=None)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `by`.", "question_id": 2177},
{"snippet": "DataFrame.plot.hist(**kwargs, bins=10)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . This function groups the values of all given Series in the DataFrame into `bins` and draws all bins in one matplotlib.axes.Axes . With arguments `**kwargs`.", "question_id": 2178},
{"snippet": "DataFrame.plot.hist(**kwargs, by=None, bins=10)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . This function groups the values of all given Series in the DataFrame into `bins` and draws all bins in one matplotlib.axes.Axes . With arguments `**kwargs`, `by`.", "question_id": 2179},
{"snippet": "DataFrame.plot.hist(**kwargs)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`.", "question_id": 2180},
{"snippet": "DataFrame.plot.hist(**kwargs, by=None)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `by`.", "question_id": 2181},
{"snippet": "DataFrame.plot.hist(**kwargs, bins=10)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . This function groups the values of all given Series in the DataFrame into `bins` and draws all bins in one matplotlib.axes.Axes . With arguments `**kwargs`.", "question_id": 2182},
{"snippet": "DataFrame.plot.hist(**kwargs, by=None, bins=10)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . This function groups the values of all given Series in the DataFrame into `bins` and draws all bins in one matplotlib.axes.Axes . With arguments `**kwargs`, `by`.", "question_id": 2183},
{"snippet": "DataFrame.plot(*args, **kwargs)", "intent": "Make plots of Series or DataFrame . With arguments `*args`, `**kwargs`.", "question_id": 2184},
{"snippet": "DataFrame.plot(*args, **kwargs)", "intent": "Make plots of Series or DataFrame . With arguments `*args`, `**kwargs`.", "question_id": 2185},
{"snippet": "DataFrame.plot(*args, **kwargs)", "intent": "Make plots of Series or DataFrame . With arguments `*args`, `**kwargs`.", "question_id": 2186},
{"snippet": "DataFrame.plot.kde(**kwargs)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`.", "question_id": 2187},
{"snippet": "DataFrame.plot.kde(**kwargs, bw_method=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`, `bw_method`.", "question_id": 2188},
{"snippet": "DataFrame.plot.kde(**kwargs, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`.", "question_id": 2189},
{"snippet": "DataFrame.plot.kde(**kwargs, bw_method=None, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`, `bw_method`.", "question_id": 2190},
{"snippet": "DataFrame.plot.kde(**kwargs)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`.", "question_id": 2191},
{"snippet": "DataFrame.plot.kde(**kwargs, bw_method=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`, `bw_method`.", "question_id": 2192},
{"snippet": "DataFrame.plot.kde(**kwargs, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`.", "question_id": 2193},
{"snippet": "DataFrame.plot.kde(**kwargs, bw_method=None, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`, `bw_method`.", "question_id": 2194},
{"snippet": "DataFrame.plot.kde(**kwargs)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`.", "question_id": 2195},
{"snippet": "DataFrame.plot.kde(**kwargs, bw_method=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`, `bw_method`.", "question_id": 2196},
{"snippet": "DataFrame.plot.kde(**kwargs, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`.", "question_id": 2197},
{"snippet": "DataFrame.plot.kde(**kwargs, bw_method=None, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`, `bw_method`.", "question_id": 2198},
{"snippet": "DataFrame.plot.line(**kwargs)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`.", "question_id": 2199},
{"snippet": "DataFrame.plot.line(**kwargs, x=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `x`.", "question_id": 2200},
{"snippet": "DataFrame.plot.line(**kwargs, y=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `y`.", "question_id": 2201},
{"snippet": "DataFrame.plot.line(**kwargs, x=None, y=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `x`, `y`.", "question_id": 2202},
{"snippet": "DataFrame.plot.line(**kwargs)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`.", "question_id": 2203},
{"snippet": "DataFrame.plot.line(**kwargs, x=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `x`.", "question_id": 2204},
{"snippet": "DataFrame.plot.line(**kwargs, y=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `y`.", "question_id": 2205},
{"snippet": "DataFrame.plot.line(**kwargs, x=None, y=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `x`, `y`.", "question_id": 2206},
{"snippet": "DataFrame.plot.line(**kwargs)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`.", "question_id": 2207},
{"snippet": "DataFrame.plot.line(**kwargs, x=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `x`.", "question_id": 2208},
{"snippet": "DataFrame.plot.line(**kwargs, y=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `y`.", "question_id": 2209},
{"snippet": "DataFrame.plot.line(**kwargs, x=None, y=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `x`, `y`.", "question_id": 2210},
{"snippet": "DataFrame.plot.pie(**kwargs)", "intent": "Generate a pie plot . With arguments `**kwargs`.", "question_id": 2211},
{"snippet": "DataFrame.plot.pie(**kwargs)", "intent": "Generate a pie plot . With arguments `**kwargs`.", "question_id": 2212},
{"snippet": "DataFrame.plot.pie(**kwargs)", "intent": "Generate a pie plot . With arguments `**kwargs`.", "question_id": 2213},
{"snippet": "DataFrame.plot.scatter(x, y, **kwargs)", "intent": "Create a scatter plot with varying marker point size and color . With arguments `x`, `y`, `**kwargs`.", "question_id": 2214},
{"snippet": "DataFrame.plot.scatter(x, y, **kwargs, s=None)", "intent": "Create a scatter plot with varying marker point size and color . Let \u2019 `s` see how to draw a scatter plot using coordinates from the values in a DataFrame \u2019 s columns . With arguments `x`, `y`, `**kwargs`.", "question_id": 2215},
{"snippet": "DataFrame.plot.scatter(x, y, **kwargs, c=None)", "intent": "Create a scatter plot with varying marker point size and color . With arguments `x`, `y`, `**kwargs`, `c`.", "question_id": 2216},
{"snippet": "DataFrame.plot.scatter(x, y, **kwargs, s=None, c=None)", "intent": "Create a scatter plot with varying marker point size and color . Let \u2019 `s` see how to draw a scatter plot using coordinates from the values in a DataFrame \u2019 s columns . With arguments `x`, `y`, `**kwargs`, `c`.", "question_id": 2217},
{"snippet": "DataFrame.plot.scatter(x, y, **kwargs)", "intent": "Create a scatter plot with varying marker point size and color . With arguments `x`, `y`, `**kwargs`.", "question_id": 2218},
{"snippet": "DataFrame.plot.scatter(x, y, **kwargs, s=None)", "intent": "Create a scatter plot with varying marker point size and color . Let \u2019 `s` see how to draw a scatter plot using coordinates from the values in a DataFrame \u2019 s columns . With arguments `x`, `y`, `**kwargs`.", "question_id": 2219},
{"snippet": "DataFrame.plot.scatter(x, y, **kwargs, c=None)", "intent": "Create a scatter plot with varying marker point size and color . With arguments `x`, `y`, `**kwargs`, `c`.", "question_id": 2220},
{"snippet": "DataFrame.plot.scatter(x, y, **kwargs, s=None, c=None)", "intent": "Create a scatter plot with varying marker point size and color . Let \u2019 `s` see how to draw a scatter plot using coordinates from the values in a DataFrame \u2019 s columns . With arguments `x`, `y`, `**kwargs`, `c`.", "question_id": 2221},
{"snippet": "DataFrame.plot.scatter(x, y, **kwargs)", "intent": "Create a scatter plot with varying marker point size and color . With arguments `x`, `y`, `**kwargs`.", "question_id": 2222},
{"snippet": "DataFrame.plot.scatter(x, y, **kwargs, s=None)", "intent": "Create a scatter plot with varying marker point size and color . Let \u2019 `s` see how to draw a scatter plot using coordinates from the values in a DataFrame \u2019 s columns . With arguments `x`, `y`, `**kwargs`.", "question_id": 2223},
{"snippet": "DataFrame.plot.scatter(x, y, **kwargs, c=None)", "intent": "Create a scatter plot with varying marker point size and color . With arguments `x`, `y`, `**kwargs`, `c`.", "question_id": 2224},
{"snippet": "DataFrame.plot.scatter(x, y, **kwargs, s=None, c=None)", "intent": "Create a scatter plot with varying marker point size and color . Let \u2019 `s` see how to draw a scatter plot using coordinates from the values in a DataFrame \u2019 s columns . With arguments `x`, `y`, `**kwargs`, `c`.", "question_id": 2225},
{"snippet": "DataFrame.pop(item)", "intent": "Return `item` and drop from frame .", "question_id": 2226},
{"snippet": "DataFrame.pop(item)", "intent": "Return `item` and drop from frame .", "question_id": 2227},
{"snippet": "DataFrame.pop(item)", "intent": "Return `item` and drop from frame .", "question_id": 2228},
{"snippet": "DataFrame.pow(other)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) .", "question_id": 2229},
{"snippet": "DataFrame.pow(other, axis='columns')", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2230},
{"snippet": "DataFrame.pow(other, level=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Divide by a MultiIndex by `level` .", "question_id": 2231},
{"snippet": "DataFrame.pow(other, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Equivalent to dataframe * * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2232},
{"snippet": "DataFrame.pow(other, axis='columns', level=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2233},
{"snippet": "DataFrame.pow(other, axis='columns', fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe * * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2234},
{"snippet": "DataFrame.pow(other, level=None, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Divide by a MultiIndex by `level` . Equivalent to dataframe * * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2235},
{"snippet": "DataFrame.pow(other, axis='columns', level=None, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe * * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2236},
{"snippet": "DataFrame.pow(other)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) .", "question_id": 2237},
{"snippet": "DataFrame.pow(other, axis='columns')", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2238},
{"snippet": "DataFrame.pow(other, level=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Divide by a MultiIndex by `level` .", "question_id": 2239},
{"snippet": "DataFrame.pow(other, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Equivalent to dataframe * * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2240},
{"snippet": "DataFrame.pow(other, axis='columns', level=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2241},
{"snippet": "DataFrame.pow(other, axis='columns', fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe * * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2242},
{"snippet": "DataFrame.pow(other, level=None, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Divide by a MultiIndex by `level` . Equivalent to dataframe * * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2243},
{"snippet": "DataFrame.pow(other, axis='columns', level=None, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe * * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2244},
{"snippet": "DataFrame.pow(other)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) .", "question_id": 2245},
{"snippet": "DataFrame.pow(other, axis='columns')", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2246},
{"snippet": "DataFrame.pow(other, level=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Divide by a MultiIndex by `level` .", "question_id": 2247},
{"snippet": "DataFrame.pow(other, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Equivalent to dataframe * * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2248},
{"snippet": "DataFrame.pow(other, axis='columns', level=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2249},
{"snippet": "DataFrame.pow(other, axis='columns', fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe * * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2250},
{"snippet": "DataFrame.pow(other, level=None, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Divide by a MultiIndex by `level` . Equivalent to dataframe * * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2251},
{"snippet": "DataFrame.pow(other, axis='columns', level=None, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator pow ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe * * other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2252},
{"snippet": "DataFrame.prod(**kwargs)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 2253},
{"snippet": "DataFrame.prod(**kwargs, axis=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 2254},
{"snippet": "DataFrame.prod(**kwargs, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 2255},
{"snippet": "DataFrame.prod(**kwargs, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2256},
{"snippet": "DataFrame.prod(**kwargs, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2257},
{"snippet": "DataFrame.prod(**kwargs, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 2258},
{"snippet": "DataFrame.prod(**kwargs, axis=None, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 2259},
{"snippet": "DataFrame.prod(**kwargs, axis=None, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2260},
{"snippet": "DataFrame.prod(**kwargs, axis=None, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2261},
{"snippet": "DataFrame.prod(**kwargs, axis=None, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 2262},
{"snippet": "DataFrame.prod(**kwargs)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 2263},
{"snippet": "DataFrame.prod(**kwargs, axis=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 2264},
{"snippet": "DataFrame.prod(**kwargs, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 2265},
{"snippet": "DataFrame.prod(**kwargs, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2266},
{"snippet": "DataFrame.prod(**kwargs, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2267},
{"snippet": "DataFrame.prod(**kwargs, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 2268},
{"snippet": "DataFrame.prod(**kwargs, axis=None, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 2269},
{"snippet": "DataFrame.prod(**kwargs, axis=None, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2270},
{"snippet": "DataFrame.prod(**kwargs, axis=None, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2271},
{"snippet": "DataFrame.prod(**kwargs, axis=None, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 2272},
{"snippet": "DataFrame.prod(**kwargs)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 2273},
{"snippet": "DataFrame.prod(**kwargs, axis=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 2274},
{"snippet": "DataFrame.prod(**kwargs, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 2275},
{"snippet": "DataFrame.prod(**kwargs, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2276},
{"snippet": "DataFrame.prod(**kwargs, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2277},
{"snippet": "DataFrame.prod(**kwargs, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 2278},
{"snippet": "DataFrame.prod(**kwargs, axis=None, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 2279},
{"snippet": "DataFrame.prod(**kwargs, axis=None, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2280},
{"snippet": "DataFrame.prod(**kwargs, axis=None, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2281},
{"snippet": "DataFrame.prod(**kwargs, axis=None, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 2282},
{"snippet": "DataFrame.product(**kwargs)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 2283},
{"snippet": "DataFrame.product(**kwargs, axis=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 2284},
{"snippet": "DataFrame.product(**kwargs, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 2285},
{"snippet": "DataFrame.product(**kwargs, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2286},
{"snippet": "DataFrame.product(**kwargs, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2287},
{"snippet": "DataFrame.product(**kwargs, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 2288},
{"snippet": "DataFrame.product(**kwargs, axis=None, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 2289},
{"snippet": "DataFrame.product(**kwargs, axis=None, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2290},
{"snippet": "DataFrame.product(**kwargs, axis=None, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2291},
{"snippet": "DataFrame.product(**kwargs, axis=None, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 2292},
{"snippet": "DataFrame.product(**kwargs)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 2293},
{"snippet": "DataFrame.product(**kwargs, axis=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 2294},
{"snippet": "DataFrame.product(**kwargs, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 2295},
{"snippet": "DataFrame.product(**kwargs, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2296},
{"snippet": "DataFrame.product(**kwargs, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2297},
{"snippet": "DataFrame.product(**kwargs, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 2298},
{"snippet": "DataFrame.product(**kwargs, axis=None, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 2299},
{"snippet": "DataFrame.product(**kwargs, axis=None, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2300},
{"snippet": "DataFrame.product(**kwargs, axis=None, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2301},
{"snippet": "DataFrame.product(**kwargs, axis=None, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 2302},
{"snippet": "DataFrame.product(**kwargs)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 2303},
{"snippet": "DataFrame.product(**kwargs, axis=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 2304},
{"snippet": "DataFrame.product(**kwargs, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 2305},
{"snippet": "DataFrame.product(**kwargs, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2306},
{"snippet": "DataFrame.product(**kwargs, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2307},
{"snippet": "DataFrame.product(**kwargs, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 2308},
{"snippet": "DataFrame.product(**kwargs, axis=None, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 2309},
{"snippet": "DataFrame.product(**kwargs, axis=None, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2310},
{"snippet": "DataFrame.product(**kwargs, axis=None, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2311},
{"snippet": "DataFrame.product(**kwargs, axis=None, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 2312},
{"snippet": "DataFrame.quantile()", "intent": "Return values at the given quantile over requested `axis` .", "question_id": 2313},
{"snippet": "DataFrame.quantile(q=0.5)", "intent": "Return values at the given quantile over requested `axis` . With arguments `q`.", "question_id": 2314},
{"snippet": "DataFrame.quantile(axis=0)", "intent": "Return values at the given quantile over requested `axis` .", "question_id": 2315},
{"snippet": "DataFrame.quantile(numeric_only=True)", "intent": "Return values at the given quantile over requested `axis` . With arguments `numeric_only`.", "question_id": 2316},
{"snippet": "DataFrame.quantile(interpolation='linear')", "intent": "Return values at the given quantile over requested `axis` . With arguments `interpolation`.", "question_id": 2317},
{"snippet": "DataFrame.quantile(q=0.5, axis=0)", "intent": "Return values at the given quantile over requested `axis` . With arguments `q`.", "question_id": 2318},
{"snippet": "DataFrame.quantile(q=0.5, numeric_only=True)", "intent": "Return values at the given quantile over requested `axis` . With arguments `q`, `numeric_only`.", "question_id": 2319},
{"snippet": "DataFrame.quantile(q=0.5, interpolation='linear')", "intent": "Return values at the given quantile over requested `axis` . With arguments `q`, `interpolation`.", "question_id": 2320},
{"snippet": "DataFrame.quantile(axis=0, numeric_only=True)", "intent": "Return values at the given quantile over requested `axis` . With arguments `numeric_only`.", "question_id": 2321},
{"snippet": "DataFrame.quantile(axis=0, interpolation='linear')", "intent": "Return values at the given quantile over requested `axis` . With arguments `interpolation`.", "question_id": 2322},
{"snippet": "DataFrame.quantile()", "intent": "Return values at the given quantile over requested `axis` .", "question_id": 2323},
{"snippet": "DataFrame.quantile(q=0.5)", "intent": "Return values at the given quantile over requested `axis` . With arguments `q`.", "question_id": 2324},
{"snippet": "DataFrame.quantile(axis=0)", "intent": "Return values at the given quantile over requested `axis` .", "question_id": 2325},
{"snippet": "DataFrame.quantile(numeric_only=True)", "intent": "Return values at the given quantile over requested `axis` . With arguments `numeric_only`.", "question_id": 2326},
{"snippet": "DataFrame.quantile(interpolation='linear')", "intent": "Return values at the given quantile over requested `axis` . With arguments `interpolation`.", "question_id": 2327},
{"snippet": "DataFrame.quantile(q=0.5, axis=0)", "intent": "Return values at the given quantile over requested `axis` . With arguments `q`.", "question_id": 2328},
{"snippet": "DataFrame.quantile(q=0.5, numeric_only=True)", "intent": "Return values at the given quantile over requested `axis` . With arguments `q`, `numeric_only`.", "question_id": 2329},
{"snippet": "DataFrame.quantile(q=0.5, interpolation='linear')", "intent": "Return values at the given quantile over requested `axis` . With arguments `q`, `interpolation`.", "question_id": 2330},
{"snippet": "DataFrame.quantile(axis=0, numeric_only=True)", "intent": "Return values at the given quantile over requested `axis` . With arguments `numeric_only`.", "question_id": 2331},
{"snippet": "DataFrame.quantile(axis=0, interpolation='linear')", "intent": "Return values at the given quantile over requested `axis` . With arguments `interpolation`.", "question_id": 2332},
{"snippet": "DataFrame.quantile()", "intent": "Return values at the given quantile over requested `axis` .", "question_id": 2333},
{"snippet": "DataFrame.quantile(q=0.5)", "intent": "Return values at the given quantile over requested `axis` . With arguments `q`.", "question_id": 2334},
{"snippet": "DataFrame.quantile(axis=0)", "intent": "Return values at the given quantile over requested `axis` .", "question_id": 2335},
{"snippet": "DataFrame.quantile(numeric_only=True)", "intent": "Return values at the given quantile over requested `axis` . With arguments `numeric_only`.", "question_id": 2336},
{"snippet": "DataFrame.quantile(interpolation='linear')", "intent": "Return values at the given quantile over requested `axis` . With arguments `interpolation`.", "question_id": 2337},
{"snippet": "DataFrame.quantile(q=0.5, axis=0)", "intent": "Return values at the given quantile over requested `axis` . With arguments `q`.", "question_id": 2338},
{"snippet": "DataFrame.quantile(q=0.5, numeric_only=True)", "intent": "Return values at the given quantile over requested `axis` . With arguments `q`, `numeric_only`.", "question_id": 2339},
{"snippet": "DataFrame.quantile(q=0.5, interpolation='linear')", "intent": "Return values at the given quantile over requested `axis` . With arguments `q`, `interpolation`.", "question_id": 2340},
{"snippet": "DataFrame.quantile(axis=0, numeric_only=True)", "intent": "Return values at the given quantile over requested `axis` . With arguments `numeric_only`.", "question_id": 2341},
{"snippet": "DataFrame.quantile(axis=0, interpolation='linear')", "intent": "Return values at the given quantile over requested `axis` . With arguments `interpolation`.", "question_id": 2342},
{"snippet": "DataFrame.query(expr, **kwargs)", "intent": "Query the columns of a DataFrame with a boolean expression . With arguments `expr`, `**kwargs`.", "question_id": 2343},
{"snippet": "DataFrame.query(expr, **kwargs, inplace=False)", "intent": "Query the columns of a DataFrame with a boolean expression . With arguments `expr`, `**kwargs`, `inplace`.", "question_id": 2344},
{"snippet": "DataFrame.query(expr, **kwargs)", "intent": "Query the columns of a DataFrame with a boolean expression . With arguments `expr`, `**kwargs`.", "question_id": 2345},
{"snippet": "DataFrame.query(expr, **kwargs, inplace=False)", "intent": "Query the columns of a DataFrame with a boolean expression . With arguments `expr`, `**kwargs`, `inplace`.", "question_id": 2346},
{"snippet": "DataFrame.query(expr, **kwargs)", "intent": "Query the columns of a DataFrame with a boolean expression . With arguments `expr`, `**kwargs`.", "question_id": 2347},
{"snippet": "DataFrame.query(expr, **kwargs, inplace=False)", "intent": "Query the columns of a DataFrame with a boolean expression . With arguments `expr`, `**kwargs`, `inplace`.", "question_id": 2348},
{"snippet": "DataFrame.radd(other)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) .", "question_id": 2349},
{"snippet": "DataFrame.radd(other, axis='columns')", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2350},
{"snippet": "DataFrame.radd(other, level=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Divide by a MultiIndex by `level` .", "question_id": 2351},
{"snippet": "DataFrame.radd(other, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Equivalent to other + dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2352},
{"snippet": "DataFrame.radd(other, axis='columns', level=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2353},
{"snippet": "DataFrame.radd(other, axis='columns', fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Subtract a list and Series by `axis` with operator version . Equivalent to other + dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2354},
{"snippet": "DataFrame.radd(other, level=None, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Divide by a MultiIndex by `level` . Equivalent to other + dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2355},
{"snippet": "DataFrame.radd(other, axis='columns', level=None, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other + dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2356},
{"snippet": "DataFrame.radd(other)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) .", "question_id": 2357},
{"snippet": "DataFrame.radd(other, axis='columns')", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2358},
{"snippet": "DataFrame.radd(other, level=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Divide by a MultiIndex by `level` .", "question_id": 2359},
{"snippet": "DataFrame.radd(other, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Equivalent to other + dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2360},
{"snippet": "DataFrame.radd(other, axis='columns', level=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2361},
{"snippet": "DataFrame.radd(other, axis='columns', fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Subtract a list and Series by `axis` with operator version . Equivalent to other + dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2362},
{"snippet": "DataFrame.radd(other, level=None, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Divide by a MultiIndex by `level` . Equivalent to other + dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2363},
{"snippet": "DataFrame.radd(other, axis='columns', level=None, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other + dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2364},
{"snippet": "DataFrame.radd(other)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) .", "question_id": 2365},
{"snippet": "DataFrame.radd(other, axis='columns')", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2366},
{"snippet": "DataFrame.radd(other, level=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Divide by a MultiIndex by `level` .", "question_id": 2367},
{"snippet": "DataFrame.radd(other, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Equivalent to other + dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2368},
{"snippet": "DataFrame.radd(other, axis='columns', level=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2369},
{"snippet": "DataFrame.radd(other, axis='columns', fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Subtract a list and Series by `axis` with operator version . Equivalent to other + dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2370},
{"snippet": "DataFrame.radd(other, level=None, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Divide by a MultiIndex by `level` . Equivalent to other + dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2371},
{"snippet": "DataFrame.radd(other, axis='columns', level=None, fill_value=None)", "intent": "Get Addition of dataframe and `other` , element-wise ( binary operator radd ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other + dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2372},
{"snippet": "DataFrame.rank()", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` .", "question_id": 2373},
{"snippet": "DataFrame.rank(axis=0)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` .", "question_id": 2374},
{"snippet": "DataFrame.rank(method='average')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . The following example shows how the `method` behaves with the above parameters :", "question_id": 2375},
{"snippet": "DataFrame.rank(numeric_only=None)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `numeric_only`.", "question_id": 2376},
{"snippet": "DataFrame.rank(na_option='keep')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `na_option`.", "question_id": 2377},
{"snippet": "DataFrame.rank(ascending=True)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `ascending`.", "question_id": 2378},
{"snippet": "DataFrame.rank(pct=False)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `pct`.", "question_id": 2379},
{"snippet": "DataFrame.rank(axis=0, method='average')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . The following example shows how the `method` behaves with the above parameters :", "question_id": 2380},
{"snippet": "DataFrame.rank(axis=0, numeric_only=None)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `numeric_only`.", "question_id": 2381},
{"snippet": "DataFrame.rank(axis=0, na_option='keep')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `na_option`.", "question_id": 2382},
{"snippet": "DataFrame.rank()", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` .", "question_id": 2383},
{"snippet": "DataFrame.rank(axis=0)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` .", "question_id": 2384},
{"snippet": "DataFrame.rank(method='average')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . The following example shows how the `method` behaves with the above parameters :", "question_id": 2385},
{"snippet": "DataFrame.rank(numeric_only=None)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `numeric_only`.", "question_id": 2386},
{"snippet": "DataFrame.rank(na_option='keep')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `na_option`.", "question_id": 2387},
{"snippet": "DataFrame.rank(ascending=True)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `ascending`.", "question_id": 2388},
{"snippet": "DataFrame.rank(pct=False)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `pct`.", "question_id": 2389},
{"snippet": "DataFrame.rank(axis=0, method='average')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . The following example shows how the `method` behaves with the above parameters :", "question_id": 2390},
{"snippet": "DataFrame.rank(axis=0, numeric_only=None)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `numeric_only`.", "question_id": 2391},
{"snippet": "DataFrame.rank(axis=0, na_option='keep')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `na_option`.", "question_id": 2392},
{"snippet": "DataFrame.rank()", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` .", "question_id": 2393},
{"snippet": "DataFrame.rank(axis=0)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` .", "question_id": 2394},
{"snippet": "DataFrame.rank(method='average')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . The following example shows how the `method` behaves with the above parameters :", "question_id": 2395},
{"snippet": "DataFrame.rank(numeric_only=None)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `numeric_only`.", "question_id": 2396},
{"snippet": "DataFrame.rank(na_option='keep')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `na_option`.", "question_id": 2397},
{"snippet": "DataFrame.rank(ascending=True)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `ascending`.", "question_id": 2398},
{"snippet": "DataFrame.rank(pct=False)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `pct`.", "question_id": 2399},
{"snippet": "DataFrame.rank(axis=0, method='average')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . The following example shows how the `method` behaves with the above parameters :", "question_id": 2400},
{"snippet": "DataFrame.rank(axis=0, numeric_only=None)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `numeric_only`.", "question_id": 2401},
{"snippet": "DataFrame.rank(axis=0, na_option='keep')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `na_option`.", "question_id": 2402},
{"snippet": "DataFrame.rdiv(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) .", "question_id": 2403},
{"snippet": "DataFrame.rdiv(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2404},
{"snippet": "DataFrame.rdiv(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Divide by a MultiIndex by `level` .", "question_id": 2405},
{"snippet": "DataFrame.rdiv(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2406},
{"snippet": "DataFrame.rdiv(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2407},
{"snippet": "DataFrame.rdiv(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2408},
{"snippet": "DataFrame.rdiv(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Divide by a MultiIndex by `level` . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2409},
{"snippet": "DataFrame.rdiv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2410},
{"snippet": "DataFrame.rdiv(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) .", "question_id": 2411},
{"snippet": "DataFrame.rdiv(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2412},
{"snippet": "DataFrame.rdiv(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Divide by a MultiIndex by `level` .", "question_id": 2413},
{"snippet": "DataFrame.rdiv(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2414},
{"snippet": "DataFrame.rdiv(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2415},
{"snippet": "DataFrame.rdiv(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2416},
{"snippet": "DataFrame.rdiv(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Divide by a MultiIndex by `level` . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2417},
{"snippet": "DataFrame.rdiv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2418},
{"snippet": "DataFrame.rdiv(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) .", "question_id": 2419},
{"snippet": "DataFrame.rdiv(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2420},
{"snippet": "DataFrame.rdiv(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Divide by a MultiIndex by `level` .", "question_id": 2421},
{"snippet": "DataFrame.rdiv(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2422},
{"snippet": "DataFrame.rdiv(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2423},
{"snippet": "DataFrame.rdiv(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2424},
{"snippet": "DataFrame.rdiv(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Divide by a MultiIndex by `level` . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2425},
{"snippet": "DataFrame.rdiv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2426},
{"snippet": "DataFrame.reindex()", "intent": "Conform Series/DataFrame to new `index` with optional filling logic .", "question_id": 2427},
{"snippet": "DataFrame.reindex(labels=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `labels`.", "question_id": 2428},
{"snippet": "DataFrame.reindex(index=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic .", "question_id": 2429},
{"snippet": "DataFrame.reindex(columns=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . We can also reindex the `columns` .", "question_id": 2430},
{"snippet": "DataFrame.reindex(axis=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `axis`.", "question_id": 2431},
{"snippet": "DataFrame.reindex(method=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . Because the index is not monotonically increasing or decreasing , we can not use arguments to the keyword `method` to fill the NaN values .", "question_id": 2432},
{"snippet": "DataFrame.reindex(copy=True)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `copy`.", "question_id": 2433},
{"snippet": "DataFrame.reindex(level=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `level`.", "question_id": 2434},
{"snippet": "DataFrame.reindex(fill_value=nan)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . We can fill in the missing values by passing a value to the keyword `fill_value` .", "question_id": 2435},
{"snippet": "DataFrame.reindex(limit=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `limit`.", "question_id": 2436},
{"snippet": "DataFrame.reindex()", "intent": "Conform Series/DataFrame to new `index` with optional filling logic .", "question_id": 2437},
{"snippet": "DataFrame.reindex(labels=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `labels`.", "question_id": 2438},
{"snippet": "DataFrame.reindex(index=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic .", "question_id": 2439},
{"snippet": "DataFrame.reindex(columns=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . We can also reindex the `columns` .", "question_id": 2440},
{"snippet": "DataFrame.reindex(axis=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `axis`.", "question_id": 2441},
{"snippet": "DataFrame.reindex(method=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . Because the index is not monotonically increasing or decreasing , we can not use arguments to the keyword `method` to fill the NaN values .", "question_id": 2442},
{"snippet": "DataFrame.reindex(copy=True)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `copy`.", "question_id": 2443},
{"snippet": "DataFrame.reindex(level=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `level`.", "question_id": 2444},
{"snippet": "DataFrame.reindex(fill_value=nan)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . We can fill in the missing values by passing a value to the keyword `fill_value` .", "question_id": 2445},
{"snippet": "DataFrame.reindex(limit=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `limit`.", "question_id": 2446},
{"snippet": "DataFrame.reindex()", "intent": "Conform Series/DataFrame to new `index` with optional filling logic .", "question_id": 2447},
{"snippet": "DataFrame.reindex(labels=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `labels`.", "question_id": 2448},
{"snippet": "DataFrame.reindex(index=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic .", "question_id": 2449},
{"snippet": "DataFrame.reindex(columns=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . We can also reindex the `columns` .", "question_id": 2450},
{"snippet": "DataFrame.reindex(axis=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `axis`.", "question_id": 2451},
{"snippet": "DataFrame.reindex(method=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . Because the index is not monotonically increasing or decreasing , we can not use arguments to the keyword `method` to fill the NaN values .", "question_id": 2452},
{"snippet": "DataFrame.reindex(copy=True)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `copy`.", "question_id": 2453},
{"snippet": "DataFrame.reindex(level=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `level`.", "question_id": 2454},
{"snippet": "DataFrame.reindex(fill_value=nan)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . We can fill in the missing values by passing a value to the keyword `fill_value` .", "question_id": 2455},
{"snippet": "DataFrame.reindex(limit=None)", "intent": "Conform Series/DataFrame to new `index` with optional filling logic . With arguments `limit`.", "question_id": 2456},
{"snippet": "DataFrame.reindex_like(other)", "intent": "Return an object with matching indices as `other` object .", "question_id": 2457},
{"snippet": "DataFrame.reindex_like(other, method=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`.", "question_id": 2458},
{"snippet": "DataFrame.reindex_like(other, copy=True)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`.", "question_id": 2459},
{"snippet": "DataFrame.reindex_like(other, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `limit`.", "question_id": 2460},
{"snippet": "DataFrame.reindex_like(other, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `tolerance`.", "question_id": 2461},
{"snippet": "DataFrame.reindex_like(other, method=None, copy=True)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `copy`.", "question_id": 2462},
{"snippet": "DataFrame.reindex_like(other, method=None, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `limit`.", "question_id": 2463},
{"snippet": "DataFrame.reindex_like(other, method=None, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `tolerance`.", "question_id": 2464},
{"snippet": "DataFrame.reindex_like(other, copy=True, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`, `limit`.", "question_id": 2465},
{"snippet": "DataFrame.reindex_like(other, copy=True, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`, `tolerance`.", "question_id": 2466},
{"snippet": "DataFrame.reindex_like(other)", "intent": "Return an object with matching indices as `other` object .", "question_id": 2467},
{"snippet": "DataFrame.reindex_like(other, method=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`.", "question_id": 2468},
{"snippet": "DataFrame.reindex_like(other, copy=True)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`.", "question_id": 2469},
{"snippet": "DataFrame.reindex_like(other, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `limit`.", "question_id": 2470},
{"snippet": "DataFrame.reindex_like(other, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `tolerance`.", "question_id": 2471},
{"snippet": "DataFrame.reindex_like(other, method=None, copy=True)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `copy`.", "question_id": 2472},
{"snippet": "DataFrame.reindex_like(other, method=None, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `limit`.", "question_id": 2473},
{"snippet": "DataFrame.reindex_like(other, method=None, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `tolerance`.", "question_id": 2474},
{"snippet": "DataFrame.reindex_like(other, copy=True, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`, `limit`.", "question_id": 2475},
{"snippet": "DataFrame.reindex_like(other, copy=True, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`, `tolerance`.", "question_id": 2476},
{"snippet": "DataFrame.reindex_like(other)", "intent": "Return an object with matching indices as `other` object .", "question_id": 2477},
{"snippet": "DataFrame.reindex_like(other, method=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`.", "question_id": 2478},
{"snippet": "DataFrame.reindex_like(other, copy=True)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`.", "question_id": 2479},
{"snippet": "DataFrame.reindex_like(other, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `limit`.", "question_id": 2480},
{"snippet": "DataFrame.reindex_like(other, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `tolerance`.", "question_id": 2481},
{"snippet": "DataFrame.reindex_like(other, method=None, copy=True)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `copy`.", "question_id": 2482},
{"snippet": "DataFrame.reindex_like(other, method=None, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `limit`.", "question_id": 2483},
{"snippet": "DataFrame.reindex_like(other, method=None, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `tolerance`.", "question_id": 2484},
{"snippet": "DataFrame.reindex_like(other, copy=True, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`, `limit`.", "question_id": 2485},
{"snippet": "DataFrame.reindex_like(other, copy=True, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`, `tolerance`.", "question_id": 2486},
{"snippet": "DataFrame.rename()", "intent": "Alter axes labels .", "question_id": 2487},
{"snippet": "DataFrame.rename(mapper=None)", "intent": "Alter axes labels . With arguments `mapper`.", "question_id": 2488},
{"snippet": "DataFrame.rename(index=None)", "intent": "Alter axes labels . Rename `index` using a mapping :", "question_id": 2489},
{"snippet": "DataFrame.rename(columns=None)", "intent": "Alter axes labels . Rename `columns` using a mapping :", "question_id": 2490},
{"snippet": "DataFrame.rename(axis=None)", "intent": "Alter axes labels . With arguments `axis`.", "question_id": 2491},
{"snippet": "DataFrame.rename(copy=True)", "intent": "Alter axes labels . With arguments `copy`.", "question_id": 2492},
{"snippet": "DataFrame.rename(inplace=False)", "intent": "Alter axes labels . With arguments `inplace`.", "question_id": 2493},
{"snippet": "DataFrame.rename(level=None)", "intent": "Alter axes labels . With arguments `level`.", "question_id": 2494},
{"snippet": "DataFrame.rename(errors='ignore')", "intent": "Alter axes labels . With arguments `errors`.", "question_id": 2495},
{"snippet": "DataFrame.rename(mapper=None, index=None)", "intent": "Alter axes labels . Rename `index` using a mapping : With arguments `mapper`.", "question_id": 2496},
{"snippet": "DataFrame.rename()", "intent": "Alter axes labels .", "question_id": 2497},
{"snippet": "DataFrame.rename(mapper=None)", "intent": "Alter axes labels . With arguments `mapper`.", "question_id": 2498},
{"snippet": "DataFrame.rename(index=None)", "intent": "Alter axes labels . Rename `index` using a mapping :", "question_id": 2499},
{"snippet": "DataFrame.rename(columns=None)", "intent": "Alter axes labels . Rename `columns` using a mapping :", "question_id": 2500},
{"snippet": "DataFrame.rename(axis=None)", "intent": "Alter axes labels . With arguments `axis`.", "question_id": 2501},
{"snippet": "DataFrame.rename(copy=True)", "intent": "Alter axes labels . With arguments `copy`.", "question_id": 2502},
{"snippet": "DataFrame.rename(inplace=False)", "intent": "Alter axes labels . With arguments `inplace`.", "question_id": 2503},
{"snippet": "DataFrame.rename(level=None)", "intent": "Alter axes labels . With arguments `level`.", "question_id": 2504},
{"snippet": "DataFrame.rename(errors='ignore')", "intent": "Alter axes labels . With arguments `errors`.", "question_id": 2505},
{"snippet": "DataFrame.rename(mapper=None, index=None)", "intent": "Alter axes labels . Rename `index` using a mapping : With arguments `mapper`.", "question_id": 2506},
{"snippet": "DataFrame.rename()", "intent": "Alter axes labels .", "question_id": 2507},
{"snippet": "DataFrame.rename(mapper=None)", "intent": "Alter axes labels . With arguments `mapper`.", "question_id": 2508},
{"snippet": "DataFrame.rename(index=None)", "intent": "Alter axes labels . Rename `index` using a mapping :", "question_id": 2509},
{"snippet": "DataFrame.rename(columns=None)", "intent": "Alter axes labels . Rename `columns` using a mapping :", "question_id": 2510},
{"snippet": "DataFrame.rename(axis=None)", "intent": "Alter axes labels . With arguments `axis`.", "question_id": 2511},
{"snippet": "DataFrame.rename(copy=True)", "intent": "Alter axes labels . With arguments `copy`.", "question_id": 2512},
{"snippet": "DataFrame.rename(inplace=False)", "intent": "Alter axes labels . With arguments `inplace`.", "question_id": 2513},
{"snippet": "DataFrame.rename(level=None)", "intent": "Alter axes labels . With arguments `level`.", "question_id": 2514},
{"snippet": "DataFrame.rename(errors='ignore')", "intent": "Alter axes labels . With arguments `errors`.", "question_id": 2515},
{"snippet": "DataFrame.rename(mapper=None, index=None)", "intent": "Alter axes labels . Rename `index` using a mapping : With arguments `mapper`.", "question_id": 2516},
{"snippet": "DataFrame.rename_axis()", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 2517},
{"snippet": "DataFrame.rename_axis(mapper=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 2518},
{"snippet": "DataFrame.rename_axis(index=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 2519},
{"snippet": "DataFrame.rename_axis(columns=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 2520},
{"snippet": "DataFrame.rename_axis(axis=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 2521},
{"snippet": "DataFrame.rename_axis(copy=True)", "intent": "Set the name of the `axis` for the `index` or `columns` . In this case , the parameter `copy` is ignored .", "question_id": 2522},
{"snippet": "DataFrame.rename_axis(inplace=False)", "intent": "Set the name of the `axis` for the `index` or `columns` . With arguments `inplace`.", "question_id": 2523},
{"snippet": "DataFrame.rename_axis(mapper=None, index=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 2524},
{"snippet": "DataFrame.rename_axis(mapper=None, columns=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 2525},
{"snippet": "DataFrame.rename_axis(mapper=None, axis=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 2526},
{"snippet": "DataFrame.rename_axis()", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 2527},
{"snippet": "DataFrame.rename_axis(mapper=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 2528},
{"snippet": "DataFrame.rename_axis(index=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 2529},
{"snippet": "DataFrame.rename_axis(columns=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 2530},
{"snippet": "DataFrame.rename_axis(axis=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 2531},
{"snippet": "DataFrame.rename_axis(copy=True)", "intent": "Set the name of the `axis` for the `index` or `columns` . In this case , the parameter `copy` is ignored .", "question_id": 2532},
{"snippet": "DataFrame.rename_axis(inplace=False)", "intent": "Set the name of the `axis` for the `index` or `columns` . With arguments `inplace`.", "question_id": 2533},
{"snippet": "DataFrame.rename_axis(mapper=None, index=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 2534},
{"snippet": "DataFrame.rename_axis(mapper=None, columns=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 2535},
{"snippet": "DataFrame.rename_axis(mapper=None, axis=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 2536},
{"snippet": "DataFrame.rename_axis()", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 2537},
{"snippet": "DataFrame.rename_axis(mapper=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 2538},
{"snippet": "DataFrame.rename_axis(index=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 2539},
{"snippet": "DataFrame.rename_axis(columns=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 2540},
{"snippet": "DataFrame.rename_axis(axis=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 2541},
{"snippet": "DataFrame.rename_axis(copy=True)", "intent": "Set the name of the `axis` for the `index` or `columns` . In this case , the parameter `copy` is ignored .", "question_id": 2542},
{"snippet": "DataFrame.rename_axis(inplace=False)", "intent": "Set the name of the `axis` for the `index` or `columns` . With arguments `inplace`.", "question_id": 2543},
{"snippet": "DataFrame.rename_axis(mapper=None, index=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 2544},
{"snippet": "DataFrame.rename_axis(mapper=None, columns=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 2545},
{"snippet": "DataFrame.rename_axis(mapper=None, axis=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 2546},
{"snippet": "DataFrame.reorder_levels(order)", "intent": "Rearrange index levels using input `order` .", "question_id": 2547},
{"snippet": "DataFrame.reorder_levels(order, axis=0)", "intent": "Rearrange index levels using input `order` . With arguments `axis`.", "question_id": 2548},
{"snippet": "DataFrame.reorder_levels(order)", "intent": "Rearrange index levels using input `order` .", "question_id": 2549},
{"snippet": "DataFrame.reorder_levels(order, axis=0)", "intent": "Rearrange index levels using input `order` . With arguments `axis`.", "question_id": 2550},
{"snippet": "DataFrame.reorder_levels(order)", "intent": "Rearrange index levels using input `order` .", "question_id": 2551},
{"snippet": "DataFrame.reorder_levels(order, axis=0)", "intent": "Rearrange index levels using input `order` . With arguments `axis`.", "question_id": 2552},
{"snippet": "DataFrame.replace()", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 2553},
{"snippet": "DataFrame.replace(to_replace=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 2554},
{"snippet": "DataFrame.replace(value=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 2555},
{"snippet": "DataFrame.replace(inplace=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `inplace`.", "question_id": 2556},
{"snippet": "DataFrame.replace(limit=None)", "intent": "Replace values given in `to_replace` with `value` . With arguments `limit`.", "question_id": 2557},
{"snippet": "DataFrame.replace(regex=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `regex`.", "question_id": 2558},
{"snippet": "DataFrame.replace(method='pad')", "intent": "Replace values given in `to_replace` with `value` . When value=None and to_replace is a scalar , list or tuple , replace uses the `method` parameter ( default \u2018 pad \u2019 ) to do the replacement .", "question_id": 2559},
{"snippet": "DataFrame.replace(to_replace=None, value=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 2560},
{"snippet": "DataFrame.replace(to_replace=None, inplace=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `inplace`.", "question_id": 2561},
{"snippet": "DataFrame.replace(to_replace=None, limit=None)", "intent": "Replace values given in `to_replace` with `value` . With arguments `limit`.", "question_id": 2562},
{"snippet": "DataFrame.replace()", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 2563},
{"snippet": "DataFrame.replace(to_replace=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 2564},
{"snippet": "DataFrame.replace(value=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 2565},
{"snippet": "DataFrame.replace(inplace=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `inplace`.", "question_id": 2566},
{"snippet": "DataFrame.replace(limit=None)", "intent": "Replace values given in `to_replace` with `value` . With arguments `limit`.", "question_id": 2567},
{"snippet": "DataFrame.replace(regex=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `regex`.", "question_id": 2568},
{"snippet": "DataFrame.replace(method='pad')", "intent": "Replace values given in `to_replace` with `value` . When value=None and to_replace is a scalar , list or tuple , replace uses the `method` parameter ( default \u2018 pad \u2019 ) to do the replacement .", "question_id": 2569},
{"snippet": "DataFrame.replace(to_replace=None, value=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 2570},
{"snippet": "DataFrame.replace(to_replace=None, inplace=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `inplace`.", "question_id": 2571},
{"snippet": "DataFrame.replace(to_replace=None, limit=None)", "intent": "Replace values given in `to_replace` with `value` . With arguments `limit`.", "question_id": 2572},
{"snippet": "DataFrame.replace()", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 2573},
{"snippet": "DataFrame.replace(to_replace=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 2574},
{"snippet": "DataFrame.replace(value=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 2575},
{"snippet": "DataFrame.replace(inplace=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `inplace`.", "question_id": 2576},
{"snippet": "DataFrame.replace(limit=None)", "intent": "Replace values given in `to_replace` with `value` . With arguments `limit`.", "question_id": 2577},
{"snippet": "DataFrame.replace(regex=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `regex`.", "question_id": 2578},
{"snippet": "DataFrame.replace(method='pad')", "intent": "Replace values given in `to_replace` with `value` . When value=None and to_replace is a scalar , list or tuple , replace uses the `method` parameter ( default \u2018 pad \u2019 ) to do the replacement .", "question_id": 2579},
{"snippet": "DataFrame.replace(to_replace=None, value=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 2580},
{"snippet": "DataFrame.replace(to_replace=None, inplace=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `inplace`.", "question_id": 2581},
{"snippet": "DataFrame.replace(to_replace=None, limit=None)", "intent": "Replace values given in `to_replace` with `value` . With arguments `limit`.", "question_id": 2582},
{"snippet": "DataFrame.resample(rule)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` .", "question_id": 2583},
{"snippet": "DataFrame.resample(rule, axis=0)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `axis`.", "question_id": 2584},
{"snippet": "DataFrame.resample(rule, closed=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `closed`.", "question_id": 2585},
{"snippet": "DataFrame.resample(rule, label=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . The object must have a datetime-like index ( DatetimeIndex , PeriodIndex , or TimedeltaIndex ) , or the caller must pass the `label` of a datetime-like series/index to the on/level keyword parameter .", "question_id": 2586},
{"snippet": "DataFrame.resample(rule, convention='start')", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` .", "question_id": 2587},
{"snippet": "DataFrame.resample(rule, kind=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `kind`.", "question_id": 2588},
{"snippet": "DataFrame.resample(rule, loffset=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . To replace the use of the deprecated `loffset` argument :", "question_id": 2589},
{"snippet": "DataFrame.resample(rule, base=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . To replace the use of the deprecated `base` argument , you can now use offset , in this example it is equivalent to have base=2 :", "question_id": 2590},
{"snippet": "DataFrame.resample(rule, on=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . For DataFrame objects , the keyword `on` can be used to specify the column instead of the index for resampling .", "question_id": 2591},
{"snippet": "DataFrame.resample(rule, level=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . For a DataFrame with MultiIndex , the keyword `level` can be used to specify on which level the resampling needs to take place .", "question_id": 2592},
{"snippet": "DataFrame.resample(rule)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` .", "question_id": 2593},
{"snippet": "DataFrame.resample(rule, axis=0)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `axis`.", "question_id": 2594},
{"snippet": "DataFrame.resample(rule, closed=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `closed`.", "question_id": 2595},
{"snippet": "DataFrame.resample(rule, label=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . The object must have a datetime-like index ( DatetimeIndex , PeriodIndex , or TimedeltaIndex ) , or the caller must pass the `label` of a datetime-like series/index to the on/level keyword parameter .", "question_id": 2596},
{"snippet": "DataFrame.resample(rule, convention='start')", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` .", "question_id": 2597},
{"snippet": "DataFrame.resample(rule, kind=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `kind`.", "question_id": 2598},
{"snippet": "DataFrame.resample(rule, loffset=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . To replace the use of the deprecated `loffset` argument :", "question_id": 2599},
{"snippet": "DataFrame.resample(rule, base=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . To replace the use of the deprecated `base` argument , you can now use offset , in this example it is equivalent to have base=2 :", "question_id": 2600},
{"snippet": "DataFrame.resample(rule, on=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . For DataFrame objects , the keyword `on` can be used to specify the column instead of the index for resampling .", "question_id": 2601},
{"snippet": "DataFrame.resample(rule, level=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . For a DataFrame with MultiIndex , the keyword `level` can be used to specify on which level the resampling needs to take place .", "question_id": 2602},
{"snippet": "DataFrame.resample(rule)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` .", "question_id": 2603},
{"snippet": "DataFrame.resample(rule, axis=0)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `axis`.", "question_id": 2604},
{"snippet": "DataFrame.resample(rule, closed=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `closed`.", "question_id": 2605},
{"snippet": "DataFrame.resample(rule, label=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . The object must have a datetime-like index ( DatetimeIndex , PeriodIndex , or TimedeltaIndex ) , or the caller must pass the `label` of a datetime-like series/index to the on/level keyword parameter .", "question_id": 2606},
{"snippet": "DataFrame.resample(rule, convention='start')", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` .", "question_id": 2607},
{"snippet": "DataFrame.resample(rule, kind=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `kind`.", "question_id": 2608},
{"snippet": "DataFrame.resample(rule, loffset=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . To replace the use of the deprecated `loffset` argument :", "question_id": 2609},
{"snippet": "DataFrame.resample(rule, base=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . To replace the use of the deprecated `base` argument , you can now use offset , in this example it is equivalent to have base=2 :", "question_id": 2610},
{"snippet": "DataFrame.resample(rule, on=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . For DataFrame objects , the keyword `on` can be used to specify the column instead of the index for resampling .", "question_id": 2611},
{"snippet": "DataFrame.resample(rule, level=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . For a DataFrame with MultiIndex , the keyword `level` can be used to specify on which level the resampling needs to take place .", "question_id": 2612},
{"snippet": "DataFrame.reset_index()", "intent": "Reset the index , or a `level` of it .", "question_id": 2613},
{"snippet": "DataFrame.reset_index(level=None)", "intent": "Reset the index , or a `level` of it .", "question_id": 2614},
{"snippet": "DataFrame.reset_index(drop=False)", "intent": "Reset the index , or a `level` of it . We can use the `drop` parameter to avoid the old index being added as a column :", "question_id": 2615},
{"snippet": "DataFrame.reset_index(inplace=False)", "intent": "Reset the index , or a `level` of it . With arguments `inplace`.", "question_id": 2616},
{"snippet": "DataFrame.reset_index(col_level=0)", "intent": "Reset the index , or a `level` of it . With arguments `col_level`.", "question_id": 2617},
{"snippet": "DataFrame.reset_index(col_fill='')", "intent": "Reset the index , or a `level` of it . When the index is inserted under another level , we can specify under which one with the parameter `col_fill` :", "question_id": 2618},
{"snippet": "DataFrame.reset_index(level=None, drop=False)", "intent": "Reset the index , or a `level` of it . We can use the `drop` parameter to avoid the old index being added as a column :", "question_id": 2619},
{"snippet": "DataFrame.reset_index(level=None, inplace=False)", "intent": "Reset the index , or a `level` of it . With arguments `inplace`.", "question_id": 2620},
{"snippet": "DataFrame.reset_index(level=None, col_level=0)", "intent": "Reset the index , or a `level` of it . With arguments `col_level`.", "question_id": 2621},
{"snippet": "DataFrame.reset_index(level=None, col_fill='')", "intent": "Reset the index , or a `level` of it . When the index is inserted under another level , we can specify under which one with the parameter `col_fill` :", "question_id": 2622},
{"snippet": "DataFrame.reset_index()", "intent": "Reset the index , or a `level` of it .", "question_id": 2623},
{"snippet": "DataFrame.reset_index(level=None)", "intent": "Reset the index , or a `level` of it .", "question_id": 2624},
{"snippet": "DataFrame.reset_index(drop=False)", "intent": "Reset the index , or a `level` of it . We can use the `drop` parameter to avoid the old index being added as a column :", "question_id": 2625},
{"snippet": "DataFrame.reset_index(inplace=False)", "intent": "Reset the index , or a `level` of it . With arguments `inplace`.", "question_id": 2626},
{"snippet": "DataFrame.reset_index(col_level=0)", "intent": "Reset the index , or a `level` of it . With arguments `col_level`.", "question_id": 2627},
{"snippet": "DataFrame.reset_index(col_fill='')", "intent": "Reset the index , or a `level` of it . When the index is inserted under another level , we can specify under which one with the parameter `col_fill` :", "question_id": 2628},
{"snippet": "DataFrame.reset_index(level=None, drop=False)", "intent": "Reset the index , or a `level` of it . We can use the `drop` parameter to avoid the old index being added as a column :", "question_id": 2629},
{"snippet": "DataFrame.reset_index(level=None, inplace=False)", "intent": "Reset the index , or a `level` of it . With arguments `inplace`.", "question_id": 2630},
{"snippet": "DataFrame.reset_index(level=None, col_level=0)", "intent": "Reset the index , or a `level` of it . With arguments `col_level`.", "question_id": 2631},
{"snippet": "DataFrame.reset_index(level=None, col_fill='')", "intent": "Reset the index , or a `level` of it . When the index is inserted under another level , we can specify under which one with the parameter `col_fill` :", "question_id": 2632},
{"snippet": "DataFrame.reset_index()", "intent": "Reset the index , or a `level` of it .", "question_id": 2633},
{"snippet": "DataFrame.reset_index(level=None)", "intent": "Reset the index , or a `level` of it .", "question_id": 2634},
{"snippet": "DataFrame.reset_index(drop=False)", "intent": "Reset the index , or a `level` of it . We can use the `drop` parameter to avoid the old index being added as a column :", "question_id": 2635},
{"snippet": "DataFrame.reset_index(inplace=False)", "intent": "Reset the index , or a `level` of it . With arguments `inplace`.", "question_id": 2636},
{"snippet": "DataFrame.reset_index(col_level=0)", "intent": "Reset the index , or a `level` of it . With arguments `col_level`.", "question_id": 2637},
{"snippet": "DataFrame.reset_index(col_fill='')", "intent": "Reset the index , or a `level` of it . When the index is inserted under another level , we can specify under which one with the parameter `col_fill` :", "question_id": 2638},
{"snippet": "DataFrame.reset_index(level=None, drop=False)", "intent": "Reset the index , or a `level` of it . We can use the `drop` parameter to avoid the old index being added as a column :", "question_id": 2639},
{"snippet": "DataFrame.reset_index(level=None, inplace=False)", "intent": "Reset the index , or a `level` of it . With arguments `inplace`.", "question_id": 2640},
{"snippet": "DataFrame.reset_index(level=None, col_level=0)", "intent": "Reset the index , or a `level` of it . With arguments `col_level`.", "question_id": 2641},
{"snippet": "DataFrame.reset_index(level=None, col_fill='')", "intent": "Reset the index , or a `level` of it . When the index is inserted under another level , we can specify under which one with the parameter `col_fill` :", "question_id": 2642},
{"snippet": "DataFrame.rfloordiv(other)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) .", "question_id": 2643},
{"snippet": "DataFrame.rfloordiv(other, axis='columns')", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2644},
{"snippet": "DataFrame.rfloordiv(other, level=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Divide by a MultiIndex by `level` .", "question_id": 2645},
{"snippet": "DataFrame.rfloordiv(other, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2646},
{"snippet": "DataFrame.rfloordiv(other, axis='columns', level=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2647},
{"snippet": "DataFrame.rfloordiv(other, axis='columns', fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Subtract a list and Series by `axis` with operator version . Equivalent to other // dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2648},
{"snippet": "DataFrame.rfloordiv(other, level=None, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Divide by a MultiIndex by `level` . Equivalent to other // dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2649},
{"snippet": "DataFrame.rfloordiv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other // dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2650},
{"snippet": "DataFrame.rfloordiv(other)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) .", "question_id": 2651},
{"snippet": "DataFrame.rfloordiv(other, axis='columns')", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2652},
{"snippet": "DataFrame.rfloordiv(other, level=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Divide by a MultiIndex by `level` .", "question_id": 2653},
{"snippet": "DataFrame.rfloordiv(other, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2654},
{"snippet": "DataFrame.rfloordiv(other, axis='columns', level=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2655},
{"snippet": "DataFrame.rfloordiv(other, axis='columns', fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Subtract a list and Series by `axis` with operator version . Equivalent to other // dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2656},
{"snippet": "DataFrame.rfloordiv(other, level=None, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Divide by a MultiIndex by `level` . Equivalent to other // dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2657},
{"snippet": "DataFrame.rfloordiv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other // dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2658},
{"snippet": "DataFrame.rfloordiv(other)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) .", "question_id": 2659},
{"snippet": "DataFrame.rfloordiv(other, axis='columns')", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2660},
{"snippet": "DataFrame.rfloordiv(other, level=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Divide by a MultiIndex by `level` .", "question_id": 2661},
{"snippet": "DataFrame.rfloordiv(other, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2662},
{"snippet": "DataFrame.rfloordiv(other, axis='columns', level=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2663},
{"snippet": "DataFrame.rfloordiv(other, axis='columns', fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Subtract a list and Series by `axis` with operator version . Equivalent to other // dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2664},
{"snippet": "DataFrame.rfloordiv(other, level=None, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Divide by a MultiIndex by `level` . Equivalent to other // dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2665},
{"snippet": "DataFrame.rfloordiv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Integer division of dataframe and `other` , element-wise ( binary operator rfloordiv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other // dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2666},
{"snippet": "DataFrame.rmod(other)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) .", "question_id": 2667},
{"snippet": "DataFrame.rmod(other, axis='columns')", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2668},
{"snippet": "DataFrame.rmod(other, level=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Divide by a MultiIndex by `level` .", "question_id": 2669},
{"snippet": "DataFrame.rmod(other, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Equivalent to other % dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2670},
{"snippet": "DataFrame.rmod(other, axis='columns', level=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2671},
{"snippet": "DataFrame.rmod(other, axis='columns', fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Subtract a list and Series by `axis` with operator version . Equivalent to other % dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2672},
{"snippet": "DataFrame.rmod(other, level=None, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Divide by a MultiIndex by `level` . Equivalent to other % dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2673},
{"snippet": "DataFrame.rmod(other, axis='columns', level=None, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other % dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2674},
{"snippet": "DataFrame.rmod(other)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) .", "question_id": 2675},
{"snippet": "DataFrame.rmod(other, axis='columns')", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2676},
{"snippet": "DataFrame.rmod(other, level=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Divide by a MultiIndex by `level` .", "question_id": 2677},
{"snippet": "DataFrame.rmod(other, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Equivalent to other % dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2678},
{"snippet": "DataFrame.rmod(other, axis='columns', level=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2679},
{"snippet": "DataFrame.rmod(other, axis='columns', fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Subtract a list and Series by `axis` with operator version . Equivalent to other % dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2680},
{"snippet": "DataFrame.rmod(other, level=None, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Divide by a MultiIndex by `level` . Equivalent to other % dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2681},
{"snippet": "DataFrame.rmod(other, axis='columns', level=None, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other % dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2682},
{"snippet": "DataFrame.rmod(other)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) .", "question_id": 2683},
{"snippet": "DataFrame.rmod(other, axis='columns')", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2684},
{"snippet": "DataFrame.rmod(other, level=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Divide by a MultiIndex by `level` .", "question_id": 2685},
{"snippet": "DataFrame.rmod(other, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Equivalent to other % dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2686},
{"snippet": "DataFrame.rmod(other, axis='columns', level=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2687},
{"snippet": "DataFrame.rmod(other, axis='columns', fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Subtract a list and Series by `axis` with operator version . Equivalent to other % dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2688},
{"snippet": "DataFrame.rmod(other, level=None, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Divide by a MultiIndex by `level` . Equivalent to other % dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2689},
{"snippet": "DataFrame.rmod(other, axis='columns', level=None, fill_value=None)", "intent": "Get Modulo of dataframe and `other` , element-wise ( binary operator rmod ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other % dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2690},
{"snippet": "DataFrame.rmul(other)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) .", "question_id": 2691},
{"snippet": "DataFrame.rmul(other, axis='columns')", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2692},
{"snippet": "DataFrame.rmul(other, level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Divide by a MultiIndex by `level` .", "question_id": 2693},
{"snippet": "DataFrame.rmul(other, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Equivalent to other * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2694},
{"snippet": "DataFrame.rmul(other, axis='columns', level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2695},
{"snippet": "DataFrame.rmul(other, axis='columns', fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Subtract a list and Series by `axis` with operator version . Equivalent to other * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2696},
{"snippet": "DataFrame.rmul(other, level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Divide by a MultiIndex by `level` . Equivalent to other * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2697},
{"snippet": "DataFrame.rmul(other, axis='columns', level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2698},
{"snippet": "DataFrame.rmul(other)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) .", "question_id": 2699},
{"snippet": "DataFrame.rmul(other, axis='columns')", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2700},
{"snippet": "DataFrame.rmul(other, level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Divide by a MultiIndex by `level` .", "question_id": 2701},
{"snippet": "DataFrame.rmul(other, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Equivalent to other * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2702},
{"snippet": "DataFrame.rmul(other, axis='columns', level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2703},
{"snippet": "DataFrame.rmul(other, axis='columns', fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Subtract a list and Series by `axis` with operator version . Equivalent to other * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2704},
{"snippet": "DataFrame.rmul(other, level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Divide by a MultiIndex by `level` . Equivalent to other * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2705},
{"snippet": "DataFrame.rmul(other, axis='columns', level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2706},
{"snippet": "DataFrame.rmul(other)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) .", "question_id": 2707},
{"snippet": "DataFrame.rmul(other, axis='columns')", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2708},
{"snippet": "DataFrame.rmul(other, level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Divide by a MultiIndex by `level` .", "question_id": 2709},
{"snippet": "DataFrame.rmul(other, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Equivalent to other * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2710},
{"snippet": "DataFrame.rmul(other, axis='columns', level=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2711},
{"snippet": "DataFrame.rmul(other, axis='columns', fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Subtract a list and Series by `axis` with operator version . Equivalent to other * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2712},
{"snippet": "DataFrame.rmul(other, level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Divide by a MultiIndex by `level` . Equivalent to other * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2713},
{"snippet": "DataFrame.rmul(other, axis='columns', level=None, fill_value=None)", "intent": "Get Multiplication of dataframe and `other` , element-wise ( binary operator rmul ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2714},
{"snippet": "DataFrame.rolling(window)", "intent": "Provide rolling `window` calculations .", "question_id": 2715},
{"snippet": "DataFrame.rolling(window, min_periods=None)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length .", "question_id": 2716},
{"snippet": "DataFrame.rolling(window, center=False)", "intent": "Provide rolling `window` calculations . This can be changed to the `center` of the window by setting center=True .", "question_id": 2717},
{"snippet": "DataFrame.rolling(window, win_type=None)", "intent": "Provide rolling `window` calculations . If win_type=None , all points are evenly weighted ; otherwise , `win_type` can accept a string of any scipy.signal window function .", "question_id": 2718},
{"snippet": "DataFrame.rolling(window, on=None)", "intent": "Provide rolling `window` calculations . Please see the third example below `on` how to add the additional parameters .", "question_id": 2719},
{"snippet": "DataFrame.rolling(window, axis=0)", "intent": "Provide rolling `window` calculations . With arguments `axis`.", "question_id": 2720},
{"snippet": "DataFrame.rolling(window, closed=None)", "intent": "Provide rolling `window` calculations . With arguments `closed`.", "question_id": 2721},
{"snippet": "DataFrame.rolling(window, method='single')", "intent": "Provide rolling `window` calculations . The additional parameters must match the keywords specified in the Scipy window type `method` signature .", "question_id": 2722},
{"snippet": "DataFrame.rolling(window, min_periods=None, center=False)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length . This can be changed to the `center` of the window by setting center=True .", "question_id": 2723},
{"snippet": "DataFrame.rolling(window, min_periods=None, win_type=None)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length . If win_type=None , all points are evenly weighted ; otherwise , `win_type` can accept a string of any scipy.signal window function .", "question_id": 2724},
{"snippet": "DataFrame.rolling(window)", "intent": "Provide rolling `window` calculations .", "question_id": 2725},
{"snippet": "DataFrame.rolling(window, min_periods=None)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length .", "question_id": 2726},
{"snippet": "DataFrame.rolling(window, center=False)", "intent": "Provide rolling `window` calculations . This can be changed to the `center` of the window by setting center=True .", "question_id": 2727},
{"snippet": "DataFrame.rolling(window, win_type=None)", "intent": "Provide rolling `window` calculations . If win_type=None , all points are evenly weighted ; otherwise , `win_type` can accept a string of any scipy.signal window function .", "question_id": 2728},
{"snippet": "DataFrame.rolling(window, on=None)", "intent": "Provide rolling `window` calculations . Please see the third example below `on` how to add the additional parameters .", "question_id": 2729},
{"snippet": "DataFrame.rolling(window, axis=0)", "intent": "Provide rolling `window` calculations . With arguments `axis`.", "question_id": 2730},
{"snippet": "DataFrame.rolling(window, closed=None)", "intent": "Provide rolling `window` calculations . With arguments `closed`.", "question_id": 2731},
{"snippet": "DataFrame.rolling(window, method='single')", "intent": "Provide rolling `window` calculations . The additional parameters must match the keywords specified in the Scipy window type `method` signature .", "question_id": 2732},
{"snippet": "DataFrame.rolling(window, min_periods=None, center=False)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length . This can be changed to the `center` of the window by setting center=True .", "question_id": 2733},
{"snippet": "DataFrame.rolling(window, min_periods=None, win_type=None)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length . If win_type=None , all points are evenly weighted ; otherwise , `win_type` can accept a string of any scipy.signal window function .", "question_id": 2734},
{"snippet": "DataFrame.rolling(window)", "intent": "Provide rolling `window` calculations .", "question_id": 2735},
{"snippet": "DataFrame.rolling(window, min_periods=None)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length .", "question_id": 2736},
{"snippet": "DataFrame.rolling(window, center=False)", "intent": "Provide rolling `window` calculations . This can be changed to the `center` of the window by setting center=True .", "question_id": 2737},
{"snippet": "DataFrame.rolling(window, win_type=None)", "intent": "Provide rolling `window` calculations . If win_type=None , all points are evenly weighted ; otherwise , `win_type` can accept a string of any scipy.signal window function .", "question_id": 2738},
{"snippet": "DataFrame.rolling(window, on=None)", "intent": "Provide rolling `window` calculations . Please see the third example below `on` how to add the additional parameters .", "question_id": 2739},
{"snippet": "DataFrame.rolling(window, axis=0)", "intent": "Provide rolling `window` calculations . With arguments `axis`.", "question_id": 2740},
{"snippet": "DataFrame.rolling(window, closed=None)", "intent": "Provide rolling `window` calculations . With arguments `closed`.", "question_id": 2741},
{"snippet": "DataFrame.rolling(window, method='single')", "intent": "Provide rolling `window` calculations . The additional parameters must match the keywords specified in the Scipy window type `method` signature .", "question_id": 2742},
{"snippet": "DataFrame.rolling(window, min_periods=None, center=False)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length . This can be changed to the `center` of the window by setting center=True .", "question_id": 2743},
{"snippet": "DataFrame.rolling(window, min_periods=None, win_type=None)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length . If win_type=None , all points are evenly weighted ; otherwise , `win_type` can accept a string of any scipy.signal window function .", "question_id": 2744},
{"snippet": "DataFrame.round(*args, **kwargs)", "intent": "Round a DataFrame to a variable number of decimal places . With arguments `*args`, `**kwargs`.", "question_id": 2745},
{"snippet": "DataFrame.round(*args, **kwargs, decimals=0)", "intent": "Round a DataFrame to a variable number of decimal places . With arguments `*args`, `**kwargs`, `decimals`.", "question_id": 2746},
{"snippet": "DataFrame.round(*args, **kwargs)", "intent": "Round a DataFrame to a variable number of decimal places . With arguments `*args`, `**kwargs`.", "question_id": 2747},
{"snippet": "DataFrame.round(*args, **kwargs, decimals=0)", "intent": "Round a DataFrame to a variable number of decimal places . With arguments `*args`, `**kwargs`, `decimals`.", "question_id": 2748},
{"snippet": "DataFrame.round(*args, **kwargs)", "intent": "Round a DataFrame to a variable number of decimal places . With arguments `*args`, `**kwargs`.", "question_id": 2749},
{"snippet": "DataFrame.round(*args, **kwargs, decimals=0)", "intent": "Round a DataFrame to a variable number of decimal places . With arguments `*args`, `**kwargs`, `decimals`.", "question_id": 2750},
{"snippet": "DataFrame.rpow(other)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) .", "question_id": 2751},
{"snippet": "DataFrame.rpow(other, axis='columns')", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2752},
{"snippet": "DataFrame.rpow(other, level=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Divide by a MultiIndex by `level` .", "question_id": 2753},
{"snippet": "DataFrame.rpow(other, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2754},
{"snippet": "DataFrame.rpow(other, axis='columns', level=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2755},
{"snippet": "DataFrame.rpow(other, axis='columns', fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Subtract a list and Series by `axis` with operator version . Equivalent to other * * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2756},
{"snippet": "DataFrame.rpow(other, level=None, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Divide by a MultiIndex by `level` . Equivalent to other * * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2757},
{"snippet": "DataFrame.rpow(other, axis='columns', level=None, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other * * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2758},
{"snippet": "DataFrame.rpow(other)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) .", "question_id": 2759},
{"snippet": "DataFrame.rpow(other, axis='columns')", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2760},
{"snippet": "DataFrame.rpow(other, level=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Divide by a MultiIndex by `level` .", "question_id": 2761},
{"snippet": "DataFrame.rpow(other, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2762},
{"snippet": "DataFrame.rpow(other, axis='columns', level=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2763},
{"snippet": "DataFrame.rpow(other, axis='columns', fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Subtract a list and Series by `axis` with operator version . Equivalent to other * * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2764},
{"snippet": "DataFrame.rpow(other, level=None, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Divide by a MultiIndex by `level` . Equivalent to other * * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2765},
{"snippet": "DataFrame.rpow(other, axis='columns', level=None, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other * * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2766},
{"snippet": "DataFrame.rpow(other)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) .", "question_id": 2767},
{"snippet": "DataFrame.rpow(other, axis='columns')", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2768},
{"snippet": "DataFrame.rpow(other, level=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Divide by a MultiIndex by `level` .", "question_id": 2769},
{"snippet": "DataFrame.rpow(other, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2770},
{"snippet": "DataFrame.rpow(other, axis='columns', level=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2771},
{"snippet": "DataFrame.rpow(other, axis='columns', fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Subtract a list and Series by `axis` with operator version . Equivalent to other * * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2772},
{"snippet": "DataFrame.rpow(other, level=None, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Divide by a MultiIndex by `level` . Equivalent to other * * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2773},
{"snippet": "DataFrame.rpow(other, axis='columns', level=None, fill_value=None)", "intent": "Get Exponential power of dataframe and `other` , element-wise ( binary operator rpow ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other * * dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2774},
{"snippet": "DataFrame.rsub(other)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) .", "question_id": 2775},
{"snippet": "DataFrame.rsub(other, axis='columns')", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2776},
{"snippet": "DataFrame.rsub(other, level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Divide by a MultiIndex by `level` .", "question_id": 2777},
{"snippet": "DataFrame.rsub(other, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Equivalent to other - dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2778},
{"snippet": "DataFrame.rsub(other, axis='columns', level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2779},
{"snippet": "DataFrame.rsub(other, axis='columns', fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Subtract a list and Series by `axis` with operator version . Equivalent to other - dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2780},
{"snippet": "DataFrame.rsub(other, level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Divide by a MultiIndex by `level` . Equivalent to other - dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2781},
{"snippet": "DataFrame.rsub(other, axis='columns', level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other - dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2782},
{"snippet": "DataFrame.rsub(other)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) .", "question_id": 2783},
{"snippet": "DataFrame.rsub(other, axis='columns')", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2784},
{"snippet": "DataFrame.rsub(other, level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Divide by a MultiIndex by `level` .", "question_id": 2785},
{"snippet": "DataFrame.rsub(other, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Equivalent to other - dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2786},
{"snippet": "DataFrame.rsub(other, axis='columns', level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2787},
{"snippet": "DataFrame.rsub(other, axis='columns', fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Subtract a list and Series by `axis` with operator version . Equivalent to other - dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2788},
{"snippet": "DataFrame.rsub(other, level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Divide by a MultiIndex by `level` . Equivalent to other - dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2789},
{"snippet": "DataFrame.rsub(other, axis='columns', level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other - dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2790},
{"snippet": "DataFrame.rsub(other)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) .", "question_id": 2791},
{"snippet": "DataFrame.rsub(other, axis='columns')", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2792},
{"snippet": "DataFrame.rsub(other, level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Divide by a MultiIndex by `level` .", "question_id": 2793},
{"snippet": "DataFrame.rsub(other, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Equivalent to other - dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2794},
{"snippet": "DataFrame.rsub(other, axis='columns', level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2795},
{"snippet": "DataFrame.rsub(other, axis='columns', fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Subtract a list and Series by `axis` with operator version . Equivalent to other - dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2796},
{"snippet": "DataFrame.rsub(other, level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Divide by a MultiIndex by `level` . Equivalent to other - dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2797},
{"snippet": "DataFrame.rsub(other, axis='columns', level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator rsub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other - dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2798},
{"snippet": "DataFrame.rtruediv(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) .", "question_id": 2799},
{"snippet": "DataFrame.rtruediv(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2800},
{"snippet": "DataFrame.rtruediv(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Divide by a MultiIndex by `level` .", "question_id": 2801},
{"snippet": "DataFrame.rtruediv(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2802},
{"snippet": "DataFrame.rtruediv(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2803},
{"snippet": "DataFrame.rtruediv(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2804},
{"snippet": "DataFrame.rtruediv(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Divide by a MultiIndex by `level` . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2805},
{"snippet": "DataFrame.rtruediv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2806},
{"snippet": "DataFrame.rtruediv(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) .", "question_id": 2807},
{"snippet": "DataFrame.rtruediv(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2808},
{"snippet": "DataFrame.rtruediv(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Divide by a MultiIndex by `level` .", "question_id": 2809},
{"snippet": "DataFrame.rtruediv(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2810},
{"snippet": "DataFrame.rtruediv(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2811},
{"snippet": "DataFrame.rtruediv(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2812},
{"snippet": "DataFrame.rtruediv(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Divide by a MultiIndex by `level` . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2813},
{"snippet": "DataFrame.rtruediv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2814},
{"snippet": "DataFrame.rtruediv(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) .", "question_id": 2815},
{"snippet": "DataFrame.rtruediv(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 2816},
{"snippet": "DataFrame.rtruediv(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Divide by a MultiIndex by `level` .", "question_id": 2817},
{"snippet": "DataFrame.rtruediv(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2818},
{"snippet": "DataFrame.rtruediv(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 2819},
{"snippet": "DataFrame.rtruediv(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2820},
{"snippet": "DataFrame.rtruediv(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Divide by a MultiIndex by `level` . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2821},
{"snippet": "DataFrame.rtruediv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator rtruediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to other / dataframe , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 2822},
{"snippet": "DataFrame.sample()", "intent": "Return a random sample of items from an `axis` of object .", "question_id": 2823},
{"snippet": "DataFrame.sample(n=None)", "intent": "Return a random sample of items from an `axis` of object . With arguments `n`.", "question_id": 2824},
{"snippet": "DataFrame.sample(frac=None)", "intent": "Return a random sample of items from an `axis` of object . If `frac` > 1 , replacement should be set to True .", "question_id": 2825},
{"snippet": "DataFrame.sample(replace=False)", "intent": "Return a random sample of items from an `axis` of object . An upsample sample of the DataFrame with replacement : Note that `replace` parameter has to be True for frac parameter > 1 .", "question_id": 2826},
{"snippet": "DataFrame.sample(weights=None)", "intent": "Return a random sample of items from an `axis` of object . Using a DataFrame column as `weights` .", "question_id": 2827},
{"snippet": "DataFrame.sample(random_state=None)", "intent": "Return a random sample of items from an `axis` of object . You can use `random_state` for reproducibility .", "question_id": 2828},
{"snippet": "DataFrame.sample(axis=None)", "intent": "Return a random sample of items from an `axis` of object .", "question_id": 2829},
{"snippet": "DataFrame.sample(ignore_index=False)", "intent": "Return a random sample of items from an `axis` of object . With arguments `ignore_index`.", "question_id": 2830},
{"snippet": "DataFrame.sample(n=None, frac=None)", "intent": "Return a random sample of items from an `axis` of object . If `frac` > 1 , replacement should be set to True . With arguments `n`.", "question_id": 2831},
{"snippet": "DataFrame.sample(n=None, replace=False)", "intent": "Return a random sample of items from an `axis` of object . An upsample sample of the DataFrame with replacement : Note that `replace` parameter has to be True for frac parameter > 1 . With arguments `n`.", "question_id": 2832},
{"snippet": "DataFrame.sample()", "intent": "Return a random sample of items from an `axis` of object .", "question_id": 2833},
{"snippet": "DataFrame.sample(n=None)", "intent": "Return a random sample of items from an `axis` of object . With arguments `n`.", "question_id": 2834},
{"snippet": "DataFrame.sample(frac=None)", "intent": "Return a random sample of items from an `axis` of object . If `frac` > 1 , replacement should be set to True .", "question_id": 2835},
{"snippet": "DataFrame.sample(replace=False)", "intent": "Return a random sample of items from an `axis` of object . An upsample sample of the DataFrame with replacement : Note that `replace` parameter has to be True for frac parameter > 1 .", "question_id": 2836},
{"snippet": "DataFrame.sample(weights=None)", "intent": "Return a random sample of items from an `axis` of object . Using a DataFrame column as `weights` .", "question_id": 2837},
{"snippet": "DataFrame.sample(random_state=None)", "intent": "Return a random sample of items from an `axis` of object . You can use `random_state` for reproducibility .", "question_id": 2838},
{"snippet": "DataFrame.sample(axis=None)", "intent": "Return a random sample of items from an `axis` of object .", "question_id": 2839},
{"snippet": "DataFrame.sample(ignore_index=False)", "intent": "Return a random sample of items from an `axis` of object . With arguments `ignore_index`.", "question_id": 2840},
{"snippet": "DataFrame.sample(n=None, frac=None)", "intent": "Return a random sample of items from an `axis` of object . If `frac` > 1 , replacement should be set to True . With arguments `n`.", "question_id": 2841},
{"snippet": "DataFrame.sample(n=None, replace=False)", "intent": "Return a random sample of items from an `axis` of object . An upsample sample of the DataFrame with replacement : Note that `replace` parameter has to be True for frac parameter > 1 . With arguments `n`.", "question_id": 2842},
{"snippet": "DataFrame.sample()", "intent": "Return a random sample of items from an `axis` of object .", "question_id": 2843},
{"snippet": "DataFrame.sample(n=None)", "intent": "Return a random sample of items from an `axis` of object . With arguments `n`.", "question_id": 2844},
{"snippet": "DataFrame.sample(frac=None)", "intent": "Return a random sample of items from an `axis` of object . If `frac` > 1 , replacement should be set to True .", "question_id": 2845},
{"snippet": "DataFrame.sample(replace=False)", "intent": "Return a random sample of items from an `axis` of object . An upsample sample of the DataFrame with replacement : Note that `replace` parameter has to be True for frac parameter > 1 .", "question_id": 2846},
{"snippet": "DataFrame.sample(weights=None)", "intent": "Return a random sample of items from an `axis` of object . Using a DataFrame column as `weights` .", "question_id": 2847},
{"snippet": "DataFrame.sample(random_state=None)", "intent": "Return a random sample of items from an `axis` of object . You can use `random_state` for reproducibility .", "question_id": 2848},
{"snippet": "DataFrame.sample(axis=None)", "intent": "Return a random sample of items from an `axis` of object .", "question_id": 2849},
{"snippet": "DataFrame.sample(ignore_index=False)", "intent": "Return a random sample of items from an `axis` of object . With arguments `ignore_index`.", "question_id": 2850},
{"snippet": "DataFrame.sample(n=None, frac=None)", "intent": "Return a random sample of items from an `axis` of object . If `frac` > 1 , replacement should be set to True . With arguments `n`.", "question_id": 2851},
{"snippet": "DataFrame.sample(n=None, replace=False)", "intent": "Return a random sample of items from an `axis` of object . An upsample sample of the DataFrame with replacement : Note that `replace` parameter has to be True for frac parameter > 1 . With arguments `n`.", "question_id": 2852},
{"snippet": "DataFrame.select_dtypes()", "intent": "Return a subset of the DataFrame \u2019 s columns based on the column dtypes .", "question_id": 2853},
{"snippet": "DataFrame.select_dtypes(include=None)", "intent": "Return a subset of the DataFrame \u2019 s columns based on the column dtypes . With arguments `include`.", "question_id": 2854},
{"snippet": "DataFrame.select_dtypes(exclude=None)", "intent": "Return a subset of the DataFrame \u2019 s columns based on the column dtypes . With arguments `exclude`.", "question_id": 2855},
{"snippet": "DataFrame.select_dtypes(include=None, exclude=None)", "intent": "Return a subset of the DataFrame \u2019 s columns based on the column dtypes . With arguments `include`, `exclude`.", "question_id": 2856},
{"snippet": "DataFrame.select_dtypes()", "intent": "Return a subset of the DataFrame \u2019 s columns based on the column dtypes .", "question_id": 2857},
{"snippet": "DataFrame.select_dtypes(include=None)", "intent": "Return a subset of the DataFrame \u2019 s columns based on the column dtypes . With arguments `include`.", "question_id": 2858},
{"snippet": "DataFrame.select_dtypes(exclude=None)", "intent": "Return a subset of the DataFrame \u2019 s columns based on the column dtypes . With arguments `exclude`.", "question_id": 2859},
{"snippet": "DataFrame.select_dtypes(include=None, exclude=None)", "intent": "Return a subset of the DataFrame \u2019 s columns based on the column dtypes . With arguments `include`, `exclude`.", "question_id": 2860},
{"snippet": "DataFrame.select_dtypes()", "intent": "Return a subset of the DataFrame \u2019 s columns based on the column dtypes .", "question_id": 2861},
{"snippet": "DataFrame.select_dtypes(include=None)", "intent": "Return a subset of the DataFrame \u2019 s columns based on the column dtypes . With arguments `include`.", "question_id": 2862},
{"snippet": "DataFrame.select_dtypes(exclude=None)", "intent": "Return a subset of the DataFrame \u2019 s columns based on the column dtypes . With arguments `exclude`.", "question_id": 2863},
{"snippet": "DataFrame.select_dtypes(include=None, exclude=None)", "intent": "Return a subset of the DataFrame \u2019 s columns based on the column dtypes . With arguments `include`, `exclude`.", "question_id": 2864},
{"snippet": "DataFrame.sem(**kwargs)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`.", "question_id": 2865},
{"snippet": "DataFrame.sem(**kwargs, axis=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`.", "question_id": 2866},
{"snippet": "DataFrame.sem(**kwargs, skipna=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 2867},
{"snippet": "DataFrame.sem(**kwargs, level=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2868},
{"snippet": "DataFrame.sem(**kwargs, ddof=1)", "intent": "Return unbiased standard error of the mean over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 2869},
{"snippet": "DataFrame.sem(**kwargs, numeric_only=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2870},
{"snippet": "DataFrame.sem(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 2871},
{"snippet": "DataFrame.sem(**kwargs, axis=None, level=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2872},
{"snippet": "DataFrame.sem(**kwargs, axis=None, ddof=1)", "intent": "Return unbiased standard error of the mean over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 2873},
{"snippet": "DataFrame.sem(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2874},
{"snippet": "DataFrame.sem(**kwargs)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`.", "question_id": 2875},
{"snippet": "DataFrame.sem(**kwargs, axis=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`.", "question_id": 2876},
{"snippet": "DataFrame.sem(**kwargs, skipna=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 2877},
{"snippet": "DataFrame.sem(**kwargs, level=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2878},
{"snippet": "DataFrame.sem(**kwargs, ddof=1)", "intent": "Return unbiased standard error of the mean over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 2879},
{"snippet": "DataFrame.sem(**kwargs, numeric_only=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2880},
{"snippet": "DataFrame.sem(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 2881},
{"snippet": "DataFrame.sem(**kwargs, axis=None, level=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2882},
{"snippet": "DataFrame.sem(**kwargs, axis=None, ddof=1)", "intent": "Return unbiased standard error of the mean over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 2883},
{"snippet": "DataFrame.sem(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2884},
{"snippet": "DataFrame.sem(**kwargs)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`.", "question_id": 2885},
{"snippet": "DataFrame.sem(**kwargs, axis=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`.", "question_id": 2886},
{"snippet": "DataFrame.sem(**kwargs, skipna=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 2887},
{"snippet": "DataFrame.sem(**kwargs, level=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2888},
{"snippet": "DataFrame.sem(**kwargs, ddof=1)", "intent": "Return unbiased standard error of the mean over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 2889},
{"snippet": "DataFrame.sem(**kwargs, numeric_only=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2890},
{"snippet": "DataFrame.sem(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 2891},
{"snippet": "DataFrame.sem(**kwargs, axis=None, level=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2892},
{"snippet": "DataFrame.sem(**kwargs, axis=None, ddof=1)", "intent": "Return unbiased standard error of the mean over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 2893},
{"snippet": "DataFrame.sem(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2894},
{"snippet": "DataFrame.set_axis(labels)", "intent": "Assign desired index to given `axis` . Indexes for column or row `labels` can be changed by assigning a list-like or Index .", "question_id": 2895},
{"snippet": "DataFrame.set_axis(labels, axis=0)", "intent": "Assign desired index to given `axis` . Indexes for column or row `labels` can be changed by assigning a list-like or Index .", "question_id": 2896},
{"snippet": "DataFrame.set_axis(labels, inplace=False)", "intent": "Assign desired index to given `axis` . Indexes for column or row `labels` can be changed by assigning a list-like or Index . Now , update the labels `inplace` .", "question_id": 2897},
{"snippet": "DataFrame.set_axis(labels, axis=0, inplace=False)", "intent": "Assign desired index to given `axis` . Indexes for column or row `labels` can be changed by assigning a list-like or Index . Now , update the labels `inplace` .", "question_id": 2898},
{"snippet": "DataFrame.set_axis(labels)", "intent": "Assign desired index to given `axis` . Indexes for column or row `labels` can be changed by assigning a list-like or Index .", "question_id": 2899},
{"snippet": "DataFrame.set_axis(labels, axis=0)", "intent": "Assign desired index to given `axis` . Indexes for column or row `labels` can be changed by assigning a list-like or Index .", "question_id": 2900},
{"snippet": "DataFrame.set_axis(labels, inplace=False)", "intent": "Assign desired index to given `axis` . Indexes for column or row `labels` can be changed by assigning a list-like or Index . Now , update the labels `inplace` .", "question_id": 2901},
{"snippet": "DataFrame.set_axis(labels, axis=0, inplace=False)", "intent": "Assign desired index to given `axis` . Indexes for column or row `labels` can be changed by assigning a list-like or Index . Now , update the labels `inplace` .", "question_id": 2902},
{"snippet": "DataFrame.set_axis(labels)", "intent": "Assign desired index to given `axis` . Indexes for column or row `labels` can be changed by assigning a list-like or Index .", "question_id": 2903},
{"snippet": "DataFrame.set_axis(labels, axis=0)", "intent": "Assign desired index to given `axis` . Indexes for column or row `labels` can be changed by assigning a list-like or Index .", "question_id": 2904},
{"snippet": "DataFrame.set_axis(labels, inplace=False)", "intent": "Assign desired index to given `axis` . Indexes for column or row `labels` can be changed by assigning a list-like or Index . Now , update the labels `inplace` .", "question_id": 2905},
{"snippet": "DataFrame.set_axis(labels, axis=0, inplace=False)", "intent": "Assign desired index to given `axis` . Indexes for column or row `labels` can be changed by assigning a list-like or Index . Now , update the labels `inplace` .", "question_id": 2906},
{"snippet": "DataFrame.set_flags()", "intent": "Return a new object with updated flags .", "question_id": 2907},
{"snippet": "DataFrame.set_flags(copy=False)", "intent": "Return a new object with updated flags . With arguments `copy`.", "question_id": 2908},
{"snippet": "DataFrame.set_flags(allows_duplicate_labels=None)", "intent": "Return a new object with updated flags . With arguments `allows_duplicate_labels`.", "question_id": 2909},
{"snippet": "DataFrame.set_flags(copy=False, allows_duplicate_labels=None)", "intent": "Return a new object with updated flags . With arguments `copy`, `allows_duplicate_labels`.", "question_id": 2910},
{"snippet": "DataFrame.set_flags()", "intent": "Return a new object with updated flags .", "question_id": 2911},
{"snippet": "DataFrame.set_flags(copy=False)", "intent": "Return a new object with updated flags . With arguments `copy`.", "question_id": 2912},
{"snippet": "DataFrame.set_flags(allows_duplicate_labels=None)", "intent": "Return a new object with updated flags . With arguments `allows_duplicate_labels`.", "question_id": 2913},
{"snippet": "DataFrame.set_flags(copy=False, allows_duplicate_labels=None)", "intent": "Return a new object with updated flags . With arguments `copy`, `allows_duplicate_labels`.", "question_id": 2914},
{"snippet": "DataFrame.set_flags()", "intent": "Return a new object with updated flags .", "question_id": 2915},
{"snippet": "DataFrame.set_flags(copy=False)", "intent": "Return a new object with updated flags . With arguments `copy`.", "question_id": 2916},
{"snippet": "DataFrame.set_flags(allows_duplicate_labels=None)", "intent": "Return a new object with updated flags . With arguments `allows_duplicate_labels`.", "question_id": 2917},
{"snippet": "DataFrame.set_flags(copy=False, allows_duplicate_labels=None)", "intent": "Return a new object with updated flags . With arguments `copy`, `allows_duplicate_labels`.", "question_id": 2918},
{"snippet": "DataFrame.set_index(keys)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`.", "question_id": 2919},
{"snippet": "DataFrame.set_index(keys, drop=True)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `drop`.", "question_id": 2920},
{"snippet": "DataFrame.set_index(keys, append=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `append`.", "question_id": 2921},
{"snippet": "DataFrame.set_index(keys, inplace=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `inplace`.", "question_id": 2922},
{"snippet": "DataFrame.set_index(keys, verify_integrity=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `verify_integrity`.", "question_id": 2923},
{"snippet": "DataFrame.set_index(keys, drop=True, append=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `drop`, `append`.", "question_id": 2924},
{"snippet": "DataFrame.set_index(keys, drop=True, inplace=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `drop`, `inplace`.", "question_id": 2925},
{"snippet": "DataFrame.set_index(keys, drop=True, verify_integrity=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `drop`, `verify_integrity`.", "question_id": 2926},
{"snippet": "DataFrame.set_index(keys, append=False, inplace=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `append`, `inplace`.", "question_id": 2927},
{"snippet": "DataFrame.set_index(keys, append=False, verify_integrity=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `append`, `verify_integrity`.", "question_id": 2928},
{"snippet": "DataFrame.set_index(keys)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`.", "question_id": 2929},
{"snippet": "DataFrame.set_index(keys, drop=True)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `drop`.", "question_id": 2930},
{"snippet": "DataFrame.set_index(keys, append=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `append`.", "question_id": 2931},
{"snippet": "DataFrame.set_index(keys, inplace=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `inplace`.", "question_id": 2932},
{"snippet": "DataFrame.set_index(keys, verify_integrity=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `verify_integrity`.", "question_id": 2933},
{"snippet": "DataFrame.set_index(keys, drop=True, append=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `drop`, `append`.", "question_id": 2934},
{"snippet": "DataFrame.set_index(keys, drop=True, inplace=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `drop`, `inplace`.", "question_id": 2935},
{"snippet": "DataFrame.set_index(keys, drop=True, verify_integrity=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `drop`, `verify_integrity`.", "question_id": 2936},
{"snippet": "DataFrame.set_index(keys, append=False, inplace=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `append`, `inplace`.", "question_id": 2937},
{"snippet": "DataFrame.set_index(keys, append=False, verify_integrity=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `append`, `verify_integrity`.", "question_id": 2938},
{"snippet": "DataFrame.set_index(keys)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`.", "question_id": 2939},
{"snippet": "DataFrame.set_index(keys, drop=True)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `drop`.", "question_id": 2940},
{"snippet": "DataFrame.set_index(keys, append=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `append`.", "question_id": 2941},
{"snippet": "DataFrame.set_index(keys, inplace=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `inplace`.", "question_id": 2942},
{"snippet": "DataFrame.set_index(keys, verify_integrity=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `verify_integrity`.", "question_id": 2943},
{"snippet": "DataFrame.set_index(keys, drop=True, append=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `drop`, `append`.", "question_id": 2944},
{"snippet": "DataFrame.set_index(keys, drop=True, inplace=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `drop`, `inplace`.", "question_id": 2945},
{"snippet": "DataFrame.set_index(keys, drop=True, verify_integrity=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `drop`, `verify_integrity`.", "question_id": 2946},
{"snippet": "DataFrame.set_index(keys, append=False, inplace=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `append`, `inplace`.", "question_id": 2947},
{"snippet": "DataFrame.set_index(keys, append=False, verify_integrity=False)", "intent": "Set the DataFrame index using existing columns . With arguments `keys`, `append`, `verify_integrity`.", "question_id": 2948},
{"snippet": "DataFrame.shift()", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 2949},
{"snippet": "DataFrame.shift(periods=1)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 2950},
{"snippet": "DataFrame.shift(freq=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 2951},
{"snippet": "DataFrame.shift(axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 2952},
{"snippet": "DataFrame.shift(fill_value=NoDefault.no_default)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 2953},
{"snippet": "DataFrame.shift(periods=1, freq=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 2954},
{"snippet": "DataFrame.shift(periods=1, axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 2955},
{"snippet": "DataFrame.shift(periods=1, fill_value=NoDefault.no_default)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 2956},
{"snippet": "DataFrame.shift(freq=None, axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 2957},
{"snippet": "DataFrame.shift(freq=None, fill_value=NoDefault.no_default)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 2958},
{"snippet": "DataFrame.shift()", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 2959},
{"snippet": "DataFrame.shift(periods=1)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 2960},
{"snippet": "DataFrame.shift(freq=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 2961},
{"snippet": "DataFrame.shift(axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 2962},
{"snippet": "DataFrame.shift(fill_value=NoDefault.no_default)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 2963},
{"snippet": "DataFrame.shift(periods=1, freq=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 2964},
{"snippet": "DataFrame.shift(periods=1, axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 2965},
{"snippet": "DataFrame.shift(periods=1, fill_value=NoDefault.no_default)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 2966},
{"snippet": "DataFrame.shift(freq=None, axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 2967},
{"snippet": "DataFrame.shift(freq=None, fill_value=NoDefault.no_default)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 2968},
{"snippet": "DataFrame.shift()", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 2969},
{"snippet": "DataFrame.shift(periods=1)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 2970},
{"snippet": "DataFrame.shift(freq=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 2971},
{"snippet": "DataFrame.shift(axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 2972},
{"snippet": "DataFrame.shift(fill_value=NoDefault.no_default)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 2973},
{"snippet": "DataFrame.shift(periods=1, freq=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 2974},
{"snippet": "DataFrame.shift(periods=1, axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 2975},
{"snippet": "DataFrame.shift(periods=1, fill_value=NoDefault.no_default)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 2976},
{"snippet": "DataFrame.shift(freq=None, axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 2977},
{"snippet": "DataFrame.shift(freq=None, fill_value=NoDefault.no_default)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 2978},
{"snippet": "DataFrame.skew(**kwargs)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`.", "question_id": 2979},
{"snippet": "DataFrame.skew(**kwargs, axis=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`.", "question_id": 2980},
{"snippet": "DataFrame.skew(**kwargs, skipna=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 2981},
{"snippet": "DataFrame.skew(**kwargs, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2982},
{"snippet": "DataFrame.skew(**kwargs, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2983},
{"snippet": "DataFrame.skew(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 2984},
{"snippet": "DataFrame.skew(**kwargs, axis=None, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2985},
{"snippet": "DataFrame.skew(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2986},
{"snippet": "DataFrame.skew(**kwargs, skipna=None, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 2987},
{"snippet": "DataFrame.skew(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 2988},
{"snippet": "DataFrame.skew(**kwargs)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`.", "question_id": 2989},
{"snippet": "DataFrame.skew(**kwargs, axis=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`.", "question_id": 2990},
{"snippet": "DataFrame.skew(**kwargs, skipna=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 2991},
{"snippet": "DataFrame.skew(**kwargs, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2992},
{"snippet": "DataFrame.skew(**kwargs, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2993},
{"snippet": "DataFrame.skew(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 2994},
{"snippet": "DataFrame.skew(**kwargs, axis=None, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 2995},
{"snippet": "DataFrame.skew(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 2996},
{"snippet": "DataFrame.skew(**kwargs, skipna=None, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 2997},
{"snippet": "DataFrame.skew(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 2998},
{"snippet": "DataFrame.skew(**kwargs)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`.", "question_id": 2999},
{"snippet": "DataFrame.skew(**kwargs, axis=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`.", "question_id": 3000},
{"snippet": "DataFrame.skew(**kwargs, skipna=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 3001},
{"snippet": "DataFrame.skew(**kwargs, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 3002},
{"snippet": "DataFrame.skew(**kwargs, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 3003},
{"snippet": "DataFrame.skew(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 3004},
{"snippet": "DataFrame.skew(**kwargs, axis=None, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 3005},
{"snippet": "DataFrame.skew(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 3006},
{"snippet": "DataFrame.skew(**kwargs, skipna=None, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 3007},
{"snippet": "DataFrame.skew(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 3008},
{"snippet": "DataFrame.slice_shift()", "intent": "Equivalent to shift without copying data .", "question_id": 3009},
{"snippet": "DataFrame.slice_shift(periods=1)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 3010},
{"snippet": "DataFrame.slice_shift(axis=0)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 3011},
{"snippet": "DataFrame.slice_shift(periods=1, axis=0)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 3012},
{"snippet": "DataFrame.slice_shift()", "intent": "Equivalent to shift without copying data .", "question_id": 3013},
{"snippet": "DataFrame.slice_shift(periods=1)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 3014},
{"snippet": "DataFrame.slice_shift(axis=0)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 3015},
{"snippet": "DataFrame.slice_shift(periods=1, axis=0)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 3016},
{"snippet": "DataFrame.slice_shift()", "intent": "Equivalent to shift without copying data .", "question_id": 3017},
{"snippet": "DataFrame.slice_shift(periods=1)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 3018},
{"snippet": "DataFrame.slice_shift(axis=0)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 3019},
{"snippet": "DataFrame.slice_shift(periods=1, axis=0)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 3020},
{"snippet": "DataFrame.sort_index()", "intent": "Sort object by labels ( along an `axis` ) .", "question_id": 3021},
{"snippet": "DataFrame.sort_index(axis=0)", "intent": "Sort object by labels ( along an `axis` ) .", "question_id": 3022},
{"snippet": "DataFrame.sort_index(level=None)", "intent": "Sort object by labels ( along an `axis` ) . For a MultiIndex this is applied to each `level` separately .", "question_id": 3023},
{"snippet": "DataFrame.sort_index(ascending=True)", "intent": "Sort object by labels ( along an `axis` ) . By default , it sorts in `ascending` order , to sort in descending order , use ascending=False", "question_id": 3024},
{"snippet": "DataFrame.sort_index(inplace=False)", "intent": "Sort object by labels ( along an `axis` ) . Returns a new DataFrame sorted by label if `inplace` argument is False , otherwise updates the original DataFrame and returns None .", "question_id": 3025},
{"snippet": "DataFrame.sort_index(kind='quicksort')", "intent": "Sort object by labels ( along an `axis` ) . With arguments `kind`.", "question_id": 3026},
{"snippet": "DataFrame.sort_index(na_position='last')", "intent": "Sort object by labels ( along an `axis` ) . With arguments `na_position`.", "question_id": 3027},
{"snippet": "DataFrame.sort_index(sort_remaining=True)", "intent": "Sort object by labels ( along an `axis` ) . With arguments `sort_remaining`.", "question_id": 3028},
{"snippet": "DataFrame.sort_index(ignore_index=False)", "intent": "Sort object by labels ( along an `axis` ) . With arguments `ignore_index`.", "question_id": 3029},
{"snippet": "DataFrame.sort_index(key=None)", "intent": "Sort object by labels ( along an `axis` ) . A `key` function can be specified which is applied to the index before sorting .", "question_id": 3030},
{"snippet": "DataFrame.sort_index()", "intent": "Sort object by labels ( along an `axis` ) .", "question_id": 3031},
{"snippet": "DataFrame.sort_index(axis=0)", "intent": "Sort object by labels ( along an `axis` ) .", "question_id": 3032},
{"snippet": "DataFrame.sort_index(level=None)", "intent": "Sort object by labels ( along an `axis` ) . For a MultiIndex this is applied to each `level` separately .", "question_id": 3033},
{"snippet": "DataFrame.sort_index(ascending=True)", "intent": "Sort object by labels ( along an `axis` ) . By default , it sorts in `ascending` order , to sort in descending order , use ascending=False", "question_id": 3034},
{"snippet": "DataFrame.sort_index(inplace=False)", "intent": "Sort object by labels ( along an `axis` ) . Returns a new DataFrame sorted by label if `inplace` argument is False , otherwise updates the original DataFrame and returns None .", "question_id": 3035},
{"snippet": "DataFrame.sort_index(kind='quicksort')", "intent": "Sort object by labels ( along an `axis` ) . With arguments `kind`.", "question_id": 3036},
{"snippet": "DataFrame.sort_index(na_position='last')", "intent": "Sort object by labels ( along an `axis` ) . With arguments `na_position`.", "question_id": 3037},
{"snippet": "DataFrame.sort_index(sort_remaining=True)", "intent": "Sort object by labels ( along an `axis` ) . With arguments `sort_remaining`.", "question_id": 3038},
{"snippet": "DataFrame.sort_index(ignore_index=False)", "intent": "Sort object by labels ( along an `axis` ) . With arguments `ignore_index`.", "question_id": 3039},
{"snippet": "DataFrame.sort_index(key=None)", "intent": "Sort object by labels ( along an `axis` ) . A `key` function can be specified which is applied to the index before sorting .", "question_id": 3040},
{"snippet": "DataFrame.sort_index()", "intent": "Sort object by labels ( along an `axis` ) .", "question_id": 3041},
{"snippet": "DataFrame.sort_index(axis=0)", "intent": "Sort object by labels ( along an `axis` ) .", "question_id": 3042},
{"snippet": "DataFrame.sort_index(level=None)", "intent": "Sort object by labels ( along an `axis` ) . For a MultiIndex this is applied to each `level` separately .", "question_id": 3043},
{"snippet": "DataFrame.sort_index(ascending=True)", "intent": "Sort object by labels ( along an `axis` ) . By default , it sorts in `ascending` order , to sort in descending order , use ascending=False", "question_id": 3044},
{"snippet": "DataFrame.sort_index(inplace=False)", "intent": "Sort object by labels ( along an `axis` ) . Returns a new DataFrame sorted by label if `inplace` argument is False , otherwise updates the original DataFrame and returns None .", "question_id": 3045},
{"snippet": "DataFrame.sort_index(kind='quicksort')", "intent": "Sort object by labels ( along an `axis` ) . With arguments `kind`.", "question_id": 3046},
{"snippet": "DataFrame.sort_index(na_position='last')", "intent": "Sort object by labels ( along an `axis` ) . With arguments `na_position`.", "question_id": 3047},
{"snippet": "DataFrame.sort_index(sort_remaining=True)", "intent": "Sort object by labels ( along an `axis` ) . With arguments `sort_remaining`.", "question_id": 3048},
{"snippet": "DataFrame.sort_index(ignore_index=False)", "intent": "Sort object by labels ( along an `axis` ) . With arguments `ignore_index`.", "question_id": 3049},
{"snippet": "DataFrame.sort_index(key=None)", "intent": "Sort object by labels ( along an `axis` ) . A `key` function can be specified which is applied to the index before sorting .", "question_id": 3050},
{"snippet": "DataFrame.sort_values(by)", "intent": "Sort `by` the values along either `axis` .", "question_id": 3051},
{"snippet": "DataFrame.sort_values(by, axis=0)", "intent": "Sort `by` the values along either `axis` .", "question_id": 3052},
{"snippet": "DataFrame.sort_values(by, ascending=True)", "intent": "Sort `by` the values along either `axis` . With arguments `ascending`.", "question_id": 3053},
{"snippet": "DataFrame.sort_values(by, inplace=False)", "intent": "Sort `by` the values along either `axis` . With arguments `inplace`.", "question_id": 3054},
{"snippet": "DataFrame.sort_values(by, kind='quicksort')", "intent": "Sort `by` the values along either `axis` . With arguments `kind`.", "question_id": 3055},
{"snippet": "DataFrame.sort_values(by, na_position='last')", "intent": "Sort `by` the values along either `axis` . With arguments `na_position`.", "question_id": 3056},
{"snippet": "DataFrame.sort_values(by, ignore_index=False)", "intent": "Sort `by` the values along either `axis` . With arguments `ignore_index`.", "question_id": 3057},
{"snippet": "DataFrame.sort_values(by, key=None)", "intent": "Sort `by` the values along either `axis` . Sorting with a `key` function", "question_id": 3058},
{"snippet": "DataFrame.sort_values(by, axis=0, ascending=True)", "intent": "Sort `by` the values along either `axis` . With arguments `ascending`.", "question_id": 3059},
{"snippet": "DataFrame.sort_values(by, axis=0, inplace=False)", "intent": "Sort `by` the values along either `axis` . With arguments `inplace`.", "question_id": 3060},
{"snippet": "DataFrame.sort_values(by)", "intent": "Sort `by` the values along either `axis` .", "question_id": 3061},
{"snippet": "DataFrame.sort_values(by, axis=0)", "intent": "Sort `by` the values along either `axis` .", "question_id": 3062},
{"snippet": "DataFrame.sort_values(by, ascending=True)", "intent": "Sort `by` the values along either `axis` . With arguments `ascending`.", "question_id": 3063},
{"snippet": "DataFrame.sort_values(by, inplace=False)", "intent": "Sort `by` the values along either `axis` . With arguments `inplace`.", "question_id": 3064},
{"snippet": "DataFrame.sort_values(by, kind='quicksort')", "intent": "Sort `by` the values along either `axis` . With arguments `kind`.", "question_id": 3065},
{"snippet": "DataFrame.sort_values(by, na_position='last')", "intent": "Sort `by` the values along either `axis` . With arguments `na_position`.", "question_id": 3066},
{"snippet": "DataFrame.sort_values(by, ignore_index=False)", "intent": "Sort `by` the values along either `axis` . With arguments `ignore_index`.", "question_id": 3067},
{"snippet": "DataFrame.sort_values(by, key=None)", "intent": "Sort `by` the values along either `axis` . Sorting with a `key` function", "question_id": 3068},
{"snippet": "DataFrame.sort_values(by, axis=0, ascending=True)", "intent": "Sort `by` the values along either `axis` . With arguments `ascending`.", "question_id": 3069},
{"snippet": "DataFrame.sort_values(by, axis=0, inplace=False)", "intent": "Sort `by` the values along either `axis` . With arguments `inplace`.", "question_id": 3070},
{"snippet": "DataFrame.sort_values(by)", "intent": "Sort `by` the values along either `axis` .", "question_id": 3071},
{"snippet": "DataFrame.sort_values(by, axis=0)", "intent": "Sort `by` the values along either `axis` .", "question_id": 3072},
{"snippet": "DataFrame.sort_values(by, ascending=True)", "intent": "Sort `by` the values along either `axis` . With arguments `ascending`.", "question_id": 3073},
{"snippet": "DataFrame.sort_values(by, inplace=False)", "intent": "Sort `by` the values along either `axis` . With arguments `inplace`.", "question_id": 3074},
{"snippet": "DataFrame.sort_values(by, kind='quicksort')", "intent": "Sort `by` the values along either `axis` . With arguments `kind`.", "question_id": 3075},
{"snippet": "DataFrame.sort_values(by, na_position='last')", "intent": "Sort `by` the values along either `axis` . With arguments `na_position`.", "question_id": 3076},
{"snippet": "DataFrame.sort_values(by, ignore_index=False)", "intent": "Sort `by` the values along either `axis` . With arguments `ignore_index`.", "question_id": 3077},
{"snippet": "DataFrame.sort_values(by, key=None)", "intent": "Sort `by` the values along either `axis` . Sorting with a `key` function", "question_id": 3078},
{"snippet": "DataFrame.sort_values(by, axis=0, ascending=True)", "intent": "Sort `by` the values along either `axis` . With arguments `ascending`.", "question_id": 3079},
{"snippet": "DataFrame.sort_values(by, axis=0, inplace=False)", "intent": "Sort `by` the values along either `axis` . With arguments `inplace`.", "question_id": 3080},
{"snippet": "DataFrame.sparse.density", "intent": "Ratio of non-sparse points to total (dense) data points.", "question_id": 3081},
{"snippet": "DataFrame.sparse.density", "intent": "Ratio of non-sparse points to total (dense) data points.", "question_id": 3082},
{"snippet": "DataFrame.sparse.density", "intent": "Ratio of non-sparse points to total (dense) data points.", "question_id": 3083},
{"snippet": "DataFrame.sparse.from_spmatrix(data)", "intent": "Create a new DataFrame from a scipy sparse matrix . With arguments `data`.", "question_id": 3084},
{"snippet": "DataFrame.sparse.from_spmatrix(data, index=None)", "intent": "Create a new DataFrame from a scipy sparse matrix . With arguments `data`, `index`.", "question_id": 3085},
{"snippet": "DataFrame.sparse.from_spmatrix(data, columns=None)", "intent": "Create a new DataFrame from a scipy sparse matrix . With arguments `data`, `columns`.", "question_id": 3086},
{"snippet": "DataFrame.sparse.from_spmatrix(data, index=None, columns=None)", "intent": "Create a new DataFrame from a scipy sparse matrix . With arguments `data`, `index`, `columns`.", "question_id": 3087},
{"snippet": "DataFrame.sparse.from_spmatrix(data)", "intent": "Create a new DataFrame from a scipy sparse matrix . With arguments `data`.", "question_id": 3088},
{"snippet": "DataFrame.sparse.from_spmatrix(data, index=None)", "intent": "Create a new DataFrame from a scipy sparse matrix . With arguments `data`, `index`.", "question_id": 3089},
{"snippet": "DataFrame.sparse.from_spmatrix(data, columns=None)", "intent": "Create a new DataFrame from a scipy sparse matrix . With arguments `data`, `columns`.", "question_id": 3090},
{"snippet": "DataFrame.sparse.from_spmatrix(data, index=None, columns=None)", "intent": "Create a new DataFrame from a scipy sparse matrix . With arguments `data`, `index`, `columns`.", "question_id": 3091},
{"snippet": "DataFrame.sparse.from_spmatrix(data)", "intent": "Create a new DataFrame from a scipy sparse matrix . With arguments `data`.", "question_id": 3092},
{"snippet": "DataFrame.sparse.from_spmatrix(data, index=None)", "intent": "Create a new DataFrame from a scipy sparse matrix . With arguments `data`, `index`.", "question_id": 3093},
{"snippet": "DataFrame.sparse.from_spmatrix(data, columns=None)", "intent": "Create a new DataFrame from a scipy sparse matrix . With arguments `data`, `columns`.", "question_id": 3094},
{"snippet": "DataFrame.sparse.from_spmatrix(data, index=None, columns=None)", "intent": "Create a new DataFrame from a scipy sparse matrix . With arguments `data`, `index`, `columns`.", "question_id": 3095},
{"snippet": "DataFrame.sparse()", "intent": "DataFrame accessor for sparse data .", "question_id": 3096},
{"snippet": "DataFrame.sparse()", "intent": "DataFrame accessor for sparse data .", "question_id": 3097},
{"snippet": "DataFrame.sparse()", "intent": "DataFrame accessor for sparse data .", "question_id": 3098},
{"snippet": "DataFrame.sparse.to_coo()", "intent": "Return the contents of the frame as a sparse SciPy COO matrix .", "question_id": 3099},
{"snippet": "DataFrame.sparse.to_coo()", "intent": "Return the contents of the frame as a sparse SciPy COO matrix .", "question_id": 3100},
{"snippet": "DataFrame.sparse.to_coo()", "intent": "Return the contents of the frame as a sparse SciPy COO matrix .", "question_id": 3101},
{"snippet": "DataFrame.sparse.to_dense()", "intent": "Convert a DataFrame with sparse values to dense .", "question_id": 3102},
{"snippet": "DataFrame.sparse.to_dense()", "intent": "Convert a DataFrame with sparse values to dense .", "question_id": 3103},
{"snippet": "DataFrame.sparse.to_dense()", "intent": "Convert a DataFrame with sparse values to dense .", "question_id": 3104},
{"snippet": "DataFrame.squeeze()", "intent": "Squeeze 1 dimensional `axis` objects into scalars .", "question_id": 3105},
{"snippet": "DataFrame.squeeze(axis=None)", "intent": "Squeeze 1 dimensional `axis` objects into scalars .", "question_id": 3106},
{"snippet": "DataFrame.squeeze()", "intent": "Squeeze 1 dimensional `axis` objects into scalars .", "question_id": 3107},
{"snippet": "DataFrame.squeeze(axis=None)", "intent": "Squeeze 1 dimensional `axis` objects into scalars .", "question_id": 3108},
{"snippet": "DataFrame.squeeze()", "intent": "Squeeze 1 dimensional `axis` objects into scalars .", "question_id": 3109},
{"snippet": "DataFrame.squeeze(axis=None)", "intent": "Squeeze 1 dimensional `axis` objects into scalars .", "question_id": 3110},
{"snippet": "DataFrame.stack()", "intent": "Stack the prescribed `level` ( s ) from columns to index .", "question_id": 3111},
{"snippet": "DataFrame.stack(level=- 1)", "intent": "Stack the prescribed `level` ( s ) from columns to index .", "question_id": 3112},
{"snippet": "DataFrame.stack(dropna=True)", "intent": "Stack the prescribed `level` ( s ) from columns to index . Note that rows where all values are missing are dropped by default but this behaviour can be controlled via the `dropna` keyword parameter :", "question_id": 3113},
{"snippet": "DataFrame.stack(level=- 1, dropna=True)", "intent": "Stack the prescribed `level` ( s ) from columns to index . Note that rows where all values are missing are dropped by default but this behaviour can be controlled via the `dropna` keyword parameter :", "question_id": 3114},
{"snippet": "DataFrame.stack()", "intent": "Stack the prescribed `level` ( s ) from columns to index .", "question_id": 3115},
{"snippet": "DataFrame.stack(level=- 1)", "intent": "Stack the prescribed `level` ( s ) from columns to index .", "question_id": 3116},
{"snippet": "DataFrame.stack(dropna=True)", "intent": "Stack the prescribed `level` ( s ) from columns to index . Note that rows where all values are missing are dropped by default but this behaviour can be controlled via the `dropna` keyword parameter :", "question_id": 3117},
{"snippet": "DataFrame.stack(level=- 1, dropna=True)", "intent": "Stack the prescribed `level` ( s ) from columns to index . Note that rows where all values are missing are dropped by default but this behaviour can be controlled via the `dropna` keyword parameter :", "question_id": 3118},
{"snippet": "DataFrame.stack()", "intent": "Stack the prescribed `level` ( s ) from columns to index .", "question_id": 3119},
{"snippet": "DataFrame.stack(level=- 1)", "intent": "Stack the prescribed `level` ( s ) from columns to index .", "question_id": 3120},
{"snippet": "DataFrame.stack(dropna=True)", "intent": "Stack the prescribed `level` ( s ) from columns to index . Note that rows where all values are missing are dropped by default but this behaviour can be controlled via the `dropna` keyword parameter :", "question_id": 3121},
{"snippet": "DataFrame.stack(level=- 1, dropna=True)", "intent": "Stack the prescribed `level` ( s ) from columns to index . Note that rows where all values are missing are dropped by default but this behaviour can be controlled via the `dropna` keyword parameter :", "question_id": 3122},
{"snippet": "DataFrame.std(**kwargs)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`.", "question_id": 3123},
{"snippet": "DataFrame.std(**kwargs, axis=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`.", "question_id": 3124},
{"snippet": "DataFrame.std(**kwargs, skipna=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 3125},
{"snippet": "DataFrame.std(**kwargs, level=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 3126},
{"snippet": "DataFrame.std(**kwargs, ddof=1)", "intent": "Return sample standard deviation over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 3127},
{"snippet": "DataFrame.std(**kwargs, numeric_only=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 3128},
{"snippet": "DataFrame.std(**kwargs, axis=None, skipna=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 3129},
{"snippet": "DataFrame.std(**kwargs, axis=None, level=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 3130},
{"snippet": "DataFrame.std(**kwargs, axis=None, ddof=1)", "intent": "Return sample standard deviation over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 3131},
{"snippet": "DataFrame.std(**kwargs, axis=None, numeric_only=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 3132},
{"snippet": "DataFrame.std(**kwargs)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`.", "question_id": 3133},
{"snippet": "DataFrame.std(**kwargs, axis=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`.", "question_id": 3134},
{"snippet": "DataFrame.std(**kwargs, skipna=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 3135},
{"snippet": "DataFrame.std(**kwargs, level=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 3136},
{"snippet": "DataFrame.std(**kwargs, ddof=1)", "intent": "Return sample standard deviation over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 3137},
{"snippet": "DataFrame.std(**kwargs, numeric_only=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 3138},
{"snippet": "DataFrame.std(**kwargs, axis=None, skipna=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 3139},
{"snippet": "DataFrame.std(**kwargs, axis=None, level=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 3140},
{"snippet": "DataFrame.std(**kwargs, axis=None, ddof=1)", "intent": "Return sample standard deviation over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 3141},
{"snippet": "DataFrame.std(**kwargs, axis=None, numeric_only=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 3142},
{"snippet": "DataFrame.std(**kwargs)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`.", "question_id": 3143},
{"snippet": "DataFrame.std(**kwargs, axis=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`.", "question_id": 3144},
{"snippet": "DataFrame.std(**kwargs, skipna=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 3145},
{"snippet": "DataFrame.std(**kwargs, level=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 3146},
{"snippet": "DataFrame.std(**kwargs, ddof=1)", "intent": "Return sample standard deviation over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 3147},
{"snippet": "DataFrame.std(**kwargs, numeric_only=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 3148},
{"snippet": "DataFrame.std(**kwargs, axis=None, skipna=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 3149},
{"snippet": "DataFrame.std(**kwargs, axis=None, level=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 3150},
{"snippet": "DataFrame.std(**kwargs, axis=None, ddof=1)", "intent": "Return sample standard deviation over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 3151},
{"snippet": "DataFrame.std(**kwargs, axis=None, numeric_only=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 3152},
{"snippet": "DataFrame.sub(other)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) .", "question_id": 3153},
{"snippet": "DataFrame.sub(other, axis='columns')", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version .", "question_id": 3154},
{"snippet": "DataFrame.sub(other, level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Divide by a MultiIndex by `level` .", "question_id": 3155},
{"snippet": "DataFrame.sub(other, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3156},
{"snippet": "DataFrame.sub(other, axis='columns', level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 3157},
{"snippet": "DataFrame.sub(other, axis='columns', fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3158},
{"snippet": "DataFrame.sub(other, level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Divide by a MultiIndex by `level` . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3159},
{"snippet": "DataFrame.sub(other, axis='columns', level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3160},
{"snippet": "DataFrame.sub(other)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) .", "question_id": 3161},
{"snippet": "DataFrame.sub(other, axis='columns')", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version .", "question_id": 3162},
{"snippet": "DataFrame.sub(other, level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Divide by a MultiIndex by `level` .", "question_id": 3163},
{"snippet": "DataFrame.sub(other, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3164},
{"snippet": "DataFrame.sub(other, axis='columns', level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 3165},
{"snippet": "DataFrame.sub(other, axis='columns', fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3166},
{"snippet": "DataFrame.sub(other, level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Divide by a MultiIndex by `level` . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3167},
{"snippet": "DataFrame.sub(other, axis='columns', level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3168},
{"snippet": "DataFrame.sub(other)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) .", "question_id": 3169},
{"snippet": "DataFrame.sub(other, axis='columns')", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version .", "question_id": 3170},
{"snippet": "DataFrame.sub(other, level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Divide by a MultiIndex by `level` .", "question_id": 3171},
{"snippet": "DataFrame.sub(other, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3172},
{"snippet": "DataFrame.sub(other, axis='columns', level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 3173},
{"snippet": "DataFrame.sub(other, axis='columns', fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3174},
{"snippet": "DataFrame.sub(other, level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Divide by a MultiIndex by `level` . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3175},
{"snippet": "DataFrame.sub(other, axis='columns', level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3176},
{"snippet": "DataFrame.subtract(other)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) .", "question_id": 3177},
{"snippet": "DataFrame.subtract(other, axis='columns')", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version .", "question_id": 3178},
{"snippet": "DataFrame.subtract(other, level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Divide by a MultiIndex by `level` .", "question_id": 3179},
{"snippet": "DataFrame.subtract(other, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3180},
{"snippet": "DataFrame.subtract(other, axis='columns', level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 3181},
{"snippet": "DataFrame.subtract(other, axis='columns', fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3182},
{"snippet": "DataFrame.subtract(other, level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Divide by a MultiIndex by `level` . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3183},
{"snippet": "DataFrame.subtract(other, axis='columns', level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3184},
{"snippet": "DataFrame.subtract(other)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) .", "question_id": 3185},
{"snippet": "DataFrame.subtract(other, axis='columns')", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version .", "question_id": 3186},
{"snippet": "DataFrame.subtract(other, level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Divide by a MultiIndex by `level` .", "question_id": 3187},
{"snippet": "DataFrame.subtract(other, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3188},
{"snippet": "DataFrame.subtract(other, axis='columns', level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 3189},
{"snippet": "DataFrame.subtract(other, axis='columns', fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3190},
{"snippet": "DataFrame.subtract(other, level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Divide by a MultiIndex by `level` . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3191},
{"snippet": "DataFrame.subtract(other, axis='columns', level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3192},
{"snippet": "DataFrame.subtract(other)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) .", "question_id": 3193},
{"snippet": "DataFrame.subtract(other, axis='columns')", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version .", "question_id": 3194},
{"snippet": "DataFrame.subtract(other, level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Divide by a MultiIndex by `level` .", "question_id": 3195},
{"snippet": "DataFrame.subtract(other, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3196},
{"snippet": "DataFrame.subtract(other, axis='columns', level=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 3197},
{"snippet": "DataFrame.subtract(other, axis='columns', fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3198},
{"snippet": "DataFrame.subtract(other, level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Divide by a MultiIndex by `level` . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3199},
{"snippet": "DataFrame.subtract(other, axis='columns', level=None, fill_value=None)", "intent": "Get Subtraction of dataframe and `other` , element-wise ( binary operator sub ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe - other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3200},
{"snippet": "DataFrame.sum(**kwargs)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 3201},
{"snippet": "DataFrame.sum(**kwargs, axis=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 3202},
{"snippet": "DataFrame.sum(**kwargs, skipna=None)", "intent": "Return the sum of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 3203},
{"snippet": "DataFrame.sum(**kwargs, level=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 3204},
{"snippet": "DataFrame.sum(**kwargs, numeric_only=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 3205},
{"snippet": "DataFrame.sum(**kwargs, min_count=0)", "intent": "Return the sum of the values over the requested `axis` . This can be controlled with the `min_count` parameter . With arguments `**kwargs`.", "question_id": 3206},
{"snippet": "DataFrame.sum(**kwargs, axis=None, skipna=None)", "intent": "Return the sum of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 3207},
{"snippet": "DataFrame.sum(**kwargs, axis=None, level=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 3208},
{"snippet": "DataFrame.sum(**kwargs, axis=None, numeric_only=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 3209},
{"snippet": "DataFrame.sum(**kwargs, axis=None, min_count=0)", "intent": "Return the sum of the values over the requested `axis` . This can be controlled with the `min_count` parameter . With arguments `**kwargs`.", "question_id": 3210},
{"snippet": "DataFrame.sum(**kwargs)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 3211},
{"snippet": "DataFrame.sum(**kwargs, axis=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 3212},
{"snippet": "DataFrame.sum(**kwargs, skipna=None)", "intent": "Return the sum of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 3213},
{"snippet": "DataFrame.sum(**kwargs, level=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 3214},
{"snippet": "DataFrame.sum(**kwargs, numeric_only=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 3215},
{"snippet": "DataFrame.sum(**kwargs, min_count=0)", "intent": "Return the sum of the values over the requested `axis` . This can be controlled with the `min_count` parameter . With arguments `**kwargs`.", "question_id": 3216},
{"snippet": "DataFrame.sum(**kwargs, axis=None, skipna=None)", "intent": "Return the sum of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 3217},
{"snippet": "DataFrame.sum(**kwargs, axis=None, level=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 3218},
{"snippet": "DataFrame.sum(**kwargs, axis=None, numeric_only=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 3219},
{"snippet": "DataFrame.sum(**kwargs, axis=None, min_count=0)", "intent": "Return the sum of the values over the requested `axis` . This can be controlled with the `min_count` parameter . With arguments `**kwargs`.", "question_id": 3220},
{"snippet": "DataFrame.sum(**kwargs)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 3221},
{"snippet": "DataFrame.sum(**kwargs, axis=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 3222},
{"snippet": "DataFrame.sum(**kwargs, skipna=None)", "intent": "Return the sum of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 3223},
{"snippet": "DataFrame.sum(**kwargs, level=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 3224},
{"snippet": "DataFrame.sum(**kwargs, numeric_only=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 3225},
{"snippet": "DataFrame.sum(**kwargs, min_count=0)", "intent": "Return the sum of the values over the requested `axis` . This can be controlled with the `min_count` parameter . With arguments `**kwargs`.", "question_id": 3226},
{"snippet": "DataFrame.sum(**kwargs, axis=None, skipna=None)", "intent": "Return the sum of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 3227},
{"snippet": "DataFrame.sum(**kwargs, axis=None, level=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 3228},
{"snippet": "DataFrame.sum(**kwargs, axis=None, numeric_only=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 3229},
{"snippet": "DataFrame.sum(**kwargs, axis=None, min_count=0)", "intent": "Return the sum of the values over the requested `axis` . This can be controlled with the `min_count` parameter . With arguments `**kwargs`.", "question_id": 3230},
{"snippet": "DataFrame.swapaxes(axis1, axis2)", "intent": "Interchange axes and swap values axes appropriately . With arguments `axis1`, `axis2`.", "question_id": 3231},
{"snippet": "DataFrame.swapaxes(axis1, axis2, copy=True)", "intent": "Interchange axes and swap values axes appropriately . With arguments `axis1`, `axis2`, `copy`.", "question_id": 3232},
{"snippet": "DataFrame.swapaxes(axis1, axis2)", "intent": "Interchange axes and swap values axes appropriately . With arguments `axis1`, `axis2`.", "question_id": 3233},
{"snippet": "DataFrame.swapaxes(axis1, axis2, copy=True)", "intent": "Interchange axes and swap values axes appropriately . With arguments `axis1`, `axis2`, `copy`.", "question_id": 3234},
{"snippet": "DataFrame.swapaxes(axis1, axis2)", "intent": "Interchange axes and swap values axes appropriately . With arguments `axis1`, `axis2`.", "question_id": 3235},
{"snippet": "DataFrame.swapaxes(axis1, axis2, copy=True)", "intent": "Interchange axes and swap values axes appropriately . With arguments `axis1`, `axis2`, `copy`.", "question_id": 3236},
{"snippet": "DataFrame.swaplevel()", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 3237},
{"snippet": "DataFrame.swaplevel(i=- 2)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 3238},
{"snippet": "DataFrame.swaplevel(j=- 1)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 3239},
{"snippet": "DataFrame.swaplevel(axis=0)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `axis`.", "question_id": 3240},
{"snippet": "DataFrame.swaplevel(i=- 2, j=- 1)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 3241},
{"snippet": "DataFrame.swaplevel(i=- 2, axis=0)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `axis`.", "question_id": 3242},
{"snippet": "DataFrame.swaplevel(j=- 1, axis=0)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `axis`.", "question_id": 3243},
{"snippet": "DataFrame.swaplevel(i=- 2, j=- 1, axis=0)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `axis`.", "question_id": 3244},
{"snippet": "DataFrame.swaplevel()", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 3245},
{"snippet": "DataFrame.swaplevel(i=- 2)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 3246},
{"snippet": "DataFrame.swaplevel(j=- 1)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 3247},
{"snippet": "DataFrame.swaplevel(axis=0)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `axis`.", "question_id": 3248},
{"snippet": "DataFrame.swaplevel(i=- 2, j=- 1)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 3249},
{"snippet": "DataFrame.swaplevel(i=- 2, axis=0)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `axis`.", "question_id": 3250},
{"snippet": "DataFrame.swaplevel(j=- 1, axis=0)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `axis`.", "question_id": 3251},
{"snippet": "DataFrame.swaplevel(i=- 2, j=- 1, axis=0)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `axis`.", "question_id": 3252},
{"snippet": "DataFrame.swaplevel()", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 3253},
{"snippet": "DataFrame.swaplevel(i=- 2)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 3254},
{"snippet": "DataFrame.swaplevel(j=- 1)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 3255},
{"snippet": "DataFrame.swaplevel(axis=0)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `axis`.", "question_id": 3256},
{"snippet": "DataFrame.swaplevel(i=- 2, j=- 1)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 3257},
{"snippet": "DataFrame.swaplevel(i=- 2, axis=0)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `axis`.", "question_id": 3258},
{"snippet": "DataFrame.swaplevel(j=- 1, axis=0)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `axis`.", "question_id": 3259},
{"snippet": "DataFrame.swaplevel(i=- 2, j=- 1, axis=0)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `axis`.", "question_id": 3260},
{"snippet": "DataFrame.tail()", "intent": "Return the last `n` rows .", "question_id": 3261},
{"snippet": "DataFrame.tail(n=5)", "intent": "Return the last `n` rows .", "question_id": 3262},
{"snippet": "DataFrame.tail()", "intent": "Return the last `n` rows .", "question_id": 3263},
{"snippet": "DataFrame.tail(n=5)", "intent": "Return the last `n` rows .", "question_id": 3264},
{"snippet": "DataFrame.tail()", "intent": "Return the last `n` rows .", "question_id": 3265},
{"snippet": "DataFrame.tail(n=5)", "intent": "Return the last `n` rows .", "question_id": 3266},
{"snippet": "DataFrame.take(indices, **kwargs)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`.", "question_id": 3267},
{"snippet": "DataFrame.take(indices, **kwargs, axis=0)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`.", "question_id": 3268},
{"snippet": "DataFrame.take(indices, **kwargs, is_copy=None)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`, `is_copy`.", "question_id": 3269},
{"snippet": "DataFrame.take(indices, **kwargs, axis=0, is_copy=None)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`, `is_copy`.", "question_id": 3270},
{"snippet": "DataFrame.take(indices, **kwargs)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`.", "question_id": 3271},
{"snippet": "DataFrame.take(indices, **kwargs, axis=0)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`.", "question_id": 3272},
{"snippet": "DataFrame.take(indices, **kwargs, is_copy=None)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`, `is_copy`.", "question_id": 3273},
{"snippet": "DataFrame.take(indices, **kwargs, axis=0, is_copy=None)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`, `is_copy`.", "question_id": 3274},
{"snippet": "DataFrame.take(indices, **kwargs)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`.", "question_id": 3275},
{"snippet": "DataFrame.take(indices, **kwargs, axis=0)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`.", "question_id": 3276},
{"snippet": "DataFrame.take(indices, **kwargs, is_copy=None)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`, `is_copy`.", "question_id": 3277},
{"snippet": "DataFrame.take(indices, **kwargs, axis=0, is_copy=None)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`, `is_copy`.", "question_id": 3278},
{"snippet": "DataFrame.to_clipboard(**kwargs)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`.", "question_id": 3279},
{"snippet": "DataFrame.to_clipboard(**kwargs, excel=True)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `excel`.", "question_id": 3280},
{"snippet": "DataFrame.to_clipboard(**kwargs, sep=None)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `sep`.", "question_id": 3281},
{"snippet": "DataFrame.to_clipboard(**kwargs, excel=True, sep=None)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `excel`, `sep`.", "question_id": 3282},
{"snippet": "DataFrame.to_clipboard(**kwargs)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`.", "question_id": 3283},
{"snippet": "DataFrame.to_clipboard(**kwargs, excel=True)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `excel`.", "question_id": 3284},
{"snippet": "DataFrame.to_clipboard(**kwargs, sep=None)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `sep`.", "question_id": 3285},
{"snippet": "DataFrame.to_clipboard(**kwargs, excel=True, sep=None)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `excel`, `sep`.", "question_id": 3286},
{"snippet": "DataFrame.to_clipboard(**kwargs)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`.", "question_id": 3287},
{"snippet": "DataFrame.to_clipboard(**kwargs, excel=True)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `excel`.", "question_id": 3288},
{"snippet": "DataFrame.to_clipboard(**kwargs, sep=None)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `sep`.", "question_id": 3289},
{"snippet": "DataFrame.to_clipboard(**kwargs, excel=True, sep=None)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `excel`, `sep`.", "question_id": 3290},
{"snippet": "DataFrame.to_csv()", "intent": "Write object to a comma-separated values ( csv ) file .", "question_id": 3291},
{"snippet": "DataFrame.to_csv(path_or_buf=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `path_or_buf`.", "question_id": 3292},
{"snippet": "DataFrame.to_csv(sep=',')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `sep`.", "question_id": 3293},
{"snippet": "DataFrame.to_csv(na_rep='')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `na_rep`.", "question_id": 3294},
{"snippet": "DataFrame.to_csv(float_format=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `float_format`.", "question_id": 3295},
{"snippet": "DataFrame.to_csv(columns=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `columns`.", "question_id": 3296},
{"snippet": "DataFrame.to_csv(header=True)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `header`.", "question_id": 3297},
{"snippet": "DataFrame.to_csv(index=True)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `index`.", "question_id": 3298},
{"snippet": "DataFrame.to_csv(index_label=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `index_label`.", "question_id": 3299},
{"snippet": "DataFrame.to_csv(mode='w')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `mode`.", "question_id": 3300},
{"snippet": "DataFrame.to_csv()", "intent": "Write object to a comma-separated values ( csv ) file .", "question_id": 3301},
{"snippet": "DataFrame.to_csv(path_or_buf=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `path_or_buf`.", "question_id": 3302},
{"snippet": "DataFrame.to_csv(sep=',')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `sep`.", "question_id": 3303},
{"snippet": "DataFrame.to_csv(na_rep='')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `na_rep`.", "question_id": 3304},
{"snippet": "DataFrame.to_csv(float_format=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `float_format`.", "question_id": 3305},
{"snippet": "DataFrame.to_csv(columns=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `columns`.", "question_id": 3306},
{"snippet": "DataFrame.to_csv(header=True)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `header`.", "question_id": 3307},
{"snippet": "DataFrame.to_csv(index=True)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `index`.", "question_id": 3308},
{"snippet": "DataFrame.to_csv(index_label=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `index_label`.", "question_id": 3309},
{"snippet": "DataFrame.to_csv(mode='w')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `mode`.", "question_id": 3310},
{"snippet": "DataFrame.to_csv()", "intent": "Write object to a comma-separated values ( csv ) file .", "question_id": 3311},
{"snippet": "DataFrame.to_csv(path_or_buf=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `path_or_buf`.", "question_id": 3312},
{"snippet": "DataFrame.to_csv(sep=',')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `sep`.", "question_id": 3313},
{"snippet": "DataFrame.to_csv(na_rep='')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `na_rep`.", "question_id": 3314},
{"snippet": "DataFrame.to_csv(float_format=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `float_format`.", "question_id": 3315},
{"snippet": "DataFrame.to_csv(columns=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `columns`.", "question_id": 3316},
{"snippet": "DataFrame.to_csv(header=True)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `header`.", "question_id": 3317},
{"snippet": "DataFrame.to_csv(index=True)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `index`.", "question_id": 3318},
{"snippet": "DataFrame.to_csv(index_label=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `index_label`.", "question_id": 3319},
{"snippet": "DataFrame.to_csv(mode='w')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `mode`.", "question_id": 3320},
{"snippet": "DataFrame.to_dict()", "intent": "Convert the DataFrame to a dictionary .", "question_id": 3321},
{"snippet": "DataFrame.to_dict(orient='dict')", "intent": "Convert the DataFrame to a dictionary . With arguments `orient`.", "question_id": 3322},
{"snippet": "DataFrame.to_dict(into=<class 'dict'>)", "intent": "Convert the DataFrame to a dictionary . With arguments `into`.", "question_id": 3323},
{"snippet": "DataFrame.to_dict(orient='dict', into=<class 'dict'>)", "intent": "Convert the DataFrame to a dictionary . With arguments `orient`, `into`.", "question_id": 3324},
{"snippet": "DataFrame.to_dict()", "intent": "Convert the DataFrame to a dictionary .", "question_id": 3325},
{"snippet": "DataFrame.to_dict(orient='dict')", "intent": "Convert the DataFrame to a dictionary . With arguments `orient`.", "question_id": 3326},
{"snippet": "DataFrame.to_dict(into=<class 'dict'>)", "intent": "Convert the DataFrame to a dictionary . With arguments `into`.", "question_id": 3327},
{"snippet": "DataFrame.to_dict(orient='dict', into=<class 'dict'>)", "intent": "Convert the DataFrame to a dictionary . With arguments `orient`, `into`.", "question_id": 3328},
{"snippet": "DataFrame.to_dict()", "intent": "Convert the DataFrame to a dictionary .", "question_id": 3329},
{"snippet": "DataFrame.to_dict(orient='dict')", "intent": "Convert the DataFrame to a dictionary . With arguments `orient`.", "question_id": 3330},
{"snippet": "DataFrame.to_dict(into=<class 'dict'>)", "intent": "Convert the DataFrame to a dictionary . With arguments `into`.", "question_id": 3331},
{"snippet": "DataFrame.to_dict(orient='dict', into=<class 'dict'>)", "intent": "Convert the DataFrame to a dictionary . With arguments `orient`, `into`.", "question_id": 3332},
{"snippet": "DataFrame.to_excel(excel_writer)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`.", "question_id": 3333},
{"snippet": "DataFrame.to_excel(excel_writer, sheet_name='Sheet1')", "intent": "Write object to an Excel sheet . Multiple sheets may be written to by specifying unique `sheet_name` . With arguments `excel_writer`.", "question_id": 3334},
{"snippet": "DataFrame.to_excel(excel_writer, na_rep='')", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `na_rep`.", "question_id": 3335},
{"snippet": "DataFrame.to_excel(excel_writer, float_format=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `float_format`.", "question_id": 3336},
{"snippet": "DataFrame.to_excel(excel_writer, columns=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `columns`.", "question_id": 3337},
{"snippet": "DataFrame.to_excel(excel_writer, header=True)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `header`.", "question_id": 3338},
{"snippet": "DataFrame.to_excel(excel_writer, index=True)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `index`.", "question_id": 3339},
{"snippet": "DataFrame.to_excel(excel_writer, index_label=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `index_label`.", "question_id": 3340},
{"snippet": "DataFrame.to_excel(excel_writer, startrow=0)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `startrow`.", "question_id": 3341},
{"snippet": "DataFrame.to_excel(excel_writer, startcol=0)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `startcol`.", "question_id": 3342},
{"snippet": "DataFrame.to_excel(excel_writer)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`.", "question_id": 3343},
{"snippet": "DataFrame.to_excel(excel_writer, sheet_name='Sheet1')", "intent": "Write object to an Excel sheet . Multiple sheets may be written to by specifying unique `sheet_name` . With arguments `excel_writer`.", "question_id": 3344},
{"snippet": "DataFrame.to_excel(excel_writer, na_rep='')", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `na_rep`.", "question_id": 3345},
{"snippet": "DataFrame.to_excel(excel_writer, float_format=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `float_format`.", "question_id": 3346},
{"snippet": "DataFrame.to_excel(excel_writer, columns=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `columns`.", "question_id": 3347},
{"snippet": "DataFrame.to_excel(excel_writer, header=True)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `header`.", "question_id": 3348},
{"snippet": "DataFrame.to_excel(excel_writer, index=True)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `index`.", "question_id": 3349},
{"snippet": "DataFrame.to_excel(excel_writer, index_label=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `index_label`.", "question_id": 3350},
{"snippet": "DataFrame.to_excel(excel_writer, startrow=0)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `startrow`.", "question_id": 3351},
{"snippet": "DataFrame.to_excel(excel_writer, startcol=0)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `startcol`.", "question_id": 3352},
{"snippet": "DataFrame.to_excel(excel_writer)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`.", "question_id": 3353},
{"snippet": "DataFrame.to_excel(excel_writer, sheet_name='Sheet1')", "intent": "Write object to an Excel sheet . Multiple sheets may be written to by specifying unique `sheet_name` . With arguments `excel_writer`.", "question_id": 3354},
{"snippet": "DataFrame.to_excel(excel_writer, na_rep='')", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `na_rep`.", "question_id": 3355},
{"snippet": "DataFrame.to_excel(excel_writer, float_format=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `float_format`.", "question_id": 3356},
{"snippet": "DataFrame.to_excel(excel_writer, columns=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `columns`.", "question_id": 3357},
{"snippet": "DataFrame.to_excel(excel_writer, header=True)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `header`.", "question_id": 3358},
{"snippet": "DataFrame.to_excel(excel_writer, index=True)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `index`.", "question_id": 3359},
{"snippet": "DataFrame.to_excel(excel_writer, index_label=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `index_label`.", "question_id": 3360},
{"snippet": "DataFrame.to_excel(excel_writer, startrow=0)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `startrow`.", "question_id": 3361},
{"snippet": "DataFrame.to_excel(excel_writer, startcol=0)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `startcol`.", "question_id": 3362},
{"snippet": "DataFrame.to_feather(path, **kwargs)", "intent": "Write a DataFrame to the binary Feather format . With arguments `path`, `**kwargs`.", "question_id": 3363},
{"snippet": "DataFrame.to_feather(path, **kwargs)", "intent": "Write a DataFrame to the binary Feather format . With arguments `path`, `**kwargs`.", "question_id": 3364},
{"snippet": "DataFrame.to_feather(path, **kwargs)", "intent": "Write a DataFrame to the binary Feather format . With arguments `path`, `**kwargs`.", "question_id": 3365},
{"snippet": "DataFrame.to_gbq(destination_table)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`.", "question_id": 3366},
{"snippet": "DataFrame.to_gbq(destination_table, project_id=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `project_id`.", "question_id": 3367},
{"snippet": "DataFrame.to_gbq(destination_table, chunksize=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `chunksize`.", "question_id": 3368},
{"snippet": "DataFrame.to_gbq(destination_table, reauth=False)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `reauth`.", "question_id": 3369},
{"snippet": "DataFrame.to_gbq(destination_table, if_exists='fail')", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `if_exists`.", "question_id": 3370},
{"snippet": "DataFrame.to_gbq(destination_table, auth_local_webserver=False)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `auth_local_webserver`.", "question_id": 3371},
{"snippet": "DataFrame.to_gbq(destination_table, table_schema=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `table_schema`.", "question_id": 3372},
{"snippet": "DataFrame.to_gbq(destination_table, location=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `location`.", "question_id": 3373},
{"snippet": "DataFrame.to_gbq(destination_table, progress_bar=True)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `progress_bar`.", "question_id": 3374},
{"snippet": "DataFrame.to_gbq(destination_table, credentials=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `credentials`.", "question_id": 3375},
{"snippet": "DataFrame.to_gbq(destination_table)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`.", "question_id": 3376},
{"snippet": "DataFrame.to_gbq(destination_table, project_id=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `project_id`.", "question_id": 3377},
{"snippet": "DataFrame.to_gbq(destination_table, chunksize=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `chunksize`.", "question_id": 3378},
{"snippet": "DataFrame.to_gbq(destination_table, reauth=False)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `reauth`.", "question_id": 3379},
{"snippet": "DataFrame.to_gbq(destination_table, if_exists='fail')", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `if_exists`.", "question_id": 3380},
{"snippet": "DataFrame.to_gbq(destination_table, auth_local_webserver=False)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `auth_local_webserver`.", "question_id": 3381},
{"snippet": "DataFrame.to_gbq(destination_table, table_schema=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `table_schema`.", "question_id": 3382},
{"snippet": "DataFrame.to_gbq(destination_table, location=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `location`.", "question_id": 3383},
{"snippet": "DataFrame.to_gbq(destination_table, progress_bar=True)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `progress_bar`.", "question_id": 3384},
{"snippet": "DataFrame.to_gbq(destination_table, credentials=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `credentials`.", "question_id": 3385},
{"snippet": "DataFrame.to_gbq(destination_table)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`.", "question_id": 3386},
{"snippet": "DataFrame.to_gbq(destination_table, project_id=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `project_id`.", "question_id": 3387},
{"snippet": "DataFrame.to_gbq(destination_table, chunksize=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `chunksize`.", "question_id": 3388},
{"snippet": "DataFrame.to_gbq(destination_table, reauth=False)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `reauth`.", "question_id": 3389},
{"snippet": "DataFrame.to_gbq(destination_table, if_exists='fail')", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `if_exists`.", "question_id": 3390},
{"snippet": "DataFrame.to_gbq(destination_table, auth_local_webserver=False)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `auth_local_webserver`.", "question_id": 3391},
{"snippet": "DataFrame.to_gbq(destination_table, table_schema=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `table_schema`.", "question_id": 3392},
{"snippet": "DataFrame.to_gbq(destination_table, location=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `location`.", "question_id": 3393},
{"snippet": "DataFrame.to_gbq(destination_table, progress_bar=True)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `progress_bar`.", "question_id": 3394},
{"snippet": "DataFrame.to_gbq(destination_table, credentials=None)", "intent": "Write a DataFrame to a Google BigQuery table . With arguments `destination_table`, `credentials`.", "question_id": 3395},
{"snippet": "DataFrame.to_hdf(path_or_buf, key)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 3396},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, mode='a')", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 3397},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, complevel=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `complevel`.", "question_id": 3398},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, complib=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `complib`.", "question_id": 3399},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, append=False)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 3400},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, format=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `format`.", "question_id": 3401},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, index=True)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `index`.", "question_id": 3402},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, min_itemsize=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `min_itemsize`.", "question_id": 3403},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, nan_rep=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `nan_rep`.", "question_id": 3404},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, dropna=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `dropna`.", "question_id": 3405},
{"snippet": "DataFrame.to_hdf(path_or_buf, key)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 3406},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, mode='a')", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 3407},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, complevel=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `complevel`.", "question_id": 3408},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, complib=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `complib`.", "question_id": 3409},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, append=False)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 3410},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, format=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `format`.", "question_id": 3411},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, index=True)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `index`.", "question_id": 3412},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, min_itemsize=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `min_itemsize`.", "question_id": 3413},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, nan_rep=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `nan_rep`.", "question_id": 3414},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, dropna=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `dropna`.", "question_id": 3415},
{"snippet": "DataFrame.to_hdf(path_or_buf, key)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 3416},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, mode='a')", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 3417},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, complevel=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `complevel`.", "question_id": 3418},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, complib=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `complib`.", "question_id": 3419},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, append=False)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 3420},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, format=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `format`.", "question_id": 3421},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, index=True)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `index`.", "question_id": 3422},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, min_itemsize=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `min_itemsize`.", "question_id": 3423},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, nan_rep=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `nan_rep`.", "question_id": 3424},
{"snippet": "DataFrame.to_hdf(path_or_buf, key, dropna=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `dropna`.", "question_id": 3425},
{"snippet": "DataFrame.to_html()", "intent": "Render a DataFrame as an HTML table .", "question_id": 3426},
{"snippet": "DataFrame.to_html(buf=None)", "intent": "Render a DataFrame as an HTML table . With arguments `buf`.", "question_id": 3427},
{"snippet": "DataFrame.to_html(columns=None)", "intent": "Render a DataFrame as an HTML table . With arguments `columns`.", "question_id": 3428},
{"snippet": "DataFrame.to_html(col_space=None)", "intent": "Render a DataFrame as an HTML table . With arguments `col_space`.", "question_id": 3429},
{"snippet": "DataFrame.to_html(header=True)", "intent": "Render a DataFrame as an HTML table . With arguments `header`.", "question_id": 3430},
{"snippet": "DataFrame.to_html(index=True)", "intent": "Render a DataFrame as an HTML table . With arguments `index`.", "question_id": 3431},
{"snippet": "DataFrame.to_html(na_rep='NaN')", "intent": "Render a DataFrame as an HTML table . With arguments `na_rep`.", "question_id": 3432},
{"snippet": "DataFrame.to_html(formatters=None)", "intent": "Render a DataFrame as an HTML table . With arguments `formatters`.", "question_id": 3433},
{"snippet": "DataFrame.to_html(float_format=None)", "intent": "Render a DataFrame as an HTML table . With arguments `float_format`.", "question_id": 3434},
{"snippet": "DataFrame.to_html(sparsify=None)", "intent": "Render a DataFrame as an HTML table . With arguments `sparsify`.", "question_id": 3435},
{"snippet": "DataFrame.to_html()", "intent": "Render a DataFrame as an HTML table .", "question_id": 3436},
{"snippet": "DataFrame.to_html(buf=None)", "intent": "Render a DataFrame as an HTML table . With arguments `buf`.", "question_id": 3437},
{"snippet": "DataFrame.to_html(columns=None)", "intent": "Render a DataFrame as an HTML table . With arguments `columns`.", "question_id": 3438},
{"snippet": "DataFrame.to_html(col_space=None)", "intent": "Render a DataFrame as an HTML table . With arguments `col_space`.", "question_id": 3439},
{"snippet": "DataFrame.to_html(header=True)", "intent": "Render a DataFrame as an HTML table . With arguments `header`.", "question_id": 3440},
{"snippet": "DataFrame.to_html(index=True)", "intent": "Render a DataFrame as an HTML table . With arguments `index`.", "question_id": 3441},
{"snippet": "DataFrame.to_html(na_rep='NaN')", "intent": "Render a DataFrame as an HTML table . With arguments `na_rep`.", "question_id": 3442},
{"snippet": "DataFrame.to_html(formatters=None)", "intent": "Render a DataFrame as an HTML table . With arguments `formatters`.", "question_id": 3443},
{"snippet": "DataFrame.to_html(float_format=None)", "intent": "Render a DataFrame as an HTML table . With arguments `float_format`.", "question_id": 3444},
{"snippet": "DataFrame.to_html(sparsify=None)", "intent": "Render a DataFrame as an HTML table . With arguments `sparsify`.", "question_id": 3445},
{"snippet": "DataFrame.to_html()", "intent": "Render a DataFrame as an HTML table .", "question_id": 3446},
{"snippet": "DataFrame.to_html(buf=None)", "intent": "Render a DataFrame as an HTML table . With arguments `buf`.", "question_id": 3447},
{"snippet": "DataFrame.to_html(columns=None)", "intent": "Render a DataFrame as an HTML table . With arguments `columns`.", "question_id": 3448},
{"snippet": "DataFrame.to_html(col_space=None)", "intent": "Render a DataFrame as an HTML table . With arguments `col_space`.", "question_id": 3449},
{"snippet": "DataFrame.to_html(header=True)", "intent": "Render a DataFrame as an HTML table . With arguments `header`.", "question_id": 3450},
{"snippet": "DataFrame.to_html(index=True)", "intent": "Render a DataFrame as an HTML table . With arguments `index`.", "question_id": 3451},
{"snippet": "DataFrame.to_html(na_rep='NaN')", "intent": "Render a DataFrame as an HTML table . With arguments `na_rep`.", "question_id": 3452},
{"snippet": "DataFrame.to_html(formatters=None)", "intent": "Render a DataFrame as an HTML table . With arguments `formatters`.", "question_id": 3453},
{"snippet": "DataFrame.to_html(float_format=None)", "intent": "Render a DataFrame as an HTML table . With arguments `float_format`.", "question_id": 3454},
{"snippet": "DataFrame.to_html(sparsify=None)", "intent": "Render a DataFrame as an HTML table . With arguments `sparsify`.", "question_id": 3455},
{"snippet": "DataFrame.to_json()", "intent": "Convert the object to a JSON string .", "question_id": 3456},
{"snippet": "DataFrame.to_json(path_or_buf=None)", "intent": "Convert the object to a JSON string . With arguments `path_or_buf`.", "question_id": 3457},
{"snippet": "DataFrame.to_json(orient=None)", "intent": "Convert the object to a JSON string . With arguments `orient`.", "question_id": 3458},
{"snippet": "DataFrame.to_json(date_format=None)", "intent": "Convert the object to a JSON string . With arguments `date_format`.", "question_id": 3459},
{"snippet": "DataFrame.to_json(double_precision=10)", "intent": "Convert the object to a JSON string . With arguments `double_precision`.", "question_id": 3460},
{"snippet": "DataFrame.to_json(force_ascii=True)", "intent": "Convert the object to a JSON string . With arguments `force_ascii`.", "question_id": 3461},
{"snippet": "DataFrame.to_json(date_unit='ms')", "intent": "Convert the object to a JSON string . With arguments `date_unit`.", "question_id": 3462},
{"snippet": "DataFrame.to_json(default_handler=None)", "intent": "Convert the object to a JSON string . With arguments `default_handler`.", "question_id": 3463},
{"snippet": "DataFrame.to_json(lines=False)", "intent": "Convert the object to a JSON string . With arguments `lines`.", "question_id": 3464},
{"snippet": "DataFrame.to_json(compression='infer')", "intent": "Convert the object to a JSON string . With arguments `compression`.", "question_id": 3465},
{"snippet": "DataFrame.to_json()", "intent": "Convert the object to a JSON string .", "question_id": 3466},
{"snippet": "DataFrame.to_json(path_or_buf=None)", "intent": "Convert the object to a JSON string . With arguments `path_or_buf`.", "question_id": 3467},
{"snippet": "DataFrame.to_json(orient=None)", "intent": "Convert the object to a JSON string . With arguments `orient`.", "question_id": 3468},
{"snippet": "DataFrame.to_json(date_format=None)", "intent": "Convert the object to a JSON string . With arguments `date_format`.", "question_id": 3469},
{"snippet": "DataFrame.to_json(double_precision=10)", "intent": "Convert the object to a JSON string . With arguments `double_precision`.", "question_id": 3470},
{"snippet": "DataFrame.to_json(force_ascii=True)", "intent": "Convert the object to a JSON string . With arguments `force_ascii`.", "question_id": 3471},
{"snippet": "DataFrame.to_json(date_unit='ms')", "intent": "Convert the object to a JSON string . With arguments `date_unit`.", "question_id": 3472},
{"snippet": "DataFrame.to_json(default_handler=None)", "intent": "Convert the object to a JSON string . With arguments `default_handler`.", "question_id": 3473},
{"snippet": "DataFrame.to_json(lines=False)", "intent": "Convert the object to a JSON string . With arguments `lines`.", "question_id": 3474},
{"snippet": "DataFrame.to_json(compression='infer')", "intent": "Convert the object to a JSON string . With arguments `compression`.", "question_id": 3475},
{"snippet": "DataFrame.to_json()", "intent": "Convert the object to a JSON string .", "question_id": 3476},
{"snippet": "DataFrame.to_json(path_or_buf=None)", "intent": "Convert the object to a JSON string . With arguments `path_or_buf`.", "question_id": 3477},
{"snippet": "DataFrame.to_json(orient=None)", "intent": "Convert the object to a JSON string . With arguments `orient`.", "question_id": 3478},
{"snippet": "DataFrame.to_json(date_format=None)", "intent": "Convert the object to a JSON string . With arguments `date_format`.", "question_id": 3479},
{"snippet": "DataFrame.to_json(double_precision=10)", "intent": "Convert the object to a JSON string . With arguments `double_precision`.", "question_id": 3480},
{"snippet": "DataFrame.to_json(force_ascii=True)", "intent": "Convert the object to a JSON string . With arguments `force_ascii`.", "question_id": 3481},
{"snippet": "DataFrame.to_json(date_unit='ms')", "intent": "Convert the object to a JSON string . With arguments `date_unit`.", "question_id": 3482},
{"snippet": "DataFrame.to_json(default_handler=None)", "intent": "Convert the object to a JSON string . With arguments `default_handler`.", "question_id": 3483},
{"snippet": "DataFrame.to_json(lines=False)", "intent": "Convert the object to a JSON string . With arguments `lines`.", "question_id": 3484},
{"snippet": "DataFrame.to_json(compression='infer')", "intent": "Convert the object to a JSON string . With arguments `compression`.", "question_id": 3485},
{"snippet": "DataFrame.to_latex()", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular .", "question_id": 3486},
{"snippet": "DataFrame.to_latex(buf=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `buf`.", "question_id": 3487},
{"snippet": "DataFrame.to_latex(columns=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `columns`.", "question_id": 3488},
{"snippet": "DataFrame.to_latex(col_space=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `col_space`.", "question_id": 3489},
{"snippet": "DataFrame.to_latex(header=True)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `header`.", "question_id": 3490},
{"snippet": "DataFrame.to_latex(index=True)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `index`.", "question_id": 3491},
{"snippet": "DataFrame.to_latex(na_rep='NaN')", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `na_rep`.", "question_id": 3492},
{"snippet": "DataFrame.to_latex(formatters=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `formatters`.", "question_id": 3493},
{"snippet": "DataFrame.to_latex(float_format=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `float_format`.", "question_id": 3494},
{"snippet": "DataFrame.to_latex(sparsify=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `sparsify`.", "question_id": 3495},
{"snippet": "DataFrame.to_latex()", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular .", "question_id": 3496},
{"snippet": "DataFrame.to_latex(buf=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `buf`.", "question_id": 3497},
{"snippet": "DataFrame.to_latex(columns=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `columns`.", "question_id": 3498},
{"snippet": "DataFrame.to_latex(col_space=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `col_space`.", "question_id": 3499},
{"snippet": "DataFrame.to_latex(header=True)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `header`.", "question_id": 3500},
{"snippet": "DataFrame.to_latex(index=True)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `index`.", "question_id": 3501},
{"snippet": "DataFrame.to_latex(na_rep='NaN')", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `na_rep`.", "question_id": 3502},
{"snippet": "DataFrame.to_latex(formatters=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `formatters`.", "question_id": 3503},
{"snippet": "DataFrame.to_latex(float_format=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `float_format`.", "question_id": 3504},
{"snippet": "DataFrame.to_latex(sparsify=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `sparsify`.", "question_id": 3505},
{"snippet": "DataFrame.to_latex()", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular .", "question_id": 3506},
{"snippet": "DataFrame.to_latex(buf=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `buf`.", "question_id": 3507},
{"snippet": "DataFrame.to_latex(columns=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `columns`.", "question_id": 3508},
{"snippet": "DataFrame.to_latex(col_space=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `col_space`.", "question_id": 3509},
{"snippet": "DataFrame.to_latex(header=True)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `header`.", "question_id": 3510},
{"snippet": "DataFrame.to_latex(index=True)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `index`.", "question_id": 3511},
{"snippet": "DataFrame.to_latex(na_rep='NaN')", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `na_rep`.", "question_id": 3512},
{"snippet": "DataFrame.to_latex(formatters=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `formatters`.", "question_id": 3513},
{"snippet": "DataFrame.to_latex(float_format=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `float_format`.", "question_id": 3514},
{"snippet": "DataFrame.to_latex(sparsify=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `sparsify`.", "question_id": 3515},
{"snippet": "DataFrame.to_markdown(**kwargs)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`.", "question_id": 3516},
{"snippet": "DataFrame.to_markdown(**kwargs, buf=None)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `buf`.", "question_id": 3517},
{"snippet": "DataFrame.to_markdown(**kwargs, mode='wt')", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `mode`.", "question_id": 3518},
{"snippet": "DataFrame.to_markdown(**kwargs, index=True)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `index`.", "question_id": 3519},
{"snippet": "DataFrame.to_markdown(**kwargs, storage_options=None)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `storage_options`.", "question_id": 3520},
{"snippet": "DataFrame.to_markdown(**kwargs, buf=None, mode='wt')", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `buf`, `mode`.", "question_id": 3521},
{"snippet": "DataFrame.to_markdown(**kwargs, buf=None, index=True)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `buf`, `index`.", "question_id": 3522},
{"snippet": "DataFrame.to_markdown(**kwargs, buf=None, storage_options=None)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `buf`, `storage_options`.", "question_id": 3523},
{"snippet": "DataFrame.to_markdown(**kwargs, mode='wt', index=True)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `mode`, `index`.", "question_id": 3524},
{"snippet": "DataFrame.to_markdown(**kwargs, mode='wt', storage_options=None)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `mode`, `storage_options`.", "question_id": 3525},
{"snippet": "DataFrame.to_markdown(**kwargs)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`.", "question_id": 3526},
{"snippet": "DataFrame.to_markdown(**kwargs, buf=None)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `buf`.", "question_id": 3527},
{"snippet": "DataFrame.to_markdown(**kwargs, mode='wt')", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `mode`.", "question_id": 3528},
{"snippet": "DataFrame.to_markdown(**kwargs, index=True)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `index`.", "question_id": 3529},
{"snippet": "DataFrame.to_markdown(**kwargs, storage_options=None)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `storage_options`.", "question_id": 3530},
{"snippet": "DataFrame.to_markdown(**kwargs, buf=None, mode='wt')", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `buf`, `mode`.", "question_id": 3531},
{"snippet": "DataFrame.to_markdown(**kwargs, buf=None, index=True)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `buf`, `index`.", "question_id": 3532},
{"snippet": "DataFrame.to_markdown(**kwargs, buf=None, storage_options=None)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `buf`, `storage_options`.", "question_id": 3533},
{"snippet": "DataFrame.to_markdown(**kwargs, mode='wt', index=True)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `mode`, `index`.", "question_id": 3534},
{"snippet": "DataFrame.to_markdown(**kwargs, mode='wt', storage_options=None)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `mode`, `storage_options`.", "question_id": 3535},
{"snippet": "DataFrame.to_markdown(**kwargs)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`.", "question_id": 3536},
{"snippet": "DataFrame.to_markdown(**kwargs, buf=None)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `buf`.", "question_id": 3537},
{"snippet": "DataFrame.to_markdown(**kwargs, mode='wt')", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `mode`.", "question_id": 3538},
{"snippet": "DataFrame.to_markdown(**kwargs, index=True)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `index`.", "question_id": 3539},
{"snippet": "DataFrame.to_markdown(**kwargs, storage_options=None)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `storage_options`.", "question_id": 3540},
{"snippet": "DataFrame.to_markdown(**kwargs, buf=None, mode='wt')", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `buf`, `mode`.", "question_id": 3541},
{"snippet": "DataFrame.to_markdown(**kwargs, buf=None, index=True)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `buf`, `index`.", "question_id": 3542},
{"snippet": "DataFrame.to_markdown(**kwargs, buf=None, storage_options=None)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `buf`, `storage_options`.", "question_id": 3543},
{"snippet": "DataFrame.to_markdown(**kwargs, mode='wt', index=True)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `mode`, `index`.", "question_id": 3544},
{"snippet": "DataFrame.to_markdown(**kwargs, mode='wt', storage_options=None)", "intent": "Print DataFrame in Markdown-friendly format . With arguments `**kwargs`, `mode`, `storage_options`.", "question_id": 3545},
{"snippet": "DataFrame.to_numpy()", "intent": "Convert the DataFrame to a NumPy array .", "question_id": 3546},
{"snippet": "DataFrame.to_numpy(dtype=None)", "intent": "Convert the DataFrame to a NumPy array . By default , the `dtype` of the returned array will be the common NumPy dtype of all types in the DataFrame .", "question_id": 3547},
{"snippet": "DataFrame.to_numpy(copy=False)", "intent": "Convert the DataFrame to a NumPy array . With arguments `copy`.", "question_id": 3548},
{"snippet": "DataFrame.to_numpy(na_value=NoDefault.no_default)", "intent": "Convert the DataFrame to a NumPy array . With arguments `na_value`.", "question_id": 3549},
{"snippet": "DataFrame.to_numpy(dtype=None, copy=False)", "intent": "Convert the DataFrame to a NumPy array . By default , the `dtype` of the returned array will be the common NumPy dtype of all types in the DataFrame . With arguments `copy`.", "question_id": 3550},
{"snippet": "DataFrame.to_numpy(dtype=None, na_value=NoDefault.no_default)", "intent": "Convert the DataFrame to a NumPy array . By default , the `dtype` of the returned array will be the common NumPy dtype of all types in the DataFrame . With arguments `na_value`.", "question_id": 3551},
{"snippet": "DataFrame.to_numpy(copy=False, na_value=NoDefault.no_default)", "intent": "Convert the DataFrame to a NumPy array . With arguments `copy`, `na_value`.", "question_id": 3552},
{"snippet": "DataFrame.to_numpy(dtype=None, copy=False, na_value=NoDefault.no_default)", "intent": "Convert the DataFrame to a NumPy array . By default , the `dtype` of the returned array will be the common NumPy dtype of all types in the DataFrame . With arguments `copy`, `na_value`.", "question_id": 3553},
{"snippet": "DataFrame.to_numpy()", "intent": "Convert the DataFrame to a NumPy array .", "question_id": 3554},
{"snippet": "DataFrame.to_numpy(dtype=None)", "intent": "Convert the DataFrame to a NumPy array . By default , the `dtype` of the returned array will be the common NumPy dtype of all types in the DataFrame .", "question_id": 3555},
{"snippet": "DataFrame.to_numpy(copy=False)", "intent": "Convert the DataFrame to a NumPy array . With arguments `copy`.", "question_id": 3556},
{"snippet": "DataFrame.to_numpy(na_value=NoDefault.no_default)", "intent": "Convert the DataFrame to a NumPy array . With arguments `na_value`.", "question_id": 3557},
{"snippet": "DataFrame.to_numpy(dtype=None, copy=False)", "intent": "Convert the DataFrame to a NumPy array . By default , the `dtype` of the returned array will be the common NumPy dtype of all types in the DataFrame . With arguments `copy`.", "question_id": 3558},
{"snippet": "DataFrame.to_numpy(dtype=None, na_value=NoDefault.no_default)", "intent": "Convert the DataFrame to a NumPy array . By default , the `dtype` of the returned array will be the common NumPy dtype of all types in the DataFrame . With arguments `na_value`.", "question_id": 3559},
{"snippet": "DataFrame.to_numpy(copy=False, na_value=NoDefault.no_default)", "intent": "Convert the DataFrame to a NumPy array . With arguments `copy`, `na_value`.", "question_id": 3560},
{"snippet": "DataFrame.to_numpy(dtype=None, copy=False, na_value=NoDefault.no_default)", "intent": "Convert the DataFrame to a NumPy array . By default , the `dtype` of the returned array will be the common NumPy dtype of all types in the DataFrame . With arguments `copy`, `na_value`.", "question_id": 3561},
{"snippet": "DataFrame.to_numpy()", "intent": "Convert the DataFrame to a NumPy array .", "question_id": 3562},
{"snippet": "DataFrame.to_numpy(dtype=None)", "intent": "Convert the DataFrame to a NumPy array . By default , the `dtype` of the returned array will be the common NumPy dtype of all types in the DataFrame .", "question_id": 3563},
{"snippet": "DataFrame.to_numpy(copy=False)", "intent": "Convert the DataFrame to a NumPy array . With arguments `copy`.", "question_id": 3564},
{"snippet": "DataFrame.to_numpy(na_value=NoDefault.no_default)", "intent": "Convert the DataFrame to a NumPy array . With arguments `na_value`.", "question_id": 3565},
{"snippet": "DataFrame.to_numpy(dtype=None, copy=False)", "intent": "Convert the DataFrame to a NumPy array . By default , the `dtype` of the returned array will be the common NumPy dtype of all types in the DataFrame . With arguments `copy`.", "question_id": 3566},
{"snippet": "DataFrame.to_numpy(dtype=None, na_value=NoDefault.no_default)", "intent": "Convert the DataFrame to a NumPy array . By default , the `dtype` of the returned array will be the common NumPy dtype of all types in the DataFrame . With arguments `na_value`.", "question_id": 3567},
{"snippet": "DataFrame.to_numpy(copy=False, na_value=NoDefault.no_default)", "intent": "Convert the DataFrame to a NumPy array . With arguments `copy`, `na_value`.", "question_id": 3568},
{"snippet": "DataFrame.to_numpy(dtype=None, copy=False, na_value=NoDefault.no_default)", "intent": "Convert the DataFrame to a NumPy array . By default , the `dtype` of the returned array will be the common NumPy dtype of all types in the DataFrame . With arguments `copy`, `na_value`.", "question_id": 3569},
{"snippet": "DataFrame.to_parquet(**kwargs)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`.", "question_id": 3570},
{"snippet": "DataFrame.to_parquet(**kwargs, path=None)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `path`.", "question_id": 3571},
{"snippet": "DataFrame.to_parquet(**kwargs, engine='auto')", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `engine`.", "question_id": 3572},
{"snippet": "DataFrame.to_parquet(**kwargs, compression='snappy')", "intent": "Write a DataFrame to the binary parquet format . You can choose different parquet backends , and have the option of `compression` . With arguments `**kwargs`.", "question_id": 3573},
{"snippet": "DataFrame.to_parquet(**kwargs, index=None)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `index`.", "question_id": 3574},
{"snippet": "DataFrame.to_parquet(**kwargs, partition_cols=None)", "intent": "Write a DataFrame to the binary parquet format . If you want to get a buffer to the parquet content you can use a io.BytesIO object , as long as you don \u2019 t use `partition_cols` , which creates multiple files . With arguments `**kwargs`.", "question_id": 3575},
{"snippet": "DataFrame.to_parquet(**kwargs, storage_options=None)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `storage_options`.", "question_id": 3576},
{"snippet": "DataFrame.to_parquet(**kwargs, path=None, engine='auto')", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `path`, `engine`.", "question_id": 3577},
{"snippet": "DataFrame.to_parquet(**kwargs, path=None, compression='snappy')", "intent": "Write a DataFrame to the binary parquet format . You can choose different parquet backends , and have the option of `compression` . With arguments `**kwargs`, `path`.", "question_id": 3578},
{"snippet": "DataFrame.to_parquet(**kwargs, path=None, index=None)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `path`, `index`.", "question_id": 3579},
{"snippet": "DataFrame.to_parquet(**kwargs)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`.", "question_id": 3580},
{"snippet": "DataFrame.to_parquet(**kwargs, path=None)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `path`.", "question_id": 3581},
{"snippet": "DataFrame.to_parquet(**kwargs, engine='auto')", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `engine`.", "question_id": 3582},
{"snippet": "DataFrame.to_parquet(**kwargs, compression='snappy')", "intent": "Write a DataFrame to the binary parquet format . You can choose different parquet backends , and have the option of `compression` . With arguments `**kwargs`.", "question_id": 3583},
{"snippet": "DataFrame.to_parquet(**kwargs, index=None)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `index`.", "question_id": 3584},
{"snippet": "DataFrame.to_parquet(**kwargs, partition_cols=None)", "intent": "Write a DataFrame to the binary parquet format . If you want to get a buffer to the parquet content you can use a io.BytesIO object , as long as you don \u2019 t use `partition_cols` , which creates multiple files . With arguments `**kwargs`.", "question_id": 3585},
{"snippet": "DataFrame.to_parquet(**kwargs, storage_options=None)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `storage_options`.", "question_id": 3586},
{"snippet": "DataFrame.to_parquet(**kwargs, path=None, engine='auto')", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `path`, `engine`.", "question_id": 3587},
{"snippet": "DataFrame.to_parquet(**kwargs, path=None, compression='snappy')", "intent": "Write a DataFrame to the binary parquet format . You can choose different parquet backends , and have the option of `compression` . With arguments `**kwargs`, `path`.", "question_id": 3588},
{"snippet": "DataFrame.to_parquet(**kwargs, path=None, index=None)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `path`, `index`.", "question_id": 3589},
{"snippet": "DataFrame.to_parquet(**kwargs)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`.", "question_id": 3590},
{"snippet": "DataFrame.to_parquet(**kwargs, path=None)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `path`.", "question_id": 3591},
{"snippet": "DataFrame.to_parquet(**kwargs, engine='auto')", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `engine`.", "question_id": 3592},
{"snippet": "DataFrame.to_parquet(**kwargs, compression='snappy')", "intent": "Write a DataFrame to the binary parquet format . You can choose different parquet backends , and have the option of `compression` . With arguments `**kwargs`.", "question_id": 3593},
{"snippet": "DataFrame.to_parquet(**kwargs, index=None)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `index`.", "question_id": 3594},
{"snippet": "DataFrame.to_parquet(**kwargs, partition_cols=None)", "intent": "Write a DataFrame to the binary parquet format . If you want to get a buffer to the parquet content you can use a io.BytesIO object , as long as you don \u2019 t use `partition_cols` , which creates multiple files . With arguments `**kwargs`.", "question_id": 3595},
{"snippet": "DataFrame.to_parquet(**kwargs, storage_options=None)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `storage_options`.", "question_id": 3596},
{"snippet": "DataFrame.to_parquet(**kwargs, path=None, engine='auto')", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `path`, `engine`.", "question_id": 3597},
{"snippet": "DataFrame.to_parquet(**kwargs, path=None, compression='snappy')", "intent": "Write a DataFrame to the binary parquet format . You can choose different parquet backends , and have the option of `compression` . With arguments `**kwargs`, `path`.", "question_id": 3598},
{"snippet": "DataFrame.to_parquet(**kwargs, path=None, index=None)", "intent": "Write a DataFrame to the binary parquet format . With arguments `**kwargs`, `path`, `index`.", "question_id": 3599},
{"snippet": "DataFrame.to_period()", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex .", "question_id": 3600},
{"snippet": "DataFrame.to_period(freq=None)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `freq`.", "question_id": 3601},
{"snippet": "DataFrame.to_period(axis=0)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `axis`.", "question_id": 3602},
{"snippet": "DataFrame.to_period(copy=True)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `copy`.", "question_id": 3603},
{"snippet": "DataFrame.to_period(freq=None, axis=0)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `freq`, `axis`.", "question_id": 3604},
{"snippet": "DataFrame.to_period(freq=None, copy=True)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `freq`, `copy`.", "question_id": 3605},
{"snippet": "DataFrame.to_period(axis=0, copy=True)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `axis`, `copy`.", "question_id": 3606},
{"snippet": "DataFrame.to_period(freq=None, axis=0, copy=True)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `freq`, `axis`, `copy`.", "question_id": 3607},
{"snippet": "DataFrame.to_period()", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex .", "question_id": 3608},
{"snippet": "DataFrame.to_period(freq=None)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `freq`.", "question_id": 3609},
{"snippet": "DataFrame.to_period(axis=0)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `axis`.", "question_id": 3610},
{"snippet": "DataFrame.to_period(copy=True)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `copy`.", "question_id": 3611},
{"snippet": "DataFrame.to_period(freq=None, axis=0)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `freq`, `axis`.", "question_id": 3612},
{"snippet": "DataFrame.to_period(freq=None, copy=True)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `freq`, `copy`.", "question_id": 3613},
{"snippet": "DataFrame.to_period(axis=0, copy=True)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `axis`, `copy`.", "question_id": 3614},
{"snippet": "DataFrame.to_period(freq=None, axis=0, copy=True)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `freq`, `axis`, `copy`.", "question_id": 3615},
{"snippet": "DataFrame.to_period()", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex .", "question_id": 3616},
{"snippet": "DataFrame.to_period(freq=None)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `freq`.", "question_id": 3617},
{"snippet": "DataFrame.to_period(axis=0)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `axis`.", "question_id": 3618},
{"snippet": "DataFrame.to_period(copy=True)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `copy`.", "question_id": 3619},
{"snippet": "DataFrame.to_period(freq=None, axis=0)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `freq`, `axis`.", "question_id": 3620},
{"snippet": "DataFrame.to_period(freq=None, copy=True)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `freq`, `copy`.", "question_id": 3621},
{"snippet": "DataFrame.to_period(axis=0, copy=True)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `axis`, `copy`.", "question_id": 3622},
{"snippet": "DataFrame.to_period(freq=None, axis=0, copy=True)", "intent": "Convert DataFrame from DatetimeIndex to PeriodIndex . With arguments `freq`, `axis`, `copy`.", "question_id": 3623},
{"snippet": "DataFrame.to_pickle(path)", "intent": "Pickle ( serialize ) object to file . With arguments `path`.", "question_id": 3624},
{"snippet": "DataFrame.to_pickle(path, compression='infer')", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`.", "question_id": 3625},
{"snippet": "DataFrame.to_pickle(path, protocol=5)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `protocol`.", "question_id": 3626},
{"snippet": "DataFrame.to_pickle(path, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `storage_options`.", "question_id": 3627},
{"snippet": "DataFrame.to_pickle(path, compression='infer', protocol=5)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `protocol`.", "question_id": 3628},
{"snippet": "DataFrame.to_pickle(path, compression='infer', storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `storage_options`.", "question_id": 3629},
{"snippet": "DataFrame.to_pickle(path, protocol=5, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `protocol`, `storage_options`.", "question_id": 3630},
{"snippet": "DataFrame.to_pickle(path, compression='infer', protocol=5, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `protocol`, `storage_options`.", "question_id": 3631},
{"snippet": "DataFrame.to_pickle(path)", "intent": "Pickle ( serialize ) object to file . With arguments `path`.", "question_id": 3632},
{"snippet": "DataFrame.to_pickle(path, compression='infer')", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`.", "question_id": 3633},
{"snippet": "DataFrame.to_pickle(path, protocol=5)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `protocol`.", "question_id": 3634},
{"snippet": "DataFrame.to_pickle(path, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `storage_options`.", "question_id": 3635},
{"snippet": "DataFrame.to_pickle(path, compression='infer', protocol=5)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `protocol`.", "question_id": 3636},
{"snippet": "DataFrame.to_pickle(path, compression='infer', storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `storage_options`.", "question_id": 3637},
{"snippet": "DataFrame.to_pickle(path, protocol=5, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `protocol`, `storage_options`.", "question_id": 3638},
{"snippet": "DataFrame.to_pickle(path, compression='infer', protocol=5, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `protocol`, `storage_options`.", "question_id": 3639},
{"snippet": "DataFrame.to_pickle(path)", "intent": "Pickle ( serialize ) object to file . With arguments `path`.", "question_id": 3640},
{"snippet": "DataFrame.to_pickle(path, compression='infer')", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`.", "question_id": 3641},
{"snippet": "DataFrame.to_pickle(path, protocol=5)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `protocol`.", "question_id": 3642},
{"snippet": "DataFrame.to_pickle(path, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `storage_options`.", "question_id": 3643},
{"snippet": "DataFrame.to_pickle(path, compression='infer', protocol=5)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `protocol`.", "question_id": 3644},
{"snippet": "DataFrame.to_pickle(path, compression='infer', storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `storage_options`.", "question_id": 3645},
{"snippet": "DataFrame.to_pickle(path, protocol=5, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `protocol`, `storage_options`.", "question_id": 3646},
{"snippet": "DataFrame.to_pickle(path, compression='infer', protocol=5, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `protocol`, `storage_options`.", "question_id": 3647},
{"snippet": "DataFrame.to_records()", "intent": "Convert DataFrame to a NumPy record array .", "question_id": 3648},
{"snippet": "DataFrame.to_records(index=True)", "intent": "Convert DataFrame to a NumPy record array . If the DataFrame `index` has no label then the recarray field name is set to \u2018 index \u2019 .", "question_id": 3649},
{"snippet": "DataFrame.to_records(column_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . With arguments `column_dtypes`.", "question_id": 3650},
{"snippet": "DataFrame.to_records(index_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . With arguments `index_dtypes`.", "question_id": 3651},
{"snippet": "DataFrame.to_records(index=True, column_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . If the DataFrame `index` has no label then the recarray field name is set to \u2018 index \u2019 . With arguments `column_dtypes`.", "question_id": 3652},
{"snippet": "DataFrame.to_records(index=True, index_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . If the DataFrame `index` has no label then the recarray field name is set to \u2018 index \u2019 . With arguments `index_dtypes`.", "question_id": 3653},
{"snippet": "DataFrame.to_records(column_dtypes=None, index_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . With arguments `column_dtypes`, `index_dtypes`.", "question_id": 3654},
{"snippet": "DataFrame.to_records(index=True, column_dtypes=None, index_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . If the DataFrame `index` has no label then the recarray field name is set to \u2018 index \u2019 . With arguments `column_dtypes`, `index_dtypes`.", "question_id": 3655},
{"snippet": "DataFrame.to_records()", "intent": "Convert DataFrame to a NumPy record array .", "question_id": 3656},
{"snippet": "DataFrame.to_records(index=True)", "intent": "Convert DataFrame to a NumPy record array . If the DataFrame `index` has no label then the recarray field name is set to \u2018 index \u2019 .", "question_id": 3657},
{"snippet": "DataFrame.to_records(column_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . With arguments `column_dtypes`.", "question_id": 3658},
{"snippet": "DataFrame.to_records(index_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . With arguments `index_dtypes`.", "question_id": 3659},
{"snippet": "DataFrame.to_records(index=True, column_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . If the DataFrame `index` has no label then the recarray field name is set to \u2018 index \u2019 . With arguments `column_dtypes`.", "question_id": 3660},
{"snippet": "DataFrame.to_records(index=True, index_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . If the DataFrame `index` has no label then the recarray field name is set to \u2018 index \u2019 . With arguments `index_dtypes`.", "question_id": 3661},
{"snippet": "DataFrame.to_records(column_dtypes=None, index_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . With arguments `column_dtypes`, `index_dtypes`.", "question_id": 3662},
{"snippet": "DataFrame.to_records(index=True, column_dtypes=None, index_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . If the DataFrame `index` has no label then the recarray field name is set to \u2018 index \u2019 . With arguments `column_dtypes`, `index_dtypes`.", "question_id": 3663},
{"snippet": "DataFrame.to_records()", "intent": "Convert DataFrame to a NumPy record array .", "question_id": 3664},
{"snippet": "DataFrame.to_records(index=True)", "intent": "Convert DataFrame to a NumPy record array . If the DataFrame `index` has no label then the recarray field name is set to \u2018 index \u2019 .", "question_id": 3665},
{"snippet": "DataFrame.to_records(column_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . With arguments `column_dtypes`.", "question_id": 3666},
{"snippet": "DataFrame.to_records(index_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . With arguments `index_dtypes`.", "question_id": 3667},
{"snippet": "DataFrame.to_records(index=True, column_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . If the DataFrame `index` has no label then the recarray field name is set to \u2018 index \u2019 . With arguments `column_dtypes`.", "question_id": 3668},
{"snippet": "DataFrame.to_records(index=True, index_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . If the DataFrame `index` has no label then the recarray field name is set to \u2018 index \u2019 . With arguments `index_dtypes`.", "question_id": 3669},
{"snippet": "DataFrame.to_records(column_dtypes=None, index_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . With arguments `column_dtypes`, `index_dtypes`.", "question_id": 3670},
{"snippet": "DataFrame.to_records(index=True, column_dtypes=None, index_dtypes=None)", "intent": "Convert DataFrame to a NumPy record array . If the DataFrame `index` has no label then the recarray field name is set to \u2018 index \u2019 . With arguments `column_dtypes`, `index_dtypes`.", "question_id": 3671},
{"snippet": "DataFrame.to_sql(name, con)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`.", "question_id": 3672},
{"snippet": "DataFrame.to_sql(name, con, schema=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`.", "question_id": 3673},
{"snippet": "DataFrame.to_sql(name, con, if_exists='fail')", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `if_exists`.", "question_id": 3674},
{"snippet": "DataFrame.to_sql(name, con, index=True)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `index`.", "question_id": 3675},
{"snippet": "DataFrame.to_sql(name, con, index_label=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `index_label`.", "question_id": 3676},
{"snippet": "DataFrame.to_sql(name, con, chunksize=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `chunksize`.", "question_id": 3677},
{"snippet": "DataFrame.to_sql(name, con, dtype=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : Specify the `dtype` ( especially useful for integers with missing values ) . With arguments `name`.", "question_id": 3678},
{"snippet": "DataFrame.to_sql(name, con, method=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `method`.", "question_id": 3679},
{"snippet": "DataFrame.to_sql(name, con, schema=None, if_exists='fail')", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`, `if_exists`.", "question_id": 3680},
{"snippet": "DataFrame.to_sql(name, con, schema=None, index=True)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`, `index`.", "question_id": 3681},
{"snippet": "DataFrame.to_sql(name, con)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`.", "question_id": 3682},
{"snippet": "DataFrame.to_sql(name, con, schema=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`.", "question_id": 3683},
{"snippet": "DataFrame.to_sql(name, con, if_exists='fail')", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `if_exists`.", "question_id": 3684},
{"snippet": "DataFrame.to_sql(name, con, index=True)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `index`.", "question_id": 3685},
{"snippet": "DataFrame.to_sql(name, con, index_label=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `index_label`.", "question_id": 3686},
{"snippet": "DataFrame.to_sql(name, con, chunksize=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `chunksize`.", "question_id": 3687},
{"snippet": "DataFrame.to_sql(name, con, dtype=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : Specify the `dtype` ( especially useful for integers with missing values ) . With arguments `name`.", "question_id": 3688},
{"snippet": "DataFrame.to_sql(name, con, method=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `method`.", "question_id": 3689},
{"snippet": "DataFrame.to_sql(name, con, schema=None, if_exists='fail')", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`, `if_exists`.", "question_id": 3690},
{"snippet": "DataFrame.to_sql(name, con, schema=None, index=True)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`, `index`.", "question_id": 3691},
{"snippet": "DataFrame.to_sql(name, con)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`.", "question_id": 3692},
{"snippet": "DataFrame.to_sql(name, con, schema=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`.", "question_id": 3693},
{"snippet": "DataFrame.to_sql(name, con, if_exists='fail')", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `if_exists`.", "question_id": 3694},
{"snippet": "DataFrame.to_sql(name, con, index=True)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `index`.", "question_id": 3695},
{"snippet": "DataFrame.to_sql(name, con, index_label=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `index_label`.", "question_id": 3696},
{"snippet": "DataFrame.to_sql(name, con, chunksize=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `chunksize`.", "question_id": 3697},
{"snippet": "DataFrame.to_sql(name, con, dtype=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : Specify the `dtype` ( especially useful for integers with missing values ) . With arguments `name`.", "question_id": 3698},
{"snippet": "DataFrame.to_sql(name, con, method=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `method`.", "question_id": 3699},
{"snippet": "DataFrame.to_sql(name, con, schema=None, if_exists='fail')", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`, `if_exists`.", "question_id": 3700},
{"snippet": "DataFrame.to_sql(name, con, schema=None, index=True)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`, `index`.", "question_id": 3701},
{"snippet": "DataFrame.to_stata(path)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`.", "question_id": 3702},
{"snippet": "DataFrame.to_stata(path, convert_dates=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `convert_dates`.", "question_id": 3703},
{"snippet": "DataFrame.to_stata(path, write_index=True)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `write_index`.", "question_id": 3704},
{"snippet": "DataFrame.to_stata(path, byteorder=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `byteorder`.", "question_id": 3705},
{"snippet": "DataFrame.to_stata(path, time_stamp=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `time_stamp`.", "question_id": 3706},
{"snippet": "DataFrame.to_stata(path, data_label=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `data_label`.", "question_id": 3707},
{"snippet": "DataFrame.to_stata(path, variable_labels=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `variable_labels`.", "question_id": 3708},
{"snippet": "DataFrame.to_stata(path, version=114)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `version`.", "question_id": 3709},
{"snippet": "DataFrame.to_stata(path, convert_strl=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `convert_strl`.", "question_id": 3710},
{"snippet": "DataFrame.to_stata(path, compression='infer')", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `compression`.", "question_id": 3711},
{"snippet": "DataFrame.to_stata(path)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`.", "question_id": 3712},
{"snippet": "DataFrame.to_stata(path, convert_dates=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `convert_dates`.", "question_id": 3713},
{"snippet": "DataFrame.to_stata(path, write_index=True)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `write_index`.", "question_id": 3714},
{"snippet": "DataFrame.to_stata(path, byteorder=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `byteorder`.", "question_id": 3715},
{"snippet": "DataFrame.to_stata(path, time_stamp=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `time_stamp`.", "question_id": 3716},
{"snippet": "DataFrame.to_stata(path, data_label=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `data_label`.", "question_id": 3717},
{"snippet": "DataFrame.to_stata(path, variable_labels=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `variable_labels`.", "question_id": 3718},
{"snippet": "DataFrame.to_stata(path, version=114)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `version`.", "question_id": 3719},
{"snippet": "DataFrame.to_stata(path, convert_strl=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `convert_strl`.", "question_id": 3720},
{"snippet": "DataFrame.to_stata(path, compression='infer')", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `compression`.", "question_id": 3721},
{"snippet": "DataFrame.to_stata(path)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`.", "question_id": 3722},
{"snippet": "DataFrame.to_stata(path, convert_dates=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `convert_dates`.", "question_id": 3723},
{"snippet": "DataFrame.to_stata(path, write_index=True)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `write_index`.", "question_id": 3724},
{"snippet": "DataFrame.to_stata(path, byteorder=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `byteorder`.", "question_id": 3725},
{"snippet": "DataFrame.to_stata(path, time_stamp=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `time_stamp`.", "question_id": 3726},
{"snippet": "DataFrame.to_stata(path, data_label=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `data_label`.", "question_id": 3727},
{"snippet": "DataFrame.to_stata(path, variable_labels=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `variable_labels`.", "question_id": 3728},
{"snippet": "DataFrame.to_stata(path, version=114)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `version`.", "question_id": 3729},
{"snippet": "DataFrame.to_stata(path, convert_strl=None)", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `convert_strl`.", "question_id": 3730},
{"snippet": "DataFrame.to_stata(path, compression='infer')", "intent": "Export DataFrame object to Stata dta format . With arguments `path`, `compression`.", "question_id": 3731},
{"snippet": "DataFrame.to_string()", "intent": "Render a DataFrame to a console-friendly tabular output .", "question_id": 3732},
{"snippet": "DataFrame.to_string(buf=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `buf`.", "question_id": 3733},
{"snippet": "DataFrame.to_string(columns=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `columns`.", "question_id": 3734},
{"snippet": "DataFrame.to_string(col_space=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `col_space`.", "question_id": 3735},
{"snippet": "DataFrame.to_string(header=True)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `header`.", "question_id": 3736},
{"snippet": "DataFrame.to_string(index=True)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `index`.", "question_id": 3737},
{"snippet": "DataFrame.to_string(na_rep='NaN')", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `na_rep`.", "question_id": 3738},
{"snippet": "DataFrame.to_string(formatters=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `formatters`.", "question_id": 3739},
{"snippet": "DataFrame.to_string(float_format=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `float_format`.", "question_id": 3740},
{"snippet": "DataFrame.to_string(sparsify=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `sparsify`.", "question_id": 3741},
{"snippet": "DataFrame.to_string()", "intent": "Render a DataFrame to a console-friendly tabular output .", "question_id": 3742},
{"snippet": "DataFrame.to_string(buf=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `buf`.", "question_id": 3743},
{"snippet": "DataFrame.to_string(columns=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `columns`.", "question_id": 3744},
{"snippet": "DataFrame.to_string(col_space=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `col_space`.", "question_id": 3745},
{"snippet": "DataFrame.to_string(header=True)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `header`.", "question_id": 3746},
{"snippet": "DataFrame.to_string(index=True)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `index`.", "question_id": 3747},
{"snippet": "DataFrame.to_string(na_rep='NaN')", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `na_rep`.", "question_id": 3748},
{"snippet": "DataFrame.to_string(formatters=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `formatters`.", "question_id": 3749},
{"snippet": "DataFrame.to_string(float_format=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `float_format`.", "question_id": 3750},
{"snippet": "DataFrame.to_string(sparsify=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `sparsify`.", "question_id": 3751},
{"snippet": "DataFrame.to_string()", "intent": "Render a DataFrame to a console-friendly tabular output .", "question_id": 3752},
{"snippet": "DataFrame.to_string(buf=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `buf`.", "question_id": 3753},
{"snippet": "DataFrame.to_string(columns=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `columns`.", "question_id": 3754},
{"snippet": "DataFrame.to_string(col_space=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `col_space`.", "question_id": 3755},
{"snippet": "DataFrame.to_string(header=True)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `header`.", "question_id": 3756},
{"snippet": "DataFrame.to_string(index=True)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `index`.", "question_id": 3757},
{"snippet": "DataFrame.to_string(na_rep='NaN')", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `na_rep`.", "question_id": 3758},
{"snippet": "DataFrame.to_string(formatters=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `formatters`.", "question_id": 3759},
{"snippet": "DataFrame.to_string(float_format=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `float_format`.", "question_id": 3760},
{"snippet": "DataFrame.to_string(sparsify=None)", "intent": "Render a DataFrame to a console-friendly tabular output . With arguments `sparsify`.", "question_id": 3761},
{"snippet": "DataFrame.to_timestamp()", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period .", "question_id": 3762},
{"snippet": "DataFrame.to_timestamp(freq=None)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `freq`.", "question_id": 3763},
{"snippet": "DataFrame.to_timestamp(how='start')", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `how`.", "question_id": 3764},
{"snippet": "DataFrame.to_timestamp(axis=0)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `axis`.", "question_id": 3765},
{"snippet": "DataFrame.to_timestamp(copy=True)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `copy`.", "question_id": 3766},
{"snippet": "DataFrame.to_timestamp(freq=None, how='start')", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `freq`, `how`.", "question_id": 3767},
{"snippet": "DataFrame.to_timestamp(freq=None, axis=0)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `freq`, `axis`.", "question_id": 3768},
{"snippet": "DataFrame.to_timestamp(freq=None, copy=True)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `freq`, `copy`.", "question_id": 3769},
{"snippet": "DataFrame.to_timestamp(how='start', axis=0)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `how`, `axis`.", "question_id": 3770},
{"snippet": "DataFrame.to_timestamp(how='start', copy=True)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `how`, `copy`.", "question_id": 3771},
{"snippet": "DataFrame.to_timestamp()", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period .", "question_id": 3772},
{"snippet": "DataFrame.to_timestamp(freq=None)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `freq`.", "question_id": 3773},
{"snippet": "DataFrame.to_timestamp(how='start')", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `how`.", "question_id": 3774},
{"snippet": "DataFrame.to_timestamp(axis=0)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `axis`.", "question_id": 3775},
{"snippet": "DataFrame.to_timestamp(copy=True)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `copy`.", "question_id": 3776},
{"snippet": "DataFrame.to_timestamp(freq=None, how='start')", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `freq`, `how`.", "question_id": 3777},
{"snippet": "DataFrame.to_timestamp(freq=None, axis=0)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `freq`, `axis`.", "question_id": 3778},
{"snippet": "DataFrame.to_timestamp(freq=None, copy=True)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `freq`, `copy`.", "question_id": 3779},
{"snippet": "DataFrame.to_timestamp(how='start', axis=0)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `how`, `axis`.", "question_id": 3780},
{"snippet": "DataFrame.to_timestamp(how='start', copy=True)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `how`, `copy`.", "question_id": 3781},
{"snippet": "DataFrame.to_timestamp()", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period .", "question_id": 3782},
{"snippet": "DataFrame.to_timestamp(freq=None)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `freq`.", "question_id": 3783},
{"snippet": "DataFrame.to_timestamp(how='start')", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `how`.", "question_id": 3784},
{"snippet": "DataFrame.to_timestamp(axis=0)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `axis`.", "question_id": 3785},
{"snippet": "DataFrame.to_timestamp(copy=True)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `copy`.", "question_id": 3786},
{"snippet": "DataFrame.to_timestamp(freq=None, how='start')", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `freq`, `how`.", "question_id": 3787},
{"snippet": "DataFrame.to_timestamp(freq=None, axis=0)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `freq`, `axis`.", "question_id": 3788},
{"snippet": "DataFrame.to_timestamp(freq=None, copy=True)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `freq`, `copy`.", "question_id": 3789},
{"snippet": "DataFrame.to_timestamp(how='start', axis=0)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `how`, `axis`.", "question_id": 3790},
{"snippet": "DataFrame.to_timestamp(how='start', copy=True)", "intent": "Cast to DatetimeIndex of timestamps , at beginning of period . With arguments `how`, `copy`.", "question_id": 3791},
{"snippet": "DataFrame.to_xarray()", "intent": "Return an xarray object from the pandas object .", "question_id": 3792},
{"snippet": "DataFrame.to_xarray()", "intent": "Return an xarray object from the pandas object .", "question_id": 3793},
{"snippet": "DataFrame.to_xarray()", "intent": "Return an xarray object from the pandas object .", "question_id": 3794},
{"snippet": "DataFrame.to_xml()", "intent": "Render a DataFrame to an XML document .", "question_id": 3795},
{"snippet": "DataFrame.to_xml(path_or_buffer=None)", "intent": "Render a DataFrame to an XML document . With arguments `path_or_buffer`.", "question_id": 3796},
{"snippet": "DataFrame.to_xml(index=True)", "intent": "Render a DataFrame to an XML document . With arguments `index`.", "question_id": 3797},
{"snippet": "DataFrame.to_xml(root_name='data')", "intent": "Render a DataFrame to an XML document . With arguments `root_name`.", "question_id": 3798},
{"snippet": "DataFrame.to_xml(row_name='row')", "intent": "Render a DataFrame to an XML document . With arguments `row_name`.", "question_id": 3799},
{"snippet": "DataFrame.to_xml(na_rep=None)", "intent": "Render a DataFrame to an XML document . With arguments `na_rep`.", "question_id": 3800},
{"snippet": "DataFrame.to_xml(attr_cols=None)", "intent": "Render a DataFrame to an XML document . With arguments `attr_cols`.", "question_id": 3801},
{"snippet": "DataFrame.to_xml(elem_cols=None)", "intent": "Render a DataFrame to an XML document . With arguments `elem_cols`.", "question_id": 3802},
{"snippet": "DataFrame.to_xml(namespaces=None)", "intent": "Render a DataFrame to an XML document . With arguments `namespaces`.", "question_id": 3803},
{"snippet": "DataFrame.to_xml(prefix=None)", "intent": "Render a DataFrame to an XML document . With arguments `prefix`.", "question_id": 3804},
{"snippet": "DataFrame.to_xml()", "intent": "Render a DataFrame to an XML document .", "question_id": 3805},
{"snippet": "DataFrame.to_xml(path_or_buffer=None)", "intent": "Render a DataFrame to an XML document . With arguments `path_or_buffer`.", "question_id": 3806},
{"snippet": "DataFrame.to_xml(index=True)", "intent": "Render a DataFrame to an XML document . With arguments `index`.", "question_id": 3807},
{"snippet": "DataFrame.to_xml(root_name='data')", "intent": "Render a DataFrame to an XML document . With arguments `root_name`.", "question_id": 3808},
{"snippet": "DataFrame.to_xml(row_name='row')", "intent": "Render a DataFrame to an XML document . With arguments `row_name`.", "question_id": 3809},
{"snippet": "DataFrame.to_xml(na_rep=None)", "intent": "Render a DataFrame to an XML document . With arguments `na_rep`.", "question_id": 3810},
{"snippet": "DataFrame.to_xml(attr_cols=None)", "intent": "Render a DataFrame to an XML document . With arguments `attr_cols`.", "question_id": 3811},
{"snippet": "DataFrame.to_xml(elem_cols=None)", "intent": "Render a DataFrame to an XML document . With arguments `elem_cols`.", "question_id": 3812},
{"snippet": "DataFrame.to_xml(namespaces=None)", "intent": "Render a DataFrame to an XML document . With arguments `namespaces`.", "question_id": 3813},
{"snippet": "DataFrame.to_xml(prefix=None)", "intent": "Render a DataFrame to an XML document . With arguments `prefix`.", "question_id": 3814},
{"snippet": "DataFrame.to_xml()", "intent": "Render a DataFrame to an XML document .", "question_id": 3815},
{"snippet": "DataFrame.to_xml(path_or_buffer=None)", "intent": "Render a DataFrame to an XML document . With arguments `path_or_buffer`.", "question_id": 3816},
{"snippet": "DataFrame.to_xml(index=True)", "intent": "Render a DataFrame to an XML document . With arguments `index`.", "question_id": 3817},
{"snippet": "DataFrame.to_xml(root_name='data')", "intent": "Render a DataFrame to an XML document . With arguments `root_name`.", "question_id": 3818},
{"snippet": "DataFrame.to_xml(row_name='row')", "intent": "Render a DataFrame to an XML document . With arguments `row_name`.", "question_id": 3819},
{"snippet": "DataFrame.to_xml(na_rep=None)", "intent": "Render a DataFrame to an XML document . With arguments `na_rep`.", "question_id": 3820},
{"snippet": "DataFrame.to_xml(attr_cols=None)", "intent": "Render a DataFrame to an XML document . With arguments `attr_cols`.", "question_id": 3821},
{"snippet": "DataFrame.to_xml(elem_cols=None)", "intent": "Render a DataFrame to an XML document . With arguments `elem_cols`.", "question_id": 3822},
{"snippet": "DataFrame.to_xml(namespaces=None)", "intent": "Render a DataFrame to an XML document . With arguments `namespaces`.", "question_id": 3823},
{"snippet": "DataFrame.to_xml(prefix=None)", "intent": "Render a DataFrame to an XML document . With arguments `prefix`.", "question_id": 3824},
{"snippet": "DataFrame.transform(func, *args, **kwargs)", "intent": "Call `func` on self producing a DataFrame with transformed values . With arguments `*args`, `**kwargs`.", "question_id": 3825},
{"snippet": "DataFrame.transform(func, *args, **kwargs, axis=0)", "intent": "Call `func` on self producing a DataFrame with transformed values . Produced DataFrame will have same `axis` length as self . With arguments `*args`, `**kwargs`.", "question_id": 3826},
{"snippet": "DataFrame.transform(func, *args, **kwargs)", "intent": "Call `func` on self producing a DataFrame with transformed values . With arguments `*args`, `**kwargs`.", "question_id": 3827},
{"snippet": "DataFrame.transform(func, *args, **kwargs, axis=0)", "intent": "Call `func` on self producing a DataFrame with transformed values . Produced DataFrame will have same `axis` length as self . With arguments `*args`, `**kwargs`.", "question_id": 3828},
{"snippet": "DataFrame.transform(func, *args, **kwargs)", "intent": "Call `func` on self producing a DataFrame with transformed values . With arguments `*args`, `**kwargs`.", "question_id": 3829},
{"snippet": "DataFrame.transform(func, *args, **kwargs, axis=0)", "intent": "Call `func` on self producing a DataFrame with transformed values . Produced DataFrame will have same `axis` length as self . With arguments `*args`, `**kwargs`.", "question_id": 3830},
{"snippet": "DataFrame.transpose(*args)", "intent": "Transpose index and columns . With arguments `*args`.", "question_id": 3831},
{"snippet": "DataFrame.transpose(*args, copy=False)", "intent": "Transpose index and columns . In such a case , a `copy` of the data is always made . With arguments `*args`.", "question_id": 3832},
{"snippet": "DataFrame.transpose(*args)", "intent": "Transpose index and columns . With arguments `*args`.", "question_id": 3833},
{"snippet": "DataFrame.transpose(*args, copy=False)", "intent": "Transpose index and columns . In such a case , a `copy` of the data is always made . With arguments `*args`.", "question_id": 3834},
{"snippet": "DataFrame.transpose(*args)", "intent": "Transpose index and columns . With arguments `*args`.", "question_id": 3835},
{"snippet": "DataFrame.transpose(*args, copy=False)", "intent": "Transpose index and columns . In such a case , a `copy` of the data is always made . With arguments `*args`.", "question_id": 3836},
{"snippet": "DataFrame.truediv(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) .", "question_id": 3837},
{"snippet": "DataFrame.truediv(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 3838},
{"snippet": "DataFrame.truediv(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` .", "question_id": 3839},
{"snippet": "DataFrame.truediv(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3840},
{"snippet": "DataFrame.truediv(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 3841},
{"snippet": "DataFrame.truediv(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3842},
{"snippet": "DataFrame.truediv(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3843},
{"snippet": "DataFrame.truediv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3844},
{"snippet": "DataFrame.truediv(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) .", "question_id": 3845},
{"snippet": "DataFrame.truediv(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 3846},
{"snippet": "DataFrame.truediv(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` .", "question_id": 3847},
{"snippet": "DataFrame.truediv(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3848},
{"snippet": "DataFrame.truediv(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 3849},
{"snippet": "DataFrame.truediv(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3850},
{"snippet": "DataFrame.truediv(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3851},
{"snippet": "DataFrame.truediv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3852},
{"snippet": "DataFrame.truediv(other)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) .", "question_id": 3853},
{"snippet": "DataFrame.truediv(other, axis='columns')", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version .", "question_id": 3854},
{"snippet": "DataFrame.truediv(other, level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` .", "question_id": 3855},
{"snippet": "DataFrame.truediv(other, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3856},
{"snippet": "DataFrame.truediv(other, axis='columns', level=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` .", "question_id": 3857},
{"snippet": "DataFrame.truediv(other, axis='columns', fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3858},
{"snippet": "DataFrame.truediv(other, level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3859},
{"snippet": "DataFrame.truediv(other, axis='columns', level=None, fill_value=None)", "intent": "Get Floating division of dataframe and `other` , element-wise ( binary operator truediv ) . Subtract a list and Series by `axis` with operator version . Divide by a MultiIndex by `level` . Equivalent to dataframe / other , but with support to substitute a `fill_value` for missing data in one of the inputs .", "question_id": 3860},
{"snippet": "DataFrame.truncate()", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 3861},
{"snippet": "DataFrame.truncate(before=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 3862},
{"snippet": "DataFrame.truncate(after=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 3863},
{"snippet": "DataFrame.truncate(axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 3864},
{"snippet": "DataFrame.truncate(copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 3865},
{"snippet": "DataFrame.truncate(before=None, after=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 3866},
{"snippet": "DataFrame.truncate(before=None, axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 3867},
{"snippet": "DataFrame.truncate(before=None, copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 3868},
{"snippet": "DataFrame.truncate(after=None, axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 3869},
{"snippet": "DataFrame.truncate(after=None, copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 3870},
{"snippet": "DataFrame.truncate()", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 3871},
{"snippet": "DataFrame.truncate(before=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 3872},
{"snippet": "DataFrame.truncate(after=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 3873},
{"snippet": "DataFrame.truncate(axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 3874},
{"snippet": "DataFrame.truncate(copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 3875},
{"snippet": "DataFrame.truncate(before=None, after=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 3876},
{"snippet": "DataFrame.truncate(before=None, axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 3877},
{"snippet": "DataFrame.truncate(before=None, copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 3878},
{"snippet": "DataFrame.truncate(after=None, axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 3879},
{"snippet": "DataFrame.truncate(after=None, copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 3880},
{"snippet": "DataFrame.truncate()", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 3881},
{"snippet": "DataFrame.truncate(before=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 3882},
{"snippet": "DataFrame.truncate(after=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 3883},
{"snippet": "DataFrame.truncate(axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 3884},
{"snippet": "DataFrame.truncate(copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 3885},
{"snippet": "DataFrame.truncate(before=None, after=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 3886},
{"snippet": "DataFrame.truncate(before=None, axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 3887},
{"snippet": "DataFrame.truncate(before=None, copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 3888},
{"snippet": "DataFrame.truncate(after=None, axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 3889},
{"snippet": "DataFrame.truncate(after=None, copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 3890},
{"snippet": "DataFrame.tshift()", "intent": "Shift the time index , using the index \u2019 s frequency if available .", "question_id": 3891},
{"snippet": "DataFrame.tshift(periods=1)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `periods`.", "question_id": 3892},
{"snippet": "DataFrame.tshift(freq=None)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index .", "question_id": 3893},
{"snippet": "DataFrame.tshift(axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `axis`.", "question_id": 3894},
{"snippet": "DataFrame.tshift(periods=1, freq=None)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `periods`.", "question_id": 3895},
{"snippet": "DataFrame.tshift(periods=1, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `periods`, `axis`.", "question_id": 3896},
{"snippet": "DataFrame.tshift(freq=None, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `axis`.", "question_id": 3897},
{"snippet": "DataFrame.tshift(periods=1, freq=None, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `periods`, `axis`.", "question_id": 3898},
{"snippet": "DataFrame.tshift()", "intent": "Shift the time index , using the index \u2019 s frequency if available .", "question_id": 3899},
{"snippet": "DataFrame.tshift(periods=1)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `periods`.", "question_id": 3900},
{"snippet": "DataFrame.tshift(freq=None)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index .", "question_id": 3901},
{"snippet": "DataFrame.tshift(axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `axis`.", "question_id": 3902},
{"snippet": "DataFrame.tshift(periods=1, freq=None)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `periods`.", "question_id": 3903},
{"snippet": "DataFrame.tshift(periods=1, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `periods`, `axis`.", "question_id": 3904},
{"snippet": "DataFrame.tshift(freq=None, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `axis`.", "question_id": 3905},
{"snippet": "DataFrame.tshift(periods=1, freq=None, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `periods`, `axis`.", "question_id": 3906},
{"snippet": "DataFrame.tshift()", "intent": "Shift the time index , using the index \u2019 s frequency if available .", "question_id": 3907},
{"snippet": "DataFrame.tshift(periods=1)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `periods`.", "question_id": 3908},
{"snippet": "DataFrame.tshift(freq=None)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index .", "question_id": 3909},
{"snippet": "DataFrame.tshift(axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `axis`.", "question_id": 3910},
{"snippet": "DataFrame.tshift(periods=1, freq=None)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `periods`.", "question_id": 3911},
{"snippet": "DataFrame.tshift(periods=1, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `periods`, `axis`.", "question_id": 3912},
{"snippet": "DataFrame.tshift(freq=None, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `axis`.", "question_id": 3913},
{"snippet": "DataFrame.tshift(periods=1, freq=None, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `periods`, `axis`.", "question_id": 3914},
{"snippet": "DataFrame.tz_convert(tz)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`.", "question_id": 3915},
{"snippet": "DataFrame.tz_convert(tz, axis=0)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`.", "question_id": 3916},
{"snippet": "DataFrame.tz_convert(tz, level=None)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`.", "question_id": 3917},
{"snippet": "DataFrame.tz_convert(tz, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `copy`.", "question_id": 3918},
{"snippet": "DataFrame.tz_convert(tz, axis=0, level=None)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`.", "question_id": 3919},
{"snippet": "DataFrame.tz_convert(tz, axis=0, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `copy`.", "question_id": 3920},
{"snippet": "DataFrame.tz_convert(tz, level=None, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`, `copy`.", "question_id": 3921},
{"snippet": "DataFrame.tz_convert(tz, axis=0, level=None, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`, `copy`.", "question_id": 3922},
{"snippet": "DataFrame.tz_convert(tz)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`.", "question_id": 3923},
{"snippet": "DataFrame.tz_convert(tz, axis=0)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`.", "question_id": 3924},
{"snippet": "DataFrame.tz_convert(tz, level=None)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`.", "question_id": 3925},
{"snippet": "DataFrame.tz_convert(tz, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `copy`.", "question_id": 3926},
{"snippet": "DataFrame.tz_convert(tz, axis=0, level=None)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`.", "question_id": 3927},
{"snippet": "DataFrame.tz_convert(tz, axis=0, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `copy`.", "question_id": 3928},
{"snippet": "DataFrame.tz_convert(tz, level=None, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`, `copy`.", "question_id": 3929},
{"snippet": "DataFrame.tz_convert(tz, axis=0, level=None, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`, `copy`.", "question_id": 3930},
{"snippet": "DataFrame.tz_convert(tz)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`.", "question_id": 3931},
{"snippet": "DataFrame.tz_convert(tz, axis=0)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`.", "question_id": 3932},
{"snippet": "DataFrame.tz_convert(tz, level=None)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`.", "question_id": 3933},
{"snippet": "DataFrame.tz_convert(tz, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `copy`.", "question_id": 3934},
{"snippet": "DataFrame.tz_convert(tz, axis=0, level=None)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`.", "question_id": 3935},
{"snippet": "DataFrame.tz_convert(tz, axis=0, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `copy`.", "question_id": 3936},
{"snippet": "DataFrame.tz_convert(tz, level=None, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`, `copy`.", "question_id": 3937},
{"snippet": "DataFrame.tz_convert(tz, axis=0, level=None, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`, `copy`.", "question_id": 3938},
{"snippet": "DataFrame.tz_localize(tz)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`.", "question_id": 3939},
{"snippet": "DataFrame.tz_localize(tz, axis=0)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`.", "question_id": 3940},
{"snippet": "DataFrame.tz_localize(tz, level=None)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `level`.", "question_id": 3941},
{"snippet": "DataFrame.tz_localize(tz, copy=True)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `copy`.", "question_id": 3942},
{"snippet": "DataFrame.tz_localize(tz, ambiguous='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly With arguments `tz`.", "question_id": 3943},
{"snippet": "DataFrame.tz_localize(tz, nonexistent='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . If the DST transition causes `nonexistent` times , you can shift these dates forward or backward with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backward \u2019 . With arguments `tz`.", "question_id": 3944},
{"snippet": "DataFrame.tz_localize(tz, axis=0, level=None)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`, `level`.", "question_id": 3945},
{"snippet": "DataFrame.tz_localize(tz, axis=0, copy=True)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`, `copy`.", "question_id": 3946},
{"snippet": "DataFrame.tz_localize(tz, axis=0, ambiguous='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly With arguments `tz`, `axis`.", "question_id": 3947},
{"snippet": "DataFrame.tz_localize(tz, axis=0, nonexistent='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . If the DST transition causes `nonexistent` times , you can shift these dates forward or backward with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backward \u2019 . With arguments `tz`, `axis`.", "question_id": 3948},
{"snippet": "DataFrame.tz_localize(tz)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`.", "question_id": 3949},
{"snippet": "DataFrame.tz_localize(tz, axis=0)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`.", "question_id": 3950},
{"snippet": "DataFrame.tz_localize(tz, level=None)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `level`.", "question_id": 3951},
{"snippet": "DataFrame.tz_localize(tz, copy=True)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `copy`.", "question_id": 3952},
{"snippet": "DataFrame.tz_localize(tz, ambiguous='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly With arguments `tz`.", "question_id": 3953},
{"snippet": "DataFrame.tz_localize(tz, nonexistent='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . If the DST transition causes `nonexistent` times , you can shift these dates forward or backward with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backward \u2019 . With arguments `tz`.", "question_id": 3954},
{"snippet": "DataFrame.tz_localize(tz, axis=0, level=None)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`, `level`.", "question_id": 3955},
{"snippet": "DataFrame.tz_localize(tz, axis=0, copy=True)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`, `copy`.", "question_id": 3956},
{"snippet": "DataFrame.tz_localize(tz, axis=0, ambiguous='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly With arguments `tz`, `axis`.", "question_id": 3957},
{"snippet": "DataFrame.tz_localize(tz, axis=0, nonexistent='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . If the DST transition causes `nonexistent` times , you can shift these dates forward or backward with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backward \u2019 . With arguments `tz`, `axis`.", "question_id": 3958},
{"snippet": "DataFrame.tz_localize(tz)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`.", "question_id": 3959},
{"snippet": "DataFrame.tz_localize(tz, axis=0)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`.", "question_id": 3960},
{"snippet": "DataFrame.tz_localize(tz, level=None)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `level`.", "question_id": 3961},
{"snippet": "DataFrame.tz_localize(tz, copy=True)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `copy`.", "question_id": 3962},
{"snippet": "DataFrame.tz_localize(tz, ambiguous='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly With arguments `tz`.", "question_id": 3963},
{"snippet": "DataFrame.tz_localize(tz, nonexistent='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . If the DST transition causes `nonexistent` times , you can shift these dates forward or backward with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backward \u2019 . With arguments `tz`.", "question_id": 3964},
{"snippet": "DataFrame.tz_localize(tz, axis=0, level=None)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`, `level`.", "question_id": 3965},
{"snippet": "DataFrame.tz_localize(tz, axis=0, copy=True)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`, `copy`.", "question_id": 3966},
{"snippet": "DataFrame.tz_localize(tz, axis=0, ambiguous='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly With arguments `tz`, `axis`.", "question_id": 3967},
{"snippet": "DataFrame.tz_localize(tz, axis=0, nonexistent='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . If the DST transition causes `nonexistent` times , you can shift these dates forward or backward with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backward \u2019 . With arguments `tz`, `axis`.", "question_id": 3968},
{"snippet": "DataFrame.unstack()", "intent": "Pivot a `level` of the ( necessarily hierarchical ) index labels .", "question_id": 3969},
{"snippet": "DataFrame.unstack(level=- 1)", "intent": "Pivot a `level` of the ( necessarily hierarchical ) index labels .", "question_id": 3970},
{"snippet": "DataFrame.unstack(fill_value=None)", "intent": "Pivot a `level` of the ( necessarily hierarchical ) index labels . With arguments `fill_value`.", "question_id": 3971},
{"snippet": "DataFrame.unstack(level=- 1, fill_value=None)", "intent": "Pivot a `level` of the ( necessarily hierarchical ) index labels . With arguments `fill_value`.", "question_id": 3972},
{"snippet": "DataFrame.unstack()", "intent": "Pivot a `level` of the ( necessarily hierarchical ) index labels .", "question_id": 3973},
{"snippet": "DataFrame.unstack(level=- 1)", "intent": "Pivot a `level` of the ( necessarily hierarchical ) index labels .", "question_id": 3974},
{"snippet": "DataFrame.unstack(fill_value=None)", "intent": "Pivot a `level` of the ( necessarily hierarchical ) index labels . With arguments `fill_value`.", "question_id": 3975},
{"snippet": "DataFrame.unstack(level=- 1, fill_value=None)", "intent": "Pivot a `level` of the ( necessarily hierarchical ) index labels . With arguments `fill_value`.", "question_id": 3976},
{"snippet": "DataFrame.unstack()", "intent": "Pivot a `level` of the ( necessarily hierarchical ) index labels .", "question_id": 3977},
{"snippet": "DataFrame.unstack(level=- 1)", "intent": "Pivot a `level` of the ( necessarily hierarchical ) index labels .", "question_id": 3978},
{"snippet": "DataFrame.unstack(fill_value=None)", "intent": "Pivot a `level` of the ( necessarily hierarchical ) index labels . With arguments `fill_value`.", "question_id": 3979},
{"snippet": "DataFrame.unstack(level=- 1, fill_value=None)", "intent": "Pivot a `level` of the ( necessarily hierarchical ) index labels . With arguments `fill_value`.", "question_id": 3980},
{"snippet": "DataFrame.update(other)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe .", "question_id": 3981},
{"snippet": "DataFrame.update(other, join='left')", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `join`.", "question_id": 3982},
{"snippet": "DataFrame.update(other, overwrite=True)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `overwrite`.", "question_id": 3983},
{"snippet": "DataFrame.update(other, filter_func=None)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `filter_func`.", "question_id": 3984},
{"snippet": "DataFrame.update(other, errors='ignore')", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `errors`.", "question_id": 3985},
{"snippet": "DataFrame.update(other, join='left', overwrite=True)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `join`, `overwrite`.", "question_id": 3986},
{"snippet": "DataFrame.update(other, join='left', filter_func=None)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `join`, `filter_func`.", "question_id": 3987},
{"snippet": "DataFrame.update(other, join='left', errors='ignore')", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `join`, `errors`.", "question_id": 3988},
{"snippet": "DataFrame.update(other, overwrite=True, filter_func=None)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `overwrite`, `filter_func`.", "question_id": 3989},
{"snippet": "DataFrame.update(other, overwrite=True, errors='ignore')", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `overwrite`, `errors`.", "question_id": 3990},
{"snippet": "DataFrame.update(other)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe .", "question_id": 3991},
{"snippet": "DataFrame.update(other, join='left')", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `join`.", "question_id": 3992},
{"snippet": "DataFrame.update(other, overwrite=True)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `overwrite`.", "question_id": 3993},
{"snippet": "DataFrame.update(other, filter_func=None)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `filter_func`.", "question_id": 3994},
{"snippet": "DataFrame.update(other, errors='ignore')", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `errors`.", "question_id": 3995},
{"snippet": "DataFrame.update(other, join='left', overwrite=True)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `join`, `overwrite`.", "question_id": 3996},
{"snippet": "DataFrame.update(other, join='left', filter_func=None)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `join`, `filter_func`.", "question_id": 3997},
{"snippet": "DataFrame.update(other, join='left', errors='ignore')", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `join`, `errors`.", "question_id": 3998},
{"snippet": "DataFrame.update(other, overwrite=True, filter_func=None)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `overwrite`, `filter_func`.", "question_id": 3999},
{"snippet": "DataFrame.update(other, overwrite=True, errors='ignore')", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `overwrite`, `errors`.", "question_id": 4000},
{"snippet": "DataFrame.update(other)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe .", "question_id": 4001},
{"snippet": "DataFrame.update(other, join='left')", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `join`.", "question_id": 4002},
{"snippet": "DataFrame.update(other, overwrite=True)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `overwrite`.", "question_id": 4003},
{"snippet": "DataFrame.update(other, filter_func=None)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `filter_func`.", "question_id": 4004},
{"snippet": "DataFrame.update(other, errors='ignore')", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `errors`.", "question_id": 4005},
{"snippet": "DataFrame.update(other, join='left', overwrite=True)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `join`, `overwrite`.", "question_id": 4006},
{"snippet": "DataFrame.update(other, join='left', filter_func=None)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `join`, `filter_func`.", "question_id": 4007},
{"snippet": "DataFrame.update(other, join='left', errors='ignore')", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `join`, `errors`.", "question_id": 4008},
{"snippet": "DataFrame.update(other, overwrite=True, filter_func=None)", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `overwrite`, `filter_func`.", "question_id": 4009},
{"snippet": "DataFrame.update(other, overwrite=True, errors='ignore')", "intent": "Modify in place using non-NA values from another DataFrame . If `other` contains NaNs the corresponding values are not updated in the original dataframe . With arguments `overwrite`, `errors`.", "question_id": 4010},
{"snippet": "DataFrame.value_counts()", "intent": "Return a Series containing counts of unique rows in the DataFrame .", "question_id": 4011},
{"snippet": "DataFrame.value_counts(subset=None)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `subset`.", "question_id": 4012},
{"snippet": "DataFrame.value_counts(normalize=False)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `normalize`.", "question_id": 4013},
{"snippet": "DataFrame.value_counts(sort=True)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `sort`.", "question_id": 4014},
{"snippet": "DataFrame.value_counts(ascending=False)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `ascending`.", "question_id": 4015},
{"snippet": "DataFrame.value_counts(dropna=True)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With `dropna` set to False we can also count rows with NA values .", "question_id": 4016},
{"snippet": "DataFrame.value_counts(subset=None, normalize=False)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `subset`, `normalize`.", "question_id": 4017},
{"snippet": "DataFrame.value_counts(subset=None, sort=True)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `subset`, `sort`.", "question_id": 4018},
{"snippet": "DataFrame.value_counts(subset=None, ascending=False)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `subset`, `ascending`.", "question_id": 4019},
{"snippet": "DataFrame.value_counts(subset=None, dropna=True)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With `dropna` set to False we can also count rows with NA values . With arguments `subset`.", "question_id": 4020},
{"snippet": "DataFrame.value_counts()", "intent": "Return a Series containing counts of unique rows in the DataFrame .", "question_id": 4021},
{"snippet": "DataFrame.value_counts(subset=None)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `subset`.", "question_id": 4022},
{"snippet": "DataFrame.value_counts(normalize=False)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `normalize`.", "question_id": 4023},
{"snippet": "DataFrame.value_counts(sort=True)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `sort`.", "question_id": 4024},
{"snippet": "DataFrame.value_counts(ascending=False)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `ascending`.", "question_id": 4025},
{"snippet": "DataFrame.value_counts(dropna=True)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With `dropna` set to False we can also count rows with NA values .", "question_id": 4026},
{"snippet": "DataFrame.value_counts(subset=None, normalize=False)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `subset`, `normalize`.", "question_id": 4027},
{"snippet": "DataFrame.value_counts(subset=None, sort=True)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `subset`, `sort`.", "question_id": 4028},
{"snippet": "DataFrame.value_counts(subset=None, ascending=False)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `subset`, `ascending`.", "question_id": 4029},
{"snippet": "DataFrame.value_counts(subset=None, dropna=True)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With `dropna` set to False we can also count rows with NA values . With arguments `subset`.", "question_id": 4030},
{"snippet": "DataFrame.value_counts()", "intent": "Return a Series containing counts of unique rows in the DataFrame .", "question_id": 4031},
{"snippet": "DataFrame.value_counts(subset=None)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `subset`.", "question_id": 4032},
{"snippet": "DataFrame.value_counts(normalize=False)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `normalize`.", "question_id": 4033},
{"snippet": "DataFrame.value_counts(sort=True)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `sort`.", "question_id": 4034},
{"snippet": "DataFrame.value_counts(ascending=False)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `ascending`.", "question_id": 4035},
{"snippet": "DataFrame.value_counts(dropna=True)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With `dropna` set to False we can also count rows with NA values .", "question_id": 4036},
{"snippet": "DataFrame.value_counts(subset=None, normalize=False)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `subset`, `normalize`.", "question_id": 4037},
{"snippet": "DataFrame.value_counts(subset=None, sort=True)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `subset`, `sort`.", "question_id": 4038},
{"snippet": "DataFrame.value_counts(subset=None, ascending=False)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With arguments `subset`, `ascending`.", "question_id": 4039},
{"snippet": "DataFrame.value_counts(subset=None, dropna=True)", "intent": "Return a Series containing counts of unique rows in the DataFrame . With `dropna` set to False we can also count rows with NA values . With arguments `subset`.", "question_id": 4040},
{"snippet": "DataFrame.var(**kwargs)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`.", "question_id": 4041},
{"snippet": "DataFrame.var(**kwargs, axis=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`.", "question_id": 4042},
{"snippet": "DataFrame.var(**kwargs, skipna=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 4043},
{"snippet": "DataFrame.var(**kwargs, level=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 4044},
{"snippet": "DataFrame.var(**kwargs, ddof=1)", "intent": "Return unbiased variance over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 4045},
{"snippet": "DataFrame.var(**kwargs, numeric_only=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 4046},
{"snippet": "DataFrame.var(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 4047},
{"snippet": "DataFrame.var(**kwargs, axis=None, level=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 4048},
{"snippet": "DataFrame.var(**kwargs, axis=None, ddof=1)", "intent": "Return unbiased variance over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 4049},
{"snippet": "DataFrame.var(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 4050},
{"snippet": "DataFrame.var(**kwargs)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`.", "question_id": 4051},
{"snippet": "DataFrame.var(**kwargs, axis=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`.", "question_id": 4052},
{"snippet": "DataFrame.var(**kwargs, skipna=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 4053},
{"snippet": "DataFrame.var(**kwargs, level=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 4054},
{"snippet": "DataFrame.var(**kwargs, ddof=1)", "intent": "Return unbiased variance over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 4055},
{"snippet": "DataFrame.var(**kwargs, numeric_only=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 4056},
{"snippet": "DataFrame.var(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 4057},
{"snippet": "DataFrame.var(**kwargs, axis=None, level=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 4058},
{"snippet": "DataFrame.var(**kwargs, axis=None, ddof=1)", "intent": "Return unbiased variance over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 4059},
{"snippet": "DataFrame.var(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 4060},
{"snippet": "DataFrame.var(**kwargs)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`.", "question_id": 4061},
{"snippet": "DataFrame.var(**kwargs, axis=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`.", "question_id": 4062},
{"snippet": "DataFrame.var(**kwargs, skipna=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 4063},
{"snippet": "DataFrame.var(**kwargs, level=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 4064},
{"snippet": "DataFrame.var(**kwargs, ddof=1)", "intent": "Return unbiased variance over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 4065},
{"snippet": "DataFrame.var(**kwargs, numeric_only=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 4066},
{"snippet": "DataFrame.var(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 4067},
{"snippet": "DataFrame.var(**kwargs, axis=None, level=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 4068},
{"snippet": "DataFrame.var(**kwargs, axis=None, ddof=1)", "intent": "Return unbiased variance over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 4069},
{"snippet": "DataFrame.var(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 4070},
{"snippet": "DataFrame.where(cond)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 4071},
{"snippet": "DataFrame.where(cond, other=nan)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 4072},
{"snippet": "DataFrame.where(cond, inplace=False)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 4073},
{"snippet": "DataFrame.where(cond, axis=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 4074},
{"snippet": "DataFrame.where(cond, level=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 4075},
{"snippet": "DataFrame.where(cond, errors='raise')", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `errors`.", "question_id": 4076},
{"snippet": "DataFrame.where(cond, try_cast=NoDefault.no_default)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `try_cast`.", "question_id": 4077},
{"snippet": "DataFrame.where(cond, other=nan, inplace=False)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 4078},
{"snippet": "DataFrame.where(cond, other=nan, axis=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 4079},
{"snippet": "DataFrame.where(cond, other=nan, level=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 4080},
{"snippet": "DataFrame.where(cond)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 4081},
{"snippet": "DataFrame.where(cond, other=nan)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 4082},
{"snippet": "DataFrame.where(cond, inplace=False)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 4083},
{"snippet": "DataFrame.where(cond, axis=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 4084},
{"snippet": "DataFrame.where(cond, level=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 4085},
{"snippet": "DataFrame.where(cond, errors='raise')", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `errors`.", "question_id": 4086},
{"snippet": "DataFrame.where(cond, try_cast=NoDefault.no_default)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `try_cast`.", "question_id": 4087},
{"snippet": "DataFrame.where(cond, other=nan, inplace=False)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 4088},
{"snippet": "DataFrame.where(cond, other=nan, axis=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 4089},
{"snippet": "DataFrame.where(cond, other=nan, level=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 4090},
{"snippet": "DataFrame.where(cond)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 4091},
{"snippet": "DataFrame.where(cond, other=nan)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 4092},
{"snippet": "DataFrame.where(cond, inplace=False)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 4093},
{"snippet": "DataFrame.where(cond, axis=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 4094},
{"snippet": "DataFrame.where(cond, level=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 4095},
{"snippet": "DataFrame.where(cond, errors='raise')", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `errors`.", "question_id": 4096},
{"snippet": "DataFrame.where(cond, try_cast=NoDefault.no_default)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `try_cast`.", "question_id": 4097},
{"snippet": "DataFrame.where(cond, other=nan, inplace=False)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 4098},
{"snippet": "DataFrame.where(cond, other=nan, axis=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 4099},
{"snippet": "DataFrame.where(cond, other=nan, level=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 4100},
{"snippet": "DataFrame.xs(key)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex .", "question_id": 4101},
{"snippet": "DataFrame.xs(key, axis=0)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis`", "question_id": 4102},
{"snippet": "DataFrame.xs(key, level=None)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex .", "question_id": 4103},
{"snippet": "DataFrame.xs(key, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . With arguments `drop_level`.", "question_id": 4104},
{"snippet": "DataFrame.xs(key, axis=0, level=None)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis`", "question_id": 4105},
{"snippet": "DataFrame.xs(key, axis=0, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis` With arguments `drop_level`.", "question_id": 4106},
{"snippet": "DataFrame.xs(key, level=None, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . With arguments `drop_level`.", "question_id": 4107},
{"snippet": "DataFrame.xs(key, axis=0, level=None, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis` With arguments `drop_level`.", "question_id": 4108},
{"snippet": "DataFrame.xs(key)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex .", "question_id": 4109},
{"snippet": "DataFrame.xs(key, axis=0)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis`", "question_id": 4110},
{"snippet": "DataFrame.xs(key, level=None)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex .", "question_id": 4111},
{"snippet": "DataFrame.xs(key, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . With arguments `drop_level`.", "question_id": 4112},
{"snippet": "DataFrame.xs(key, axis=0, level=None)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis`", "question_id": 4113},
{"snippet": "DataFrame.xs(key, axis=0, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis` With arguments `drop_level`.", "question_id": 4114},
{"snippet": "DataFrame.xs(key, level=None, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . With arguments `drop_level`.", "question_id": 4115},
{"snippet": "DataFrame.xs(key, axis=0, level=None, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis` With arguments `drop_level`.", "question_id": 4116},
{"snippet": "DataFrame.xs(key)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex .", "question_id": 4117},
{"snippet": "DataFrame.xs(key, axis=0)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis`", "question_id": 4118},
{"snippet": "DataFrame.xs(key, level=None)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex .", "question_id": 4119},
{"snippet": "DataFrame.xs(key, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . With arguments `drop_level`.", "question_id": 4120},
{"snippet": "DataFrame.xs(key, axis=0, level=None)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis`", "question_id": 4121},
{"snippet": "DataFrame.xs(key, axis=0, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis` With arguments `drop_level`.", "question_id": 4122},
{"snippet": "DataFrame.xs(key, level=None, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . With arguments `drop_level`.", "question_id": 4123},
{"snippet": "DataFrame.xs(key, axis=0, level=None, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis` With arguments `drop_level`.", "question_id": 4124},
{"snippet": "DatetimeIndex.ceil(*args, **kwargs)", "intent": "Perform ceil operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 4125},
{"snippet": "DatetimeIndex.ceil(*args, **kwargs)", "intent": "Perform ceil operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 4126},
{"snippet": "DatetimeIndex.ceil(*args, **kwargs)", "intent": "Perform ceil operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 4127},
{"snippet": "DatetimeIndex.day_name(*args, **kwargs)", "intent": "Return the day names of the DateTimeIndex with specified locale . With arguments `*args`, `**kwargs`.", "question_id": 4128},
{"snippet": "DatetimeIndex.day_name(*args, **kwargs)", "intent": "Return the day names of the DateTimeIndex with specified locale . With arguments `*args`, `**kwargs`.", "question_id": 4129},
{"snippet": "DatetimeIndex.day_name(*args, **kwargs)", "intent": "Return the day names of the DateTimeIndex with specified locale . With arguments `*args`, `**kwargs`.", "question_id": 4130},
{"snippet": "DatetimeIndex.floor(*args, **kwargs)", "intent": "Perform floor operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 4131},
{"snippet": "DatetimeIndex.floor(*args, **kwargs)", "intent": "Perform floor operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 4132},
{"snippet": "DatetimeIndex.floor(*args, **kwargs)", "intent": "Perform floor operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 4133},
{"snippet": "pandas.DatetimeIndex()", "intent": "Immutable ndarray-like of datetime64 `data` .", "question_id": 4134},
{"snippet": "pandas.DatetimeIndex(data=None)", "intent": "Immutable ndarray-like of datetime64 `data` .", "question_id": 4135},
{"snippet": "pandas.DatetimeIndex(freq=NoDefault.no_default)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `freq`.", "question_id": 4136},
{"snippet": "pandas.DatetimeIndex(tz=None)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `tz`.", "question_id": 4137},
{"snippet": "pandas.DatetimeIndex(normalize=False)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `normalize`.", "question_id": 4138},
{"snippet": "pandas.DatetimeIndex(closed=None)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `closed`.", "question_id": 4139},
{"snippet": "pandas.DatetimeIndex(ambiguous='raise')", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `ambiguous`.", "question_id": 4140},
{"snippet": "pandas.DatetimeIndex(dayfirst=False)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `dayfirst`.", "question_id": 4141},
{"snippet": "pandas.DatetimeIndex(yearfirst=False)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `yearfirst`.", "question_id": 4142},
{"snippet": "pandas.DatetimeIndex(dtype=None)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `dtype`.", "question_id": 4143},
{"snippet": "pandas.DatetimeIndex()", "intent": "Immutable ndarray-like of datetime64 `data` .", "question_id": 4144},
{"snippet": "pandas.DatetimeIndex(data=None)", "intent": "Immutable ndarray-like of datetime64 `data` .", "question_id": 4145},
{"snippet": "pandas.DatetimeIndex(freq=NoDefault.no_default)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `freq`.", "question_id": 4146},
{"snippet": "pandas.DatetimeIndex(tz=None)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `tz`.", "question_id": 4147},
{"snippet": "pandas.DatetimeIndex(normalize=False)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `normalize`.", "question_id": 4148},
{"snippet": "pandas.DatetimeIndex(closed=None)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `closed`.", "question_id": 4149},
{"snippet": "pandas.DatetimeIndex(ambiguous='raise')", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `ambiguous`.", "question_id": 4150},
{"snippet": "pandas.DatetimeIndex(dayfirst=False)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `dayfirst`.", "question_id": 4151},
{"snippet": "pandas.DatetimeIndex(yearfirst=False)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `yearfirst`.", "question_id": 4152},
{"snippet": "pandas.DatetimeIndex(dtype=None)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `dtype`.", "question_id": 4153},
{"snippet": "pandas.DatetimeIndex()", "intent": "Immutable ndarray-like of datetime64 `data` .", "question_id": 4154},
{"snippet": "pandas.DatetimeIndex(data=None)", "intent": "Immutable ndarray-like of datetime64 `data` .", "question_id": 4155},
{"snippet": "pandas.DatetimeIndex(freq=NoDefault.no_default)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `freq`.", "question_id": 4156},
{"snippet": "pandas.DatetimeIndex(tz=None)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `tz`.", "question_id": 4157},
{"snippet": "pandas.DatetimeIndex(normalize=False)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `normalize`.", "question_id": 4158},
{"snippet": "pandas.DatetimeIndex(closed=None)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `closed`.", "question_id": 4159},
{"snippet": "pandas.DatetimeIndex(ambiguous='raise')", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `ambiguous`.", "question_id": 4160},
{"snippet": "pandas.DatetimeIndex(dayfirst=False)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `dayfirst`.", "question_id": 4161},
{"snippet": "pandas.DatetimeIndex(yearfirst=False)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `yearfirst`.", "question_id": 4162},
{"snippet": "pandas.DatetimeIndex(dtype=None)", "intent": "Immutable ndarray-like of datetime64 `data` . With arguments `dtype`.", "question_id": 4163},
{"snippet": "DatetimeIndex.indexer_at_time(time)", "intent": "Return index locations of values at particular `time` of day ( e.g .", "question_id": 4164},
{"snippet": "DatetimeIndex.indexer_at_time(time, asof=False)", "intent": "Return index locations of values at particular `time` of day ( e.g . With arguments `asof`.", "question_id": 4165},
{"snippet": "DatetimeIndex.indexer_at_time(time)", "intent": "Return index locations of values at particular `time` of day ( e.g .", "question_id": 4166},
{"snippet": "DatetimeIndex.indexer_at_time(time, asof=False)", "intent": "Return index locations of values at particular `time` of day ( e.g . With arguments `asof`.", "question_id": 4167},
{"snippet": "DatetimeIndex.indexer_at_time(time)", "intent": "Return index locations of values at particular `time` of day ( e.g .", "question_id": 4168},
{"snippet": "DatetimeIndex.indexer_at_time(time, asof=False)", "intent": "Return index locations of values at particular `time` of day ( e.g . With arguments `asof`.", "question_id": 4169},
{"snippet": "DatetimeIndex.indexer_between_time(start_time, end_time)", "intent": "Return index locations of values between particular times of day ( e.g. , 9:00-9:30AM ) . With arguments `start_time`, `end_time`.", "question_id": 4170},
{"snippet": "DatetimeIndex.indexer_between_time(start_time, end_time, include_start=True)", "intent": "Return index locations of values between particular times of day ( e.g. , 9:00-9:30AM ) . With arguments `start_time`, `end_time`, `include_start`.", "question_id": 4171},
{"snippet": "DatetimeIndex.indexer_between_time(start_time, end_time, include_end=True)", "intent": "Return index locations of values between particular times of day ( e.g. , 9:00-9:30AM ) . With arguments `start_time`, `end_time`, `include_end`.", "question_id": 4172},
{"snippet": "DatetimeIndex.indexer_between_time(start_time, end_time, include_start=True, include_end=True)", "intent": "Return index locations of values between particular times of day ( e.g. , 9:00-9:30AM ) . With arguments `start_time`, `end_time`, `include_start`, `include_end`.", "question_id": 4173},
{"snippet": "DatetimeIndex.indexer_between_time(start_time, end_time)", "intent": "Return index locations of values between particular times of day ( e.g. , 9:00-9:30AM ) . With arguments `start_time`, `end_time`.", "question_id": 4174},
{"snippet": "DatetimeIndex.indexer_between_time(start_time, end_time, include_start=True)", "intent": "Return index locations of values between particular times of day ( e.g. , 9:00-9:30AM ) . With arguments `start_time`, `end_time`, `include_start`.", "question_id": 4175},
{"snippet": "DatetimeIndex.indexer_between_time(start_time, end_time, include_end=True)", "intent": "Return index locations of values between particular times of day ( e.g. , 9:00-9:30AM ) . With arguments `start_time`, `end_time`, `include_end`.", "question_id": 4176},
{"snippet": "DatetimeIndex.indexer_between_time(start_time, end_time, include_start=True, include_end=True)", "intent": "Return index locations of values between particular times of day ( e.g. , 9:00-9:30AM ) . With arguments `start_time`, `end_time`, `include_start`, `include_end`.", "question_id": 4177},
{"snippet": "DatetimeIndex.indexer_between_time(start_time, end_time)", "intent": "Return index locations of values between particular times of day ( e.g. , 9:00-9:30AM ) . With arguments `start_time`, `end_time`.", "question_id": 4178},
{"snippet": "DatetimeIndex.indexer_between_time(start_time, end_time, include_start=True)", "intent": "Return index locations of values between particular times of day ( e.g. , 9:00-9:30AM ) . With arguments `start_time`, `end_time`, `include_start`.", "question_id": 4179},
{"snippet": "DatetimeIndex.indexer_between_time(start_time, end_time, include_end=True)", "intent": "Return index locations of values between particular times of day ( e.g. , 9:00-9:30AM ) . With arguments `start_time`, `end_time`, `include_end`.", "question_id": 4180},
{"snippet": "DatetimeIndex.indexer_between_time(start_time, end_time, include_start=True, include_end=True)", "intent": "Return index locations of values between particular times of day ( e.g. , 9:00-9:30AM ) . With arguments `start_time`, `end_time`, `include_start`, `include_end`.", "question_id": 4181},
{"snippet": "DatetimeIndex.inferred_freq", "intent": "Tries to return a string representing a frequency guess, generated by infer_freq.", "question_id": 4182},
{"snippet": "DatetimeIndex.inferred_freq", "intent": "Tries to return a string representing a frequency guess, generated by infer_freq.", "question_id": 4183},
{"snippet": "DatetimeIndex.inferred_freq", "intent": "Tries to return a string representing a frequency guess, generated by infer_freq.", "question_id": 4184},
{"snippet": "DatetimeIndex.mean(*args, **kwargs)", "intent": "Return the mean value of the Array . With arguments `*args`, `**kwargs`.", "question_id": 4185},
{"snippet": "DatetimeIndex.mean(*args, **kwargs)", "intent": "Return the mean value of the Array . With arguments `*args`, `**kwargs`.", "question_id": 4186},
{"snippet": "DatetimeIndex.mean(*args, **kwargs)", "intent": "Return the mean value of the Array . With arguments `*args`, `**kwargs`.", "question_id": 4187},
{"snippet": "DatetimeIndex.month_name(*args, **kwargs)", "intent": "Return the month names of the DateTimeIndex with specified locale . With arguments `*args`, `**kwargs`.", "question_id": 4188},
{"snippet": "DatetimeIndex.month_name(*args, **kwargs)", "intent": "Return the month names of the DateTimeIndex with specified locale . With arguments `*args`, `**kwargs`.", "question_id": 4189},
{"snippet": "DatetimeIndex.month_name(*args, **kwargs)", "intent": "Return the month names of the DateTimeIndex with specified locale . With arguments `*args`, `**kwargs`.", "question_id": 4190},
{"snippet": "DatetimeIndex.normalize(*args, **kwargs)", "intent": "Convert times to midnight . With arguments `*args`, `**kwargs`.", "question_id": 4191},
{"snippet": "DatetimeIndex.normalize(*args, **kwargs)", "intent": "Convert times to midnight . With arguments `*args`, `**kwargs`.", "question_id": 4192},
{"snippet": "DatetimeIndex.normalize(*args, **kwargs)", "intent": "Convert times to midnight . With arguments `*args`, `**kwargs`.", "question_id": 4193},
{"snippet": "DatetimeIndex.round(*args, **kwargs)", "intent": "Perform round operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 4194},
{"snippet": "DatetimeIndex.round(*args, **kwargs)", "intent": "Perform round operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 4195},
{"snippet": "DatetimeIndex.round(*args, **kwargs)", "intent": "Perform round operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 4196},
{"snippet": "DatetimeIndex.snap()", "intent": "Snap time stamps to nearest occurring frequency .", "question_id": 4197},
{"snippet": "DatetimeIndex.snap(freq='S')", "intent": "Snap time stamps to nearest occurring frequency . With arguments `freq`.", "question_id": 4198},
{"snippet": "DatetimeIndex.snap()", "intent": "Snap time stamps to nearest occurring frequency .", "question_id": 4199},
{"snippet": "DatetimeIndex.snap(freq='S')", "intent": "Snap time stamps to nearest occurring frequency . With arguments `freq`.", "question_id": 4200},
{"snippet": "DatetimeIndex.snap()", "intent": "Snap time stamps to nearest occurring frequency .", "question_id": 4201},
{"snippet": "DatetimeIndex.snap(freq='S')", "intent": "Snap time stamps to nearest occurring frequency . With arguments `freq`.", "question_id": 4202},
{"snippet": "DatetimeIndex.strftime(*args, **kwargs)", "intent": "Convert to Index using specified date_format . With arguments `*args`, `**kwargs`.", "question_id": 4203},
{"snippet": "DatetimeIndex.strftime(*args, **kwargs)", "intent": "Convert to Index using specified date_format . With arguments `*args`, `**kwargs`.", "question_id": 4204},
{"snippet": "DatetimeIndex.strftime(*args, **kwargs)", "intent": "Convert to Index using specified date_format . With arguments `*args`, `**kwargs`.", "question_id": 4205},
{"snippet": "DatetimeIndex.to_frame()", "intent": "Create a DataFrame with a column containing the Index .", "question_id": 4206},
{"snippet": "DatetimeIndex.to_frame(index=True)", "intent": "Create a DataFrame with a column containing the Index . With arguments `index`.", "question_id": 4207},
{"snippet": "DatetimeIndex.to_frame(name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name :", "question_id": 4208},
{"snippet": "DatetimeIndex.to_frame(index=True, name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name : With arguments `index`.", "question_id": 4209},
{"snippet": "DatetimeIndex.to_frame()", "intent": "Create a DataFrame with a column containing the Index .", "question_id": 4210},
{"snippet": "DatetimeIndex.to_frame(index=True)", "intent": "Create a DataFrame with a column containing the Index . With arguments `index`.", "question_id": 4211},
{"snippet": "DatetimeIndex.to_frame(name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name :", "question_id": 4212},
{"snippet": "DatetimeIndex.to_frame(index=True, name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name : With arguments `index`.", "question_id": 4213},
{"snippet": "DatetimeIndex.to_frame()", "intent": "Create a DataFrame with a column containing the Index .", "question_id": 4214},
{"snippet": "DatetimeIndex.to_frame(index=True)", "intent": "Create a DataFrame with a column containing the Index . With arguments `index`.", "question_id": 4215},
{"snippet": "DatetimeIndex.to_frame(name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name :", "question_id": 4216},
{"snippet": "DatetimeIndex.to_frame(index=True, name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name : With arguments `index`.", "question_id": 4217},
{"snippet": "DatetimeIndex.to_period(*args, **kwargs)", "intent": "Cast to PeriodArray/Index at a particular frequency . With arguments `*args`, `**kwargs`.", "question_id": 4218},
{"snippet": "DatetimeIndex.to_period(*args, **kwargs)", "intent": "Cast to PeriodArray/Index at a particular frequency . With arguments `*args`, `**kwargs`.", "question_id": 4219},
{"snippet": "DatetimeIndex.to_period(*args, **kwargs)", "intent": "Cast to PeriodArray/Index at a particular frequency . With arguments `*args`, `**kwargs`.", "question_id": 4220},
{"snippet": "DatetimeIndex.to_perioddelta(freq)", "intent": "Calculate TimedeltaArray of difference between index values and index converted to PeriodArray at specified `freq` .", "question_id": 4221},
{"snippet": "DatetimeIndex.to_perioddelta(freq)", "intent": "Calculate TimedeltaArray of difference between index values and index converted to PeriodArray at specified `freq` .", "question_id": 4222},
{"snippet": "DatetimeIndex.to_perioddelta(freq)", "intent": "Calculate TimedeltaArray of difference between index values and index converted to PeriodArray at specified `freq` .", "question_id": 4223},
{"snippet": "DatetimeIndex.to_pydatetime(*args, **kwargs)", "intent": "Return Datetime Array/Index as object ndarray of datetime.datetime objects . With arguments `*args`, `**kwargs`.", "question_id": 4224},
{"snippet": "DatetimeIndex.to_pydatetime(*args, **kwargs)", "intent": "Return Datetime Array/Index as object ndarray of datetime.datetime objects . With arguments `*args`, `**kwargs`.", "question_id": 4225},
{"snippet": "DatetimeIndex.to_pydatetime(*args, **kwargs)", "intent": "Return Datetime Array/Index as object ndarray of datetime.datetime objects . With arguments `*args`, `**kwargs`.", "question_id": 4226},
{"snippet": "DatetimeIndex.to_series()", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index .", "question_id": 4227},
{"snippet": "DatetimeIndex.to_series(keep_tz=NoDefault.no_default)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `keep_tz`.", "question_id": 4228},
{"snippet": "DatetimeIndex.to_series(index=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index .", "question_id": 4229},
{"snippet": "DatetimeIndex.to_series(name=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `name`.", "question_id": 4230},
{"snippet": "DatetimeIndex.to_series(keep_tz=NoDefault.no_default, index=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `keep_tz`.", "question_id": 4231},
{"snippet": "DatetimeIndex.to_series(keep_tz=NoDefault.no_default, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `keep_tz`, `name`.", "question_id": 4232},
{"snippet": "DatetimeIndex.to_series(index=None, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `name`.", "question_id": 4233},
{"snippet": "DatetimeIndex.to_series(keep_tz=NoDefault.no_default, index=None, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `keep_tz`, `name`.", "question_id": 4234},
{"snippet": "DatetimeIndex.to_series()", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index .", "question_id": 4235},
{"snippet": "DatetimeIndex.to_series(keep_tz=NoDefault.no_default)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `keep_tz`.", "question_id": 4236},
{"snippet": "DatetimeIndex.to_series(index=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index .", "question_id": 4237},
{"snippet": "DatetimeIndex.to_series(name=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `name`.", "question_id": 4238},
{"snippet": "DatetimeIndex.to_series(keep_tz=NoDefault.no_default, index=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `keep_tz`.", "question_id": 4239},
{"snippet": "DatetimeIndex.to_series(keep_tz=NoDefault.no_default, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `keep_tz`, `name`.", "question_id": 4240},
{"snippet": "DatetimeIndex.to_series(index=None, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `name`.", "question_id": 4241},
{"snippet": "DatetimeIndex.to_series(keep_tz=NoDefault.no_default, index=None, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `keep_tz`, `name`.", "question_id": 4242},
{"snippet": "DatetimeIndex.to_series()", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index .", "question_id": 4243},
{"snippet": "DatetimeIndex.to_series(keep_tz=NoDefault.no_default)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `keep_tz`.", "question_id": 4244},
{"snippet": "DatetimeIndex.to_series(index=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index .", "question_id": 4245},
{"snippet": "DatetimeIndex.to_series(name=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `name`.", "question_id": 4246},
{"snippet": "DatetimeIndex.to_series(keep_tz=NoDefault.no_default, index=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `keep_tz`.", "question_id": 4247},
{"snippet": "DatetimeIndex.to_series(keep_tz=NoDefault.no_default, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `keep_tz`, `name`.", "question_id": 4248},
{"snippet": "DatetimeIndex.to_series(index=None, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `name`.", "question_id": 4249},
{"snippet": "DatetimeIndex.to_series(keep_tz=NoDefault.no_default, index=None, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys useful with map for returning an indexer based on an index . With arguments `keep_tz`, `name`.", "question_id": 4250},
{"snippet": "DatetimeIndex.tz_convert(tz)", "intent": "Convert tz-aware Datetime Array/Index from one time zone to another . With the `tz` parameter , we can change the DatetimeIndex to other time zones :", "question_id": 4251},
{"snippet": "DatetimeIndex.tz_convert(tz)", "intent": "Convert tz-aware Datetime Array/Index from one time zone to another . With the `tz` parameter , we can change the DatetimeIndex to other time zones :", "question_id": 4252},
{"snippet": "DatetimeIndex.tz_convert(tz)", "intent": "Convert tz-aware Datetime Array/Index from one time zone to another . With the `tz` parameter , we can change the DatetimeIndex to other time zones :", "question_id": 4253},
{"snippet": "DatetimeIndex.tz_localize(tz)", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . This method takes a time zone ( `tz` ) naive Datetime Array/Index object and makes this time zone aware .", "question_id": 4254},
{"snippet": "DatetimeIndex.tz_localize(tz, ambiguous='raise')", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . This method takes a time zone ( `tz` ) naive Datetime Array/Index object and makes this time zone aware . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly", "question_id": 4255},
{"snippet": "DatetimeIndex.tz_localize(tz, nonexistent='raise')", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . This method takes a time zone ( `tz` ) naive Datetime Array/Index object and makes this time zone aware . If the DST transition causes `nonexistent` times , you can shift these dates forward or backwards with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backwards \u2019 .", "question_id": 4256},
{"snippet": "DatetimeIndex.tz_localize(tz, ambiguous='raise', nonexistent='raise')", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . This method takes a time zone ( `tz` ) naive Datetime Array/Index object and makes this time zone aware . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly If the DST transition causes `nonexistent` times , you can shift these dates forward or backwards with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backwards \u2019 .", "question_id": 4257},
{"snippet": "DatetimeIndex.tz_localize(tz)", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . This method takes a time zone ( `tz` ) naive Datetime Array/Index object and makes this time zone aware .", "question_id": 4258},
{"snippet": "DatetimeIndex.tz_localize(tz, ambiguous='raise')", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . This method takes a time zone ( `tz` ) naive Datetime Array/Index object and makes this time zone aware . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly", "question_id": 4259},
{"snippet": "DatetimeIndex.tz_localize(tz, nonexistent='raise')", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . This method takes a time zone ( `tz` ) naive Datetime Array/Index object and makes this time zone aware . If the DST transition causes `nonexistent` times , you can shift these dates forward or backwards with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backwards \u2019 .", "question_id": 4260},
{"snippet": "DatetimeIndex.tz_localize(tz, ambiguous='raise', nonexistent='raise')", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . This method takes a time zone ( `tz` ) naive Datetime Array/Index object and makes this time zone aware . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly If the DST transition causes `nonexistent` times , you can shift these dates forward or backwards with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backwards \u2019 .", "question_id": 4261},
{"snippet": "DatetimeIndex.tz_localize(tz)", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . This method takes a time zone ( `tz` ) naive Datetime Array/Index object and makes this time zone aware .", "question_id": 4262},
{"snippet": "DatetimeIndex.tz_localize(tz, ambiguous='raise')", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . This method takes a time zone ( `tz` ) naive Datetime Array/Index object and makes this time zone aware . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly", "question_id": 4263},
{"snippet": "DatetimeIndex.tz_localize(tz, nonexistent='raise')", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . This method takes a time zone ( `tz` ) naive Datetime Array/Index object and makes this time zone aware . If the DST transition causes `nonexistent` times , you can shift these dates forward or backwards with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backwards \u2019 .", "question_id": 4264},
{"snippet": "DatetimeIndex.tz_localize(tz, ambiguous='raise', nonexistent='raise')", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . This method takes a time zone ( `tz` ) naive Datetime Array/Index object and makes this time zone aware . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly If the DST transition causes `nonexistent` times , you can shift these dates forward or backwards with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backwards \u2019 .", "question_id": 4265},
{"snippet": "pandas.DatetimeTZDtype()", "intent": "An ExtensionDtype for timezone-aware datetime data .", "question_id": 4266},
{"snippet": "pandas.DatetimeTZDtype(unit='ns')", "intent": "An ExtensionDtype for timezone-aware datetime data . With arguments `unit`.", "question_id": 4267},
{"snippet": "pandas.DatetimeTZDtype(tz=None)", "intent": "An ExtensionDtype for timezone-aware datetime data . With arguments `tz`.", "question_id": 4268},
{"snippet": "pandas.DatetimeTZDtype(unit='ns', tz=None)", "intent": "An ExtensionDtype for timezone-aware datetime data . With arguments `unit`, `tz`.", "question_id": 4269},
{"snippet": "pandas.DatetimeTZDtype()", "intent": "An ExtensionDtype for timezone-aware datetime data .", "question_id": 4270},
{"snippet": "pandas.DatetimeTZDtype(unit='ns')", "intent": "An ExtensionDtype for timezone-aware datetime data . With arguments `unit`.", "question_id": 4271},
{"snippet": "pandas.DatetimeTZDtype(tz=None)", "intent": "An ExtensionDtype for timezone-aware datetime data . With arguments `tz`.", "question_id": 4272},
{"snippet": "pandas.DatetimeTZDtype(unit='ns', tz=None)", "intent": "An ExtensionDtype for timezone-aware datetime data . With arguments `unit`, `tz`.", "question_id": 4273},
{"snippet": "pandas.DatetimeTZDtype()", "intent": "An ExtensionDtype for timezone-aware datetime data .", "question_id": 4274},
{"snippet": "pandas.DatetimeTZDtype(unit='ns')", "intent": "An ExtensionDtype for timezone-aware datetime data . With arguments `unit`.", "question_id": 4275},
{"snippet": "pandas.DatetimeTZDtype(tz=None)", "intent": "An ExtensionDtype for timezone-aware datetime data . With arguments `tz`.", "question_id": 4276},
{"snippet": "pandas.DatetimeTZDtype(unit='ns', tz=None)", "intent": "An ExtensionDtype for timezone-aware datetime data . With arguments `unit`, `tz`.", "question_id": 4277},
{"snippet": "ExcelFile.parse(**kwds)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`.", "question_id": 4278},
{"snippet": "ExcelFile.parse(**kwds, sheet_name=0)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `sheet_name`.", "question_id": 4279},
{"snippet": "ExcelFile.parse(**kwds, header=0)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `header`.", "question_id": 4280},
{"snippet": "ExcelFile.parse(**kwds, names=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `names`.", "question_id": 4281},
{"snippet": "ExcelFile.parse(**kwds, index_col=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `index_col`.", "question_id": 4282},
{"snippet": "ExcelFile.parse(**kwds, usecols=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `usecols`.", "question_id": 4283},
{"snippet": "ExcelFile.parse(**kwds, squeeze=False)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `squeeze`.", "question_id": 4284},
{"snippet": "ExcelFile.parse(**kwds, converters=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `converters`.", "question_id": 4285},
{"snippet": "ExcelFile.parse(**kwds, true_values=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `true_values`.", "question_id": 4286},
{"snippet": "ExcelFile.parse(**kwds, false_values=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `false_values`.", "question_id": 4287},
{"snippet": "ExcelFile.parse(**kwds)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`.", "question_id": 4288},
{"snippet": "ExcelFile.parse(**kwds, sheet_name=0)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `sheet_name`.", "question_id": 4289},
{"snippet": "ExcelFile.parse(**kwds, header=0)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `header`.", "question_id": 4290},
{"snippet": "ExcelFile.parse(**kwds, names=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `names`.", "question_id": 4291},
{"snippet": "ExcelFile.parse(**kwds, index_col=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `index_col`.", "question_id": 4292},
{"snippet": "ExcelFile.parse(**kwds, usecols=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `usecols`.", "question_id": 4293},
{"snippet": "ExcelFile.parse(**kwds, squeeze=False)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `squeeze`.", "question_id": 4294},
{"snippet": "ExcelFile.parse(**kwds, converters=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `converters`.", "question_id": 4295},
{"snippet": "ExcelFile.parse(**kwds, true_values=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `true_values`.", "question_id": 4296},
{"snippet": "ExcelFile.parse(**kwds, false_values=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `false_values`.", "question_id": 4297},
{"snippet": "ExcelFile.parse(**kwds)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`.", "question_id": 4298},
{"snippet": "ExcelFile.parse(**kwds, sheet_name=0)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `sheet_name`.", "question_id": 4299},
{"snippet": "ExcelFile.parse(**kwds, header=0)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `header`.", "question_id": 4300},
{"snippet": "ExcelFile.parse(**kwds, names=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `names`.", "question_id": 4301},
{"snippet": "ExcelFile.parse(**kwds, index_col=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `index_col`.", "question_id": 4302},
{"snippet": "ExcelFile.parse(**kwds, usecols=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `usecols`.", "question_id": 4303},
{"snippet": "ExcelFile.parse(**kwds, squeeze=False)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `squeeze`.", "question_id": 4304},
{"snippet": "ExcelFile.parse(**kwds, converters=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `converters`.", "question_id": 4305},
{"snippet": "ExcelFile.parse(**kwds, true_values=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `true_values`.", "question_id": 4306},
{"snippet": "ExcelFile.parse(**kwds, false_values=None)", "intent": "Parse specified sheet ( s ) into a DataFrame . With arguments `**kwds`, `false_values`.", "question_id": 4307},
{"snippet": "pandas.ExcelWriter(path, **kwargs)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`.", "question_id": 4308},
{"snippet": "pandas.ExcelWriter(path, **kwargs, engine=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `engine`.", "question_id": 4309},
{"snippet": "pandas.ExcelWriter(path, **kwargs, date_format=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `date_format`.", "question_id": 4310},
{"snippet": "pandas.ExcelWriter(path, **kwargs, datetime_format=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `datetime_format`.", "question_id": 4311},
{"snippet": "pandas.ExcelWriter(path, **kwargs, mode='w')", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `mode`.", "question_id": 4312},
{"snippet": "pandas.ExcelWriter(path, **kwargs, storage_options=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `storage_options`.", "question_id": 4313},
{"snippet": "pandas.ExcelWriter(path, **kwargs, if_sheet_exists=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `if_sheet_exists`.", "question_id": 4314},
{"snippet": "pandas.ExcelWriter(path, **kwargs, engine_kwargs=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `engine_kwargs`.", "question_id": 4315},
{"snippet": "pandas.ExcelWriter(path, **kwargs, engine=None, date_format=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `engine`, `date_format`.", "question_id": 4316},
{"snippet": "pandas.ExcelWriter(path, **kwargs, engine=None, datetime_format=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `engine`, `datetime_format`.", "question_id": 4317},
{"snippet": "pandas.ExcelWriter(path, **kwargs)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`.", "question_id": 4318},
{"snippet": "pandas.ExcelWriter(path, **kwargs, engine=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `engine`.", "question_id": 4319},
{"snippet": "pandas.ExcelWriter(path, **kwargs, date_format=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `date_format`.", "question_id": 4320},
{"snippet": "pandas.ExcelWriter(path, **kwargs, datetime_format=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `datetime_format`.", "question_id": 4321},
{"snippet": "pandas.ExcelWriter(path, **kwargs, mode='w')", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `mode`.", "question_id": 4322},
{"snippet": "pandas.ExcelWriter(path, **kwargs, storage_options=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `storage_options`.", "question_id": 4323},
{"snippet": "pandas.ExcelWriter(path, **kwargs, if_sheet_exists=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `if_sheet_exists`.", "question_id": 4324},
{"snippet": "pandas.ExcelWriter(path, **kwargs, engine_kwargs=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `engine_kwargs`.", "question_id": 4325},
{"snippet": "pandas.ExcelWriter(path, **kwargs, engine=None, date_format=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `engine`, `date_format`.", "question_id": 4326},
{"snippet": "pandas.ExcelWriter(path, **kwargs, engine=None, datetime_format=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `engine`, `datetime_format`.", "question_id": 4327},
{"snippet": "pandas.ExcelWriter(path, **kwargs)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`.", "question_id": 4328},
{"snippet": "pandas.ExcelWriter(path, **kwargs, engine=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `engine`.", "question_id": 4329},
{"snippet": "pandas.ExcelWriter(path, **kwargs, date_format=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `date_format`.", "question_id": 4330},
{"snippet": "pandas.ExcelWriter(path, **kwargs, datetime_format=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `datetime_format`.", "question_id": 4331},
{"snippet": "pandas.ExcelWriter(path, **kwargs, mode='w')", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `mode`.", "question_id": 4332},
{"snippet": "pandas.ExcelWriter(path, **kwargs, storage_options=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `storage_options`.", "question_id": 4333},
{"snippet": "pandas.ExcelWriter(path, **kwargs, if_sheet_exists=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `if_sheet_exists`.", "question_id": 4334},
{"snippet": "pandas.ExcelWriter(path, **kwargs, engine_kwargs=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `engine_kwargs`.", "question_id": 4335},
{"snippet": "pandas.ExcelWriter(path, **kwargs, engine=None, date_format=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `engine`, `date_format`.", "question_id": 4336},
{"snippet": "pandas.ExcelWriter(path, **kwargs, engine=None, datetime_format=None)", "intent": "Class for writing DataFrame objects into excel sheets . With arguments `path`, `**kwargs`, `engine`, `datetime_format`.", "question_id": 4337},
{"snippet": "pandas.Flags(obj, allows_duplicate_labels)", "intent": "Flags that apply to pandas objects . With arguments `obj`, `allows_duplicate_labels`.", "question_id": 4338},
{"snippet": "pandas.Flags(obj, allows_duplicate_labels)", "intent": "Flags that apply to pandas objects . With arguments `obj`, `allows_duplicate_labels`.", "question_id": 4339},
{"snippet": "pandas.Flags(obj, allows_duplicate_labels)", "intent": "Flags that apply to pandas objects . With arguments `obj`, `allows_duplicate_labels`.", "question_id": 4340},
{"snippet": "pandas.Float64Index()", "intent": "Immutable sequence used for indexing and alignment .", "question_id": 4341},
{"snippet": "pandas.Float64Index(data=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`.", "question_id": 4342},
{"snippet": "pandas.Float64Index(dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`.", "question_id": 4343},
{"snippet": "pandas.Float64Index(copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `copy`.", "question_id": 4344},
{"snippet": "pandas.Float64Index(name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `name`.", "question_id": 4345},
{"snippet": "pandas.Float64Index(data=None, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `dtype`.", "question_id": 4346},
{"snippet": "pandas.Float64Index(data=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `copy`.", "question_id": 4347},
{"snippet": "pandas.Float64Index(data=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `name`.", "question_id": 4348},
{"snippet": "pandas.Float64Index(dtype=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `copy`.", "question_id": 4349},
{"snippet": "pandas.Float64Index(dtype=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `name`.", "question_id": 4350},
{"snippet": "pandas.Float64Index()", "intent": "Immutable sequence used for indexing and alignment .", "question_id": 4351},
{"snippet": "pandas.Float64Index(data=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`.", "question_id": 4352},
{"snippet": "pandas.Float64Index(dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`.", "question_id": 4353},
{"snippet": "pandas.Float64Index(copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `copy`.", "question_id": 4354},
{"snippet": "pandas.Float64Index(name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `name`.", "question_id": 4355},
{"snippet": "pandas.Float64Index(data=None, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `dtype`.", "question_id": 4356},
{"snippet": "pandas.Float64Index(data=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `copy`.", "question_id": 4357},
{"snippet": "pandas.Float64Index(data=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `name`.", "question_id": 4358},
{"snippet": "pandas.Float64Index(dtype=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `copy`.", "question_id": 4359},
{"snippet": "pandas.Float64Index(dtype=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `name`.", "question_id": 4360},
{"snippet": "pandas.Float64Index()", "intent": "Immutable sequence used for indexing and alignment .", "question_id": 4361},
{"snippet": "pandas.Float64Index(data=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`.", "question_id": 4362},
{"snippet": "pandas.Float64Index(dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`.", "question_id": 4363},
{"snippet": "pandas.Float64Index(copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `copy`.", "question_id": 4364},
{"snippet": "pandas.Float64Index(name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `name`.", "question_id": 4365},
{"snippet": "pandas.Float64Index(data=None, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `dtype`.", "question_id": 4366},
{"snippet": "pandas.Float64Index(data=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `copy`.", "question_id": 4367},
{"snippet": "pandas.Float64Index(data=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `name`.", "question_id": 4368},
{"snippet": "pandas.Float64Index(dtype=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `copy`.", "question_id": 4369},
{"snippet": "pandas.Float64Index(dtype=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `name`.", "question_id": 4370},
{"snippet": "pandas.Grouper(*args, **kwargs)", "intent": "A Grouper allows the user to specify a groupby instruction for an object . With arguments `*args`, `**kwargs`.", "question_id": 4371},
{"snippet": "pandas.Grouper(*args, **kwargs)", "intent": "A Grouper allows the user to specify a groupby instruction for an object . With arguments `*args`, `**kwargs`.", "question_id": 4372},
{"snippet": "pandas.Grouper(*args, **kwargs)", "intent": "A Grouper allows the user to specify a groupby instruction for an object . With arguments `*args`, `**kwargs`.", "question_id": 4373},
{"snippet": "HDFStore.append(key, value)", "intent": "Append to Table in file . With arguments `key`, `value`.", "question_id": 4374},
{"snippet": "HDFStore.append(key, value, format=None)", "intent": "Append to Table in file . Node must already exist and be Table `format` . With arguments `key`, `value`.", "question_id": 4375},
{"snippet": "HDFStore.append(key, value, axes=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `axes`.", "question_id": 4376},
{"snippet": "HDFStore.append(key, value, index=True)", "intent": "Append to Table in file . With arguments `key`, `value`, `index`.", "question_id": 4377},
{"snippet": "HDFStore.append(key, value, append=True)", "intent": "Append to Table in file . With arguments `key`, `value`, `append`.", "question_id": 4378},
{"snippet": "HDFStore.append(key, value, complib=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `complib`.", "question_id": 4379},
{"snippet": "HDFStore.append(key, value, complevel=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `complevel`.", "question_id": 4380},
{"snippet": "HDFStore.append(key, value, columns=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `columns`.", "question_id": 4381},
{"snippet": "HDFStore.append(key, value, min_itemsize=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `min_itemsize`.", "question_id": 4382},
{"snippet": "HDFStore.append(key, value, nan_rep=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `nan_rep`.", "question_id": 4383},
{"snippet": "HDFStore.append(key, value)", "intent": "Append to Table in file . With arguments `key`, `value`.", "question_id": 4384},
{"snippet": "HDFStore.append(key, value, format=None)", "intent": "Append to Table in file . Node must already exist and be Table `format` . With arguments `key`, `value`.", "question_id": 4385},
{"snippet": "HDFStore.append(key, value, axes=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `axes`.", "question_id": 4386},
{"snippet": "HDFStore.append(key, value, index=True)", "intent": "Append to Table in file . With arguments `key`, `value`, `index`.", "question_id": 4387},
{"snippet": "HDFStore.append(key, value, append=True)", "intent": "Append to Table in file . With arguments `key`, `value`, `append`.", "question_id": 4388},
{"snippet": "HDFStore.append(key, value, complib=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `complib`.", "question_id": 4389},
{"snippet": "HDFStore.append(key, value, complevel=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `complevel`.", "question_id": 4390},
{"snippet": "HDFStore.append(key, value, columns=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `columns`.", "question_id": 4391},
{"snippet": "HDFStore.append(key, value, min_itemsize=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `min_itemsize`.", "question_id": 4392},
{"snippet": "HDFStore.append(key, value, nan_rep=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `nan_rep`.", "question_id": 4393},
{"snippet": "HDFStore.append(key, value)", "intent": "Append to Table in file . With arguments `key`, `value`.", "question_id": 4394},
{"snippet": "HDFStore.append(key, value, format=None)", "intent": "Append to Table in file . Node must already exist and be Table `format` . With arguments `key`, `value`.", "question_id": 4395},
{"snippet": "HDFStore.append(key, value, axes=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `axes`.", "question_id": 4396},
{"snippet": "HDFStore.append(key, value, index=True)", "intent": "Append to Table in file . With arguments `key`, `value`, `index`.", "question_id": 4397},
{"snippet": "HDFStore.append(key, value, append=True)", "intent": "Append to Table in file . With arguments `key`, `value`, `append`.", "question_id": 4398},
{"snippet": "HDFStore.append(key, value, complib=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `complib`.", "question_id": 4399},
{"snippet": "HDFStore.append(key, value, complevel=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `complevel`.", "question_id": 4400},
{"snippet": "HDFStore.append(key, value, columns=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `columns`.", "question_id": 4401},
{"snippet": "HDFStore.append(key, value, min_itemsize=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `min_itemsize`.", "question_id": 4402},
{"snippet": "HDFStore.append(key, value, nan_rep=None)", "intent": "Append to Table in file . With arguments `key`, `value`, `nan_rep`.", "question_id": 4403},
{"snippet": "HDFStore.get(key)", "intent": "Retrieve pandas object stored in file . With arguments `key`.", "question_id": 4404},
{"snippet": "HDFStore.get(key)", "intent": "Retrieve pandas object stored in file . With arguments `key`.", "question_id": 4405},
{"snippet": "HDFStore.get(key)", "intent": "Retrieve pandas object stored in file . With arguments `key`.", "question_id": 4406},
{"snippet": "HDFStore.groups()", "intent": "Return a list of all the top-level nodes .", "question_id": 4407},
{"snippet": "HDFStore.groups()", "intent": "Return a list of all the top-level nodes .", "question_id": 4408},
{"snippet": "HDFStore.groups()", "intent": "Return a list of all the top-level nodes .", "question_id": 4409},
{"snippet": "HDFStore.info()", "intent": "Print detailed information on the store .", "question_id": 4410},
{"snippet": "HDFStore.info()", "intent": "Print detailed information on the store .", "question_id": 4411},
{"snippet": "HDFStore.info()", "intent": "Print detailed information on the store .", "question_id": 4412},
{"snippet": "HDFStore.keys()", "intent": "Return a list of keys corresponding to objects stored in HDFStore .", "question_id": 4413},
{"snippet": "HDFStore.keys(include='pandas')", "intent": "Return a list of keys corresponding to objects stored in HDFStore . With arguments `include`.", "question_id": 4414},
{"snippet": "HDFStore.keys()", "intent": "Return a list of keys corresponding to objects stored in HDFStore .", "question_id": 4415},
{"snippet": "HDFStore.keys(include='pandas')", "intent": "Return a list of keys corresponding to objects stored in HDFStore . With arguments `include`.", "question_id": 4416},
{"snippet": "HDFStore.keys()", "intent": "Return a list of keys corresponding to objects stored in HDFStore .", "question_id": 4417},
{"snippet": "HDFStore.keys(include='pandas')", "intent": "Return a list of keys corresponding to objects stored in HDFStore . With arguments `include`.", "question_id": 4418},
{"snippet": "HDFStore.put(key, value)", "intent": "Store object in HDFStore . With arguments `key`, `value`.", "question_id": 4419},
{"snippet": "HDFStore.put(key, value, format=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `format`.", "question_id": 4420},
{"snippet": "HDFStore.put(key, value, index=True)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `index`.", "question_id": 4421},
{"snippet": "HDFStore.put(key, value, append=False)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `append`.", "question_id": 4422},
{"snippet": "HDFStore.put(key, value, complib=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `complib`.", "question_id": 4423},
{"snippet": "HDFStore.put(key, value, complevel=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `complevel`.", "question_id": 4424},
{"snippet": "HDFStore.put(key, value, min_itemsize=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `min_itemsize`.", "question_id": 4425},
{"snippet": "HDFStore.put(key, value, nan_rep=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `nan_rep`.", "question_id": 4426},
{"snippet": "HDFStore.put(key, value, data_columns=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `data_columns`.", "question_id": 4427},
{"snippet": "HDFStore.put(key, value, encoding=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `encoding`.", "question_id": 4428},
{"snippet": "HDFStore.put(key, value)", "intent": "Store object in HDFStore . With arguments `key`, `value`.", "question_id": 4429},
{"snippet": "HDFStore.put(key, value, format=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `format`.", "question_id": 4430},
{"snippet": "HDFStore.put(key, value, index=True)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `index`.", "question_id": 4431},
{"snippet": "HDFStore.put(key, value, append=False)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `append`.", "question_id": 4432},
{"snippet": "HDFStore.put(key, value, complib=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `complib`.", "question_id": 4433},
{"snippet": "HDFStore.put(key, value, complevel=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `complevel`.", "question_id": 4434},
{"snippet": "HDFStore.put(key, value, min_itemsize=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `min_itemsize`.", "question_id": 4435},
{"snippet": "HDFStore.put(key, value, nan_rep=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `nan_rep`.", "question_id": 4436},
{"snippet": "HDFStore.put(key, value, data_columns=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `data_columns`.", "question_id": 4437},
{"snippet": "HDFStore.put(key, value, encoding=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `encoding`.", "question_id": 4438},
{"snippet": "HDFStore.put(key, value)", "intent": "Store object in HDFStore . With arguments `key`, `value`.", "question_id": 4439},
{"snippet": "HDFStore.put(key, value, format=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `format`.", "question_id": 4440},
{"snippet": "HDFStore.put(key, value, index=True)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `index`.", "question_id": 4441},
{"snippet": "HDFStore.put(key, value, append=False)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `append`.", "question_id": 4442},
{"snippet": "HDFStore.put(key, value, complib=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `complib`.", "question_id": 4443},
{"snippet": "HDFStore.put(key, value, complevel=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `complevel`.", "question_id": 4444},
{"snippet": "HDFStore.put(key, value, min_itemsize=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `min_itemsize`.", "question_id": 4445},
{"snippet": "HDFStore.put(key, value, nan_rep=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `nan_rep`.", "question_id": 4446},
{"snippet": "HDFStore.put(key, value, data_columns=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `data_columns`.", "question_id": 4447},
{"snippet": "HDFStore.put(key, value, encoding=None)", "intent": "Store object in HDFStore . With arguments `key`, `value`, `encoding`.", "question_id": 4448},
{"snippet": "HDFStore.select(key)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`.", "question_id": 4449},
{"snippet": "HDFStore.select(key, where=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`.", "question_id": 4450},
{"snippet": "HDFStore.select(key, start=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `start`.", "question_id": 4451},
{"snippet": "HDFStore.select(key, stop=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `stop`.", "question_id": 4452},
{"snippet": "HDFStore.select(key, columns=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `columns`.", "question_id": 4453},
{"snippet": "HDFStore.select(key, iterator=False)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `iterator`.", "question_id": 4454},
{"snippet": "HDFStore.select(key, chunksize=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `chunksize`.", "question_id": 4455},
{"snippet": "HDFStore.select(key, auto_close=False)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `auto_close`.", "question_id": 4456},
{"snippet": "HDFStore.select(key, where=None, start=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `start`.", "question_id": 4457},
{"snippet": "HDFStore.select(key, where=None, stop=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `stop`.", "question_id": 4458},
{"snippet": "HDFStore.select(key)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`.", "question_id": 4459},
{"snippet": "HDFStore.select(key, where=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`.", "question_id": 4460},
{"snippet": "HDFStore.select(key, start=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `start`.", "question_id": 4461},
{"snippet": "HDFStore.select(key, stop=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `stop`.", "question_id": 4462},
{"snippet": "HDFStore.select(key, columns=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `columns`.", "question_id": 4463},
{"snippet": "HDFStore.select(key, iterator=False)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `iterator`.", "question_id": 4464},
{"snippet": "HDFStore.select(key, chunksize=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `chunksize`.", "question_id": 4465},
{"snippet": "HDFStore.select(key, auto_close=False)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `auto_close`.", "question_id": 4466},
{"snippet": "HDFStore.select(key, where=None, start=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `start`.", "question_id": 4467},
{"snippet": "HDFStore.select(key, where=None, stop=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `stop`.", "question_id": 4468},
{"snippet": "HDFStore.select(key)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`.", "question_id": 4469},
{"snippet": "HDFStore.select(key, where=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`.", "question_id": 4470},
{"snippet": "HDFStore.select(key, start=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `start`.", "question_id": 4471},
{"snippet": "HDFStore.select(key, stop=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `stop`.", "question_id": 4472},
{"snippet": "HDFStore.select(key, columns=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `columns`.", "question_id": 4473},
{"snippet": "HDFStore.select(key, iterator=False)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `iterator`.", "question_id": 4474},
{"snippet": "HDFStore.select(key, chunksize=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `chunksize`.", "question_id": 4475},
{"snippet": "HDFStore.select(key, auto_close=False)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `auto_close`.", "question_id": 4476},
{"snippet": "HDFStore.select(key, where=None, start=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `start`.", "question_id": 4477},
{"snippet": "HDFStore.select(key, where=None, stop=None)", "intent": "Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `key`, `stop`.", "question_id": 4478},
{"snippet": "HDFStore.walk()", "intent": "Walk the pytables group hierarchy for pandas objects .", "question_id": 4479},
{"snippet": "HDFStore.walk(where='/')", "intent": "Walk the pytables group hierarchy for pandas objects . The `where` group itself is listed first ( preorder ) , then each of its child groups ( following an alphanumerical order ) is also traversed , following the same procedure .", "question_id": 4480},
{"snippet": "HDFStore.walk()", "intent": "Walk the pytables group hierarchy for pandas objects .", "question_id": 4481},
{"snippet": "HDFStore.walk(where='/')", "intent": "Walk the pytables group hierarchy for pandas objects . The `where` group itself is listed first ( preorder ) , then each of its child groups ( following an alphanumerical order ) is also traversed , following the same procedure .", "question_id": 4482},
{"snippet": "HDFStore.walk()", "intent": "Walk the pytables group hierarchy for pandas objects .", "question_id": 4483},
{"snippet": "HDFStore.walk(where='/')", "intent": "Walk the pytables group hierarchy for pandas objects . The `where` group itself is listed first ( preorder ) , then each of its child groups ( following an alphanumerical order ) is also traversed , following the same procedure .", "question_id": 4484},
{"snippet": "Index.all(*args, **kwargs)", "intent": "Return whether all elements are Truthy . With arguments `*args`, `**kwargs`.", "question_id": 4485},
{"snippet": "Index.all(*args, **kwargs)", "intent": "Return whether all elements are Truthy . With arguments `*args`, `**kwargs`.", "question_id": 4486},
{"snippet": "Index.all(*args, **kwargs)", "intent": "Return whether all elements are Truthy . With arguments `*args`, `**kwargs`.", "question_id": 4487},
{"snippet": "Index.any(*args, **kwargs)", "intent": "Return whether any element is Truthy . With arguments `*args`, `**kwargs`.", "question_id": 4488},
{"snippet": "Index.any(*args, **kwargs)", "intent": "Return whether any element is Truthy . With arguments `*args`, `**kwargs`.", "question_id": 4489},
{"snippet": "Index.any(*args, **kwargs)", "intent": "Return whether any element is Truthy . With arguments `*args`, `**kwargs`.", "question_id": 4490},
{"snippet": "Index.append(other)", "intent": "Append a collection of Index options together . With arguments `other`.", "question_id": 4491},
{"snippet": "Index.append(other)", "intent": "Append a collection of Index options together . With arguments `other`.", "question_id": 4492},
{"snippet": "Index.append(other)", "intent": "Append a collection of Index options together . With arguments `other`.", "question_id": 4493},
{"snippet": "Index.argmax(*args, **kwargs)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`.", "question_id": 4494},
{"snippet": "Index.argmax(*args, **kwargs, axis=None)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 4495},
{"snippet": "Index.argmax(*args, **kwargs, skipna=True)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 4496},
{"snippet": "Index.argmax(*args, **kwargs, axis=None, skipna=True)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 4497},
{"snippet": "Index.argmax(*args, **kwargs)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`.", "question_id": 4498},
{"snippet": "Index.argmax(*args, **kwargs, axis=None)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 4499},
{"snippet": "Index.argmax(*args, **kwargs, skipna=True)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 4500},
{"snippet": "Index.argmax(*args, **kwargs, axis=None, skipna=True)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 4501},
{"snippet": "Index.argmax(*args, **kwargs)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`.", "question_id": 4502},
{"snippet": "Index.argmax(*args, **kwargs, axis=None)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 4503},
{"snippet": "Index.argmax(*args, **kwargs, skipna=True)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 4504},
{"snippet": "Index.argmax(*args, **kwargs, axis=None, skipna=True)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 4505},
{"snippet": "Index.argmin(*args, **kwargs)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`.", "question_id": 4506},
{"snippet": "Index.argmin(*args, **kwargs, axis=None)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 4507},
{"snippet": "Index.argmin(*args, **kwargs, skipna=True)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 4508},
{"snippet": "Index.argmin(*args, **kwargs, axis=None, skipna=True)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 4509},
{"snippet": "Index.argmin(*args, **kwargs)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`.", "question_id": 4510},
{"snippet": "Index.argmin(*args, **kwargs, axis=None)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 4511},
{"snippet": "Index.argmin(*args, **kwargs, skipna=True)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 4512},
{"snippet": "Index.argmin(*args, **kwargs, axis=None, skipna=True)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 4513},
{"snippet": "Index.argmin(*args, **kwargs)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`.", "question_id": 4514},
{"snippet": "Index.argmin(*args, **kwargs, axis=None)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 4515},
{"snippet": "Index.argmin(*args, **kwargs, skipna=True)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 4516},
{"snippet": "Index.argmin(*args, **kwargs, axis=None, skipna=True)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 4517},
{"snippet": "Index.argsort(*args, **kwargs)", "intent": "Return the integer indices that would sort the index . With arguments `*args`, `**kwargs`.", "question_id": 4518},
{"snippet": "Index.argsort(*args, **kwargs)", "intent": "Return the integer indices that would sort the index . With arguments `*args`, `**kwargs`.", "question_id": 4519},
{"snippet": "Index.argsort(*args, **kwargs)", "intent": "Return the integer indices that would sort the index . With arguments `*args`, `**kwargs`.", "question_id": 4520},
{"snippet": "Index.array", "intent": "The ExtensionArray of the data backing this Series or Index.", "question_id": 4521},
{"snippet": "Index.array", "intent": "The ExtensionArray of the data backing this Series or Index.", "question_id": 4522},
{"snippet": "Index.array", "intent": "The ExtensionArray of the data backing this Series or Index.", "question_id": 4523},
{"snippet": "Index.asof(label)", "intent": "Return the `label` from the index , or , if not present , the previous one .", "question_id": 4524},
{"snippet": "Index.asof(label)", "intent": "Return the `label` from the index , or , if not present , the previous one .", "question_id": 4525},
{"snippet": "Index.asof(label)", "intent": "Return the `label` from the index , or , if not present , the previous one .", "question_id": 4526},
{"snippet": "Index.asof_locs(where, mask)", "intent": "Return the locations ( indices ) of labels in the index . As in the asof function , if the label ( a particular entry in `where` ) is not in the index , the latest index label up to the passed label is chosen and its index returned . `mask` is used to ignore NA values in the index during calculation .", "question_id": 4527},
{"snippet": "Index.asof_locs(where, mask)", "intent": "Return the locations ( indices ) of labels in the index . As in the asof function , if the label ( a particular entry in `where` ) is not in the index , the latest index label up to the passed label is chosen and its index returned . `mask` is used to ignore NA values in the index during calculation .", "question_id": 4528},
{"snippet": "Index.asof_locs(where, mask)", "intent": "Return the locations ( indices ) of labels in the index . As in the asof function , if the label ( a particular entry in `where` ) is not in the index , the latest index label up to the passed label is chosen and its index returned . `mask` is used to ignore NA values in the index during calculation .", "question_id": 4529},
{"snippet": "Index.astype(dtype)", "intent": "Create an Index with values cast to dtypes . The class of a new Index is determined by `dtype` .", "question_id": 4530},
{"snippet": "Index.astype(dtype, copy=True)", "intent": "Create an Index with values cast to dtypes . The class of a new Index is determined by `dtype` . With arguments `copy`.", "question_id": 4531},
{"snippet": "Index.astype(dtype)", "intent": "Create an Index with values cast to dtypes . The class of a new Index is determined by `dtype` .", "question_id": 4532},
{"snippet": "Index.astype(dtype, copy=True)", "intent": "Create an Index with values cast to dtypes . The class of a new Index is determined by `dtype` . With arguments `copy`.", "question_id": 4533},
{"snippet": "Index.astype(dtype)", "intent": "Create an Index with values cast to dtypes . The class of a new Index is determined by `dtype` .", "question_id": 4534},
{"snippet": "Index.astype(dtype, copy=True)", "intent": "Create an Index with values cast to dtypes . The class of a new Index is determined by `dtype` . With arguments `copy`.", "question_id": 4535},
{"snippet": "Index.copy()", "intent": "Make a copy of this object .", "question_id": 4536},
{"snippet": "Index.copy(name=None)", "intent": "Make a copy of this object . With arguments `name`.", "question_id": 4537},
{"snippet": "Index.copy(deep=False)", "intent": "Make a copy of this object . In most cases , there should be no functional difference from using `deep` , but if deep is passed it will attempt to deepcopy .", "question_id": 4538},
{"snippet": "Index.copy(dtype=None)", "intent": "Make a copy of this object . Name and `dtype` sets those attributes on the new object .", "question_id": 4539},
{"snippet": "Index.copy(names=None)", "intent": "Make a copy of this object . With arguments `names`.", "question_id": 4540},
{"snippet": "Index.copy(name=None, deep=False)", "intent": "Make a copy of this object . In most cases , there should be no functional difference from using `deep` , but if deep is passed it will attempt to deepcopy . With arguments `name`.", "question_id": 4541},
{"snippet": "Index.copy(name=None, dtype=None)", "intent": "Make a copy of this object . Name and `dtype` sets those attributes on the new object . With arguments `name`.", "question_id": 4542},
{"snippet": "Index.copy(name=None, names=None)", "intent": "Make a copy of this object . With arguments `name`, `names`.", "question_id": 4543},
{"snippet": "Index.copy(deep=False, dtype=None)", "intent": "Make a copy of this object . In most cases , there should be no functional difference from using `deep` , but if deep is passed it will attempt to deepcopy . Name and `dtype` sets those attributes on the new object .", "question_id": 4544},
{"snippet": "Index.copy(deep=False, names=None)", "intent": "Make a copy of this object . In most cases , there should be no functional difference from using `deep` , but if deep is passed it will attempt to deepcopy . With arguments `names`.", "question_id": 4545},
{"snippet": "Index.copy()", "intent": "Make a copy of this object .", "question_id": 4546},
{"snippet": "Index.copy(name=None)", "intent": "Make a copy of this object . With arguments `name`.", "question_id": 4547},
{"snippet": "Index.copy(deep=False)", "intent": "Make a copy of this object . In most cases , there should be no functional difference from using `deep` , but if deep is passed it will attempt to deepcopy .", "question_id": 4548},
{"snippet": "Index.copy(dtype=None)", "intent": "Make a copy of this object . Name and `dtype` sets those attributes on the new object .", "question_id": 4549},
{"snippet": "Index.copy(names=None)", "intent": "Make a copy of this object . With arguments `names`.", "question_id": 4550},
{"snippet": "Index.copy(name=None, deep=False)", "intent": "Make a copy of this object . In most cases , there should be no functional difference from using `deep` , but if deep is passed it will attempt to deepcopy . With arguments `name`.", "question_id": 4551},
{"snippet": "Index.copy(name=None, dtype=None)", "intent": "Make a copy of this object . Name and `dtype` sets those attributes on the new object . With arguments `name`.", "question_id": 4552},
{"snippet": "Index.copy(name=None, names=None)", "intent": "Make a copy of this object . With arguments `name`, `names`.", "question_id": 4553},
{"snippet": "Index.copy(deep=False, dtype=None)", "intent": "Make a copy of this object . In most cases , there should be no functional difference from using `deep` , but if deep is passed it will attempt to deepcopy . Name and `dtype` sets those attributes on the new object .", "question_id": 4554},
{"snippet": "Index.copy(deep=False, names=None)", "intent": "Make a copy of this object . In most cases , there should be no functional difference from using `deep` , but if deep is passed it will attempt to deepcopy . With arguments `names`.", "question_id": 4555},
{"snippet": "Index.copy()", "intent": "Make a copy of this object .", "question_id": 4556},
{"snippet": "Index.copy(name=None)", "intent": "Make a copy of this object . With arguments `name`.", "question_id": 4557},
{"snippet": "Index.copy(deep=False)", "intent": "Make a copy of this object . In most cases , there should be no functional difference from using `deep` , but if deep is passed it will attempt to deepcopy .", "question_id": 4558},
{"snippet": "Index.copy(dtype=None)", "intent": "Make a copy of this object . Name and `dtype` sets those attributes on the new object .", "question_id": 4559},
{"snippet": "Index.copy(names=None)", "intent": "Make a copy of this object . With arguments `names`.", "question_id": 4560},
{"snippet": "Index.copy(name=None, deep=False)", "intent": "Make a copy of this object . In most cases , there should be no functional difference from using `deep` , but if deep is passed it will attempt to deepcopy . With arguments `name`.", "question_id": 4561},
{"snippet": "Index.copy(name=None, dtype=None)", "intent": "Make a copy of this object . Name and `dtype` sets those attributes on the new object . With arguments `name`.", "question_id": 4562},
{"snippet": "Index.copy(name=None, names=None)", "intent": "Make a copy of this object . With arguments `name`, `names`.", "question_id": 4563},
{"snippet": "Index.copy(deep=False, dtype=None)", "intent": "Make a copy of this object . In most cases , there should be no functional difference from using `deep` , but if deep is passed it will attempt to deepcopy . Name and `dtype` sets those attributes on the new object .", "question_id": 4564},
{"snippet": "Index.copy(deep=False, names=None)", "intent": "Make a copy of this object . In most cases , there should be no functional difference from using `deep` , but if deep is passed it will attempt to deepcopy . With arguments `names`.", "question_id": 4565},
{"snippet": "Index.delete(loc)", "intent": "Make new Index with passed location ( -s ) deleted . With arguments `loc`.", "question_id": 4566},
{"snippet": "Index.delete(loc)", "intent": "Make new Index with passed location ( -s ) deleted . With arguments `loc`.", "question_id": 4567},
{"snippet": "Index.delete(loc)", "intent": "Make new Index with passed location ( -s ) deleted . With arguments `loc`.", "question_id": 4568},
{"snippet": "Index.difference(other)", "intent": "Return a new Index with elements of index not in `other` .", "question_id": 4569},
{"snippet": "Index.difference(other, sort=None)", "intent": "Return a new Index with elements of index not in `other` . With arguments `sort`.", "question_id": 4570},
{"snippet": "Index.difference(other)", "intent": "Return a new Index with elements of index not in `other` .", "question_id": 4571},
{"snippet": "Index.difference(other, sort=None)", "intent": "Return a new Index with elements of index not in `other` . With arguments `sort`.", "question_id": 4572},
{"snippet": "Index.difference(other)", "intent": "Return a new Index with elements of index not in `other` .", "question_id": 4573},
{"snippet": "Index.difference(other, sort=None)", "intent": "Return a new Index with elements of index not in `other` . With arguments `sort`.", "question_id": 4574},
{"snippet": "Index.drop(labels)", "intent": "Make new Index with passed list of `labels` deleted .", "question_id": 4575},
{"snippet": "Index.drop(labels, errors='raise')", "intent": "Make new Index with passed list of `labels` deleted . With arguments `errors`.", "question_id": 4576},
{"snippet": "Index.drop(labels)", "intent": "Make new Index with passed list of `labels` deleted .", "question_id": 4577},
{"snippet": "Index.drop(labels, errors='raise')", "intent": "Make new Index with passed list of `labels` deleted . With arguments `errors`.", "question_id": 4578},
{"snippet": "Index.drop(labels)", "intent": "Make new Index with passed list of `labels` deleted .", "question_id": 4579},
{"snippet": "Index.drop(labels, errors='raise')", "intent": "Make new Index with passed list of `labels` deleted . With arguments `errors`.", "question_id": 4580},
{"snippet": "Index.drop_duplicates()", "intent": "Return Index with duplicate values removed .", "question_id": 4581},
{"snippet": "Index.drop_duplicates(keep='first')", "intent": "Return Index with duplicate values removed . The `keep` parameter controls which duplicate values are removed .", "question_id": 4582},
{"snippet": "Index.drop_duplicates()", "intent": "Return Index with duplicate values removed .", "question_id": 4583},
{"snippet": "Index.drop_duplicates(keep='first')", "intent": "Return Index with duplicate values removed . The `keep` parameter controls which duplicate values are removed .", "question_id": 4584},
{"snippet": "Index.drop_duplicates()", "intent": "Return Index with duplicate values removed .", "question_id": 4585},
{"snippet": "Index.drop_duplicates(keep='first')", "intent": "Return Index with duplicate values removed . The `keep` parameter controls which duplicate values are removed .", "question_id": 4586},
{"snippet": "Index.droplevel()", "intent": "Return index with requested `level` ( s ) removed .", "question_id": 4587},
{"snippet": "Index.droplevel(level=0)", "intent": "Return index with requested `level` ( s ) removed .", "question_id": 4588},
{"snippet": "Index.droplevel()", "intent": "Return index with requested `level` ( s ) removed .", "question_id": 4589},
{"snippet": "Index.droplevel(level=0)", "intent": "Return index with requested `level` ( s ) removed .", "question_id": 4590},
{"snippet": "Index.droplevel()", "intent": "Return index with requested `level` ( s ) removed .", "question_id": 4591},
{"snippet": "Index.droplevel(level=0)", "intent": "Return index with requested `level` ( s ) removed .", "question_id": 4592},
{"snippet": "Index.dropna()", "intent": "Return Index without NA/NaN values .", "question_id": 4593},
{"snippet": "Index.dropna(how='any')", "intent": "Return Index without NA/NaN values . With arguments `how`.", "question_id": 4594},
{"snippet": "Index.dropna()", "intent": "Return Index without NA/NaN values .", "question_id": 4595},
{"snippet": "Index.dropna(how='any')", "intent": "Return Index without NA/NaN values . With arguments `how`.", "question_id": 4596},
{"snippet": "Index.dropna()", "intent": "Return Index without NA/NaN values .", "question_id": 4597},
{"snippet": "Index.dropna(how='any')", "intent": "Return Index without NA/NaN values . With arguments `how`.", "question_id": 4598},
{"snippet": "Index.dtype", "intent": "Return the dtype object of the underlying data.", "question_id": 4599},
{"snippet": "Index.dtype", "intent": "Return the dtype object of the underlying data.", "question_id": 4600},
{"snippet": "Index.dtype", "intent": "Return the dtype object of the underlying data.", "question_id": 4601},
{"snippet": "Index.duplicated()", "intent": "Indicate duplicate index values .", "question_id": 4602},
{"snippet": "Index.duplicated(keep='first')", "intent": "Indicate duplicate index values . By setting `keep` on False , all duplicates are True :", "question_id": 4603},
{"snippet": "Index.duplicated()", "intent": "Indicate duplicate index values .", "question_id": 4604},
{"snippet": "Index.duplicated(keep='first')", "intent": "Indicate duplicate index values . By setting `keep` on False , all duplicates are True :", "question_id": 4605},
{"snippet": "Index.duplicated()", "intent": "Indicate duplicate index values .", "question_id": 4606},
{"snippet": "Index.duplicated(keep='first')", "intent": "Indicate duplicate index values . By setting `keep` on False , all duplicates are True :", "question_id": 4607},
{"snippet": "Index.equals(other)", "intent": "Determine if two Index object are equal . With arguments `other`.", "question_id": 4608},
{"snippet": "Index.equals(other)", "intent": "Determine if two Index object are equal . With arguments `other`.", "question_id": 4609},
{"snippet": "Index.equals(other)", "intent": "Determine if two Index object are equal . With arguments `other`.", "question_id": 4610},
{"snippet": "Index.factorize()", "intent": "Encode the object as an enumerated type or categorical variable .", "question_id": 4611},
{"snippet": "Index.factorize(sort=False)", "intent": "Encode the object as an enumerated type or categorical variable . With arguments `sort`.", "question_id": 4612},
{"snippet": "Index.factorize(na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) .", "question_id": 4613},
{"snippet": "Index.factorize(sort=False, na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `sort`.", "question_id": 4614},
{"snippet": "Index.factorize()", "intent": "Encode the object as an enumerated type or categorical variable .", "question_id": 4615},
{"snippet": "Index.factorize(sort=False)", "intent": "Encode the object as an enumerated type or categorical variable . With arguments `sort`.", "question_id": 4616},
{"snippet": "Index.factorize(na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) .", "question_id": 4617},
{"snippet": "Index.factorize(sort=False, na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `sort`.", "question_id": 4618},
{"snippet": "Index.factorize()", "intent": "Encode the object as an enumerated type or categorical variable .", "question_id": 4619},
{"snippet": "Index.factorize(sort=False)", "intent": "Encode the object as an enumerated type or categorical variable . With arguments `sort`.", "question_id": 4620},
{"snippet": "Index.factorize(na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) .", "question_id": 4621},
{"snippet": "Index.factorize(sort=False, na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `sort`.", "question_id": 4622},
{"snippet": "Index.fillna()", "intent": "Fill NA/NaN values with the specified `value` .", "question_id": 4623},
{"snippet": "Index.fillna(value=None)", "intent": "Fill NA/NaN values with the specified `value` .", "question_id": 4624},
{"snippet": "Index.fillna(downcast=None)", "intent": "Fill NA/NaN values with the specified `value` . With arguments `downcast`.", "question_id": 4625},
{"snippet": "Index.fillna(value=None, downcast=None)", "intent": "Fill NA/NaN values with the specified `value` . With arguments `downcast`.", "question_id": 4626},
{"snippet": "Index.fillna()", "intent": "Fill NA/NaN values with the specified `value` .", "question_id": 4627},
{"snippet": "Index.fillna(value=None)", "intent": "Fill NA/NaN values with the specified `value` .", "question_id": 4628},
{"snippet": "Index.fillna(downcast=None)", "intent": "Fill NA/NaN values with the specified `value` . With arguments `downcast`.", "question_id": 4629},
{"snippet": "Index.fillna(value=None, downcast=None)", "intent": "Fill NA/NaN values with the specified `value` . With arguments `downcast`.", "question_id": 4630},
{"snippet": "Index.fillna()", "intent": "Fill NA/NaN values with the specified `value` .", "question_id": 4631},
{"snippet": "Index.fillna(value=None)", "intent": "Fill NA/NaN values with the specified `value` .", "question_id": 4632},
{"snippet": "Index.fillna(downcast=None)", "intent": "Fill NA/NaN values with the specified `value` . With arguments `downcast`.", "question_id": 4633},
{"snippet": "Index.fillna(value=None, downcast=None)", "intent": "Fill NA/NaN values with the specified `value` . With arguments `downcast`.", "question_id": 4634},
{"snippet": "Index.format()", "intent": "Render a string representation of the Index .", "question_id": 4635},
{"snippet": "Index.format(name=False)", "intent": "Render a string representation of the Index . With arguments `name`.", "question_id": 4636},
{"snippet": "Index.format(formatter=None)", "intent": "Render a string representation of the Index . With arguments `formatter`.", "question_id": 4637},
{"snippet": "Index.format(na_rep='NaN')", "intent": "Render a string representation of the Index . With arguments `na_rep`.", "question_id": 4638},
{"snippet": "Index.format(name=False, formatter=None)", "intent": "Render a string representation of the Index . With arguments `name`, `formatter`.", "question_id": 4639},
{"snippet": "Index.format(name=False, na_rep='NaN')", "intent": "Render a string representation of the Index . With arguments `name`, `na_rep`.", "question_id": 4640},
{"snippet": "Index.format(formatter=None, na_rep='NaN')", "intent": "Render a string representation of the Index . With arguments `formatter`, `na_rep`.", "question_id": 4641},
{"snippet": "Index.format(name=False, formatter=None, na_rep='NaN')", "intent": "Render a string representation of the Index . With arguments `name`, `formatter`, `na_rep`.", "question_id": 4642},
{"snippet": "Index.format()", "intent": "Render a string representation of the Index .", "question_id": 4643},
{"snippet": "Index.format(name=False)", "intent": "Render a string representation of the Index . With arguments `name`.", "question_id": 4644},
{"snippet": "Index.format(formatter=None)", "intent": "Render a string representation of the Index . With arguments `formatter`.", "question_id": 4645},
{"snippet": "Index.format(na_rep='NaN')", "intent": "Render a string representation of the Index . With arguments `na_rep`.", "question_id": 4646},
{"snippet": "Index.format(name=False, formatter=None)", "intent": "Render a string representation of the Index . With arguments `name`, `formatter`.", "question_id": 4647},
{"snippet": "Index.format(name=False, na_rep='NaN')", "intent": "Render a string representation of the Index . With arguments `name`, `na_rep`.", "question_id": 4648},
{"snippet": "Index.format(formatter=None, na_rep='NaN')", "intent": "Render a string representation of the Index . With arguments `formatter`, `na_rep`.", "question_id": 4649},
{"snippet": "Index.format(name=False, formatter=None, na_rep='NaN')", "intent": "Render a string representation of the Index . With arguments `name`, `formatter`, `na_rep`.", "question_id": 4650},
{"snippet": "Index.format()", "intent": "Render a string representation of the Index .", "question_id": 4651},
{"snippet": "Index.format(name=False)", "intent": "Render a string representation of the Index . With arguments `name`.", "question_id": 4652},
{"snippet": "Index.format(formatter=None)", "intent": "Render a string representation of the Index . With arguments `formatter`.", "question_id": 4653},
{"snippet": "Index.format(na_rep='NaN')", "intent": "Render a string representation of the Index . With arguments `na_rep`.", "question_id": 4654},
{"snippet": "Index.format(name=False, formatter=None)", "intent": "Render a string representation of the Index . With arguments `name`, `formatter`.", "question_id": 4655},
{"snippet": "Index.format(name=False, na_rep='NaN')", "intent": "Render a string representation of the Index . With arguments `name`, `na_rep`.", "question_id": 4656},
{"snippet": "Index.format(formatter=None, na_rep='NaN')", "intent": "Render a string representation of the Index . With arguments `formatter`, `na_rep`.", "question_id": 4657},
{"snippet": "Index.format(name=False, formatter=None, na_rep='NaN')", "intent": "Render a string representation of the Index . With arguments `name`, `formatter`, `na_rep`.", "question_id": 4658},
{"snippet": "Index.get_indexer(target)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`.", "question_id": 4659},
{"snippet": "Index.get_indexer(target, method=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`.", "question_id": 4660},
{"snippet": "Index.get_indexer(target, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`.", "question_id": 4661},
{"snippet": "Index.get_indexer(target, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `tolerance`.", "question_id": 4662},
{"snippet": "Index.get_indexer(target, method=None, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`.", "question_id": 4663},
{"snippet": "Index.get_indexer(target, method=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `tolerance`.", "question_id": 4664},
{"snippet": "Index.get_indexer(target, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`, `tolerance`.", "question_id": 4665},
{"snippet": "Index.get_indexer(target, method=None, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`, `tolerance`.", "question_id": 4666},
{"snippet": "Index.get_indexer(target)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`.", "question_id": 4667},
{"snippet": "Index.get_indexer(target, method=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`.", "question_id": 4668},
{"snippet": "Index.get_indexer(target, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`.", "question_id": 4669},
{"snippet": "Index.get_indexer(target, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `tolerance`.", "question_id": 4670},
{"snippet": "Index.get_indexer(target, method=None, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`.", "question_id": 4671},
{"snippet": "Index.get_indexer(target, method=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `tolerance`.", "question_id": 4672},
{"snippet": "Index.get_indexer(target, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`, `tolerance`.", "question_id": 4673},
{"snippet": "Index.get_indexer(target, method=None, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`, `tolerance`.", "question_id": 4674},
{"snippet": "Index.get_indexer(target)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`.", "question_id": 4675},
{"snippet": "Index.get_indexer(target, method=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`.", "question_id": 4676},
{"snippet": "Index.get_indexer(target, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`.", "question_id": 4677},
{"snippet": "Index.get_indexer(target, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `tolerance`.", "question_id": 4678},
{"snippet": "Index.get_indexer(target, method=None, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`.", "question_id": 4679},
{"snippet": "Index.get_indexer(target, method=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `tolerance`.", "question_id": 4680},
{"snippet": "Index.get_indexer(target, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`, `tolerance`.", "question_id": 4681},
{"snippet": "Index.get_indexer(target, method=None, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`, `tolerance`.", "question_id": 4682},
{"snippet": "Index.get_indexer_for(target, **kwargs)", "intent": "Guaranteed return of an indexer even when non-unique . With arguments `target`, `**kwargs`.", "question_id": 4683},
{"snippet": "Index.get_indexer_for(target, **kwargs)", "intent": "Guaranteed return of an indexer even when non-unique . With arguments `target`, `**kwargs`.", "question_id": 4684},
{"snippet": "Index.get_indexer_for(target, **kwargs)", "intent": "Guaranteed return of an indexer even when non-unique . With arguments `target`, `**kwargs`.", "question_id": 4685},
{"snippet": "Index.get_indexer_non_unique(target)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`.", "question_id": 4686},
{"snippet": "Index.get_indexer_non_unique(target)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`.", "question_id": 4687},
{"snippet": "Index.get_indexer_non_unique(target)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`.", "question_id": 4688},
{"snippet": "Index.get_level_values(level)", "intent": "Return an Index of values for requested `level` .", "question_id": 4689},
{"snippet": "Index.get_level_values(level)", "intent": "Return an Index of values for requested `level` .", "question_id": 4690},
{"snippet": "Index.get_level_values(level)", "intent": "Return an Index of values for requested `level` .", "question_id": 4691},
{"snippet": "Index.get_loc(key)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`.", "question_id": 4692},
{"snippet": "Index.get_loc(key, method=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `method`.", "question_id": 4693},
{"snippet": "Index.get_loc(key, tolerance=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `tolerance`.", "question_id": 4694},
{"snippet": "Index.get_loc(key, method=None, tolerance=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `method`, `tolerance`.", "question_id": 4695},
{"snippet": "Index.get_loc(key)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`.", "question_id": 4696},
{"snippet": "Index.get_loc(key, method=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `method`.", "question_id": 4697},
{"snippet": "Index.get_loc(key, tolerance=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `tolerance`.", "question_id": 4698},
{"snippet": "Index.get_loc(key, method=None, tolerance=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `method`, `tolerance`.", "question_id": 4699},
{"snippet": "Index.get_loc(key)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`.", "question_id": 4700},
{"snippet": "Index.get_loc(key, method=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `method`.", "question_id": 4701},
{"snippet": "Index.get_loc(key, tolerance=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `tolerance`.", "question_id": 4702},
{"snippet": "Index.get_loc(key, method=None, tolerance=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `method`, `tolerance`.", "question_id": 4703},
{"snippet": "Index.get_slice_bound(label, side)", "intent": "Calculate slice bound that corresponds to given `label` . With arguments `side`.", "question_id": 4704},
{"snippet": "Index.get_slice_bound(label, side, kind=None)", "intent": "Calculate slice bound that corresponds to given `label` . With arguments `side`, `kind`.", "question_id": 4705},
{"snippet": "Index.get_slice_bound(label, side)", "intent": "Calculate slice bound that corresponds to given `label` . With arguments `side`.", "question_id": 4706},
{"snippet": "Index.get_slice_bound(label, side, kind=None)", "intent": "Calculate slice bound that corresponds to given `label` . With arguments `side`, `kind`.", "question_id": 4707},
{"snippet": "Index.get_slice_bound(label, side)", "intent": "Calculate slice bound that corresponds to given `label` . With arguments `side`.", "question_id": 4708},
{"snippet": "Index.get_slice_bound(label, side, kind=None)", "intent": "Calculate slice bound that corresponds to given `label` . With arguments `side`, `kind`.", "question_id": 4709},
{"snippet": "Index.get_value(series, key)", "intent": "Fast lookup of value from 1-dimensional ndarray . With arguments `series`, `key`.", "question_id": 4710},
{"snippet": "Index.get_value(series, key)", "intent": "Fast lookup of value from 1-dimensional ndarray . With arguments `series`, `key`.", "question_id": 4711},
{"snippet": "Index.get_value(series, key)", "intent": "Fast lookup of value from 1-dimensional ndarray . With arguments `series`, `key`.", "question_id": 4712},
{"snippet": "Index.groupby(values)", "intent": "Group the index labels by a given array of `values` .", "question_id": 4713},
{"snippet": "Index.groupby(values)", "intent": "Group the index labels by a given array of `values` .", "question_id": 4714},
{"snippet": "Index.groupby(values)", "intent": "Group the index labels by a given array of `values` .", "question_id": 4715},
{"snippet": "Index.hasnans", "intent": "Return if I have any nans; enables various perf speedups.", "question_id": 4716},
{"snippet": "Index.hasnans", "intent": "Return if I have any nans; enables various perf speedups.", "question_id": 4717},
{"snippet": "Index.hasnans", "intent": "Return if I have any nans; enables various perf speedups.", "question_id": 4718},
{"snippet": "Index.holds_integer()", "intent": "Whether the type is an integer type .", "question_id": 4719},
{"snippet": "Index.holds_integer()", "intent": "Whether the type is an integer type .", "question_id": 4720},
{"snippet": "Index.holds_integer()", "intent": "Whether the type is an integer type .", "question_id": 4721},
{"snippet": "pandas.Index(**kwargs)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`.", "question_id": 4722},
{"snippet": "pandas.Index(**kwargs, data=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`.", "question_id": 4723},
{"snippet": "pandas.Index(**kwargs, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `dtype`.", "question_id": 4724},
{"snippet": "pandas.Index(**kwargs, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `copy`.", "question_id": 4725},
{"snippet": "pandas.Index(**kwargs, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `name`.", "question_id": 4726},
{"snippet": "pandas.Index(**kwargs, tupleize_cols=True)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `tupleize_cols`.", "question_id": 4727},
{"snippet": "pandas.Index(**kwargs, data=None, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`, `dtype`.", "question_id": 4728},
{"snippet": "pandas.Index(**kwargs, data=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`, `copy`.", "question_id": 4729},
{"snippet": "pandas.Index(**kwargs, data=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`, `name`.", "question_id": 4730},
{"snippet": "pandas.Index(**kwargs, data=None, tupleize_cols=True)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`, `tupleize_cols`.", "question_id": 4731},
{"snippet": "pandas.Index(**kwargs)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`.", "question_id": 4732},
{"snippet": "pandas.Index(**kwargs, data=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`.", "question_id": 4733},
{"snippet": "pandas.Index(**kwargs, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `dtype`.", "question_id": 4734},
{"snippet": "pandas.Index(**kwargs, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `copy`.", "question_id": 4735},
{"snippet": "pandas.Index(**kwargs, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `name`.", "question_id": 4736},
{"snippet": "pandas.Index(**kwargs, tupleize_cols=True)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `tupleize_cols`.", "question_id": 4737},
{"snippet": "pandas.Index(**kwargs, data=None, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`, `dtype`.", "question_id": 4738},
{"snippet": "pandas.Index(**kwargs, data=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`, `copy`.", "question_id": 4739},
{"snippet": "pandas.Index(**kwargs, data=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`, `name`.", "question_id": 4740},
{"snippet": "pandas.Index(**kwargs, data=None, tupleize_cols=True)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`, `tupleize_cols`.", "question_id": 4741},
{"snippet": "pandas.Index(**kwargs)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`.", "question_id": 4742},
{"snippet": "pandas.Index(**kwargs, data=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`.", "question_id": 4743},
{"snippet": "pandas.Index(**kwargs, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `dtype`.", "question_id": 4744},
{"snippet": "pandas.Index(**kwargs, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `copy`.", "question_id": 4745},
{"snippet": "pandas.Index(**kwargs, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `name`.", "question_id": 4746},
{"snippet": "pandas.Index(**kwargs, tupleize_cols=True)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `tupleize_cols`.", "question_id": 4747},
{"snippet": "pandas.Index(**kwargs, data=None, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`, `dtype`.", "question_id": 4748},
{"snippet": "pandas.Index(**kwargs, data=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`, `copy`.", "question_id": 4749},
{"snippet": "pandas.Index(**kwargs, data=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`, `name`.", "question_id": 4750},
{"snippet": "pandas.Index(**kwargs, data=None, tupleize_cols=True)", "intent": "Immutable sequence used for indexing and alignment . With arguments `**kwargs`, `data`, `tupleize_cols`.", "question_id": 4751},
{"snippet": "Index.identical(other)", "intent": "Similar to equals , but checks that object attributes and types are also equal . With arguments `other`.", "question_id": 4752},
{"snippet": "Index.identical(other)", "intent": "Similar to equals , but checks that object attributes and types are also equal . With arguments `other`.", "question_id": 4753},
{"snippet": "Index.identical(other)", "intent": "Similar to equals , but checks that object attributes and types are also equal . With arguments `other`.", "question_id": 4754},
{"snippet": "Index.inferred_type", "intent": "Return a string of the type inferred from the values.", "question_id": 4755},
{"snippet": "Index.inferred_type", "intent": "Return a string of the type inferred from the values.", "question_id": 4756},
{"snippet": "Index.inferred_type", "intent": "Return a string of the type inferred from the values.", "question_id": 4757},
{"snippet": "Index.insert(loc, item)", "intent": "Make new Index inserting new `item` at location . With arguments `loc`.", "question_id": 4758},
{"snippet": "Index.insert(loc, item)", "intent": "Make new Index inserting new `item` at location . With arguments `loc`.", "question_id": 4759},
{"snippet": "Index.insert(loc, item)", "intent": "Make new Index inserting new `item` at location . With arguments `loc`.", "question_id": 4760},
{"snippet": "Index.intersection(other)", "intent": "Form the intersection of two Index objects . This returns a new Index with elements common to the index and `other` .", "question_id": 4761},
{"snippet": "Index.intersection(other, sort=False)", "intent": "Form the intersection of two Index objects . This returns a new Index with elements common to the index and `other` . With arguments `sort`.", "question_id": 4762},
{"snippet": "Index.intersection(other)", "intent": "Form the intersection of two Index objects . This returns a new Index with elements common to the index and `other` .", "question_id": 4763},
{"snippet": "Index.intersection(other, sort=False)", "intent": "Form the intersection of two Index objects . This returns a new Index with elements common to the index and `other` . With arguments `sort`.", "question_id": 4764},
{"snippet": "Index.intersection(other)", "intent": "Form the intersection of two Index objects . This returns a new Index with elements common to the index and `other` .", "question_id": 4765},
{"snippet": "Index.intersection(other, sort=False)", "intent": "Form the intersection of two Index objects . This returns a new Index with elements common to the index and `other` . With arguments `sort`.", "question_id": 4766},
{"snippet": "Index.is_(other)", "intent": "More flexible , faster check like is but that works through views . With arguments `other`.", "question_id": 4767},
{"snippet": "Index.is_(other)", "intent": "More flexible , faster check like is but that works through views . With arguments `other`.", "question_id": 4768},
{"snippet": "Index.is_(other)", "intent": "More flexible , faster check like is but that works through views . With arguments `other`.", "question_id": 4769},
{"snippet": "Index.is_all_dates", "intent": "Whether or not the index values only consist of dates.", "question_id": 4770},
{"snippet": "Index.is_all_dates", "intent": "Whether or not the index values only consist of dates.", "question_id": 4771},
{"snippet": "Index.is_all_dates", "intent": "Whether or not the index values only consist of dates.", "question_id": 4772},
{"snippet": "Index.is_boolean()", "intent": "Check if the Index only consists of booleans .", "question_id": 4773},
{"snippet": "Index.is_boolean()", "intent": "Check if the Index only consists of booleans .", "question_id": 4774},
{"snippet": "Index.is_boolean()", "intent": "Check if the Index only consists of booleans .", "question_id": 4775},
{"snippet": "Index.is_categorical()", "intent": "Check if the Index holds categorical data .", "question_id": 4776},
{"snippet": "Index.is_categorical()", "intent": "Check if the Index holds categorical data .", "question_id": 4777},
{"snippet": "Index.is_categorical()", "intent": "Check if the Index holds categorical data .", "question_id": 4778},
{"snippet": "Index.is_floating()", "intent": "Check if the Index is a floating type .", "question_id": 4779},
{"snippet": "Index.is_floating()", "intent": "Check if the Index is a floating type .", "question_id": 4780},
{"snippet": "Index.is_floating()", "intent": "Check if the Index is a floating type .", "question_id": 4781},
{"snippet": "Index.is_integer()", "intent": "Check if the Index only consists of integers .", "question_id": 4782},
{"snippet": "Index.is_integer()", "intent": "Check if the Index only consists of integers .", "question_id": 4783},
{"snippet": "Index.is_integer()", "intent": "Check if the Index only consists of integers .", "question_id": 4784},
{"snippet": "Index.is_interval()", "intent": "Check if the Index holds Interval objects .", "question_id": 4785},
{"snippet": "Index.is_interval()", "intent": "Check if the Index holds Interval objects .", "question_id": 4786},
{"snippet": "Index.is_interval()", "intent": "Check if the Index holds Interval objects .", "question_id": 4787},
{"snippet": "Index.is_mixed()", "intent": "Check if the Index holds data with mixed data types .", "question_id": 4788},
{"snippet": "Index.is_mixed()", "intent": "Check if the Index holds data with mixed data types .", "question_id": 4789},
{"snippet": "Index.is_mixed()", "intent": "Check if the Index holds data with mixed data types .", "question_id": 4790},
{"snippet": "Index.is_numeric()", "intent": "Check if the Index only consists of numeric data .", "question_id": 4791},
{"snippet": "Index.is_numeric()", "intent": "Check if the Index only consists of numeric data .", "question_id": 4792},
{"snippet": "Index.is_numeric()", "intent": "Check if the Index only consists of numeric data .", "question_id": 4793},
{"snippet": "Index.is_object()", "intent": "Check if the Index is of the object dtype .", "question_id": 4794},
{"snippet": "Index.is_object()", "intent": "Check if the Index is of the object dtype .", "question_id": 4795},
{"snippet": "Index.is_object()", "intent": "Check if the Index is of the object dtype .", "question_id": 4796},
{"snippet": "Index.is_type_compatible(kind)", "intent": "Whether the index type is compatible with the provided type . With arguments `kind`.", "question_id": 4797},
{"snippet": "Index.is_type_compatible(kind)", "intent": "Whether the index type is compatible with the provided type . With arguments `kind`.", "question_id": 4798},
{"snippet": "Index.is_type_compatible(kind)", "intent": "Whether the index type is compatible with the provided type . With arguments `kind`.", "question_id": 4799},
{"snippet": "Index.is_unique", "intent": "Return if the index has unique values.", "question_id": 4800},
{"snippet": "Index.is_unique", "intent": "Return if the index has unique values.", "question_id": 4801},
{"snippet": "Index.is_unique", "intent": "Return if the index has unique values.", "question_id": 4802},
{"snippet": "Index.isin(values)", "intent": "Return a boolean array where the index `values` are in values .", "question_id": 4803},
{"snippet": "Index.isin(values, level=None)", "intent": "Return a boolean array where the index `values` are in values . In the case of MultiIndex you must either specify values as a list-like object containing tuples that are the same length as the number of levels , or specify `level` .", "question_id": 4804},
{"snippet": "Index.isin(values)", "intent": "Return a boolean array where the index `values` are in values .", "question_id": 4805},
{"snippet": "Index.isin(values, level=None)", "intent": "Return a boolean array where the index `values` are in values . In the case of MultiIndex you must either specify values as a list-like object containing tuples that are the same length as the number of levels , or specify `level` .", "question_id": 4806},
{"snippet": "Index.isin(values)", "intent": "Return a boolean array where the index `values` are in values .", "question_id": 4807},
{"snippet": "Index.isin(values, level=None)", "intent": "Return a boolean array where the index `values` are in values . In the case of MultiIndex you must either specify values as a list-like object containing tuples that are the same length as the number of levels , or specify `level` .", "question_id": 4808},
{"snippet": "Index.isna()", "intent": "Detect missing values .", "question_id": 4809},
{"snippet": "Index.isna()", "intent": "Detect missing values .", "question_id": 4810},
{"snippet": "Index.isna()", "intent": "Detect missing values .", "question_id": 4811},
{"snippet": "Index.isnull()", "intent": "Detect missing values .", "question_id": 4812},
{"snippet": "Index.isnull()", "intent": "Detect missing values .", "question_id": 4813},
{"snippet": "Index.isnull()", "intent": "Detect missing values .", "question_id": 4814},
{"snippet": "Index.item()", "intent": "Return the first element of the underlying data as a Python scalar .", "question_id": 4815},
{"snippet": "Index.item()", "intent": "Return the first element of the underlying data as a Python scalar .", "question_id": 4816},
{"snippet": "Index.item()", "intent": "Return the first element of the underlying data as a Python scalar .", "question_id": 4817},
{"snippet": "Index.join(other)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`.", "question_id": 4818},
{"snippet": "Index.join(other, how='left')", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `how`.", "question_id": 4819},
{"snippet": "Index.join(other, level=None)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `level`.", "question_id": 4820},
{"snippet": "Index.join(other, return_indexers=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `return_indexers`.", "question_id": 4821},
{"snippet": "Index.join(other, sort=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `sort`.", "question_id": 4822},
{"snippet": "Index.join(other, how='left', level=None)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `how`, `level`.", "question_id": 4823},
{"snippet": "Index.join(other, how='left', return_indexers=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `how`, `return_indexers`.", "question_id": 4824},
{"snippet": "Index.join(other, how='left', sort=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `how`, `sort`.", "question_id": 4825},
{"snippet": "Index.join(other, level=None, return_indexers=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `level`, `return_indexers`.", "question_id": 4826},
{"snippet": "Index.join(other, level=None, sort=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `level`, `sort`.", "question_id": 4827},
{"snippet": "Index.join(other)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`.", "question_id": 4828},
{"snippet": "Index.join(other, how='left')", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `how`.", "question_id": 4829},
{"snippet": "Index.join(other, level=None)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `level`.", "question_id": 4830},
{"snippet": "Index.join(other, return_indexers=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `return_indexers`.", "question_id": 4831},
{"snippet": "Index.join(other, sort=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `sort`.", "question_id": 4832},
{"snippet": "Index.join(other, how='left', level=None)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `how`, `level`.", "question_id": 4833},
{"snippet": "Index.join(other, how='left', return_indexers=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `how`, `return_indexers`.", "question_id": 4834},
{"snippet": "Index.join(other, how='left', sort=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `how`, `sort`.", "question_id": 4835},
{"snippet": "Index.join(other, level=None, return_indexers=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `level`, `return_indexers`.", "question_id": 4836},
{"snippet": "Index.join(other, level=None, sort=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `level`, `sort`.", "question_id": 4837},
{"snippet": "Index.join(other)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`.", "question_id": 4838},
{"snippet": "Index.join(other, how='left')", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `how`.", "question_id": 4839},
{"snippet": "Index.join(other, level=None)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `level`.", "question_id": 4840},
{"snippet": "Index.join(other, return_indexers=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `return_indexers`.", "question_id": 4841},
{"snippet": "Index.join(other, sort=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `sort`.", "question_id": 4842},
{"snippet": "Index.join(other, how='left', level=None)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `how`, `level`.", "question_id": 4843},
{"snippet": "Index.join(other, how='left', return_indexers=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `how`, `return_indexers`.", "question_id": 4844},
{"snippet": "Index.join(other, how='left', sort=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `how`, `sort`.", "question_id": 4845},
{"snippet": "Index.join(other, level=None, return_indexers=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `level`, `return_indexers`.", "question_id": 4846},
{"snippet": "Index.join(other, level=None, sort=False)", "intent": "Compute join_index and indexers to conform data structures to the new index . With arguments `other`, `level`, `sort`.", "question_id": 4847},
{"snippet": "Index.map(mapper)", "intent": "Map values using input correspondence ( a dict , Series , or function ) . With arguments `mapper`.", "question_id": 4848},
{"snippet": "Index.map(mapper, na_action=None)", "intent": "Map values using input correspondence ( a dict , Series , or function ) . With arguments `mapper`, `na_action`.", "question_id": 4849},
{"snippet": "Index.map(mapper)", "intent": "Map values using input correspondence ( a dict , Series , or function ) . With arguments `mapper`.", "question_id": 4850},
{"snippet": "Index.map(mapper, na_action=None)", "intent": "Map values using input correspondence ( a dict , Series , or function ) . With arguments `mapper`, `na_action`.", "question_id": 4851},
{"snippet": "Index.map(mapper)", "intent": "Map values using input correspondence ( a dict , Series , or function ) . With arguments `mapper`.", "question_id": 4852},
{"snippet": "Index.map(mapper, na_action=None)", "intent": "Map values using input correspondence ( a dict , Series , or function ) . With arguments `mapper`, `na_action`.", "question_id": 4853},
{"snippet": "Index.max(*args, **kwargs)", "intent": "Return the maximum value of the Index . With arguments `*args`, `**kwargs`.", "question_id": 4854},
{"snippet": "Index.max(*args, **kwargs, axis=None)", "intent": "Return the maximum value of the Index . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 4855},
{"snippet": "Index.max(*args, **kwargs, skipna=True)", "intent": "Return the maximum value of the Index . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 4856},
{"snippet": "Index.max(*args, **kwargs, axis=None, skipna=True)", "intent": "Return the maximum value of the Index . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 4857},
{"snippet": "Index.max(*args, **kwargs)", "intent": "Return the maximum value of the Index . With arguments `*args`, `**kwargs`.", "question_id": 4858},
{"snippet": "Index.max(*args, **kwargs, axis=None)", "intent": "Return the maximum value of the Index . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 4859},
{"snippet": "Index.max(*args, **kwargs, skipna=True)", "intent": "Return the maximum value of the Index . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 4860},
{"snippet": "Index.max(*args, **kwargs, axis=None, skipna=True)", "intent": "Return the maximum value of the Index . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 4861},
{"snippet": "Index.max(*args, **kwargs)", "intent": "Return the maximum value of the Index . With arguments `*args`, `**kwargs`.", "question_id": 4862},
{"snippet": "Index.max(*args, **kwargs, axis=None)", "intent": "Return the maximum value of the Index . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 4863},
{"snippet": "Index.max(*args, **kwargs, skipna=True)", "intent": "Return the maximum value of the Index . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 4864},
{"snippet": "Index.max(*args, **kwargs, axis=None, skipna=True)", "intent": "Return the maximum value of the Index . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 4865},
{"snippet": "Index.memory_usage()", "intent": "Memory usage of the values .", "question_id": 4866},
{"snippet": "Index.memory_usage(deep=False)", "intent": "Memory usage of the values . With arguments `deep`.", "question_id": 4867},
{"snippet": "Index.memory_usage()", "intent": "Memory usage of the values .", "question_id": 4868},
{"snippet": "Index.memory_usage(deep=False)", "intent": "Memory usage of the values . With arguments `deep`.", "question_id": 4869},
{"snippet": "Index.memory_usage()", "intent": "Memory usage of the values .", "question_id": 4870},
{"snippet": "Index.memory_usage(deep=False)", "intent": "Memory usage of the values . With arguments `deep`.", "question_id": 4871},
{"snippet": "Index.min(*args, **kwargs)", "intent": "Return the minimum value of the Index . With arguments `*args`, `**kwargs`.", "question_id": 4872},
{"snippet": "Index.min(*args, **kwargs, axis=None)", "intent": "Return the minimum value of the Index . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 4873},
{"snippet": "Index.min(*args, **kwargs, skipna=True)", "intent": "Return the minimum value of the Index . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 4874},
{"snippet": "Index.min(*args, **kwargs, axis=None, skipna=True)", "intent": "Return the minimum value of the Index . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 4875},
{"snippet": "Index.min(*args, **kwargs)", "intent": "Return the minimum value of the Index . With arguments `*args`, `**kwargs`.", "question_id": 4876},
{"snippet": "Index.min(*args, **kwargs, axis=None)", "intent": "Return the minimum value of the Index . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 4877},
{"snippet": "Index.min(*args, **kwargs, skipna=True)", "intent": "Return the minimum value of the Index . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 4878},
{"snippet": "Index.min(*args, **kwargs, axis=None, skipna=True)", "intent": "Return the minimum value of the Index . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 4879},
{"snippet": "Index.min(*args, **kwargs)", "intent": "Return the minimum value of the Index . With arguments `*args`, `**kwargs`.", "question_id": 4880},
{"snippet": "Index.min(*args, **kwargs, axis=None)", "intent": "Return the minimum value of the Index . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 4881},
{"snippet": "Index.min(*args, **kwargs, skipna=True)", "intent": "Return the minimum value of the Index . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 4882},
{"snippet": "Index.min(*args, **kwargs, axis=None, skipna=True)", "intent": "Return the minimum value of the Index . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 4883},
{"snippet": "Index.notna()", "intent": "Detect existing ( non-missing ) values .", "question_id": 4884},
{"snippet": "Index.notna()", "intent": "Detect existing ( non-missing ) values .", "question_id": 4885},
{"snippet": "Index.notna()", "intent": "Detect existing ( non-missing ) values .", "question_id": 4886},
{"snippet": "Index.notnull()", "intent": "Detect existing ( non-missing ) values .", "question_id": 4887},
{"snippet": "Index.notnull()", "intent": "Detect existing ( non-missing ) values .", "question_id": 4888},
{"snippet": "Index.notnull()", "intent": "Detect existing ( non-missing ) values .", "question_id": 4889},
{"snippet": "Index.nunique()", "intent": "Return number of unique elements in the object .", "question_id": 4890},
{"snippet": "Index.nunique(dropna=True)", "intent": "Return number of unique elements in the object . With arguments `dropna`.", "question_id": 4891},
{"snippet": "Index.nunique()", "intent": "Return number of unique elements in the object .", "question_id": 4892},
{"snippet": "Index.nunique(dropna=True)", "intent": "Return number of unique elements in the object . With arguments `dropna`.", "question_id": 4893},
{"snippet": "Index.nunique()", "intent": "Return number of unique elements in the object .", "question_id": 4894},
{"snippet": "Index.nunique(dropna=True)", "intent": "Return number of unique elements in the object . With arguments `dropna`.", "question_id": 4895},
{"snippet": "Index.putmask(mask, value)", "intent": "Return a new Index of the values set with the `mask` . With arguments `value`.", "question_id": 4896},
{"snippet": "Index.putmask(mask, value)", "intent": "Return a new Index of the values set with the `mask` . With arguments `value`.", "question_id": 4897},
{"snippet": "Index.putmask(mask, value)", "intent": "Return a new Index of the values set with the `mask` . With arguments `value`.", "question_id": 4898},
{"snippet": "Index.ravel()", "intent": "Return an ndarray of the flattened values of the underlying data .", "question_id": 4899},
{"snippet": "Index.ravel(order='C')", "intent": "Return an ndarray of the flattened values of the underlying data . With arguments `order`.", "question_id": 4900},
{"snippet": "Index.ravel()", "intent": "Return an ndarray of the flattened values of the underlying data .", "question_id": 4901},
{"snippet": "Index.ravel(order='C')", "intent": "Return an ndarray of the flattened values of the underlying data . With arguments `order`.", "question_id": 4902},
{"snippet": "Index.ravel()", "intent": "Return an ndarray of the flattened values of the underlying data .", "question_id": 4903},
{"snippet": "Index.ravel(order='C')", "intent": "Return an ndarray of the flattened values of the underlying data . With arguments `order`.", "question_id": 4904},
{"snippet": "Index.reindex(target)", "intent": "Create index with `target` \u2019 s values .", "question_id": 4905},
{"snippet": "Index.reindex(target, method=None)", "intent": "Create index with `target` \u2019 s values . With arguments `method`.", "question_id": 4906},
{"snippet": "Index.reindex(target, level=None)", "intent": "Create index with `target` \u2019 s values . With arguments `level`.", "question_id": 4907},
{"snippet": "Index.reindex(target, limit=None)", "intent": "Create index with `target` \u2019 s values . With arguments `limit`.", "question_id": 4908},
{"snippet": "Index.reindex(target, tolerance=None)", "intent": "Create index with `target` \u2019 s values . With arguments `tolerance`.", "question_id": 4909},
{"snippet": "Index.reindex(target, method=None, level=None)", "intent": "Create index with `target` \u2019 s values . With arguments `method`, `level`.", "question_id": 4910},
{"snippet": "Index.reindex(target, method=None, limit=None)", "intent": "Create index with `target` \u2019 s values . With arguments `method`, `limit`.", "question_id": 4911},
{"snippet": "Index.reindex(target, method=None, tolerance=None)", "intent": "Create index with `target` \u2019 s values . With arguments `method`, `tolerance`.", "question_id": 4912},
{"snippet": "Index.reindex(target, level=None, limit=None)", "intent": "Create index with `target` \u2019 s values . With arguments `level`, `limit`.", "question_id": 4913},
{"snippet": "Index.reindex(target, level=None, tolerance=None)", "intent": "Create index with `target` \u2019 s values . With arguments `level`, `tolerance`.", "question_id": 4914},
{"snippet": "Index.reindex(target)", "intent": "Create index with `target` \u2019 s values .", "question_id": 4915},
{"snippet": "Index.reindex(target, method=None)", "intent": "Create index with `target` \u2019 s values . With arguments `method`.", "question_id": 4916},
{"snippet": "Index.reindex(target, level=None)", "intent": "Create index with `target` \u2019 s values . With arguments `level`.", "question_id": 4917},
{"snippet": "Index.reindex(target, limit=None)", "intent": "Create index with `target` \u2019 s values . With arguments `limit`.", "question_id": 4918},
{"snippet": "Index.reindex(target, tolerance=None)", "intent": "Create index with `target` \u2019 s values . With arguments `tolerance`.", "question_id": 4919},
{"snippet": "Index.reindex(target, method=None, level=None)", "intent": "Create index with `target` \u2019 s values . With arguments `method`, `level`.", "question_id": 4920},
{"snippet": "Index.reindex(target, method=None, limit=None)", "intent": "Create index with `target` \u2019 s values . With arguments `method`, `limit`.", "question_id": 4921},
{"snippet": "Index.reindex(target, method=None, tolerance=None)", "intent": "Create index with `target` \u2019 s values . With arguments `method`, `tolerance`.", "question_id": 4922},
{"snippet": "Index.reindex(target, level=None, limit=None)", "intent": "Create index with `target` \u2019 s values . With arguments `level`, `limit`.", "question_id": 4923},
{"snippet": "Index.reindex(target, level=None, tolerance=None)", "intent": "Create index with `target` \u2019 s values . With arguments `level`, `tolerance`.", "question_id": 4924},
{"snippet": "Index.reindex(target)", "intent": "Create index with `target` \u2019 s values .", "question_id": 4925},
{"snippet": "Index.reindex(target, method=None)", "intent": "Create index with `target` \u2019 s values . With arguments `method`.", "question_id": 4926},
{"snippet": "Index.reindex(target, level=None)", "intent": "Create index with `target` \u2019 s values . With arguments `level`.", "question_id": 4927},
{"snippet": "Index.reindex(target, limit=None)", "intent": "Create index with `target` \u2019 s values . With arguments `limit`.", "question_id": 4928},
{"snippet": "Index.reindex(target, tolerance=None)", "intent": "Create index with `target` \u2019 s values . With arguments `tolerance`.", "question_id": 4929},
{"snippet": "Index.reindex(target, method=None, level=None)", "intent": "Create index with `target` \u2019 s values . With arguments `method`, `level`.", "question_id": 4930},
{"snippet": "Index.reindex(target, method=None, limit=None)", "intent": "Create index with `target` \u2019 s values . With arguments `method`, `limit`.", "question_id": 4931},
{"snippet": "Index.reindex(target, method=None, tolerance=None)", "intent": "Create index with `target` \u2019 s values . With arguments `method`, `tolerance`.", "question_id": 4932},
{"snippet": "Index.reindex(target, level=None, limit=None)", "intent": "Create index with `target` \u2019 s values . With arguments `level`, `limit`.", "question_id": 4933},
{"snippet": "Index.reindex(target, level=None, tolerance=None)", "intent": "Create index with `target` \u2019 s values . With arguments `level`, `tolerance`.", "question_id": 4934},
{"snippet": "Index.rename(name)", "intent": "Alter Index or MultiIndex `name` .", "question_id": 4935},
{"snippet": "Index.rename(name, inplace=False)", "intent": "Alter Index or MultiIndex `name` . With arguments `inplace`.", "question_id": 4936},
{"snippet": "Index.rename(name)", "intent": "Alter Index or MultiIndex `name` .", "question_id": 4937},
{"snippet": "Index.rename(name, inplace=False)", "intent": "Alter Index or MultiIndex `name` . With arguments `inplace`.", "question_id": 4938},
{"snippet": "Index.rename(name)", "intent": "Alter Index or MultiIndex `name` .", "question_id": 4939},
{"snippet": "Index.rename(name, inplace=False)", "intent": "Alter Index or MultiIndex `name` . With arguments `inplace`.", "question_id": 4940},
{"snippet": "Index.repeat(repeats)", "intent": "Repeat elements of a Index . With arguments `repeats`.", "question_id": 4941},
{"snippet": "Index.repeat(repeats, axis=None)", "intent": "Repeat elements of a Index . With arguments `repeats`, `axis`.", "question_id": 4942},
{"snippet": "Index.repeat(repeats)", "intent": "Repeat elements of a Index . With arguments `repeats`.", "question_id": 4943},
{"snippet": "Index.repeat(repeats, axis=None)", "intent": "Repeat elements of a Index . With arguments `repeats`, `axis`.", "question_id": 4944},
{"snippet": "Index.repeat(repeats)", "intent": "Repeat elements of a Index . With arguments `repeats`.", "question_id": 4945},
{"snippet": "Index.repeat(repeats, axis=None)", "intent": "Repeat elements of a Index . With arguments `repeats`, `axis`.", "question_id": 4946},
{"snippet": "Index.searchsorted(value)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Index self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved .", "question_id": 4947},
{"snippet": "Index.searchsorted(value, side='left')", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Index self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`.", "question_id": 4948},
{"snippet": "Index.searchsorted(value, sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Index self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `sorter`.", "question_id": 4949},
{"snippet": "Index.searchsorted(value, side='left', sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Index self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`, `sorter`.", "question_id": 4950},
{"snippet": "Index.searchsorted(value)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Index self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved .", "question_id": 4951},
{"snippet": "Index.searchsorted(value, side='left')", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Index self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`.", "question_id": 4952},
{"snippet": "Index.searchsorted(value, sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Index self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `sorter`.", "question_id": 4953},
{"snippet": "Index.searchsorted(value, side='left', sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Index self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`, `sorter`.", "question_id": 4954},
{"snippet": "Index.searchsorted(value)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Index self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved .", "question_id": 4955},
{"snippet": "Index.searchsorted(value, side='left')", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Index self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`.", "question_id": 4956},
{"snippet": "Index.searchsorted(value, sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Index self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `sorter`.", "question_id": 4957},
{"snippet": "Index.searchsorted(value, side='left', sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Index self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`, `sorter`.", "question_id": 4958},
{"snippet": "Index.set_names(names)", "intent": "Set Index or MultiIndex name . Able to set new `names` partially and by `level` .", "question_id": 4959},
{"snippet": "Index.set_names(names, level=None)", "intent": "Set Index or MultiIndex name . Able to set new `names` partially and by `level` .", "question_id": 4960},
{"snippet": "Index.set_names(names, inplace=False)", "intent": "Set Index or MultiIndex name . Able to set new `names` partially and by `level` . With arguments `inplace`.", "question_id": 4961},
{"snippet": "Index.set_names(names, level=None, inplace=False)", "intent": "Set Index or MultiIndex name . Able to set new `names` partially and by `level` . With arguments `inplace`.", "question_id": 4962},
{"snippet": "Index.set_names(names)", "intent": "Set Index or MultiIndex name . Able to set new `names` partially and by `level` .", "question_id": 4963},
{"snippet": "Index.set_names(names, level=None)", "intent": "Set Index or MultiIndex name . Able to set new `names` partially and by `level` .", "question_id": 4964},
{"snippet": "Index.set_names(names, inplace=False)", "intent": "Set Index or MultiIndex name . Able to set new `names` partially and by `level` . With arguments `inplace`.", "question_id": 4965},
{"snippet": "Index.set_names(names, level=None, inplace=False)", "intent": "Set Index or MultiIndex name . Able to set new `names` partially and by `level` . With arguments `inplace`.", "question_id": 4966},
{"snippet": "Index.set_names(names)", "intent": "Set Index or MultiIndex name . Able to set new `names` partially and by `level` .", "question_id": 4967},
{"snippet": "Index.set_names(names, level=None)", "intent": "Set Index or MultiIndex name . Able to set new `names` partially and by `level` .", "question_id": 4968},
{"snippet": "Index.set_names(names, inplace=False)", "intent": "Set Index or MultiIndex name . Able to set new `names` partially and by `level` . With arguments `inplace`.", "question_id": 4969},
{"snippet": "Index.set_names(names, level=None, inplace=False)", "intent": "Set Index or MultiIndex name . Able to set new `names` partially and by `level` . With arguments `inplace`.", "question_id": 4970},
{"snippet": "Index.set_value(arr, key, value)", "intent": "Fast lookup of `value` from 1-dimensional ndarray . With arguments `arr`, `key`.", "question_id": 4971},
{"snippet": "Index.set_value(arr, key, value)", "intent": "Fast lookup of `value` from 1-dimensional ndarray . With arguments `arr`, `key`.", "question_id": 4972},
{"snippet": "Index.set_value(arr, key, value)", "intent": "Fast lookup of `value` from 1-dimensional ndarray . With arguments `arr`, `key`.", "question_id": 4973},
{"snippet": "Index.shift()", "intent": "Shift index by desired number of time frequency increments .", "question_id": 4974},
{"snippet": "Index.shift(periods=1)", "intent": "Shift index by desired number of time frequency increments . With arguments `periods`.", "question_id": 4975},
{"snippet": "Index.shift(freq=None)", "intent": "Shift index by desired number of time frequency increments . The default value of `freq` is the freq attribute of the index , which is \u2018 MS \u2019 ( month start ) in this example .", "question_id": 4976},
{"snippet": "Index.shift(periods=1, freq=None)", "intent": "Shift index by desired number of time frequency increments . The default value of `freq` is the freq attribute of the index , which is \u2018 MS \u2019 ( month start ) in this example . With arguments `periods`.", "question_id": 4977},
{"snippet": "Index.shift()", "intent": "Shift index by desired number of time frequency increments .", "question_id": 4978},
{"snippet": "Index.shift(periods=1)", "intent": "Shift index by desired number of time frequency increments . With arguments `periods`.", "question_id": 4979},
{"snippet": "Index.shift(freq=None)", "intent": "Shift index by desired number of time frequency increments . The default value of `freq` is the freq attribute of the index , which is \u2018 MS \u2019 ( month start ) in this example .", "question_id": 4980},
{"snippet": "Index.shift(periods=1, freq=None)", "intent": "Shift index by desired number of time frequency increments . The default value of `freq` is the freq attribute of the index , which is \u2018 MS \u2019 ( month start ) in this example . With arguments `periods`.", "question_id": 4981},
{"snippet": "Index.shift()", "intent": "Shift index by desired number of time frequency increments .", "question_id": 4982},
{"snippet": "Index.shift(periods=1)", "intent": "Shift index by desired number of time frequency increments . With arguments `periods`.", "question_id": 4983},
{"snippet": "Index.shift(freq=None)", "intent": "Shift index by desired number of time frequency increments . The default value of `freq` is the freq attribute of the index , which is \u2018 MS \u2019 ( month start ) in this example .", "question_id": 4984},
{"snippet": "Index.shift(periods=1, freq=None)", "intent": "Shift index by desired number of time frequency increments . The default value of `freq` is the freq attribute of the index , which is \u2018 MS \u2019 ( month start ) in this example . With arguments `periods`.", "question_id": 4985},
{"snippet": "Index.slice_indexer()", "intent": "Compute the slice indexer for input labels and `step` .", "question_id": 4986},
{"snippet": "Index.slice_indexer(start=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `start`.", "question_id": 4987},
{"snippet": "Index.slice_indexer(end=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `end`.", "question_id": 4988},
{"snippet": "Index.slice_indexer(step=None)", "intent": "Compute the slice indexer for input labels and `step` .", "question_id": 4989},
{"snippet": "Index.slice_indexer(kind=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `kind`.", "question_id": 4990},
{"snippet": "Index.slice_indexer(start=None, end=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `start`, `end`.", "question_id": 4991},
{"snippet": "Index.slice_indexer(start=None, step=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `start`.", "question_id": 4992},
{"snippet": "Index.slice_indexer(start=None, kind=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `start`, `kind`.", "question_id": 4993},
{"snippet": "Index.slice_indexer(end=None, step=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `end`.", "question_id": 4994},
{"snippet": "Index.slice_indexer(end=None, kind=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `end`, `kind`.", "question_id": 4995},
{"snippet": "Index.slice_indexer()", "intent": "Compute the slice indexer for input labels and `step` .", "question_id": 4996},
{"snippet": "Index.slice_indexer(start=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `start`.", "question_id": 4997},
{"snippet": "Index.slice_indexer(end=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `end`.", "question_id": 4998},
{"snippet": "Index.slice_indexer(step=None)", "intent": "Compute the slice indexer for input labels and `step` .", "question_id": 4999},
{"snippet": "Index.slice_indexer(kind=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `kind`.", "question_id": 5000},
{"snippet": "Index.slice_indexer(start=None, end=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `start`, `end`.", "question_id": 5001},
{"snippet": "Index.slice_indexer(start=None, step=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `start`.", "question_id": 5002},
{"snippet": "Index.slice_indexer(start=None, kind=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `start`, `kind`.", "question_id": 5003},
{"snippet": "Index.slice_indexer(end=None, step=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `end`.", "question_id": 5004},
{"snippet": "Index.slice_indexer(end=None, kind=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `end`, `kind`.", "question_id": 5005},
{"snippet": "Index.slice_indexer()", "intent": "Compute the slice indexer for input labels and `step` .", "question_id": 5006},
{"snippet": "Index.slice_indexer(start=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `start`.", "question_id": 5007},
{"snippet": "Index.slice_indexer(end=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `end`.", "question_id": 5008},
{"snippet": "Index.slice_indexer(step=None)", "intent": "Compute the slice indexer for input labels and `step` .", "question_id": 5009},
{"snippet": "Index.slice_indexer(kind=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `kind`.", "question_id": 5010},
{"snippet": "Index.slice_indexer(start=None, end=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `start`, `end`.", "question_id": 5011},
{"snippet": "Index.slice_indexer(start=None, step=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `start`.", "question_id": 5012},
{"snippet": "Index.slice_indexer(start=None, kind=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `start`, `kind`.", "question_id": 5013},
{"snippet": "Index.slice_indexer(end=None, step=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `end`.", "question_id": 5014},
{"snippet": "Index.slice_indexer(end=None, kind=None)", "intent": "Compute the slice indexer for input labels and `step` . With arguments `end`, `kind`.", "question_id": 5015},
{"snippet": "Index.slice_locs()", "intent": "Compute slice locations for input labels .", "question_id": 5016},
{"snippet": "Index.slice_locs(start=None)", "intent": "Compute slice locations for input labels . With arguments `start`.", "question_id": 5017},
{"snippet": "Index.slice_locs(end=None)", "intent": "Compute slice locations for input labels . With arguments `end`.", "question_id": 5018},
{"snippet": "Index.slice_locs(step=None)", "intent": "Compute slice locations for input labels . With arguments `step`.", "question_id": 5019},
{"snippet": "Index.slice_locs(kind=None)", "intent": "Compute slice locations for input labels . With arguments `kind`.", "question_id": 5020},
{"snippet": "Index.slice_locs(start=None, end=None)", "intent": "Compute slice locations for input labels . With arguments `start`, `end`.", "question_id": 5021},
{"snippet": "Index.slice_locs(start=None, step=None)", "intent": "Compute slice locations for input labels . With arguments `start`, `step`.", "question_id": 5022},
{"snippet": "Index.slice_locs(start=None, kind=None)", "intent": "Compute slice locations for input labels . With arguments `start`, `kind`.", "question_id": 5023},
{"snippet": "Index.slice_locs(end=None, step=None)", "intent": "Compute slice locations for input labels . With arguments `end`, `step`.", "question_id": 5024},
{"snippet": "Index.slice_locs(end=None, kind=None)", "intent": "Compute slice locations for input labels . With arguments `end`, `kind`.", "question_id": 5025},
{"snippet": "Index.slice_locs()", "intent": "Compute slice locations for input labels .", "question_id": 5026},
{"snippet": "Index.slice_locs(start=None)", "intent": "Compute slice locations for input labels . With arguments `start`.", "question_id": 5027},
{"snippet": "Index.slice_locs(end=None)", "intent": "Compute slice locations for input labels . With arguments `end`.", "question_id": 5028},
{"snippet": "Index.slice_locs(step=None)", "intent": "Compute slice locations for input labels . With arguments `step`.", "question_id": 5029},
{"snippet": "Index.slice_locs(kind=None)", "intent": "Compute slice locations for input labels . With arguments `kind`.", "question_id": 5030},
{"snippet": "Index.slice_locs(start=None, end=None)", "intent": "Compute slice locations for input labels . With arguments `start`, `end`.", "question_id": 5031},
{"snippet": "Index.slice_locs(start=None, step=None)", "intent": "Compute slice locations for input labels . With arguments `start`, `step`.", "question_id": 5032},
{"snippet": "Index.slice_locs(start=None, kind=None)", "intent": "Compute slice locations for input labels . With arguments `start`, `kind`.", "question_id": 5033},
{"snippet": "Index.slice_locs(end=None, step=None)", "intent": "Compute slice locations for input labels . With arguments `end`, `step`.", "question_id": 5034},
{"snippet": "Index.slice_locs(end=None, kind=None)", "intent": "Compute slice locations for input labels . With arguments `end`, `kind`.", "question_id": 5035},
{"snippet": "Index.slice_locs()", "intent": "Compute slice locations for input labels .", "question_id": 5036},
{"snippet": "Index.slice_locs(start=None)", "intent": "Compute slice locations for input labels . With arguments `start`.", "question_id": 5037},
{"snippet": "Index.slice_locs(end=None)", "intent": "Compute slice locations for input labels . With arguments `end`.", "question_id": 5038},
{"snippet": "Index.slice_locs(step=None)", "intent": "Compute slice locations for input labels . With arguments `step`.", "question_id": 5039},
{"snippet": "Index.slice_locs(kind=None)", "intent": "Compute slice locations for input labels . With arguments `kind`.", "question_id": 5040},
{"snippet": "Index.slice_locs(start=None, end=None)", "intent": "Compute slice locations for input labels . With arguments `start`, `end`.", "question_id": 5041},
{"snippet": "Index.slice_locs(start=None, step=None)", "intent": "Compute slice locations for input labels . With arguments `start`, `step`.", "question_id": 5042},
{"snippet": "Index.slice_locs(start=None, kind=None)", "intent": "Compute slice locations for input labels . With arguments `start`, `kind`.", "question_id": 5043},
{"snippet": "Index.slice_locs(end=None, step=None)", "intent": "Compute slice locations for input labels . With arguments `end`, `step`.", "question_id": 5044},
{"snippet": "Index.slice_locs(end=None, kind=None)", "intent": "Compute slice locations for input labels . With arguments `end`, `kind`.", "question_id": 5045},
{"snippet": "Index.sort(*args, **kwargs)", "intent": "Use sort_values instead . With arguments `*args`, `**kwargs`.", "question_id": 5046},
{"snippet": "Index.sort(*args, **kwargs)", "intent": "Use sort_values instead . With arguments `*args`, `**kwargs`.", "question_id": 5047},
{"snippet": "Index.sort(*args, **kwargs)", "intent": "Use sort_values instead . With arguments `*args`, `**kwargs`.", "question_id": 5048},
{"snippet": "Index.sort_values()", "intent": "Return a sorted copy of the index .", "question_id": 5049},
{"snippet": "Index.sort_values(return_indexer=False)", "intent": "Return a sorted copy of the index . With arguments `return_indexer`.", "question_id": 5050},
{"snippet": "Index.sort_values(ascending=True)", "intent": "Return a sorted copy of the index . Sort values in `ascending` order ( default behavior ) .", "question_id": 5051},
{"snippet": "Index.sort_values(na_position='last')", "intent": "Return a sorted copy of the index . With arguments `na_position`.", "question_id": 5052},
{"snippet": "Index.sort_values(key=None)", "intent": "Return a sorted copy of the index . With arguments `key`.", "question_id": 5053},
{"snippet": "Index.sort_values(return_indexer=False, ascending=True)", "intent": "Return a sorted copy of the index . Sort values in `ascending` order ( default behavior ) . With arguments `return_indexer`.", "question_id": 5054},
{"snippet": "Index.sort_values(return_indexer=False, na_position='last')", "intent": "Return a sorted copy of the index . With arguments `return_indexer`, `na_position`.", "question_id": 5055},
{"snippet": "Index.sort_values(return_indexer=False, key=None)", "intent": "Return a sorted copy of the index . With arguments `return_indexer`, `key`.", "question_id": 5056},
{"snippet": "Index.sort_values(ascending=True, na_position='last')", "intent": "Return a sorted copy of the index . Sort values in `ascending` order ( default behavior ) . With arguments `na_position`.", "question_id": 5057},
{"snippet": "Index.sort_values(ascending=True, key=None)", "intent": "Return a sorted copy of the index . Sort values in `ascending` order ( default behavior ) . With arguments `key`.", "question_id": 5058},
{"snippet": "Index.sort_values()", "intent": "Return a sorted copy of the index .", "question_id": 5059},
{"snippet": "Index.sort_values(return_indexer=False)", "intent": "Return a sorted copy of the index . With arguments `return_indexer`.", "question_id": 5060},
{"snippet": "Index.sort_values(ascending=True)", "intent": "Return a sorted copy of the index . Sort values in `ascending` order ( default behavior ) .", "question_id": 5061},
{"snippet": "Index.sort_values(na_position='last')", "intent": "Return a sorted copy of the index . With arguments `na_position`.", "question_id": 5062},
{"snippet": "Index.sort_values(key=None)", "intent": "Return a sorted copy of the index . With arguments `key`.", "question_id": 5063},
{"snippet": "Index.sort_values(return_indexer=False, ascending=True)", "intent": "Return a sorted copy of the index . Sort values in `ascending` order ( default behavior ) . With arguments `return_indexer`.", "question_id": 5064},
{"snippet": "Index.sort_values(return_indexer=False, na_position='last')", "intent": "Return a sorted copy of the index . With arguments `return_indexer`, `na_position`.", "question_id": 5065},
{"snippet": "Index.sort_values(return_indexer=False, key=None)", "intent": "Return a sorted copy of the index . With arguments `return_indexer`, `key`.", "question_id": 5066},
{"snippet": "Index.sort_values(ascending=True, na_position='last')", "intent": "Return a sorted copy of the index . Sort values in `ascending` order ( default behavior ) . With arguments `na_position`.", "question_id": 5067},
{"snippet": "Index.sort_values(ascending=True, key=None)", "intent": "Return a sorted copy of the index . Sort values in `ascending` order ( default behavior ) . With arguments `key`.", "question_id": 5068},
{"snippet": "Index.sort_values()", "intent": "Return a sorted copy of the index .", "question_id": 5069},
{"snippet": "Index.sort_values(return_indexer=False)", "intent": "Return a sorted copy of the index . With arguments `return_indexer`.", "question_id": 5070},
{"snippet": "Index.sort_values(ascending=True)", "intent": "Return a sorted copy of the index . Sort values in `ascending` order ( default behavior ) .", "question_id": 5071},
{"snippet": "Index.sort_values(na_position='last')", "intent": "Return a sorted copy of the index . With arguments `na_position`.", "question_id": 5072},
{"snippet": "Index.sort_values(key=None)", "intent": "Return a sorted copy of the index . With arguments `key`.", "question_id": 5073},
{"snippet": "Index.sort_values(return_indexer=False, ascending=True)", "intent": "Return a sorted copy of the index . Sort values in `ascending` order ( default behavior ) . With arguments `return_indexer`.", "question_id": 5074},
{"snippet": "Index.sort_values(return_indexer=False, na_position='last')", "intent": "Return a sorted copy of the index . With arguments `return_indexer`, `na_position`.", "question_id": 5075},
{"snippet": "Index.sort_values(return_indexer=False, key=None)", "intent": "Return a sorted copy of the index . With arguments `return_indexer`, `key`.", "question_id": 5076},
{"snippet": "Index.sort_values(ascending=True, na_position='last')", "intent": "Return a sorted copy of the index . Sort values in `ascending` order ( default behavior ) . With arguments `na_position`.", "question_id": 5077},
{"snippet": "Index.sort_values(ascending=True, key=None)", "intent": "Return a sorted copy of the index . Sort values in `ascending` order ( default behavior ) . With arguments `key`.", "question_id": 5078},
{"snippet": "Index.sortlevel()", "intent": "For internal compatibility with the Index API .", "question_id": 5079},
{"snippet": "Index.sortlevel(level=None)", "intent": "For internal compatibility with the Index API . With arguments `level`.", "question_id": 5080},
{"snippet": "Index.sortlevel(ascending=True)", "intent": "For internal compatibility with the Index API . With arguments `ascending`.", "question_id": 5081},
{"snippet": "Index.sortlevel(sort_remaining=None)", "intent": "For internal compatibility with the Index API . With arguments `sort_remaining`.", "question_id": 5082},
{"snippet": "Index.sortlevel(level=None, ascending=True)", "intent": "For internal compatibility with the Index API . With arguments `level`, `ascending`.", "question_id": 5083},
{"snippet": "Index.sortlevel(level=None, sort_remaining=None)", "intent": "For internal compatibility with the Index API . With arguments `level`, `sort_remaining`.", "question_id": 5084},
{"snippet": "Index.sortlevel(ascending=True, sort_remaining=None)", "intent": "For internal compatibility with the Index API . With arguments `ascending`, `sort_remaining`.", "question_id": 5085},
{"snippet": "Index.sortlevel(level=None, ascending=True, sort_remaining=None)", "intent": "For internal compatibility with the Index API . With arguments `level`, `ascending`, `sort_remaining`.", "question_id": 5086},
{"snippet": "Index.sortlevel()", "intent": "For internal compatibility with the Index API .", "question_id": 5087},
{"snippet": "Index.sortlevel(level=None)", "intent": "For internal compatibility with the Index API . With arguments `level`.", "question_id": 5088},
{"snippet": "Index.sortlevel(ascending=True)", "intent": "For internal compatibility with the Index API . With arguments `ascending`.", "question_id": 5089},
{"snippet": "Index.sortlevel(sort_remaining=None)", "intent": "For internal compatibility with the Index API . With arguments `sort_remaining`.", "question_id": 5090},
{"snippet": "Index.sortlevel(level=None, ascending=True)", "intent": "For internal compatibility with the Index API . With arguments `level`, `ascending`.", "question_id": 5091},
{"snippet": "Index.sortlevel(level=None, sort_remaining=None)", "intent": "For internal compatibility with the Index API . With arguments `level`, `sort_remaining`.", "question_id": 5092},
{"snippet": "Index.sortlevel(ascending=True, sort_remaining=None)", "intent": "For internal compatibility with the Index API . With arguments `ascending`, `sort_remaining`.", "question_id": 5093},
{"snippet": "Index.sortlevel(level=None, ascending=True, sort_remaining=None)", "intent": "For internal compatibility with the Index API . With arguments `level`, `ascending`, `sort_remaining`.", "question_id": 5094},
{"snippet": "Index.sortlevel()", "intent": "For internal compatibility with the Index API .", "question_id": 5095},
{"snippet": "Index.sortlevel(level=None)", "intent": "For internal compatibility with the Index API . With arguments `level`.", "question_id": 5096},
{"snippet": "Index.sortlevel(ascending=True)", "intent": "For internal compatibility with the Index API . With arguments `ascending`.", "question_id": 5097},
{"snippet": "Index.sortlevel(sort_remaining=None)", "intent": "For internal compatibility with the Index API . With arguments `sort_remaining`.", "question_id": 5098},
{"snippet": "Index.sortlevel(level=None, ascending=True)", "intent": "For internal compatibility with the Index API . With arguments `level`, `ascending`.", "question_id": 5099},
{"snippet": "Index.sortlevel(level=None, sort_remaining=None)", "intent": "For internal compatibility with the Index API . With arguments `level`, `sort_remaining`.", "question_id": 5100},
{"snippet": "Index.sortlevel(ascending=True, sort_remaining=None)", "intent": "For internal compatibility with the Index API . With arguments `ascending`, `sort_remaining`.", "question_id": 5101},
{"snippet": "Index.sortlevel(level=None, ascending=True, sort_remaining=None)", "intent": "For internal compatibility with the Index API . With arguments `level`, `ascending`, `sort_remaining`.", "question_id": 5102},
{"snippet": "Index.str()", "intent": "Vectorized string functions for Series and Index .", "question_id": 5103},
{"snippet": "Index.str()", "intent": "Vectorized string functions for Series and Index .", "question_id": 5104},
{"snippet": "Index.str()", "intent": "Vectorized string functions for Series and Index .", "question_id": 5105},
{"snippet": "Index.symmetric_difference(other)", "intent": "Compute the symmetric difference of two Index objects . With arguments `other`.", "question_id": 5106},
{"snippet": "Index.symmetric_difference(other, result_name=None)", "intent": "Compute the symmetric difference of two Index objects . With arguments `other`, `result_name`.", "question_id": 5107},
{"snippet": "Index.symmetric_difference(other, sort=None)", "intent": "Compute the symmetric difference of two Index objects . With arguments `other`, `sort`.", "question_id": 5108},
{"snippet": "Index.symmetric_difference(other, result_name=None, sort=None)", "intent": "Compute the symmetric difference of two Index objects . With arguments `other`, `result_name`, `sort`.", "question_id": 5109},
{"snippet": "Index.symmetric_difference(other)", "intent": "Compute the symmetric difference of two Index objects . With arguments `other`.", "question_id": 5110},
{"snippet": "Index.symmetric_difference(other, result_name=None)", "intent": "Compute the symmetric difference of two Index objects . With arguments `other`, `result_name`.", "question_id": 5111},
{"snippet": "Index.symmetric_difference(other, sort=None)", "intent": "Compute the symmetric difference of two Index objects . With arguments `other`, `sort`.", "question_id": 5112},
{"snippet": "Index.symmetric_difference(other, result_name=None, sort=None)", "intent": "Compute the symmetric difference of two Index objects . With arguments `other`, `result_name`, `sort`.", "question_id": 5113},
{"snippet": "Index.symmetric_difference(other)", "intent": "Compute the symmetric difference of two Index objects . With arguments `other`.", "question_id": 5114},
{"snippet": "Index.symmetric_difference(other, result_name=None)", "intent": "Compute the symmetric difference of two Index objects . With arguments `other`, `result_name`.", "question_id": 5115},
{"snippet": "Index.symmetric_difference(other, sort=None)", "intent": "Compute the symmetric difference of two Index objects . With arguments `other`, `sort`.", "question_id": 5116},
{"snippet": "Index.symmetric_difference(other, result_name=None, sort=None)", "intent": "Compute the symmetric difference of two Index objects . With arguments `other`, `result_name`, `sort`.", "question_id": 5117},
{"snippet": "Index.take(indices, **kwargs)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`.", "question_id": 5118},
{"snippet": "Index.take(indices, **kwargs, axis=0)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `axis`.", "question_id": 5119},
{"snippet": "Index.take(indices, **kwargs, allow_fill=True)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `allow_fill`.", "question_id": 5120},
{"snippet": "Index.take(indices, **kwargs, fill_value=None)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `fill_value`.", "question_id": 5121},
{"snippet": "Index.take(indices, **kwargs, axis=0, allow_fill=True)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `axis`, `allow_fill`.", "question_id": 5122},
{"snippet": "Index.take(indices, **kwargs, axis=0, fill_value=None)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `axis`, `fill_value`.", "question_id": 5123},
{"snippet": "Index.take(indices, **kwargs, allow_fill=True, fill_value=None)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `allow_fill`, `fill_value`.", "question_id": 5124},
{"snippet": "Index.take(indices, **kwargs, axis=0, allow_fill=True, fill_value=None)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `axis`, `allow_fill`, `fill_value`.", "question_id": 5125},
{"snippet": "Index.take(indices, **kwargs)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`.", "question_id": 5126},
{"snippet": "Index.take(indices, **kwargs, axis=0)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `axis`.", "question_id": 5127},
{"snippet": "Index.take(indices, **kwargs, allow_fill=True)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `allow_fill`.", "question_id": 5128},
{"snippet": "Index.take(indices, **kwargs, fill_value=None)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `fill_value`.", "question_id": 5129},
{"snippet": "Index.take(indices, **kwargs, axis=0, allow_fill=True)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `axis`, `allow_fill`.", "question_id": 5130},
{"snippet": "Index.take(indices, **kwargs, axis=0, fill_value=None)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `axis`, `fill_value`.", "question_id": 5131},
{"snippet": "Index.take(indices, **kwargs, allow_fill=True, fill_value=None)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `allow_fill`, `fill_value`.", "question_id": 5132},
{"snippet": "Index.take(indices, **kwargs, axis=0, allow_fill=True, fill_value=None)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `axis`, `allow_fill`, `fill_value`.", "question_id": 5133},
{"snippet": "Index.take(indices, **kwargs)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`.", "question_id": 5134},
{"snippet": "Index.take(indices, **kwargs, axis=0)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `axis`.", "question_id": 5135},
{"snippet": "Index.take(indices, **kwargs, allow_fill=True)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `allow_fill`.", "question_id": 5136},
{"snippet": "Index.take(indices, **kwargs, fill_value=None)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `fill_value`.", "question_id": 5137},
{"snippet": "Index.take(indices, **kwargs, axis=0, allow_fill=True)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `axis`, `allow_fill`.", "question_id": 5138},
{"snippet": "Index.take(indices, **kwargs, axis=0, fill_value=None)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `axis`, `fill_value`.", "question_id": 5139},
{"snippet": "Index.take(indices, **kwargs, allow_fill=True, fill_value=None)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `allow_fill`, `fill_value`.", "question_id": 5140},
{"snippet": "Index.take(indices, **kwargs, axis=0, allow_fill=True, fill_value=None)", "intent": "Return a new Index of the values selected by the `indices` . With arguments `**kwargs`, `axis`, `allow_fill`, `fill_value`.", "question_id": 5141},
{"snippet": "Index.to_flat_index()", "intent": "Identity method .", "question_id": 5142},
{"snippet": "Index.to_flat_index()", "intent": "Identity method .", "question_id": 5143},
{"snippet": "Index.to_flat_index()", "intent": "Identity method .", "question_id": 5144},
{"snippet": "Index.to_frame()", "intent": "Create a DataFrame with a column containing the Index .", "question_id": 5145},
{"snippet": "Index.to_frame(index=True)", "intent": "Create a DataFrame with a column containing the Index . With arguments `index`.", "question_id": 5146},
{"snippet": "Index.to_frame(name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name :", "question_id": 5147},
{"snippet": "Index.to_frame(index=True, name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name : With arguments `index`.", "question_id": 5148},
{"snippet": "Index.to_frame()", "intent": "Create a DataFrame with a column containing the Index .", "question_id": 5149},
{"snippet": "Index.to_frame(index=True)", "intent": "Create a DataFrame with a column containing the Index . With arguments `index`.", "question_id": 5150},
{"snippet": "Index.to_frame(name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name :", "question_id": 5151},
{"snippet": "Index.to_frame(index=True, name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name : With arguments `index`.", "question_id": 5152},
{"snippet": "Index.to_frame()", "intent": "Create a DataFrame with a column containing the Index .", "question_id": 5153},
{"snippet": "Index.to_frame(index=True)", "intent": "Create a DataFrame with a column containing the Index . With arguments `index`.", "question_id": 5154},
{"snippet": "Index.to_frame(name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name :", "question_id": 5155},
{"snippet": "Index.to_frame(index=True, name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name : With arguments `index`.", "question_id": 5156},
{"snippet": "Index.to_list()", "intent": "Return a list of the values .", "question_id": 5157},
{"snippet": "Index.to_list()", "intent": "Return a list of the values .", "question_id": 5158},
{"snippet": "Index.to_list()", "intent": "Return a list of the values .", "question_id": 5159},
{"snippet": "Index.to_native_types(**kwargs)", "intent": "Format specified values of self and return them . With arguments `**kwargs`.", "question_id": 5160},
{"snippet": "Index.to_native_types(**kwargs, slicer=None)", "intent": "Format specified values of self and return them . With arguments `**kwargs`, `slicer`.", "question_id": 5161},
{"snippet": "Index.to_native_types(**kwargs)", "intent": "Format specified values of self and return them . With arguments `**kwargs`.", "question_id": 5162},
{"snippet": "Index.to_native_types(**kwargs, slicer=None)", "intent": "Format specified values of self and return them . With arguments `**kwargs`, `slicer`.", "question_id": 5163},
{"snippet": "Index.to_native_types(**kwargs)", "intent": "Format specified values of self and return them . With arguments `**kwargs`.", "question_id": 5164},
{"snippet": "Index.to_native_types(**kwargs, slicer=None)", "intent": "Format specified values of self and return them . With arguments `**kwargs`, `slicer`.", "question_id": 5165},
{"snippet": "Index.to_numpy(**kwargs)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`.", "question_id": 5166},
{"snippet": "Index.to_numpy(**kwargs, dtype=None)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`.", "question_id": 5167},
{"snippet": "Index.to_numpy(**kwargs, copy=False)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `copy`.", "question_id": 5168},
{"snippet": "Index.to_numpy(**kwargs, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `na_value`.", "question_id": 5169},
{"snippet": "Index.to_numpy(**kwargs, dtype=None, copy=False)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `copy`.", "question_id": 5170},
{"snippet": "Index.to_numpy(**kwargs, dtype=None, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `na_value`.", "question_id": 5171},
{"snippet": "Index.to_numpy(**kwargs, copy=False, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `copy`, `na_value`.", "question_id": 5172},
{"snippet": "Index.to_numpy(**kwargs, dtype=None, copy=False, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `copy`, `na_value`.", "question_id": 5173},
{"snippet": "Index.to_numpy(**kwargs)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`.", "question_id": 5174},
{"snippet": "Index.to_numpy(**kwargs, dtype=None)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`.", "question_id": 5175},
{"snippet": "Index.to_numpy(**kwargs, copy=False)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `copy`.", "question_id": 5176},
{"snippet": "Index.to_numpy(**kwargs, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `na_value`.", "question_id": 5177},
{"snippet": "Index.to_numpy(**kwargs, dtype=None, copy=False)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `copy`.", "question_id": 5178},
{"snippet": "Index.to_numpy(**kwargs, dtype=None, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `na_value`.", "question_id": 5179},
{"snippet": "Index.to_numpy(**kwargs, copy=False, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `copy`, `na_value`.", "question_id": 5180},
{"snippet": "Index.to_numpy(**kwargs, dtype=None, copy=False, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `copy`, `na_value`.", "question_id": 5181},
{"snippet": "Index.to_numpy(**kwargs)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`.", "question_id": 5182},
{"snippet": "Index.to_numpy(**kwargs, dtype=None)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`.", "question_id": 5183},
{"snippet": "Index.to_numpy(**kwargs, copy=False)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `copy`.", "question_id": 5184},
{"snippet": "Index.to_numpy(**kwargs, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `na_value`.", "question_id": 5185},
{"snippet": "Index.to_numpy(**kwargs, dtype=None, copy=False)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `copy`.", "question_id": 5186},
{"snippet": "Index.to_numpy(**kwargs, dtype=None, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `na_value`.", "question_id": 5187},
{"snippet": "Index.to_numpy(**kwargs, copy=False, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `copy`, `na_value`.", "question_id": 5188},
{"snippet": "Index.to_numpy(**kwargs, dtype=None, copy=False, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `copy`, `na_value`.", "question_id": 5189},
{"snippet": "Index.to_series()", "intent": "Create a Series with both `index` and values equal to the index keys .", "question_id": 5190},
{"snippet": "Index.to_series(index=None)", "intent": "Create a Series with both `index` and values equal to the index keys .", "question_id": 5191},
{"snippet": "Index.to_series(name=None)", "intent": "Create a Series with both `index` and values equal to the index keys . By default , the original Index and original `name` is reused .", "question_id": 5192},
{"snippet": "Index.to_series(index=None, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys . By default , the original Index and original `name` is reused .", "question_id": 5193},
{"snippet": "Index.to_series()", "intent": "Create a Series with both `index` and values equal to the index keys .", "question_id": 5194},
{"snippet": "Index.to_series(index=None)", "intent": "Create a Series with both `index` and values equal to the index keys .", "question_id": 5195},
{"snippet": "Index.to_series(name=None)", "intent": "Create a Series with both `index` and values equal to the index keys . By default , the original Index and original `name` is reused .", "question_id": 5196},
{"snippet": "Index.to_series(index=None, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys . By default , the original Index and original `name` is reused .", "question_id": 5197},
{"snippet": "Index.to_series()", "intent": "Create a Series with both `index` and values equal to the index keys .", "question_id": 5198},
{"snippet": "Index.to_series(index=None)", "intent": "Create a Series with both `index` and values equal to the index keys .", "question_id": 5199},
{"snippet": "Index.to_series(name=None)", "intent": "Create a Series with both `index` and values equal to the index keys . By default , the original Index and original `name` is reused .", "question_id": 5200},
{"snippet": "Index.to_series(index=None, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys . By default , the original Index and original `name` is reused .", "question_id": 5201},
{"snippet": "Index.tolist()", "intent": "Return a list of the values .", "question_id": 5202},
{"snippet": "Index.tolist()", "intent": "Return a list of the values .", "question_id": 5203},
{"snippet": "Index.tolist()", "intent": "Return a list of the values .", "question_id": 5204},
{"snippet": "Index.transpose(*args, **kwargs)", "intent": "Return the transpose , which is by definition self . With arguments `*args`, `**kwargs`.", "question_id": 5205},
{"snippet": "Index.transpose(*args, **kwargs)", "intent": "Return the transpose , which is by definition self . With arguments `*args`, `**kwargs`.", "question_id": 5206},
{"snippet": "Index.transpose(*args, **kwargs)", "intent": "Return the transpose , which is by definition self . With arguments `*args`, `**kwargs`.", "question_id": 5207},
{"snippet": "Index.union(other)", "intent": "Form the union of two Index objects . With arguments `other`.", "question_id": 5208},
{"snippet": "Index.union(other, sort=None)", "intent": "Form the union of two Index objects . With arguments `other`, `sort`.", "question_id": 5209},
{"snippet": "Index.union(other)", "intent": "Form the union of two Index objects . With arguments `other`.", "question_id": 5210},
{"snippet": "Index.union(other, sort=None)", "intent": "Form the union of two Index objects . With arguments `other`, `sort`.", "question_id": 5211},
{"snippet": "Index.union(other)", "intent": "Form the union of two Index objects . With arguments `other`.", "question_id": 5212},
{"snippet": "Index.union(other, sort=None)", "intent": "Form the union of two Index objects . With arguments `other`, `sort`.", "question_id": 5213},
{"snippet": "Index.unique()", "intent": "Return unique values in the index .", "question_id": 5214},
{"snippet": "Index.unique(level=None)", "intent": "Return unique values in the index . With arguments `level`.", "question_id": 5215},
{"snippet": "Index.unique()", "intent": "Return unique values in the index .", "question_id": 5216},
{"snippet": "Index.unique(level=None)", "intent": "Return unique values in the index . With arguments `level`.", "question_id": 5217},
{"snippet": "Index.unique()", "intent": "Return unique values in the index .", "question_id": 5218},
{"snippet": "Index.unique(level=None)", "intent": "Return unique values in the index . With arguments `level`.", "question_id": 5219},
{"snippet": "Index.value_counts()", "intent": "Return a Series containing counts of unique values .", "question_id": 5220},
{"snippet": "Index.value_counts(normalize=False)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values .", "question_id": 5221},
{"snippet": "Index.value_counts(sort=True)", "intent": "Return a Series containing counts of unique values . With arguments `sort`.", "question_id": 5222},
{"snippet": "Index.value_counts(ascending=False)", "intent": "Return a Series containing counts of unique values . With arguments `ascending`.", "question_id": 5223},
{"snippet": "Index.value_counts(bins=None)", "intent": "Return a Series containing counts of unique values . `bins`", "question_id": 5224},
{"snippet": "Index.value_counts(dropna=True)", "intent": "Return a Series containing counts of unique values . `dropna`", "question_id": 5225},
{"snippet": "Index.value_counts(normalize=False, sort=True)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . With arguments `sort`.", "question_id": 5226},
{"snippet": "Index.value_counts(normalize=False, ascending=False)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . With arguments `ascending`.", "question_id": 5227},
{"snippet": "Index.value_counts(normalize=False, bins=None)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . `bins`", "question_id": 5228},
{"snippet": "Index.value_counts(normalize=False, dropna=True)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . `dropna`", "question_id": 5229},
{"snippet": "Index.value_counts()", "intent": "Return a Series containing counts of unique values .", "question_id": 5230},
{"snippet": "Index.value_counts(normalize=False)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values .", "question_id": 5231},
{"snippet": "Index.value_counts(sort=True)", "intent": "Return a Series containing counts of unique values . With arguments `sort`.", "question_id": 5232},
{"snippet": "Index.value_counts(ascending=False)", "intent": "Return a Series containing counts of unique values . With arguments `ascending`.", "question_id": 5233},
{"snippet": "Index.value_counts(bins=None)", "intent": "Return a Series containing counts of unique values . `bins`", "question_id": 5234},
{"snippet": "Index.value_counts(dropna=True)", "intent": "Return a Series containing counts of unique values . `dropna`", "question_id": 5235},
{"snippet": "Index.value_counts(normalize=False, sort=True)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . With arguments `sort`.", "question_id": 5236},
{"snippet": "Index.value_counts(normalize=False, ascending=False)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . With arguments `ascending`.", "question_id": 5237},
{"snippet": "Index.value_counts(normalize=False, bins=None)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . `bins`", "question_id": 5238},
{"snippet": "Index.value_counts(normalize=False, dropna=True)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . `dropna`", "question_id": 5239},
{"snippet": "Index.value_counts()", "intent": "Return a Series containing counts of unique values .", "question_id": 5240},
{"snippet": "Index.value_counts(normalize=False)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values .", "question_id": 5241},
{"snippet": "Index.value_counts(sort=True)", "intent": "Return a Series containing counts of unique values . With arguments `sort`.", "question_id": 5242},
{"snippet": "Index.value_counts(ascending=False)", "intent": "Return a Series containing counts of unique values . With arguments `ascending`.", "question_id": 5243},
{"snippet": "Index.value_counts(bins=None)", "intent": "Return a Series containing counts of unique values . `bins`", "question_id": 5244},
{"snippet": "Index.value_counts(dropna=True)", "intent": "Return a Series containing counts of unique values . `dropna`", "question_id": 5245},
{"snippet": "Index.value_counts(normalize=False, sort=True)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . With arguments `sort`.", "question_id": 5246},
{"snippet": "Index.value_counts(normalize=False, ascending=False)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . With arguments `ascending`.", "question_id": 5247},
{"snippet": "Index.value_counts(normalize=False, bins=None)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . `bins`", "question_id": 5248},
{"snippet": "Index.value_counts(normalize=False, dropna=True)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . `dropna`", "question_id": 5249},
{"snippet": "Index.where(cond)", "intent": "Replace values where the condition is False . With arguments `cond`.", "question_id": 5250},
{"snippet": "Index.where(cond, other=None)", "intent": "Replace values where the condition is False . The replacement is taken from `other` . With arguments `cond`.", "question_id": 5251},
{"snippet": "Index.where(cond)", "intent": "Replace values where the condition is False . With arguments `cond`.", "question_id": 5252},
{"snippet": "Index.where(cond, other=None)", "intent": "Replace values where the condition is False . The replacement is taken from `other` . With arguments `cond`.", "question_id": 5253},
{"snippet": "Index.where(cond)", "intent": "Replace values where the condition is False . With arguments `cond`.", "question_id": 5254},
{"snippet": "Index.where(cond, other=None)", "intent": "Replace values where the condition is False . The replacement is taken from `other` . With arguments `cond`.", "question_id": 5255},
{"snippet": "pandas.IndexSlice", "intent": "Create an object to more easily perform multi-index slicing.", "question_id": 5256},
{"snippet": "pandas.IndexSlice", "intent": "Create an object to more easily perform multi-index slicing.", "question_id": 5257},
{"snippet": "pandas.IndexSlice", "intent": "Create an object to more easily perform multi-index slicing.", "question_id": 5258},
{"snippet": "pandas.Int16Dtype", "intent": "An ExtensionDtype for int16 integer data.", "question_id": 5259},
{"snippet": "pandas.Int16Dtype", "intent": "An ExtensionDtype for int16 integer data.", "question_id": 5260},
{"snippet": "pandas.Int16Dtype", "intent": "An ExtensionDtype for int16 integer data.", "question_id": 5261},
{"snippet": "pandas.Int32Dtype", "intent": "An ExtensionDtype for int32 integer data.", "question_id": 5262},
{"snippet": "pandas.Int32Dtype", "intent": "An ExtensionDtype for int32 integer data.", "question_id": 5263},
{"snippet": "pandas.Int32Dtype", "intent": "An ExtensionDtype for int32 integer data.", "question_id": 5264},
{"snippet": "pandas.Int64Dtype", "intent": "An ExtensionDtype for int64 integer data.", "question_id": 5265},
{"snippet": "pandas.Int64Dtype", "intent": "An ExtensionDtype for int64 integer data.", "question_id": 5266},
{"snippet": "pandas.Int64Dtype", "intent": "An ExtensionDtype for int64 integer data.", "question_id": 5267},
{"snippet": "pandas.Int64Index()", "intent": "Immutable sequence used for indexing and alignment .", "question_id": 5268},
{"snippet": "pandas.Int64Index(data=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`.", "question_id": 5269},
{"snippet": "pandas.Int64Index(dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`.", "question_id": 5270},
{"snippet": "pandas.Int64Index(copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `copy`.", "question_id": 5271},
{"snippet": "pandas.Int64Index(name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `name`.", "question_id": 5272},
{"snippet": "pandas.Int64Index(data=None, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `dtype`.", "question_id": 5273},
{"snippet": "pandas.Int64Index(data=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `copy`.", "question_id": 5274},
{"snippet": "pandas.Int64Index(data=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `name`.", "question_id": 5275},
{"snippet": "pandas.Int64Index(dtype=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `copy`.", "question_id": 5276},
{"snippet": "pandas.Int64Index(dtype=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `name`.", "question_id": 5277},
{"snippet": "pandas.Int64Index()", "intent": "Immutable sequence used for indexing and alignment .", "question_id": 5278},
{"snippet": "pandas.Int64Index(data=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`.", "question_id": 5279},
{"snippet": "pandas.Int64Index(dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`.", "question_id": 5280},
{"snippet": "pandas.Int64Index(copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `copy`.", "question_id": 5281},
{"snippet": "pandas.Int64Index(name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `name`.", "question_id": 5282},
{"snippet": "pandas.Int64Index(data=None, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `dtype`.", "question_id": 5283},
{"snippet": "pandas.Int64Index(data=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `copy`.", "question_id": 5284},
{"snippet": "pandas.Int64Index(data=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `name`.", "question_id": 5285},
{"snippet": "pandas.Int64Index(dtype=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `copy`.", "question_id": 5286},
{"snippet": "pandas.Int64Index(dtype=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `name`.", "question_id": 5287},
{"snippet": "pandas.Int64Index()", "intent": "Immutable sequence used for indexing and alignment .", "question_id": 5288},
{"snippet": "pandas.Int64Index(data=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`.", "question_id": 5289},
{"snippet": "pandas.Int64Index(dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`.", "question_id": 5290},
{"snippet": "pandas.Int64Index(copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `copy`.", "question_id": 5291},
{"snippet": "pandas.Int64Index(name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `name`.", "question_id": 5292},
{"snippet": "pandas.Int64Index(data=None, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `dtype`.", "question_id": 5293},
{"snippet": "pandas.Int64Index(data=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `copy`.", "question_id": 5294},
{"snippet": "pandas.Int64Index(data=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `name`.", "question_id": 5295},
{"snippet": "pandas.Int64Index(dtype=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `copy`.", "question_id": 5296},
{"snippet": "pandas.Int64Index(dtype=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `name`.", "question_id": 5297},
{"snippet": "pandas.Int8Dtype", "intent": "An ExtensionDtype for int8 integer data.", "question_id": 5298},
{"snippet": "pandas.Int8Dtype", "intent": "An ExtensionDtype for int8 integer data.", "question_id": 5299},
{"snippet": "pandas.Int8Dtype", "intent": "An ExtensionDtype for int8 integer data.", "question_id": 5300},
{"snippet": "Interval.closed", "intent": "Whether the interval is closed on the left-side, right-side, both or neither.", "question_id": 5301},
{"snippet": "Interval.closed", "intent": "Whether the interval is closed on the left-side, right-side, both or neither.", "question_id": 5302},
{"snippet": "Interval.closed", "intent": "Whether the interval is closed on the left-side, right-side, both or neither.", "question_id": 5303},
{"snippet": "Interval.closed_left", "intent": "Check if the interval is closed on the left side.", "question_id": 5304},
{"snippet": "Interval.closed_left", "intent": "Check if the interval is closed on the left side.", "question_id": 5305},
{"snippet": "Interval.closed_left", "intent": "Check if the interval is closed on the left side.", "question_id": 5306},
{"snippet": "Interval.closed_right", "intent": "Check if the interval is closed on the right side.", "question_id": 5307},
{"snippet": "Interval.closed_right", "intent": "Check if the interval is closed on the right side.", "question_id": 5308},
{"snippet": "Interval.closed_right", "intent": "Check if the interval is closed on the right side.", "question_id": 5309},
{"snippet": "pandas.Interval", "intent": "Immutable object implementing an Interval, a bounded slice-like interval.", "question_id": 5310},
{"snippet": "pandas.Interval", "intent": "Immutable object implementing an Interval, a bounded slice-like interval.", "question_id": 5311},
{"snippet": "pandas.Interval", "intent": "Immutable object implementing an Interval, a bounded slice-like interval.", "question_id": 5312},
{"snippet": "Interval.is_empty", "intent": "Indicates if an interval is empty, meaning it contains no points.", "question_id": 5313},
{"snippet": "Interval.is_empty", "intent": "Indicates if an interval is empty, meaning it contains no points.", "question_id": 5314},
{"snippet": "Interval.is_empty", "intent": "Indicates if an interval is empty, meaning it contains no points.", "question_id": 5315},
{"snippet": "Interval.left", "intent": "Left bound for the interval.", "question_id": 5316},
{"snippet": "Interval.left", "intent": "Left bound for the interval.", "question_id": 5317},
{"snippet": "Interval.left", "intent": "Left bound for the interval.", "question_id": 5318},
{"snippet": "Interval.length", "intent": "Return the length of the Interval.", "question_id": 5319},
{"snippet": "Interval.length", "intent": "Return the length of the Interval.", "question_id": 5320},
{"snippet": "Interval.length", "intent": "Return the length of the Interval.", "question_id": 5321},
{"snippet": "Interval.mid", "intent": "Return the midpoint of the Interval.", "question_id": 5322},
{"snippet": "Interval.mid", "intent": "Return the midpoint of the Interval.", "question_id": 5323},
{"snippet": "Interval.mid", "intent": "Return the midpoint of the Interval.", "question_id": 5324},
{"snippet": "Interval.open_left", "intent": "Check if the interval is open on the left side.", "question_id": 5325},
{"snippet": "Interval.open_left", "intent": "Check if the interval is open on the left side.", "question_id": 5326},
{"snippet": "Interval.open_left", "intent": "Check if the interval is open on the left side.", "question_id": 5327},
{"snippet": "Interval.open_right", "intent": "Check if the interval is open on the right side.", "question_id": 5328},
{"snippet": "Interval.open_right", "intent": "Check if the interval is open on the right side.", "question_id": 5329},
{"snippet": "Interval.open_right", "intent": "Check if the interval is open on the right side.", "question_id": 5330},
{"snippet": "Interval.overlaps()", "intent": "Check whether two Interval objects overlap .", "question_id": 5331},
{"snippet": "Interval.overlaps()", "intent": "Check whether two Interval objects overlap .", "question_id": 5332},
{"snippet": "Interval.overlaps()", "intent": "Check whether two Interval objects overlap .", "question_id": 5333},
{"snippet": "Interval.right", "intent": "Right bound for the interval.", "question_id": 5334},
{"snippet": "Interval.right", "intent": "Right bound for the interval.", "question_id": 5335},
{"snippet": "Interval.right", "intent": "Right bound for the interval.", "question_id": 5336},
{"snippet": "pandas.IntervalDtype()", "intent": "An ExtensionDtype for Interval data .", "question_id": 5337},
{"snippet": "pandas.IntervalDtype(subtype=None)", "intent": "An ExtensionDtype for Interval data . With arguments `subtype`.", "question_id": 5338},
{"snippet": "pandas.IntervalDtype(closed=None)", "intent": "An ExtensionDtype for Interval data . With arguments `closed`.", "question_id": 5339},
{"snippet": "pandas.IntervalDtype(subtype=None, closed=None)", "intent": "An ExtensionDtype for Interval data . With arguments `subtype`, `closed`.", "question_id": 5340},
{"snippet": "pandas.IntervalDtype()", "intent": "An ExtensionDtype for Interval data .", "question_id": 5341},
{"snippet": "pandas.IntervalDtype(subtype=None)", "intent": "An ExtensionDtype for Interval data . With arguments `subtype`.", "question_id": 5342},
{"snippet": "pandas.IntervalDtype(closed=None)", "intent": "An ExtensionDtype for Interval data . With arguments `closed`.", "question_id": 5343},
{"snippet": "pandas.IntervalDtype(subtype=None, closed=None)", "intent": "An ExtensionDtype for Interval data . With arguments `subtype`, `closed`.", "question_id": 5344},
{"snippet": "pandas.IntervalDtype()", "intent": "An ExtensionDtype for Interval data .", "question_id": 5345},
{"snippet": "pandas.IntervalDtype(subtype=None)", "intent": "An ExtensionDtype for Interval data . With arguments `subtype`.", "question_id": 5346},
{"snippet": "pandas.IntervalDtype(closed=None)", "intent": "An ExtensionDtype for Interval data . With arguments `closed`.", "question_id": 5347},
{"snippet": "pandas.IntervalDtype(subtype=None, closed=None)", "intent": "An ExtensionDtype for Interval data . With arguments `subtype`, `closed`.", "question_id": 5348},
{"snippet": "IntervalIndex.closed", "intent": "Whether the intervals are closed on the left-side, right-side, both or neither.", "question_id": 5349},
{"snippet": "IntervalIndex.closed", "intent": "Whether the intervals are closed on the left-side, right-side, both or neither.", "question_id": 5350},
{"snippet": "IntervalIndex.closed", "intent": "Whether the intervals are closed on the left-side, right-side, both or neither.", "question_id": 5351},
{"snippet": "IntervalIndex.contains(*args, **kwargs)", "intent": "Check elementwise if the Intervals contain the value . With arguments `*args`, `**kwargs`.", "question_id": 5352},
{"snippet": "IntervalIndex.contains(*args, **kwargs)", "intent": "Check elementwise if the Intervals contain the value . With arguments `*args`, `**kwargs`.", "question_id": 5353},
{"snippet": "IntervalIndex.contains(*args, **kwargs)", "intent": "Check elementwise if the Intervals contain the value . With arguments `*args`, `**kwargs`.", "question_id": 5354},
{"snippet": "IntervalIndex.from_arrays(left, right)", "intent": "Construct from two arrays defining the `left` and `right` bounds .", "question_id": 5355},
{"snippet": "IntervalIndex.from_arrays(left, right, closed='right')", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`.", "question_id": 5356},
{"snippet": "IntervalIndex.from_arrays(left, right, name=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `name`.", "question_id": 5357},
{"snippet": "IntervalIndex.from_arrays(left, right, copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `copy`.", "question_id": 5358},
{"snippet": "IntervalIndex.from_arrays(left, right, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `dtype`.", "question_id": 5359},
{"snippet": "IntervalIndex.from_arrays(left, right, closed='right', name=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `name`.", "question_id": 5360},
{"snippet": "IntervalIndex.from_arrays(left, right, closed='right', copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `copy`.", "question_id": 5361},
{"snippet": "IntervalIndex.from_arrays(left, right, closed='right', dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `dtype`.", "question_id": 5362},
{"snippet": "IntervalIndex.from_arrays(left, right, name=None, copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `name`, `copy`.", "question_id": 5363},
{"snippet": "IntervalIndex.from_arrays(left, right, name=None, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `name`, `dtype`.", "question_id": 5364},
{"snippet": "IntervalIndex.from_arrays(left, right)", "intent": "Construct from two arrays defining the `left` and `right` bounds .", "question_id": 5365},
{"snippet": "IntervalIndex.from_arrays(left, right, closed='right')", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`.", "question_id": 5366},
{"snippet": "IntervalIndex.from_arrays(left, right, name=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `name`.", "question_id": 5367},
{"snippet": "IntervalIndex.from_arrays(left, right, copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `copy`.", "question_id": 5368},
{"snippet": "IntervalIndex.from_arrays(left, right, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `dtype`.", "question_id": 5369},
{"snippet": "IntervalIndex.from_arrays(left, right, closed='right', name=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `name`.", "question_id": 5370},
{"snippet": "IntervalIndex.from_arrays(left, right, closed='right', copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `copy`.", "question_id": 5371},
{"snippet": "IntervalIndex.from_arrays(left, right, closed='right', dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `dtype`.", "question_id": 5372},
{"snippet": "IntervalIndex.from_arrays(left, right, name=None, copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `name`, `copy`.", "question_id": 5373},
{"snippet": "IntervalIndex.from_arrays(left, right, name=None, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `name`, `dtype`.", "question_id": 5374},
{"snippet": "IntervalIndex.from_arrays(left, right)", "intent": "Construct from two arrays defining the `left` and `right` bounds .", "question_id": 5375},
{"snippet": "IntervalIndex.from_arrays(left, right, closed='right')", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`.", "question_id": 5376},
{"snippet": "IntervalIndex.from_arrays(left, right, name=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `name`.", "question_id": 5377},
{"snippet": "IntervalIndex.from_arrays(left, right, copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `copy`.", "question_id": 5378},
{"snippet": "IntervalIndex.from_arrays(left, right, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `dtype`.", "question_id": 5379},
{"snippet": "IntervalIndex.from_arrays(left, right, closed='right', name=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `name`.", "question_id": 5380},
{"snippet": "IntervalIndex.from_arrays(left, right, closed='right', copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `copy`.", "question_id": 5381},
{"snippet": "IntervalIndex.from_arrays(left, right, closed='right', dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `dtype`.", "question_id": 5382},
{"snippet": "IntervalIndex.from_arrays(left, right, name=None, copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `name`, `copy`.", "question_id": 5383},
{"snippet": "IntervalIndex.from_arrays(left, right, name=None, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `name`, `dtype`.", "question_id": 5384},
{"snippet": "IntervalIndex.from_breaks(breaks)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`.", "question_id": 5385},
{"snippet": "IntervalIndex.from_breaks(breaks, closed='right')", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `closed`.", "question_id": 5386},
{"snippet": "IntervalIndex.from_breaks(breaks, name=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `name`.", "question_id": 5387},
{"snippet": "IntervalIndex.from_breaks(breaks, copy=False)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `copy`.", "question_id": 5388},
{"snippet": "IntervalIndex.from_breaks(breaks, dtype=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `dtype`.", "question_id": 5389},
{"snippet": "IntervalIndex.from_breaks(breaks, closed='right', name=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `closed`, `name`.", "question_id": 5390},
{"snippet": "IntervalIndex.from_breaks(breaks, closed='right', copy=False)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `closed`, `copy`.", "question_id": 5391},
{"snippet": "IntervalIndex.from_breaks(breaks, closed='right', dtype=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `closed`, `dtype`.", "question_id": 5392},
{"snippet": "IntervalIndex.from_breaks(breaks, name=None, copy=False)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `name`, `copy`.", "question_id": 5393},
{"snippet": "IntervalIndex.from_breaks(breaks, name=None, dtype=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `name`, `dtype`.", "question_id": 5394},
{"snippet": "IntervalIndex.from_breaks(breaks)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`.", "question_id": 5395},
{"snippet": "IntervalIndex.from_breaks(breaks, closed='right')", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `closed`.", "question_id": 5396},
{"snippet": "IntervalIndex.from_breaks(breaks, name=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `name`.", "question_id": 5397},
{"snippet": "IntervalIndex.from_breaks(breaks, copy=False)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `copy`.", "question_id": 5398},
{"snippet": "IntervalIndex.from_breaks(breaks, dtype=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `dtype`.", "question_id": 5399},
{"snippet": "IntervalIndex.from_breaks(breaks, closed='right', name=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `closed`, `name`.", "question_id": 5400},
{"snippet": "IntervalIndex.from_breaks(breaks, closed='right', copy=False)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `closed`, `copy`.", "question_id": 5401},
{"snippet": "IntervalIndex.from_breaks(breaks, closed='right', dtype=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `closed`, `dtype`.", "question_id": 5402},
{"snippet": "IntervalIndex.from_breaks(breaks, name=None, copy=False)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `name`, `copy`.", "question_id": 5403},
{"snippet": "IntervalIndex.from_breaks(breaks, name=None, dtype=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `name`, `dtype`.", "question_id": 5404},
{"snippet": "IntervalIndex.from_breaks(breaks)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`.", "question_id": 5405},
{"snippet": "IntervalIndex.from_breaks(breaks, closed='right')", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `closed`.", "question_id": 5406},
{"snippet": "IntervalIndex.from_breaks(breaks, name=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `name`.", "question_id": 5407},
{"snippet": "IntervalIndex.from_breaks(breaks, copy=False)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `copy`.", "question_id": 5408},
{"snippet": "IntervalIndex.from_breaks(breaks, dtype=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `dtype`.", "question_id": 5409},
{"snippet": "IntervalIndex.from_breaks(breaks, closed='right', name=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `closed`, `name`.", "question_id": 5410},
{"snippet": "IntervalIndex.from_breaks(breaks, closed='right', copy=False)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `closed`, `copy`.", "question_id": 5411},
{"snippet": "IntervalIndex.from_breaks(breaks, closed='right', dtype=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `closed`, `dtype`.", "question_id": 5412},
{"snippet": "IntervalIndex.from_breaks(breaks, name=None, copy=False)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `name`, `copy`.", "question_id": 5413},
{"snippet": "IntervalIndex.from_breaks(breaks, name=None, dtype=None)", "intent": "Construct an IntervalIndex from an array of splits . With arguments `breaks`, `name`, `dtype`.", "question_id": 5414},
{"snippet": "IntervalIndex.from_tuples(data)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`.", "question_id": 5415},
{"snippet": "IntervalIndex.from_tuples(data, closed='right')", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `closed`.", "question_id": 5416},
{"snippet": "IntervalIndex.from_tuples(data, name=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `name`.", "question_id": 5417},
{"snippet": "IntervalIndex.from_tuples(data, copy=False)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `copy`.", "question_id": 5418},
{"snippet": "IntervalIndex.from_tuples(data, dtype=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `dtype`.", "question_id": 5419},
{"snippet": "IntervalIndex.from_tuples(data, closed='right', name=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `closed`, `name`.", "question_id": 5420},
{"snippet": "IntervalIndex.from_tuples(data, closed='right', copy=False)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `closed`, `copy`.", "question_id": 5421},
{"snippet": "IntervalIndex.from_tuples(data, closed='right', dtype=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `closed`, `dtype`.", "question_id": 5422},
{"snippet": "IntervalIndex.from_tuples(data, name=None, copy=False)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `name`, `copy`.", "question_id": 5423},
{"snippet": "IntervalIndex.from_tuples(data, name=None, dtype=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `name`, `dtype`.", "question_id": 5424},
{"snippet": "IntervalIndex.from_tuples(data)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`.", "question_id": 5425},
{"snippet": "IntervalIndex.from_tuples(data, closed='right')", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `closed`.", "question_id": 5426},
{"snippet": "IntervalIndex.from_tuples(data, name=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `name`.", "question_id": 5427},
{"snippet": "IntervalIndex.from_tuples(data, copy=False)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `copy`.", "question_id": 5428},
{"snippet": "IntervalIndex.from_tuples(data, dtype=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `dtype`.", "question_id": 5429},
{"snippet": "IntervalIndex.from_tuples(data, closed='right', name=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `closed`, `name`.", "question_id": 5430},
{"snippet": "IntervalIndex.from_tuples(data, closed='right', copy=False)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `closed`, `copy`.", "question_id": 5431},
{"snippet": "IntervalIndex.from_tuples(data, closed='right', dtype=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `closed`, `dtype`.", "question_id": 5432},
{"snippet": "IntervalIndex.from_tuples(data, name=None, copy=False)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `name`, `copy`.", "question_id": 5433},
{"snippet": "IntervalIndex.from_tuples(data, name=None, dtype=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `name`, `dtype`.", "question_id": 5434},
{"snippet": "IntervalIndex.from_tuples(data)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`.", "question_id": 5435},
{"snippet": "IntervalIndex.from_tuples(data, closed='right')", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `closed`.", "question_id": 5436},
{"snippet": "IntervalIndex.from_tuples(data, name=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `name`.", "question_id": 5437},
{"snippet": "IntervalIndex.from_tuples(data, copy=False)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `copy`.", "question_id": 5438},
{"snippet": "IntervalIndex.from_tuples(data, dtype=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `dtype`.", "question_id": 5439},
{"snippet": "IntervalIndex.from_tuples(data, closed='right', name=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `closed`, `name`.", "question_id": 5440},
{"snippet": "IntervalIndex.from_tuples(data, closed='right', copy=False)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `closed`, `copy`.", "question_id": 5441},
{"snippet": "IntervalIndex.from_tuples(data, closed='right', dtype=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `closed`, `dtype`.", "question_id": 5442},
{"snippet": "IntervalIndex.from_tuples(data, name=None, copy=False)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `name`, `copy`.", "question_id": 5443},
{"snippet": "IntervalIndex.from_tuples(data, name=None, dtype=None)", "intent": "Construct an IntervalIndex from an array-like of tuples . With arguments `data`, `name`, `dtype`.", "question_id": 5444},
{"snippet": "IntervalIndex.get_indexer(target)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`.", "question_id": 5445},
{"snippet": "IntervalIndex.get_indexer(target, method=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`.", "question_id": 5446},
{"snippet": "IntervalIndex.get_indexer(target, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`.", "question_id": 5447},
{"snippet": "IntervalIndex.get_indexer(target, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `tolerance`.", "question_id": 5448},
{"snippet": "IntervalIndex.get_indexer(target, method=None, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`.", "question_id": 5449},
{"snippet": "IntervalIndex.get_indexer(target, method=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `tolerance`.", "question_id": 5450},
{"snippet": "IntervalIndex.get_indexer(target, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`, `tolerance`.", "question_id": 5451},
{"snippet": "IntervalIndex.get_indexer(target, method=None, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`, `tolerance`.", "question_id": 5452},
{"snippet": "IntervalIndex.get_indexer(target)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`.", "question_id": 5453},
{"snippet": "IntervalIndex.get_indexer(target, method=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`.", "question_id": 5454},
{"snippet": "IntervalIndex.get_indexer(target, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`.", "question_id": 5455},
{"snippet": "IntervalIndex.get_indexer(target, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `tolerance`.", "question_id": 5456},
{"snippet": "IntervalIndex.get_indexer(target, method=None, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`.", "question_id": 5457},
{"snippet": "IntervalIndex.get_indexer(target, method=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `tolerance`.", "question_id": 5458},
{"snippet": "IntervalIndex.get_indexer(target, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`, `tolerance`.", "question_id": 5459},
{"snippet": "IntervalIndex.get_indexer(target, method=None, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`, `tolerance`.", "question_id": 5460},
{"snippet": "IntervalIndex.get_indexer(target)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`.", "question_id": 5461},
{"snippet": "IntervalIndex.get_indexer(target, method=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`.", "question_id": 5462},
{"snippet": "IntervalIndex.get_indexer(target, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`.", "question_id": 5463},
{"snippet": "IntervalIndex.get_indexer(target, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `tolerance`.", "question_id": 5464},
{"snippet": "IntervalIndex.get_indexer(target, method=None, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`.", "question_id": 5465},
{"snippet": "IntervalIndex.get_indexer(target, method=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `tolerance`.", "question_id": 5466},
{"snippet": "IntervalIndex.get_indexer(target, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`, `tolerance`.", "question_id": 5467},
{"snippet": "IntervalIndex.get_indexer(target, method=None, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`, `tolerance`.", "question_id": 5468},
{"snippet": "IntervalIndex.get_loc(key)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`.", "question_id": 5469},
{"snippet": "IntervalIndex.get_loc(key, method=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `method`.", "question_id": 5470},
{"snippet": "IntervalIndex.get_loc(key, tolerance=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `tolerance`.", "question_id": 5471},
{"snippet": "IntervalIndex.get_loc(key, method=None, tolerance=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `method`, `tolerance`.", "question_id": 5472},
{"snippet": "IntervalIndex.get_loc(key)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`.", "question_id": 5473},
{"snippet": "IntervalIndex.get_loc(key, method=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `method`.", "question_id": 5474},
{"snippet": "IntervalIndex.get_loc(key, tolerance=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `tolerance`.", "question_id": 5475},
{"snippet": "IntervalIndex.get_loc(key, method=None, tolerance=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `method`, `tolerance`.", "question_id": 5476},
{"snippet": "IntervalIndex.get_loc(key)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`.", "question_id": 5477},
{"snippet": "IntervalIndex.get_loc(key, method=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `method`.", "question_id": 5478},
{"snippet": "IntervalIndex.get_loc(key, tolerance=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `tolerance`.", "question_id": 5479},
{"snippet": "IntervalIndex.get_loc(key, method=None, tolerance=None)", "intent": "Get integer location , slice or boolean mask for requested label . With arguments `key`, `method`, `tolerance`.", "question_id": 5480},
{"snippet": "pandas.IntervalIndex(data)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`.", "question_id": 5481},
{"snippet": "pandas.IntervalIndex(data, closed=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`.", "question_id": 5482},
{"snippet": "pandas.IntervalIndex(data, dtype=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `dtype`.", "question_id": 5483},
{"snippet": "pandas.IntervalIndex(data, copy=False)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `copy`.", "question_id": 5484},
{"snippet": "pandas.IntervalIndex(data, name=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `name`.", "question_id": 5485},
{"snippet": "pandas.IntervalIndex(data, verify_integrity=True)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `verify_integrity`.", "question_id": 5486},
{"snippet": "pandas.IntervalIndex(data, closed=None, dtype=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `dtype`.", "question_id": 5487},
{"snippet": "pandas.IntervalIndex(data, closed=None, copy=False)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `copy`.", "question_id": 5488},
{"snippet": "pandas.IntervalIndex(data, closed=None, name=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `name`.", "question_id": 5489},
{"snippet": "pandas.IntervalIndex(data, closed=None, verify_integrity=True)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `verify_integrity`.", "question_id": 5490},
{"snippet": "pandas.IntervalIndex(data)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`.", "question_id": 5491},
{"snippet": "pandas.IntervalIndex(data, closed=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`.", "question_id": 5492},
{"snippet": "pandas.IntervalIndex(data, dtype=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `dtype`.", "question_id": 5493},
{"snippet": "pandas.IntervalIndex(data, copy=False)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `copy`.", "question_id": 5494},
{"snippet": "pandas.IntervalIndex(data, name=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `name`.", "question_id": 5495},
{"snippet": "pandas.IntervalIndex(data, verify_integrity=True)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `verify_integrity`.", "question_id": 5496},
{"snippet": "pandas.IntervalIndex(data, closed=None, dtype=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `dtype`.", "question_id": 5497},
{"snippet": "pandas.IntervalIndex(data, closed=None, copy=False)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `copy`.", "question_id": 5498},
{"snippet": "pandas.IntervalIndex(data, closed=None, name=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `name`.", "question_id": 5499},
{"snippet": "pandas.IntervalIndex(data, closed=None, verify_integrity=True)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `verify_integrity`.", "question_id": 5500},
{"snippet": "pandas.IntervalIndex(data)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`.", "question_id": 5501},
{"snippet": "pandas.IntervalIndex(data, closed=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`.", "question_id": 5502},
{"snippet": "pandas.IntervalIndex(data, dtype=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `dtype`.", "question_id": 5503},
{"snippet": "pandas.IntervalIndex(data, copy=False)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `copy`.", "question_id": 5504},
{"snippet": "pandas.IntervalIndex(data, name=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `name`.", "question_id": 5505},
{"snippet": "pandas.IntervalIndex(data, verify_integrity=True)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `verify_integrity`.", "question_id": 5506},
{"snippet": "pandas.IntervalIndex(data, closed=None, dtype=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `dtype`.", "question_id": 5507},
{"snippet": "pandas.IntervalIndex(data, closed=None, copy=False)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `copy`.", "question_id": 5508},
{"snippet": "pandas.IntervalIndex(data, closed=None, name=None)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `name`.", "question_id": 5509},
{"snippet": "pandas.IntervalIndex(data, closed=None, verify_integrity=True)", "intent": "Immutable index of intervals that are `closed` on the same side . With arguments `data`, `verify_integrity`.", "question_id": 5510},
{"snippet": "IntervalIndex.is_non_overlapping_monotonic", "intent": "Return True if the IntervalArray is non-overlapping (no Intervals share points) and is either monotonic increasing or monotonic decreasing, else False.", "question_id": 5511},
{"snippet": "IntervalIndex.is_non_overlapping_monotonic", "intent": "Return True if the IntervalArray is non-overlapping (no Intervals share points) and is either monotonic increasing or monotonic decreasing, else False.", "question_id": 5512},
{"snippet": "IntervalIndex.is_non_overlapping_monotonic", "intent": "Return True if the IntervalArray is non-overlapping (no Intervals share points) and is either monotonic increasing or monotonic decreasing, else False.", "question_id": 5513},
{"snippet": "IntervalIndex.overlaps(*args, **kwargs)", "intent": "Check elementwise if an Interval overlaps the values in the IntervalArray . With arguments `*args`, `**kwargs`.", "question_id": 5514},
{"snippet": "IntervalIndex.overlaps(*args, **kwargs)", "intent": "Check elementwise if an Interval overlaps the values in the IntervalArray . With arguments `*args`, `**kwargs`.", "question_id": 5515},
{"snippet": "IntervalIndex.overlaps(*args, **kwargs)", "intent": "Check elementwise if an Interval overlaps the values in the IntervalArray . With arguments `*args`, `**kwargs`.", "question_id": 5516},
{"snippet": "IntervalIndex.set_closed(*args, **kwargs)", "intent": "Return an IntervalArray identical to the current one , but closed on the specified side . With arguments `*args`, `**kwargs`.", "question_id": 5517},
{"snippet": "IntervalIndex.set_closed(*args, **kwargs)", "intent": "Return an IntervalArray identical to the current one , but closed on the specified side . With arguments `*args`, `**kwargs`.", "question_id": 5518},
{"snippet": "IntervalIndex.set_closed(*args, **kwargs)", "intent": "Return an IntervalArray identical to the current one , but closed on the specified side . With arguments `*args`, `**kwargs`.", "question_id": 5519},
{"snippet": "IntervalIndex.to_tuples(*args, **kwargs)", "intent": "Return an ndarray of tuples of the form ( left , right ) . With arguments `*args`, `**kwargs`.", "question_id": 5520},
{"snippet": "IntervalIndex.to_tuples(*args, **kwargs)", "intent": "Return an ndarray of tuples of the form ( left , right ) . With arguments `*args`, `**kwargs`.", "question_id": 5521},
{"snippet": "IntervalIndex.to_tuples(*args, **kwargs)", "intent": "Return an ndarray of tuples of the form ( left , right ) . With arguments `*args`, `**kwargs`.", "question_id": 5522},
{"snippet": "MultiIndex.droplevel()", "intent": "Return index with requested `level` ( s ) removed .", "question_id": 5523},
{"snippet": "MultiIndex.droplevel(level=0)", "intent": "Return index with requested `level` ( s ) removed .", "question_id": 5524},
{"snippet": "MultiIndex.droplevel()", "intent": "Return index with requested `level` ( s ) removed .", "question_id": 5525},
{"snippet": "MultiIndex.droplevel(level=0)", "intent": "Return index with requested `level` ( s ) removed .", "question_id": 5526},
{"snippet": "MultiIndex.droplevel()", "intent": "Return index with requested `level` ( s ) removed .", "question_id": 5527},
{"snippet": "MultiIndex.droplevel(level=0)", "intent": "Return index with requested `level` ( s ) removed .", "question_id": 5528},
{"snippet": "MultiIndex.dtypes", "intent": "Return the dtypes as a Series for the underlying MultiIndex", "question_id": 5529},
{"snippet": "MultiIndex.dtypes", "intent": "Return the dtypes as a Series for the underlying MultiIndex", "question_id": 5530},
{"snippet": "MultiIndex.dtypes", "intent": "Return the dtypes as a Series for the underlying MultiIndex", "question_id": 5531},
{"snippet": "MultiIndex.from_arrays(arrays)", "intent": "Convert `arrays` to MultiIndex .", "question_id": 5532},
{"snippet": "MultiIndex.from_arrays(arrays, sortorder=None)", "intent": "Convert `arrays` to MultiIndex . With arguments `sortorder`.", "question_id": 5533},
{"snippet": "MultiIndex.from_arrays(arrays, names=NoDefault.no_default)", "intent": "Convert `arrays` to MultiIndex . With arguments `names`.", "question_id": 5534},
{"snippet": "MultiIndex.from_arrays(arrays, sortorder=None, names=NoDefault.no_default)", "intent": "Convert `arrays` to MultiIndex . With arguments `sortorder`, `names`.", "question_id": 5535},
{"snippet": "MultiIndex.from_arrays(arrays)", "intent": "Convert `arrays` to MultiIndex .", "question_id": 5536},
{"snippet": "MultiIndex.from_arrays(arrays, sortorder=None)", "intent": "Convert `arrays` to MultiIndex . With arguments `sortorder`.", "question_id": 5537},
{"snippet": "MultiIndex.from_arrays(arrays, names=NoDefault.no_default)", "intent": "Convert `arrays` to MultiIndex . With arguments `names`.", "question_id": 5538},
{"snippet": "MultiIndex.from_arrays(arrays, sortorder=None, names=NoDefault.no_default)", "intent": "Convert `arrays` to MultiIndex . With arguments `sortorder`, `names`.", "question_id": 5539},
{"snippet": "MultiIndex.from_arrays(arrays)", "intent": "Convert `arrays` to MultiIndex .", "question_id": 5540},
{"snippet": "MultiIndex.from_arrays(arrays, sortorder=None)", "intent": "Convert `arrays` to MultiIndex . With arguments `sortorder`.", "question_id": 5541},
{"snippet": "MultiIndex.from_arrays(arrays, names=NoDefault.no_default)", "intent": "Convert `arrays` to MultiIndex . With arguments `names`.", "question_id": 5542},
{"snippet": "MultiIndex.from_arrays(arrays, sortorder=None, names=NoDefault.no_default)", "intent": "Convert `arrays` to MultiIndex . With arguments `sortorder`, `names`.", "question_id": 5543},
{"snippet": "MultiIndex.from_frame(df)", "intent": "Make a MultiIndex from a DataFrame . With arguments `df`.", "question_id": 5544},
{"snippet": "MultiIndex.from_frame(df, sortorder=None)", "intent": "Make a MultiIndex from a DataFrame . With arguments `df`, `sortorder`.", "question_id": 5545},
{"snippet": "MultiIndex.from_frame(df, names=None)", "intent": "Make a MultiIndex from a DataFrame . Using explicit `names` , instead of the column names With arguments `df`.", "question_id": 5546},
{"snippet": "MultiIndex.from_frame(df, sortorder=None, names=None)", "intent": "Make a MultiIndex from a DataFrame . Using explicit `names` , instead of the column names With arguments `df`, `sortorder`.", "question_id": 5547},
{"snippet": "MultiIndex.from_frame(df)", "intent": "Make a MultiIndex from a DataFrame . With arguments `df`.", "question_id": 5548},
{"snippet": "MultiIndex.from_frame(df, sortorder=None)", "intent": "Make a MultiIndex from a DataFrame . With arguments `df`, `sortorder`.", "question_id": 5549},
{"snippet": "MultiIndex.from_frame(df, names=None)", "intent": "Make a MultiIndex from a DataFrame . Using explicit `names` , instead of the column names With arguments `df`.", "question_id": 5550},
{"snippet": "MultiIndex.from_frame(df, sortorder=None, names=None)", "intent": "Make a MultiIndex from a DataFrame . Using explicit `names` , instead of the column names With arguments `df`, `sortorder`.", "question_id": 5551},
{"snippet": "MultiIndex.from_frame(df)", "intent": "Make a MultiIndex from a DataFrame . With arguments `df`.", "question_id": 5552},
{"snippet": "MultiIndex.from_frame(df, sortorder=None)", "intent": "Make a MultiIndex from a DataFrame . With arguments `df`, `sortorder`.", "question_id": 5553},
{"snippet": "MultiIndex.from_frame(df, names=None)", "intent": "Make a MultiIndex from a DataFrame . Using explicit `names` , instead of the column names With arguments `df`.", "question_id": 5554},
{"snippet": "MultiIndex.from_frame(df, sortorder=None, names=None)", "intent": "Make a MultiIndex from a DataFrame . Using explicit `names` , instead of the column names With arguments `df`, `sortorder`.", "question_id": 5555},
{"snippet": "MultiIndex.from_product(iterables)", "intent": "Make a MultiIndex from the cartesian product of multiple `iterables` .", "question_id": 5556},
{"snippet": "MultiIndex.from_product(iterables, sortorder=None)", "intent": "Make a MultiIndex from the cartesian product of multiple `iterables` . With arguments `sortorder`.", "question_id": 5557},
{"snippet": "MultiIndex.from_product(iterables, names=NoDefault.no_default)", "intent": "Make a MultiIndex from the cartesian product of multiple `iterables` . With arguments `names`.", "question_id": 5558},
{"snippet": "MultiIndex.from_product(iterables, sortorder=None, names=NoDefault.no_default)", "intent": "Make a MultiIndex from the cartesian product of multiple `iterables` . With arguments `sortorder`, `names`.", "question_id": 5559},
{"snippet": "MultiIndex.from_product(iterables)", "intent": "Make a MultiIndex from the cartesian product of multiple `iterables` .", "question_id": 5560},
{"snippet": "MultiIndex.from_product(iterables, sortorder=None)", "intent": "Make a MultiIndex from the cartesian product of multiple `iterables` . With arguments `sortorder`.", "question_id": 5561},
{"snippet": "MultiIndex.from_product(iterables, names=NoDefault.no_default)", "intent": "Make a MultiIndex from the cartesian product of multiple `iterables` . With arguments `names`.", "question_id": 5562},
{"snippet": "MultiIndex.from_product(iterables, sortorder=None, names=NoDefault.no_default)", "intent": "Make a MultiIndex from the cartesian product of multiple `iterables` . With arguments `sortorder`, `names`.", "question_id": 5563},
{"snippet": "MultiIndex.from_product(iterables)", "intent": "Make a MultiIndex from the cartesian product of multiple `iterables` .", "question_id": 5564},
{"snippet": "MultiIndex.from_product(iterables, sortorder=None)", "intent": "Make a MultiIndex from the cartesian product of multiple `iterables` . With arguments `sortorder`.", "question_id": 5565},
{"snippet": "MultiIndex.from_product(iterables, names=NoDefault.no_default)", "intent": "Make a MultiIndex from the cartesian product of multiple `iterables` . With arguments `names`.", "question_id": 5566},
{"snippet": "MultiIndex.from_product(iterables, sortorder=None, names=NoDefault.no_default)", "intent": "Make a MultiIndex from the cartesian product of multiple `iterables` . With arguments `sortorder`, `names`.", "question_id": 5567},
{"snippet": "MultiIndex.from_tuples(tuples)", "intent": "Convert list of `tuples` to MultiIndex .", "question_id": 5568},
{"snippet": "MultiIndex.from_tuples(tuples, sortorder=None)", "intent": "Convert list of `tuples` to MultiIndex . With arguments `sortorder`.", "question_id": 5569},
{"snippet": "MultiIndex.from_tuples(tuples, names=None)", "intent": "Convert list of `tuples` to MultiIndex . With arguments `names`.", "question_id": 5570},
{"snippet": "MultiIndex.from_tuples(tuples, sortorder=None, names=None)", "intent": "Convert list of `tuples` to MultiIndex . With arguments `sortorder`, `names`.", "question_id": 5571},
{"snippet": "MultiIndex.from_tuples(tuples)", "intent": "Convert list of `tuples` to MultiIndex .", "question_id": 5572},
{"snippet": "MultiIndex.from_tuples(tuples, sortorder=None)", "intent": "Convert list of `tuples` to MultiIndex . With arguments `sortorder`.", "question_id": 5573},
{"snippet": "MultiIndex.from_tuples(tuples, names=None)", "intent": "Convert list of `tuples` to MultiIndex . With arguments `names`.", "question_id": 5574},
{"snippet": "MultiIndex.from_tuples(tuples, sortorder=None, names=None)", "intent": "Convert list of `tuples` to MultiIndex . With arguments `sortorder`, `names`.", "question_id": 5575},
{"snippet": "MultiIndex.from_tuples(tuples)", "intent": "Convert list of `tuples` to MultiIndex .", "question_id": 5576},
{"snippet": "MultiIndex.from_tuples(tuples, sortorder=None)", "intent": "Convert list of `tuples` to MultiIndex . With arguments `sortorder`.", "question_id": 5577},
{"snippet": "MultiIndex.from_tuples(tuples, names=None)", "intent": "Convert list of `tuples` to MultiIndex . With arguments `names`.", "question_id": 5578},
{"snippet": "MultiIndex.from_tuples(tuples, sortorder=None, names=None)", "intent": "Convert list of `tuples` to MultiIndex . With arguments `sortorder`, `names`.", "question_id": 5579},
{"snippet": "MultiIndex.get_indexer(target)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`.", "question_id": 5580},
{"snippet": "MultiIndex.get_indexer(target, method=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`.", "question_id": 5581},
{"snippet": "MultiIndex.get_indexer(target, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`.", "question_id": 5582},
{"snippet": "MultiIndex.get_indexer(target, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `tolerance`.", "question_id": 5583},
{"snippet": "MultiIndex.get_indexer(target, method=None, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`.", "question_id": 5584},
{"snippet": "MultiIndex.get_indexer(target, method=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `tolerance`.", "question_id": 5585},
{"snippet": "MultiIndex.get_indexer(target, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`, `tolerance`.", "question_id": 5586},
{"snippet": "MultiIndex.get_indexer(target, method=None, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`, `tolerance`.", "question_id": 5587},
{"snippet": "MultiIndex.get_indexer(target)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`.", "question_id": 5588},
{"snippet": "MultiIndex.get_indexer(target, method=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`.", "question_id": 5589},
{"snippet": "MultiIndex.get_indexer(target, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`.", "question_id": 5590},
{"snippet": "MultiIndex.get_indexer(target, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `tolerance`.", "question_id": 5591},
{"snippet": "MultiIndex.get_indexer(target, method=None, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`.", "question_id": 5592},
{"snippet": "MultiIndex.get_indexer(target, method=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `tolerance`.", "question_id": 5593},
{"snippet": "MultiIndex.get_indexer(target, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`, `tolerance`.", "question_id": 5594},
{"snippet": "MultiIndex.get_indexer(target, method=None, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`, `tolerance`.", "question_id": 5595},
{"snippet": "MultiIndex.get_indexer(target)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`.", "question_id": 5596},
{"snippet": "MultiIndex.get_indexer(target, method=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`.", "question_id": 5597},
{"snippet": "MultiIndex.get_indexer(target, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`.", "question_id": 5598},
{"snippet": "MultiIndex.get_indexer(target, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `tolerance`.", "question_id": 5599},
{"snippet": "MultiIndex.get_indexer(target, method=None, limit=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`.", "question_id": 5600},
{"snippet": "MultiIndex.get_indexer(target, method=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `tolerance`.", "question_id": 5601},
{"snippet": "MultiIndex.get_indexer(target, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `limit`, `tolerance`.", "question_id": 5602},
{"snippet": "MultiIndex.get_indexer(target, method=None, limit=None, tolerance=None)", "intent": "Compute indexer and mask for new index given the current index . With arguments `target`, `method`, `limit`, `tolerance`.", "question_id": 5603},
{"snippet": "MultiIndex.get_level_values(level)", "intent": "Return vector of label values for requested `level` .", "question_id": 5604},
{"snippet": "MultiIndex.get_level_values(level)", "intent": "Return vector of label values for requested `level` .", "question_id": 5605},
{"snippet": "MultiIndex.get_level_values(level)", "intent": "Return vector of label values for requested `level` .", "question_id": 5606},
{"snippet": "MultiIndex.get_loc(key)", "intent": "Get location for a label or a tuple of labels . The `key` can not be a slice , list of same-level labels , a boolean mask , or a sequence of such .", "question_id": 5607},
{"snippet": "MultiIndex.get_loc(key, method=None)", "intent": "Get location for a label or a tuple of labels . The `key` can not be a slice , list of same-level labels , a boolean mask , or a sequence of such . With arguments `method`.", "question_id": 5608},
{"snippet": "MultiIndex.get_loc(key)", "intent": "Get location for a label or a tuple of labels . The `key` can not be a slice , list of same-level labels , a boolean mask , or a sequence of such .", "question_id": 5609},
{"snippet": "MultiIndex.get_loc(key, method=None)", "intent": "Get location for a label or a tuple of labels . The `key` can not be a slice , list of same-level labels , a boolean mask , or a sequence of such . With arguments `method`.", "question_id": 5610},
{"snippet": "MultiIndex.get_loc(key)", "intent": "Get location for a label or a tuple of labels . The `key` can not be a slice , list of same-level labels , a boolean mask , or a sequence of such .", "question_id": 5611},
{"snippet": "MultiIndex.get_loc(key, method=None)", "intent": "Get location for a label or a tuple of labels . The `key` can not be a slice , list of same-level labels , a boolean mask , or a sequence of such . With arguments `method`.", "question_id": 5612},
{"snippet": "MultiIndex.get_loc_level(key)", "intent": "Get location and sliced index for requested label ( s ) /level ( s ) . With arguments `key`.", "question_id": 5613},
{"snippet": "MultiIndex.get_loc_level(key, level=0)", "intent": "Get location and sliced index for requested label ( s ) /level ( s ) . With arguments `key`, `level`.", "question_id": 5614},
{"snippet": "MultiIndex.get_loc_level(key, drop_level=True)", "intent": "Get location and sliced index for requested label ( s ) /level ( s ) . With arguments `key`, `drop_level`.", "question_id": 5615},
{"snippet": "MultiIndex.get_loc_level(key, level=0, drop_level=True)", "intent": "Get location and sliced index for requested label ( s ) /level ( s ) . With arguments `key`, `level`, `drop_level`.", "question_id": 5616},
{"snippet": "MultiIndex.get_loc_level(key)", "intent": "Get location and sliced index for requested label ( s ) /level ( s ) . With arguments `key`.", "question_id": 5617},
{"snippet": "MultiIndex.get_loc_level(key, level=0)", "intent": "Get location and sliced index for requested label ( s ) /level ( s ) . With arguments `key`, `level`.", "question_id": 5618},
{"snippet": "MultiIndex.get_loc_level(key, drop_level=True)", "intent": "Get location and sliced index for requested label ( s ) /level ( s ) . With arguments `key`, `drop_level`.", "question_id": 5619},
{"snippet": "MultiIndex.get_loc_level(key, level=0, drop_level=True)", "intent": "Get location and sliced index for requested label ( s ) /level ( s ) . With arguments `key`, `level`, `drop_level`.", "question_id": 5620},
{"snippet": "MultiIndex.get_loc_level(key)", "intent": "Get location and sliced index for requested label ( s ) /level ( s ) . With arguments `key`.", "question_id": 5621},
{"snippet": "MultiIndex.get_loc_level(key, level=0)", "intent": "Get location and sliced index for requested label ( s ) /level ( s ) . With arguments `key`, `level`.", "question_id": 5622},
{"snippet": "MultiIndex.get_loc_level(key, drop_level=True)", "intent": "Get location and sliced index for requested label ( s ) /level ( s ) . With arguments `key`, `drop_level`.", "question_id": 5623},
{"snippet": "MultiIndex.get_loc_level(key, level=0, drop_level=True)", "intent": "Get location and sliced index for requested label ( s ) /level ( s ) . With arguments `key`, `level`, `drop_level`.", "question_id": 5624},
{"snippet": "MultiIndex.get_locs(seq)", "intent": "Get location for a sequence of labels . With arguments `seq`.", "question_id": 5625},
{"snippet": "MultiIndex.get_locs(seq)", "intent": "Get location for a sequence of labels . With arguments `seq`.", "question_id": 5626},
{"snippet": "MultiIndex.get_locs(seq)", "intent": "Get location for a sequence of labels . With arguments `seq`.", "question_id": 5627},
{"snippet": "pandas.MultiIndex()", "intent": "A multi-level , or hierarchical , index object for pandas objects .", "question_id": 5628},
{"snippet": "pandas.MultiIndex(levels=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `levels`.", "question_id": 5629},
{"snippet": "pandas.MultiIndex(codes=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `codes`.", "question_id": 5630},
{"snippet": "pandas.MultiIndex(sortorder=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `sortorder`.", "question_id": 5631},
{"snippet": "pandas.MultiIndex(names=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `names`.", "question_id": 5632},
{"snippet": "pandas.MultiIndex(dtype=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `dtype`.", "question_id": 5633},
{"snippet": "pandas.MultiIndex(copy=False)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `copy`.", "question_id": 5634},
{"snippet": "pandas.MultiIndex(name=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `name`.", "question_id": 5635},
{"snippet": "pandas.MultiIndex(verify_integrity=True)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `verify_integrity`.", "question_id": 5636},
{"snippet": "pandas.MultiIndex(levels=None, codes=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `levels`, `codes`.", "question_id": 5637},
{"snippet": "pandas.MultiIndex()", "intent": "A multi-level , or hierarchical , index object for pandas objects .", "question_id": 5638},
{"snippet": "pandas.MultiIndex(levels=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `levels`.", "question_id": 5639},
{"snippet": "pandas.MultiIndex(codes=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `codes`.", "question_id": 5640},
{"snippet": "pandas.MultiIndex(sortorder=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `sortorder`.", "question_id": 5641},
{"snippet": "pandas.MultiIndex(names=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `names`.", "question_id": 5642},
{"snippet": "pandas.MultiIndex(dtype=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `dtype`.", "question_id": 5643},
{"snippet": "pandas.MultiIndex(copy=False)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `copy`.", "question_id": 5644},
{"snippet": "pandas.MultiIndex(name=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `name`.", "question_id": 5645},
{"snippet": "pandas.MultiIndex(verify_integrity=True)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `verify_integrity`.", "question_id": 5646},
{"snippet": "pandas.MultiIndex(levels=None, codes=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `levels`, `codes`.", "question_id": 5647},
{"snippet": "pandas.MultiIndex()", "intent": "A multi-level , or hierarchical , index object for pandas objects .", "question_id": 5648},
{"snippet": "pandas.MultiIndex(levels=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `levels`.", "question_id": 5649},
{"snippet": "pandas.MultiIndex(codes=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `codes`.", "question_id": 5650},
{"snippet": "pandas.MultiIndex(sortorder=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `sortorder`.", "question_id": 5651},
{"snippet": "pandas.MultiIndex(names=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `names`.", "question_id": 5652},
{"snippet": "pandas.MultiIndex(dtype=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `dtype`.", "question_id": 5653},
{"snippet": "pandas.MultiIndex(copy=False)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `copy`.", "question_id": 5654},
{"snippet": "pandas.MultiIndex(name=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `name`.", "question_id": 5655},
{"snippet": "pandas.MultiIndex(verify_integrity=True)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `verify_integrity`.", "question_id": 5656},
{"snippet": "pandas.MultiIndex(levels=None, codes=None)", "intent": "A multi-level , or hierarchical , index object for pandas objects . With arguments `levels`, `codes`.", "question_id": 5657},
{"snippet": "MultiIndex.remove_unused_levels()", "intent": "Create new MultiIndex from current that removes unused levels .", "question_id": 5658},
{"snippet": "MultiIndex.remove_unused_levels()", "intent": "Create new MultiIndex from current that removes unused levels .", "question_id": 5659},
{"snippet": "MultiIndex.remove_unused_levels()", "intent": "Create new MultiIndex from current that removes unused levels .", "question_id": 5660},
{"snippet": "MultiIndex.reorder_levels(order)", "intent": "Rearrange levels using input `order` .", "question_id": 5661},
{"snippet": "MultiIndex.reorder_levels(order)", "intent": "Rearrange levels using input `order` .", "question_id": 5662},
{"snippet": "MultiIndex.reorder_levels(order)", "intent": "Rearrange levels using input `order` .", "question_id": 5663},
{"snippet": "MultiIndex.set_codes(codes)", "intent": "Set new `codes` on MultiIndex .", "question_id": 5664},
{"snippet": "MultiIndex.set_codes(codes, level=None)", "intent": "Set new `codes` on MultiIndex . With arguments `level`.", "question_id": 5665},
{"snippet": "MultiIndex.set_codes(codes, inplace=None)", "intent": "Set new `codes` on MultiIndex . With arguments `inplace`.", "question_id": 5666},
{"snippet": "MultiIndex.set_codes(codes, verify_integrity=True)", "intent": "Set new `codes` on MultiIndex . With arguments `verify_integrity`.", "question_id": 5667},
{"snippet": "MultiIndex.set_codes(codes, level=None, inplace=None)", "intent": "Set new `codes` on MultiIndex . With arguments `level`, `inplace`.", "question_id": 5668},
{"snippet": "MultiIndex.set_codes(codes, level=None, verify_integrity=True)", "intent": "Set new `codes` on MultiIndex . With arguments `level`, `verify_integrity`.", "question_id": 5669},
{"snippet": "MultiIndex.set_codes(codes, inplace=None, verify_integrity=True)", "intent": "Set new `codes` on MultiIndex . With arguments `inplace`, `verify_integrity`.", "question_id": 5670},
{"snippet": "MultiIndex.set_codes(codes, level=None, inplace=None, verify_integrity=True)", "intent": "Set new `codes` on MultiIndex . With arguments `level`, `inplace`, `verify_integrity`.", "question_id": 5671},
{"snippet": "MultiIndex.set_codes(codes)", "intent": "Set new `codes` on MultiIndex .", "question_id": 5672},
{"snippet": "MultiIndex.set_codes(codes, level=None)", "intent": "Set new `codes` on MultiIndex . With arguments `level`.", "question_id": 5673},
{"snippet": "MultiIndex.set_codes(codes, inplace=None)", "intent": "Set new `codes` on MultiIndex . With arguments `inplace`.", "question_id": 5674},
{"snippet": "MultiIndex.set_codes(codes, verify_integrity=True)", "intent": "Set new `codes` on MultiIndex . With arguments `verify_integrity`.", "question_id": 5675},
{"snippet": "MultiIndex.set_codes(codes, level=None, inplace=None)", "intent": "Set new `codes` on MultiIndex . With arguments `level`, `inplace`.", "question_id": 5676},
{"snippet": "MultiIndex.set_codes(codes, level=None, verify_integrity=True)", "intent": "Set new `codes` on MultiIndex . With arguments `level`, `verify_integrity`.", "question_id": 5677},
{"snippet": "MultiIndex.set_codes(codes, inplace=None, verify_integrity=True)", "intent": "Set new `codes` on MultiIndex . With arguments `inplace`, `verify_integrity`.", "question_id": 5678},
{"snippet": "MultiIndex.set_codes(codes, level=None, inplace=None, verify_integrity=True)", "intent": "Set new `codes` on MultiIndex . With arguments `level`, `inplace`, `verify_integrity`.", "question_id": 5679},
{"snippet": "MultiIndex.set_codes(codes)", "intent": "Set new `codes` on MultiIndex .", "question_id": 5680},
{"snippet": "MultiIndex.set_codes(codes, level=None)", "intent": "Set new `codes` on MultiIndex . With arguments `level`.", "question_id": 5681},
{"snippet": "MultiIndex.set_codes(codes, inplace=None)", "intent": "Set new `codes` on MultiIndex . With arguments `inplace`.", "question_id": 5682},
{"snippet": "MultiIndex.set_codes(codes, verify_integrity=True)", "intent": "Set new `codes` on MultiIndex . With arguments `verify_integrity`.", "question_id": 5683},
{"snippet": "MultiIndex.set_codes(codes, level=None, inplace=None)", "intent": "Set new `codes` on MultiIndex . With arguments `level`, `inplace`.", "question_id": 5684},
{"snippet": "MultiIndex.set_codes(codes, level=None, verify_integrity=True)", "intent": "Set new `codes` on MultiIndex . With arguments `level`, `verify_integrity`.", "question_id": 5685},
{"snippet": "MultiIndex.set_codes(codes, inplace=None, verify_integrity=True)", "intent": "Set new `codes` on MultiIndex . With arguments `inplace`, `verify_integrity`.", "question_id": 5686},
{"snippet": "MultiIndex.set_codes(codes, level=None, inplace=None, verify_integrity=True)", "intent": "Set new `codes` on MultiIndex . With arguments `level`, `inplace`, `verify_integrity`.", "question_id": 5687},
{"snippet": "MultiIndex.set_levels(levels)", "intent": "Set new `levels` on MultiIndex .", "question_id": 5688},
{"snippet": "MultiIndex.set_levels(levels, level=None)", "intent": "Set new `levels` on MultiIndex . With arguments `level`.", "question_id": 5689},
{"snippet": "MultiIndex.set_levels(levels, inplace=None)", "intent": "Set new `levels` on MultiIndex . With arguments `inplace`.", "question_id": 5690},
{"snippet": "MultiIndex.set_levels(levels, verify_integrity=True)", "intent": "Set new `levels` on MultiIndex . With arguments `verify_integrity`.", "question_id": 5691},
{"snippet": "MultiIndex.set_levels(levels, level=None, inplace=None)", "intent": "Set new `levels` on MultiIndex . With arguments `level`, `inplace`.", "question_id": 5692},
{"snippet": "MultiIndex.set_levels(levels, level=None, verify_integrity=True)", "intent": "Set new `levels` on MultiIndex . With arguments `level`, `verify_integrity`.", "question_id": 5693},
{"snippet": "MultiIndex.set_levels(levels, inplace=None, verify_integrity=True)", "intent": "Set new `levels` on MultiIndex . With arguments `inplace`, `verify_integrity`.", "question_id": 5694},
{"snippet": "MultiIndex.set_levels(levels, level=None, inplace=None, verify_integrity=True)", "intent": "Set new `levels` on MultiIndex . With arguments `level`, `inplace`, `verify_integrity`.", "question_id": 5695},
{"snippet": "MultiIndex.set_levels(levels)", "intent": "Set new `levels` on MultiIndex .", "question_id": 5696},
{"snippet": "MultiIndex.set_levels(levels, level=None)", "intent": "Set new `levels` on MultiIndex . With arguments `level`.", "question_id": 5697},
{"snippet": "MultiIndex.set_levels(levels, inplace=None)", "intent": "Set new `levels` on MultiIndex . With arguments `inplace`.", "question_id": 5698},
{"snippet": "MultiIndex.set_levels(levels, verify_integrity=True)", "intent": "Set new `levels` on MultiIndex . With arguments `verify_integrity`.", "question_id": 5699},
{"snippet": "MultiIndex.set_levels(levels, level=None, inplace=None)", "intent": "Set new `levels` on MultiIndex . With arguments `level`, `inplace`.", "question_id": 5700},
{"snippet": "MultiIndex.set_levels(levels, level=None, verify_integrity=True)", "intent": "Set new `levels` on MultiIndex . With arguments `level`, `verify_integrity`.", "question_id": 5701},
{"snippet": "MultiIndex.set_levels(levels, inplace=None, verify_integrity=True)", "intent": "Set new `levels` on MultiIndex . With arguments `inplace`, `verify_integrity`.", "question_id": 5702},
{"snippet": "MultiIndex.set_levels(levels, level=None, inplace=None, verify_integrity=True)", "intent": "Set new `levels` on MultiIndex . With arguments `level`, `inplace`, `verify_integrity`.", "question_id": 5703},
{"snippet": "MultiIndex.set_levels(levels)", "intent": "Set new `levels` on MultiIndex .", "question_id": 5704},
{"snippet": "MultiIndex.set_levels(levels, level=None)", "intent": "Set new `levels` on MultiIndex . With arguments `level`.", "question_id": 5705},
{"snippet": "MultiIndex.set_levels(levels, inplace=None)", "intent": "Set new `levels` on MultiIndex . With arguments `inplace`.", "question_id": 5706},
{"snippet": "MultiIndex.set_levels(levels, verify_integrity=True)", "intent": "Set new `levels` on MultiIndex . With arguments `verify_integrity`.", "question_id": 5707},
{"snippet": "MultiIndex.set_levels(levels, level=None, inplace=None)", "intent": "Set new `levels` on MultiIndex . With arguments `level`, `inplace`.", "question_id": 5708},
{"snippet": "MultiIndex.set_levels(levels, level=None, verify_integrity=True)", "intent": "Set new `levels` on MultiIndex . With arguments `level`, `verify_integrity`.", "question_id": 5709},
{"snippet": "MultiIndex.set_levels(levels, inplace=None, verify_integrity=True)", "intent": "Set new `levels` on MultiIndex . With arguments `inplace`, `verify_integrity`.", "question_id": 5710},
{"snippet": "MultiIndex.set_levels(levels, level=None, inplace=None, verify_integrity=True)", "intent": "Set new `levels` on MultiIndex . With arguments `level`, `inplace`, `verify_integrity`.", "question_id": 5711},
{"snippet": "MultiIndex.sortlevel()", "intent": "Sort MultiIndex at the requested `level` .", "question_id": 5712},
{"snippet": "MultiIndex.sortlevel(level=0)", "intent": "Sort MultiIndex at the requested `level` .", "question_id": 5713},
{"snippet": "MultiIndex.sortlevel(ascending=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `ascending`.", "question_id": 5714},
{"snippet": "MultiIndex.sortlevel(sort_remaining=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `sort_remaining`.", "question_id": 5715},
{"snippet": "MultiIndex.sortlevel(level=0, ascending=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `ascending`.", "question_id": 5716},
{"snippet": "MultiIndex.sortlevel(level=0, sort_remaining=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `sort_remaining`.", "question_id": 5717},
{"snippet": "MultiIndex.sortlevel(ascending=True, sort_remaining=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `ascending`, `sort_remaining`.", "question_id": 5718},
{"snippet": "MultiIndex.sortlevel(level=0, ascending=True, sort_remaining=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `ascending`, `sort_remaining`.", "question_id": 5719},
{"snippet": "MultiIndex.sortlevel()", "intent": "Sort MultiIndex at the requested `level` .", "question_id": 5720},
{"snippet": "MultiIndex.sortlevel(level=0)", "intent": "Sort MultiIndex at the requested `level` .", "question_id": 5721},
{"snippet": "MultiIndex.sortlevel(ascending=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `ascending`.", "question_id": 5722},
{"snippet": "MultiIndex.sortlevel(sort_remaining=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `sort_remaining`.", "question_id": 5723},
{"snippet": "MultiIndex.sortlevel(level=0, ascending=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `ascending`.", "question_id": 5724},
{"snippet": "MultiIndex.sortlevel(level=0, sort_remaining=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `sort_remaining`.", "question_id": 5725},
{"snippet": "MultiIndex.sortlevel(ascending=True, sort_remaining=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `ascending`, `sort_remaining`.", "question_id": 5726},
{"snippet": "MultiIndex.sortlevel(level=0, ascending=True, sort_remaining=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `ascending`, `sort_remaining`.", "question_id": 5727},
{"snippet": "MultiIndex.sortlevel()", "intent": "Sort MultiIndex at the requested `level` .", "question_id": 5728},
{"snippet": "MultiIndex.sortlevel(level=0)", "intent": "Sort MultiIndex at the requested `level` .", "question_id": 5729},
{"snippet": "MultiIndex.sortlevel(ascending=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `ascending`.", "question_id": 5730},
{"snippet": "MultiIndex.sortlevel(sort_remaining=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `sort_remaining`.", "question_id": 5731},
{"snippet": "MultiIndex.sortlevel(level=0, ascending=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `ascending`.", "question_id": 5732},
{"snippet": "MultiIndex.sortlevel(level=0, sort_remaining=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `sort_remaining`.", "question_id": 5733},
{"snippet": "MultiIndex.sortlevel(ascending=True, sort_remaining=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `ascending`, `sort_remaining`.", "question_id": 5734},
{"snippet": "MultiIndex.sortlevel(level=0, ascending=True, sort_remaining=True)", "intent": "Sort MultiIndex at the requested `level` . With arguments `ascending`, `sort_remaining`.", "question_id": 5735},
{"snippet": "MultiIndex.swaplevel()", "intent": "Swap level `i` with level `j` .", "question_id": 5736},
{"snippet": "MultiIndex.swaplevel(i=- 2)", "intent": "Swap level `i` with level `j` .", "question_id": 5737},
{"snippet": "MultiIndex.swaplevel(j=- 1)", "intent": "Swap level `i` with level `j` .", "question_id": 5738},
{"snippet": "MultiIndex.swaplevel(i=- 2, j=- 1)", "intent": "Swap level `i` with level `j` .", "question_id": 5739},
{"snippet": "MultiIndex.swaplevel()", "intent": "Swap level `i` with level `j` .", "question_id": 5740},
{"snippet": "MultiIndex.swaplevel(i=- 2)", "intent": "Swap level `i` with level `j` .", "question_id": 5741},
{"snippet": "MultiIndex.swaplevel(j=- 1)", "intent": "Swap level `i` with level `j` .", "question_id": 5742},
{"snippet": "MultiIndex.swaplevel(i=- 2, j=- 1)", "intent": "Swap level `i` with level `j` .", "question_id": 5743},
{"snippet": "MultiIndex.swaplevel()", "intent": "Swap level `i` with level `j` .", "question_id": 5744},
{"snippet": "MultiIndex.swaplevel(i=- 2)", "intent": "Swap level `i` with level `j` .", "question_id": 5745},
{"snippet": "MultiIndex.swaplevel(j=- 1)", "intent": "Swap level `i` with level `j` .", "question_id": 5746},
{"snippet": "MultiIndex.swaplevel(i=- 2, j=- 1)", "intent": "Swap level `i` with level `j` .", "question_id": 5747},
{"snippet": "MultiIndex.to_flat_index()", "intent": "Convert a MultiIndex to an Index of Tuples containing the level values .", "question_id": 5748},
{"snippet": "MultiIndex.to_flat_index()", "intent": "Convert a MultiIndex to an Index of Tuples containing the level values .", "question_id": 5749},
{"snippet": "MultiIndex.to_flat_index()", "intent": "Convert a MultiIndex to an Index of Tuples containing the level values .", "question_id": 5750},
{"snippet": "MultiIndex.to_frame()", "intent": "Create a DataFrame with the levels of the MultiIndex as columns .", "question_id": 5751},
{"snippet": "MultiIndex.to_frame(index=True)", "intent": "Create a DataFrame with the levels of the MultiIndex as columns . With arguments `index`.", "question_id": 5752},
{"snippet": "MultiIndex.to_frame(name=None)", "intent": "Create a DataFrame with the levels of the MultiIndex as columns . With arguments `name`.", "question_id": 5753},
{"snippet": "MultiIndex.to_frame(index=True, name=None)", "intent": "Create a DataFrame with the levels of the MultiIndex as columns . With arguments `index`, `name`.", "question_id": 5754},
{"snippet": "MultiIndex.to_frame()", "intent": "Create a DataFrame with the levels of the MultiIndex as columns .", "question_id": 5755},
{"snippet": "MultiIndex.to_frame(index=True)", "intent": "Create a DataFrame with the levels of the MultiIndex as columns . With arguments `index`.", "question_id": 5756},
{"snippet": "MultiIndex.to_frame(name=None)", "intent": "Create a DataFrame with the levels of the MultiIndex as columns . With arguments `name`.", "question_id": 5757},
{"snippet": "MultiIndex.to_frame(index=True, name=None)", "intent": "Create a DataFrame with the levels of the MultiIndex as columns . With arguments `index`, `name`.", "question_id": 5758},
{"snippet": "MultiIndex.to_frame()", "intent": "Create a DataFrame with the levels of the MultiIndex as columns .", "question_id": 5759},
{"snippet": "MultiIndex.to_frame(index=True)", "intent": "Create a DataFrame with the levels of the MultiIndex as columns . With arguments `index`.", "question_id": 5760},
{"snippet": "MultiIndex.to_frame(name=None)", "intent": "Create a DataFrame with the levels of the MultiIndex as columns . With arguments `name`.", "question_id": 5761},
{"snippet": "MultiIndex.to_frame(index=True, name=None)", "intent": "Create a DataFrame with the levels of the MultiIndex as columns . With arguments `index`, `name`.", "question_id": 5762},
{"snippet": "Period.asfreq()", "intent": "Convert Period to desired frequency , at the start or end of the interval .", "question_id": 5763},
{"snippet": "Period.asfreq()", "intent": "Convert Period to desired frequency , at the start or end of the interval .", "question_id": 5764},
{"snippet": "Period.asfreq()", "intent": "Convert Period to desired frequency , at the start or end of the interval .", "question_id": 5765},
{"snippet": "Period.day", "intent": "Get day of the month that a Period falls on.", "question_id": 5766},
{"snippet": "Period.day", "intent": "Get day of the month that a Period falls on.", "question_id": 5767},
{"snippet": "Period.day", "intent": "Get day of the month that a Period falls on.", "question_id": 5768},
{"snippet": "Period.day_of_week", "intent": "Day of the week the period lies in, with Monday=0 and Sunday=6.", "question_id": 5769},
{"snippet": "Period.day_of_week", "intent": "Day of the week the period lies in, with Monday=0 and Sunday=6.", "question_id": 5770},
{"snippet": "Period.day_of_week", "intent": "Day of the week the period lies in, with Monday=0 and Sunday=6.", "question_id": 5771},
{"snippet": "Period.day_of_year", "intent": "Return the day of the year.", "question_id": 5772},
{"snippet": "Period.day_of_year", "intent": "Return the day of the year.", "question_id": 5773},
{"snippet": "Period.day_of_year", "intent": "Return the day of the year.", "question_id": 5774},
{"snippet": "Period.dayofweek", "intent": "Day of the week the period lies in, with Monday=0 and Sunday=6.", "question_id": 5775},
{"snippet": "Period.dayofweek", "intent": "Day of the week the period lies in, with Monday=0 and Sunday=6.", "question_id": 5776},
{"snippet": "Period.dayofweek", "intent": "Day of the week the period lies in, with Monday=0 and Sunday=6.", "question_id": 5777},
{"snippet": "Period.dayofyear", "intent": "Return the day of the year.", "question_id": 5778},
{"snippet": "Period.dayofyear", "intent": "Return the day of the year.", "question_id": 5779},
{"snippet": "Period.dayofyear", "intent": "Return the day of the year.", "question_id": 5780},
{"snippet": "Period.days_in_month", "intent": "Get the total number of days in the month that this period falls on.", "question_id": 5781},
{"snippet": "Period.days_in_month", "intent": "Get the total number of days in the month that this period falls on.", "question_id": 5782},
{"snippet": "Period.days_in_month", "intent": "Get the total number of days in the month that this period falls on.", "question_id": 5783},
{"snippet": "Period.daysinmonth", "intent": "Get the total number of days of the month that the Period falls in.", "question_id": 5784},
{"snippet": "Period.daysinmonth", "intent": "Get the total number of days of the month that the Period falls in.", "question_id": 5785},
{"snippet": "Period.daysinmonth", "intent": "Get the total number of days of the month that the Period falls in.", "question_id": 5786},
{"snippet": "Period.hour", "intent": "Get the hour of the day component of the Period.", "question_id": 5787},
{"snippet": "Period.hour", "intent": "Get the hour of the day component of the Period.", "question_id": 5788},
{"snippet": "Period.hour", "intent": "Get the hour of the day component of the Period.", "question_id": 5789},
{"snippet": "pandas.Period()", "intent": "Represents a period of time .", "question_id": 5790},
{"snippet": "pandas.Period(value=None)", "intent": "Represents a period of time . With arguments `value`.", "question_id": 5791},
{"snippet": "pandas.Period(freq=None)", "intent": "Represents a period of time . With arguments `freq`.", "question_id": 5792},
{"snippet": "pandas.Period(ordinal=None)", "intent": "Represents a period of time . With arguments `ordinal`.", "question_id": 5793},
{"snippet": "pandas.Period(year=None)", "intent": "Represents a period of time . With arguments `year`.", "question_id": 5794},
{"snippet": "pandas.Period(month=None)", "intent": "Represents a period of time . With arguments `month`.", "question_id": 5795},
{"snippet": "pandas.Period(quarter=None)", "intent": "Represents a period of time . With arguments `quarter`.", "question_id": 5796},
{"snippet": "pandas.Period(day=None)", "intent": "Represents a period of time . With arguments `day`.", "question_id": 5797},
{"snippet": "pandas.Period(hour=None)", "intent": "Represents a period of time . With arguments `hour`.", "question_id": 5798},
{"snippet": "pandas.Period(minute=None)", "intent": "Represents a period of time . With arguments `minute`.", "question_id": 5799},
{"snippet": "pandas.Period()", "intent": "Represents a period of time .", "question_id": 5800},
{"snippet": "pandas.Period(value=None)", "intent": "Represents a period of time . With arguments `value`.", "question_id": 5801},
{"snippet": "pandas.Period(freq=None)", "intent": "Represents a period of time . With arguments `freq`.", "question_id": 5802},
{"snippet": "pandas.Period(ordinal=None)", "intent": "Represents a period of time . With arguments `ordinal`.", "question_id": 5803},
{"snippet": "pandas.Period(year=None)", "intent": "Represents a period of time . With arguments `year`.", "question_id": 5804},
{"snippet": "pandas.Period(month=None)", "intent": "Represents a period of time . With arguments `month`.", "question_id": 5805},
{"snippet": "pandas.Period(quarter=None)", "intent": "Represents a period of time . With arguments `quarter`.", "question_id": 5806},
{"snippet": "pandas.Period(day=None)", "intent": "Represents a period of time . With arguments `day`.", "question_id": 5807},
{"snippet": "pandas.Period(hour=None)", "intent": "Represents a period of time . With arguments `hour`.", "question_id": 5808},
{"snippet": "pandas.Period(minute=None)", "intent": "Represents a period of time . With arguments `minute`.", "question_id": 5809},
{"snippet": "pandas.Period()", "intent": "Represents a period of time .", "question_id": 5810},
{"snippet": "pandas.Period(value=None)", "intent": "Represents a period of time . With arguments `value`.", "question_id": 5811},
{"snippet": "pandas.Period(freq=None)", "intent": "Represents a period of time . With arguments `freq`.", "question_id": 5812},
{"snippet": "pandas.Period(ordinal=None)", "intent": "Represents a period of time . With arguments `ordinal`.", "question_id": 5813},
{"snippet": "pandas.Period(year=None)", "intent": "Represents a period of time . With arguments `year`.", "question_id": 5814},
{"snippet": "pandas.Period(month=None)", "intent": "Represents a period of time . With arguments `month`.", "question_id": 5815},
{"snippet": "pandas.Period(quarter=None)", "intent": "Represents a period of time . With arguments `quarter`.", "question_id": 5816},
{"snippet": "pandas.Period(day=None)", "intent": "Represents a period of time . With arguments `day`.", "question_id": 5817},
{"snippet": "pandas.Period(hour=None)", "intent": "Represents a period of time . With arguments `hour`.", "question_id": 5818},
{"snippet": "pandas.Period(minute=None)", "intent": "Represents a period of time . With arguments `minute`.", "question_id": 5819},
{"snippet": "Period.minute", "intent": "Get minute of the hour component of the Period.", "question_id": 5820},
{"snippet": "Period.minute", "intent": "Get minute of the hour component of the Period.", "question_id": 5821},
{"snippet": "Period.minute", "intent": "Get minute of the hour component of the Period.", "question_id": 5822},
{"snippet": "Period.qyear", "intent": "Fiscal year the Period lies in according to its starting-quarter.", "question_id": 5823},
{"snippet": "Period.qyear", "intent": "Fiscal year the Period lies in according to its starting-quarter.", "question_id": 5824},
{"snippet": "Period.qyear", "intent": "Fiscal year the Period lies in according to its starting-quarter.", "question_id": 5825},
{"snippet": "Period.second", "intent": "Get the second component of the Period.", "question_id": 5826},
{"snippet": "Period.second", "intent": "Get the second component of the Period.", "question_id": 5827},
{"snippet": "Period.second", "intent": "Get the second component of the Period.", "question_id": 5828},
{"snippet": "Period.start_time", "intent": "Get the Timestamp for the start of the period.", "question_id": 5829},
{"snippet": "Period.start_time", "intent": "Get the Timestamp for the start of the period.", "question_id": 5830},
{"snippet": "Period.start_time", "intent": "Get the Timestamp for the start of the period.", "question_id": 5831},
{"snippet": "Period.strftime()", "intent": "Returns the string representation of the Period , depending on the selected fmt .", "question_id": 5832},
{"snippet": "Period.strftime()", "intent": "Returns the string representation of the Period , depending on the selected fmt .", "question_id": 5833},
{"snippet": "Period.strftime()", "intent": "Returns the string representation of the Period , depending on the selected fmt .", "question_id": 5834},
{"snippet": "Period.to_timestamp()", "intent": "Return the Timestamp representation of the Period .", "question_id": 5835},
{"snippet": "Period.to_timestamp()", "intent": "Return the Timestamp representation of the Period .", "question_id": 5836},
{"snippet": "Period.to_timestamp()", "intent": "Return the Timestamp representation of the Period .", "question_id": 5837},
{"snippet": "Period.week", "intent": "Get the week of the year on the given Period.", "question_id": 5838},
{"snippet": "Period.week", "intent": "Get the week of the year on the given Period.", "question_id": 5839},
{"snippet": "Period.week", "intent": "Get the week of the year on the given Period.", "question_id": 5840},
{"snippet": "Period.weekday", "intent": "Day of the week the period lies in, with Monday=0 and Sunday=6.", "question_id": 5841},
{"snippet": "Period.weekday", "intent": "Day of the week the period lies in, with Monday=0 and Sunday=6.", "question_id": 5842},
{"snippet": "Period.weekday", "intent": "Day of the week the period lies in, with Monday=0 and Sunday=6.", "question_id": 5843},
{"snippet": "pandas.PeriodDtype()", "intent": "An ExtensionDtype for Period data .", "question_id": 5844},
{"snippet": "pandas.PeriodDtype(freq=None)", "intent": "An ExtensionDtype for Period data . With arguments `freq`.", "question_id": 5845},
{"snippet": "pandas.PeriodDtype()", "intent": "An ExtensionDtype for Period data .", "question_id": 5846},
{"snippet": "pandas.PeriodDtype(freq=None)", "intent": "An ExtensionDtype for Period data . With arguments `freq`.", "question_id": 5847},
{"snippet": "pandas.PeriodDtype()", "intent": "An ExtensionDtype for Period data .", "question_id": 5848},
{"snippet": "pandas.PeriodDtype(freq=None)", "intent": "An ExtensionDtype for Period data . With arguments `freq`.", "question_id": 5849},
{"snippet": "PeriodIndex.asfreq()", "intent": "Convert the PeriodArray to the specified frequency `freq` .", "question_id": 5850},
{"snippet": "PeriodIndex.asfreq(freq=None)", "intent": "Convert the PeriodArray to the specified frequency `freq` .", "question_id": 5851},
{"snippet": "PeriodIndex.asfreq(how='E')", "intent": "Convert the PeriodArray to the specified frequency `freq` . With arguments `how`.", "question_id": 5852},
{"snippet": "PeriodIndex.asfreq(freq=None, how='E')", "intent": "Convert the PeriodArray to the specified frequency `freq` . With arguments `how`.", "question_id": 5853},
{"snippet": "PeriodIndex.asfreq()", "intent": "Convert the PeriodArray to the specified frequency `freq` .", "question_id": 5854},
{"snippet": "PeriodIndex.asfreq(freq=None)", "intent": "Convert the PeriodArray to the specified frequency `freq` .", "question_id": 5855},
{"snippet": "PeriodIndex.asfreq(how='E')", "intent": "Convert the PeriodArray to the specified frequency `freq` . With arguments `how`.", "question_id": 5856},
{"snippet": "PeriodIndex.asfreq(freq=None, how='E')", "intent": "Convert the PeriodArray to the specified frequency `freq` . With arguments `how`.", "question_id": 5857},
{"snippet": "PeriodIndex.asfreq()", "intent": "Convert the PeriodArray to the specified frequency `freq` .", "question_id": 5858},
{"snippet": "PeriodIndex.asfreq(freq=None)", "intent": "Convert the PeriodArray to the specified frequency `freq` .", "question_id": 5859},
{"snippet": "PeriodIndex.asfreq(how='E')", "intent": "Convert the PeriodArray to the specified frequency `freq` . With arguments `how`.", "question_id": 5860},
{"snippet": "PeriodIndex.asfreq(freq=None, how='E')", "intent": "Convert the PeriodArray to the specified frequency `freq` . With arguments `how`.", "question_id": 5861},
{"snippet": "pandas.PeriodIndex(**fields)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`.", "question_id": 5862},
{"snippet": "pandas.PeriodIndex(**fields, data=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `data`.", "question_id": 5863},
{"snippet": "pandas.PeriodIndex(**fields, ordinal=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`.", "question_id": 5864},
{"snippet": "pandas.PeriodIndex(**fields, freq=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `freq`.", "question_id": 5865},
{"snippet": "pandas.PeriodIndex(**fields, dtype=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `dtype`.", "question_id": 5866},
{"snippet": "pandas.PeriodIndex(**fields, copy=False)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `copy`.", "question_id": 5867},
{"snippet": "pandas.PeriodIndex(**fields, name=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `name`.", "question_id": 5868},
{"snippet": "pandas.PeriodIndex(**fields, data=None, ordinal=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `data`.", "question_id": 5869},
{"snippet": "pandas.PeriodIndex(**fields, data=None, freq=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `data`, `freq`.", "question_id": 5870},
{"snippet": "pandas.PeriodIndex(**fields, data=None, dtype=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `data`, `dtype`.", "question_id": 5871},
{"snippet": "pandas.PeriodIndex(**fields)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`.", "question_id": 5872},
{"snippet": "pandas.PeriodIndex(**fields, data=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `data`.", "question_id": 5873},
{"snippet": "pandas.PeriodIndex(**fields, ordinal=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`.", "question_id": 5874},
{"snippet": "pandas.PeriodIndex(**fields, freq=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `freq`.", "question_id": 5875},
{"snippet": "pandas.PeriodIndex(**fields, dtype=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `dtype`.", "question_id": 5876},
{"snippet": "pandas.PeriodIndex(**fields, copy=False)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `copy`.", "question_id": 5877},
{"snippet": "pandas.PeriodIndex(**fields, name=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `name`.", "question_id": 5878},
{"snippet": "pandas.PeriodIndex(**fields, data=None, ordinal=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `data`.", "question_id": 5879},
{"snippet": "pandas.PeriodIndex(**fields, data=None, freq=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `data`, `freq`.", "question_id": 5880},
{"snippet": "pandas.PeriodIndex(**fields, data=None, dtype=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `data`, `dtype`.", "question_id": 5881},
{"snippet": "pandas.PeriodIndex(**fields)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`.", "question_id": 5882},
{"snippet": "pandas.PeriodIndex(**fields, data=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `data`.", "question_id": 5883},
{"snippet": "pandas.PeriodIndex(**fields, ordinal=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`.", "question_id": 5884},
{"snippet": "pandas.PeriodIndex(**fields, freq=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `freq`.", "question_id": 5885},
{"snippet": "pandas.PeriodIndex(**fields, dtype=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `dtype`.", "question_id": 5886},
{"snippet": "pandas.PeriodIndex(**fields, copy=False)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `copy`.", "question_id": 5887},
{"snippet": "pandas.PeriodIndex(**fields, name=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `name`.", "question_id": 5888},
{"snippet": "pandas.PeriodIndex(**fields, data=None, ordinal=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `data`.", "question_id": 5889},
{"snippet": "pandas.PeriodIndex(**fields, data=None, freq=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `data`, `freq`.", "question_id": 5890},
{"snippet": "pandas.PeriodIndex(**fields, data=None, dtype=None)", "intent": "Immutable ndarray holding `ordinal` values indicating regular periods in time . With arguments `**fields`, `data`, `dtype`.", "question_id": 5891},
{"snippet": "PeriodIndex.strftime(*args, **kwargs)", "intent": "Convert to Index using specified date_format . With arguments `*args`, `**kwargs`.", "question_id": 5892},
{"snippet": "PeriodIndex.strftime(*args, **kwargs)", "intent": "Convert to Index using specified date_format . With arguments `*args`, `**kwargs`.", "question_id": 5893},
{"snippet": "PeriodIndex.strftime(*args, **kwargs)", "intent": "Convert to Index using specified date_format . With arguments `*args`, `**kwargs`.", "question_id": 5894},
{"snippet": "PeriodIndex.to_timestamp()", "intent": "Cast to DatetimeArray/Index .", "question_id": 5895},
{"snippet": "PeriodIndex.to_timestamp(freq=None)", "intent": "Cast to DatetimeArray/Index . With arguments `freq`.", "question_id": 5896},
{"snippet": "PeriodIndex.to_timestamp(how='start')", "intent": "Cast to DatetimeArray/Index . With arguments `how`.", "question_id": 5897},
{"snippet": "PeriodIndex.to_timestamp(freq=None, how='start')", "intent": "Cast to DatetimeArray/Index . With arguments `freq`, `how`.", "question_id": 5898},
{"snippet": "PeriodIndex.to_timestamp()", "intent": "Cast to DatetimeArray/Index .", "question_id": 5899},
{"snippet": "PeriodIndex.to_timestamp(freq=None)", "intent": "Cast to DatetimeArray/Index . With arguments `freq`.", "question_id": 5900},
{"snippet": "PeriodIndex.to_timestamp(how='start')", "intent": "Cast to DatetimeArray/Index . With arguments `how`.", "question_id": 5901},
{"snippet": "PeriodIndex.to_timestamp(freq=None, how='start')", "intent": "Cast to DatetimeArray/Index . With arguments `freq`, `how`.", "question_id": 5902},
{"snippet": "PeriodIndex.to_timestamp()", "intent": "Cast to DatetimeArray/Index .", "question_id": 5903},
{"snippet": "PeriodIndex.to_timestamp(freq=None)", "intent": "Cast to DatetimeArray/Index . With arguments `freq`.", "question_id": 5904},
{"snippet": "PeriodIndex.to_timestamp(how='start')", "intent": "Cast to DatetimeArray/Index . With arguments `how`.", "question_id": 5905},
{"snippet": "PeriodIndex.to_timestamp(freq=None, how='start')", "intent": "Cast to DatetimeArray/Index . With arguments `freq`, `how`.", "question_id": 5906},
{"snippet": "RangeIndex.from_range(data)", "intent": "Create RangeIndex from a range object . With arguments `data`.", "question_id": 5907},
{"snippet": "RangeIndex.from_range(data, name=None)", "intent": "Create RangeIndex from a range object . With arguments `data`, `name`.", "question_id": 5908},
{"snippet": "RangeIndex.from_range(data, dtype=None)", "intent": "Create RangeIndex from a range object . With arguments `data`, `dtype`.", "question_id": 5909},
{"snippet": "RangeIndex.from_range(data, name=None, dtype=None)", "intent": "Create RangeIndex from a range object . With arguments `data`, `name`, `dtype`.", "question_id": 5910},
{"snippet": "RangeIndex.from_range(data)", "intent": "Create RangeIndex from a range object . With arguments `data`.", "question_id": 5911},
{"snippet": "RangeIndex.from_range(data, name=None)", "intent": "Create RangeIndex from a range object . With arguments `data`, `name`.", "question_id": 5912},
{"snippet": "RangeIndex.from_range(data, dtype=None)", "intent": "Create RangeIndex from a range object . With arguments `data`, `dtype`.", "question_id": 5913},
{"snippet": "RangeIndex.from_range(data, name=None, dtype=None)", "intent": "Create RangeIndex from a range object . With arguments `data`, `name`, `dtype`.", "question_id": 5914},
{"snippet": "RangeIndex.from_range(data)", "intent": "Create RangeIndex from a range object . With arguments `data`.", "question_id": 5915},
{"snippet": "RangeIndex.from_range(data, name=None)", "intent": "Create RangeIndex from a range object . With arguments `data`, `name`.", "question_id": 5916},
{"snippet": "RangeIndex.from_range(data, dtype=None)", "intent": "Create RangeIndex from a range object . With arguments `data`, `dtype`.", "question_id": 5917},
{"snippet": "RangeIndex.from_range(data, name=None, dtype=None)", "intent": "Create RangeIndex from a range object . With arguments `data`, `name`, `dtype`.", "question_id": 5918},
{"snippet": "pandas.RangeIndex()", "intent": "Immutable Index implementing a monotonic integer range .", "question_id": 5919},
{"snippet": "pandas.RangeIndex(start=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `start`.", "question_id": 5920},
{"snippet": "pandas.RangeIndex(stop=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `stop`.", "question_id": 5921},
{"snippet": "pandas.RangeIndex(step=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `step`.", "question_id": 5922},
{"snippet": "pandas.RangeIndex(dtype=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `dtype`.", "question_id": 5923},
{"snippet": "pandas.RangeIndex(copy=False)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `copy`.", "question_id": 5924},
{"snippet": "pandas.RangeIndex(name=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `name`.", "question_id": 5925},
{"snippet": "pandas.RangeIndex(start=None, stop=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `start`, `stop`.", "question_id": 5926},
{"snippet": "pandas.RangeIndex(start=None, step=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `start`, `step`.", "question_id": 5927},
{"snippet": "pandas.RangeIndex(start=None, dtype=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `start`, `dtype`.", "question_id": 5928},
{"snippet": "pandas.RangeIndex()", "intent": "Immutable Index implementing a monotonic integer range .", "question_id": 5929},
{"snippet": "pandas.RangeIndex(start=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `start`.", "question_id": 5930},
{"snippet": "pandas.RangeIndex(stop=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `stop`.", "question_id": 5931},
{"snippet": "pandas.RangeIndex(step=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `step`.", "question_id": 5932},
{"snippet": "pandas.RangeIndex(dtype=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `dtype`.", "question_id": 5933},
{"snippet": "pandas.RangeIndex(copy=False)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `copy`.", "question_id": 5934},
{"snippet": "pandas.RangeIndex(name=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `name`.", "question_id": 5935},
{"snippet": "pandas.RangeIndex(start=None, stop=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `start`, `stop`.", "question_id": 5936},
{"snippet": "pandas.RangeIndex(start=None, step=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `start`, `step`.", "question_id": 5937},
{"snippet": "pandas.RangeIndex(start=None, dtype=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `start`, `dtype`.", "question_id": 5938},
{"snippet": "pandas.RangeIndex()", "intent": "Immutable Index implementing a monotonic integer range .", "question_id": 5939},
{"snippet": "pandas.RangeIndex(start=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `start`.", "question_id": 5940},
{"snippet": "pandas.RangeIndex(stop=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `stop`.", "question_id": 5941},
{"snippet": "pandas.RangeIndex(step=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `step`.", "question_id": 5942},
{"snippet": "pandas.RangeIndex(dtype=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `dtype`.", "question_id": 5943},
{"snippet": "pandas.RangeIndex(copy=False)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `copy`.", "question_id": 5944},
{"snippet": "pandas.RangeIndex(name=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `name`.", "question_id": 5945},
{"snippet": "pandas.RangeIndex(start=None, stop=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `start`, `stop`.", "question_id": 5946},
{"snippet": "pandas.RangeIndex(start=None, step=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `start`, `step`.", "question_id": 5947},
{"snippet": "pandas.RangeIndex(start=None, dtype=None)", "intent": "Immutable Index implementing a monotonic integer range . With arguments `start`, `dtype`.", "question_id": 5948},
{"snippet": "Series.__array__()", "intent": "Return the values as a NumPy array .", "question_id": 5949},
{"snippet": "Series.__array__(dtype=None)", "intent": "Return the values as a NumPy array . With arguments `dtype`.", "question_id": 5950},
{"snippet": "Series.__array__()", "intent": "Return the values as a NumPy array .", "question_id": 5951},
{"snippet": "Series.__array__(dtype=None)", "intent": "Return the values as a NumPy array . With arguments `dtype`.", "question_id": 5952},
{"snippet": "Series.__array__()", "intent": "Return the values as a NumPy array .", "question_id": 5953},
{"snippet": "Series.__array__(dtype=None)", "intent": "Return the values as a NumPy array . With arguments `dtype`.", "question_id": 5954},
{"snippet": "Series.__iter__()", "intent": "Return an iterator of the values .", "question_id": 5955},
{"snippet": "Series.__iter__()", "intent": "Return an iterator of the values .", "question_id": 5956},
{"snippet": "Series.__iter__()", "intent": "Return an iterator of the values .", "question_id": 5957},
{"snippet": "Series.abs()", "intent": "Return a Series/DataFrame with absolute numeric value of each element .", "question_id": 5958},
{"snippet": "Series.abs()", "intent": "Return a Series/DataFrame with absolute numeric value of each element .", "question_id": 5959},
{"snippet": "Series.abs()", "intent": "Return a Series/DataFrame with absolute numeric value of each element .", "question_id": 5960},
{"snippet": "Series.add(other)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) .", "question_id": 5961},
{"snippet": "Series.add(other, level=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . With arguments `level`.", "question_id": 5962},
{"snippet": "Series.add(other, fill_value=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . Equivalent to series + other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 5963},
{"snippet": "Series.add(other, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . With arguments `axis`.", "question_id": 5964},
{"snippet": "Series.add(other, level=None, fill_value=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . Equivalent to series + other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 5965},
{"snippet": "Series.add(other, level=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . With arguments `level`, `axis`.", "question_id": 5966},
{"snippet": "Series.add(other, fill_value=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . Equivalent to series + other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 5967},
{"snippet": "Series.add(other, level=None, fill_value=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . Equivalent to series + other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 5968},
{"snippet": "Series.add(other)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) .", "question_id": 5969},
{"snippet": "Series.add(other, level=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . With arguments `level`.", "question_id": 5970},
{"snippet": "Series.add(other, fill_value=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . Equivalent to series + other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 5971},
{"snippet": "Series.add(other, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . With arguments `axis`.", "question_id": 5972},
{"snippet": "Series.add(other, level=None, fill_value=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . Equivalent to series + other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 5973},
{"snippet": "Series.add(other, level=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . With arguments `level`, `axis`.", "question_id": 5974},
{"snippet": "Series.add(other, fill_value=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . Equivalent to series + other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 5975},
{"snippet": "Series.add(other, level=None, fill_value=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . Equivalent to series + other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 5976},
{"snippet": "Series.add(other)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) .", "question_id": 5977},
{"snippet": "Series.add(other, level=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . With arguments `level`.", "question_id": 5978},
{"snippet": "Series.add(other, fill_value=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . Equivalent to series + other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 5979},
{"snippet": "Series.add(other, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . With arguments `axis`.", "question_id": 5980},
{"snippet": "Series.add(other, level=None, fill_value=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . Equivalent to series + other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 5981},
{"snippet": "Series.add(other, level=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . With arguments `level`, `axis`.", "question_id": 5982},
{"snippet": "Series.add(other, fill_value=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . Equivalent to series + other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 5983},
{"snippet": "Series.add(other, level=None, fill_value=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator add ) . Equivalent to series + other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 5984},
{"snippet": "Series.add_prefix(prefix)", "intent": "Prefix labels with string `prefix` .", "question_id": 5985},
{"snippet": "Series.add_prefix(prefix)", "intent": "Prefix labels with string `prefix` .", "question_id": 5986},
{"snippet": "Series.add_prefix(prefix)", "intent": "Prefix labels with string `prefix` .", "question_id": 5987},
{"snippet": "Series.add_suffix(suffix)", "intent": "Suffix labels with string `suffix` .", "question_id": 5988},
{"snippet": "Series.add_suffix(suffix)", "intent": "Suffix labels with string `suffix` .", "question_id": 5989},
{"snippet": "Series.add_suffix(suffix)", "intent": "Suffix labels with string `suffix` .", "question_id": 5990},
{"snippet": "Series.agg(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 5991},
{"snippet": "Series.agg(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 5992},
{"snippet": "Series.agg(*args, **kwargs, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 5993},
{"snippet": "Series.agg(*args, **kwargs, func=None, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 5994},
{"snippet": "Series.agg(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 5995},
{"snippet": "Series.agg(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 5996},
{"snippet": "Series.agg(*args, **kwargs, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 5997},
{"snippet": "Series.agg(*args, **kwargs, func=None, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 5998},
{"snippet": "Series.agg(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 5999},
{"snippet": "Series.agg(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 6000},
{"snippet": "Series.agg(*args, **kwargs, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6001},
{"snippet": "Series.agg(*args, **kwargs, func=None, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 6002},
{"snippet": "Series.aggregate(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6003},
{"snippet": "Series.aggregate(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 6004},
{"snippet": "Series.aggregate(*args, **kwargs, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6005},
{"snippet": "Series.aggregate(*args, **kwargs, func=None, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 6006},
{"snippet": "Series.aggregate(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6007},
{"snippet": "Series.aggregate(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 6008},
{"snippet": "Series.aggregate(*args, **kwargs, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6009},
{"snippet": "Series.aggregate(*args, **kwargs, func=None, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 6010},
{"snippet": "Series.aggregate(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6011},
{"snippet": "Series.aggregate(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 6012},
{"snippet": "Series.aggregate(*args, **kwargs, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6013},
{"snippet": "Series.aggregate(*args, **kwargs, func=None, axis=0)", "intent": "Aggregate using one or more operations over the specified `axis` . With arguments `*args`, `**kwargs`, `func`.", "question_id": 6014},
{"snippet": "Series.align(other)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 6015},
{"snippet": "Series.align(other, join='outer')", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 6016},
{"snippet": "Series.align(other, axis=None)", "intent": "Align two objects on their axes with the specified `join` `method` . Join method is specified for each `axis` Index . With arguments `other`.", "question_id": 6017},
{"snippet": "Series.align(other, level=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `level`.", "question_id": 6018},
{"snippet": "Series.align(other, copy=True)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `copy`.", "question_id": 6019},
{"snippet": "Series.align(other, fill_value=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `fill_value`.", "question_id": 6020},
{"snippet": "Series.align(other, method=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 6021},
{"snippet": "Series.align(other, limit=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `limit`.", "question_id": 6022},
{"snippet": "Series.align(other, fill_axis=0)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `fill_axis`.", "question_id": 6023},
{"snippet": "Series.align(other, broadcast_axis=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `broadcast_axis`.", "question_id": 6024},
{"snippet": "Series.align(other)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 6025},
{"snippet": "Series.align(other, join='outer')", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 6026},
{"snippet": "Series.align(other, axis=None)", "intent": "Align two objects on their axes with the specified `join` `method` . Join method is specified for each `axis` Index . With arguments `other`.", "question_id": 6027},
{"snippet": "Series.align(other, level=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `level`.", "question_id": 6028},
{"snippet": "Series.align(other, copy=True)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `copy`.", "question_id": 6029},
{"snippet": "Series.align(other, fill_value=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `fill_value`.", "question_id": 6030},
{"snippet": "Series.align(other, method=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 6031},
{"snippet": "Series.align(other, limit=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `limit`.", "question_id": 6032},
{"snippet": "Series.align(other, fill_axis=0)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `fill_axis`.", "question_id": 6033},
{"snippet": "Series.align(other, broadcast_axis=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `broadcast_axis`.", "question_id": 6034},
{"snippet": "Series.align(other)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 6035},
{"snippet": "Series.align(other, join='outer')", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 6036},
{"snippet": "Series.align(other, axis=None)", "intent": "Align two objects on their axes with the specified `join` `method` . Join method is specified for each `axis` Index . With arguments `other`.", "question_id": 6037},
{"snippet": "Series.align(other, level=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `level`.", "question_id": 6038},
{"snippet": "Series.align(other, copy=True)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `copy`.", "question_id": 6039},
{"snippet": "Series.align(other, fill_value=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `fill_value`.", "question_id": 6040},
{"snippet": "Series.align(other, method=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`.", "question_id": 6041},
{"snippet": "Series.align(other, limit=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `limit`.", "question_id": 6042},
{"snippet": "Series.align(other, fill_axis=0)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `fill_axis`.", "question_id": 6043},
{"snippet": "Series.align(other, broadcast_axis=None)", "intent": "Align two objects on their axes with the specified `join` `method` . With arguments `other`, `broadcast_axis`.", "question_id": 6044},
{"snippet": "Series.all(**kwargs)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 6045},
{"snippet": "Series.all(**kwargs, axis=0)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 6046},
{"snippet": "Series.all(**kwargs, bool_only=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 6047},
{"snippet": "Series.all(**kwargs, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 6048},
{"snippet": "Series.all(**kwargs, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 6049},
{"snippet": "Series.all(**kwargs, axis=0, bool_only=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 6050},
{"snippet": "Series.all(**kwargs, axis=0, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 6051},
{"snippet": "Series.all(**kwargs, axis=0, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 6052},
{"snippet": "Series.all(**kwargs, bool_only=None, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `skipna`.", "question_id": 6053},
{"snippet": "Series.all(**kwargs, bool_only=None, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `level`.", "question_id": 6054},
{"snippet": "Series.all(**kwargs)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 6055},
{"snippet": "Series.all(**kwargs, axis=0)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 6056},
{"snippet": "Series.all(**kwargs, bool_only=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 6057},
{"snippet": "Series.all(**kwargs, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 6058},
{"snippet": "Series.all(**kwargs, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 6059},
{"snippet": "Series.all(**kwargs, axis=0, bool_only=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 6060},
{"snippet": "Series.all(**kwargs, axis=0, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 6061},
{"snippet": "Series.all(**kwargs, axis=0, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 6062},
{"snippet": "Series.all(**kwargs, bool_only=None, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `skipna`.", "question_id": 6063},
{"snippet": "Series.all(**kwargs, bool_only=None, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `level`.", "question_id": 6064},
{"snippet": "Series.all(**kwargs)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 6065},
{"snippet": "Series.all(**kwargs, axis=0)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 6066},
{"snippet": "Series.all(**kwargs, bool_only=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 6067},
{"snippet": "Series.all(**kwargs, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 6068},
{"snippet": "Series.all(**kwargs, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 6069},
{"snippet": "Series.all(**kwargs, axis=0, bool_only=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 6070},
{"snippet": "Series.all(**kwargs, axis=0, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 6071},
{"snippet": "Series.all(**kwargs, axis=0, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 6072},
{"snippet": "Series.all(**kwargs, bool_only=None, skipna=True)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `skipna`.", "question_id": 6073},
{"snippet": "Series.all(**kwargs, bool_only=None, level=None)", "intent": "Return whether all elements are True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `level`.", "question_id": 6074},
{"snippet": "Series.any(**kwargs)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 6075},
{"snippet": "Series.any(**kwargs, axis=0)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 6076},
{"snippet": "Series.any(**kwargs, bool_only=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 6077},
{"snippet": "Series.any(**kwargs, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 6078},
{"snippet": "Series.any(**kwargs, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 6079},
{"snippet": "Series.any(**kwargs, axis=0, bool_only=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 6080},
{"snippet": "Series.any(**kwargs, axis=0, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 6081},
{"snippet": "Series.any(**kwargs, axis=0, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 6082},
{"snippet": "Series.any(**kwargs, bool_only=None, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `skipna`.", "question_id": 6083},
{"snippet": "Series.any(**kwargs, bool_only=None, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `level`.", "question_id": 6084},
{"snippet": "Series.any(**kwargs)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 6085},
{"snippet": "Series.any(**kwargs, axis=0)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 6086},
{"snippet": "Series.any(**kwargs, bool_only=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 6087},
{"snippet": "Series.any(**kwargs, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 6088},
{"snippet": "Series.any(**kwargs, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 6089},
{"snippet": "Series.any(**kwargs, axis=0, bool_only=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 6090},
{"snippet": "Series.any(**kwargs, axis=0, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 6091},
{"snippet": "Series.any(**kwargs, axis=0, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 6092},
{"snippet": "Series.any(**kwargs, bool_only=None, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `skipna`.", "question_id": 6093},
{"snippet": "Series.any(**kwargs, bool_only=None, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `level`.", "question_id": 6094},
{"snippet": "Series.any(**kwargs)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 6095},
{"snippet": "Series.any(**kwargs, axis=0)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`.", "question_id": 6096},
{"snippet": "Series.any(**kwargs, bool_only=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 6097},
{"snippet": "Series.any(**kwargs, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 6098},
{"snippet": "Series.any(**kwargs, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 6099},
{"snippet": "Series.any(**kwargs, axis=0, bool_only=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`.", "question_id": 6100},
{"snippet": "Series.any(**kwargs, axis=0, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 6101},
{"snippet": "Series.any(**kwargs, axis=0, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `level`.", "question_id": 6102},
{"snippet": "Series.any(**kwargs, bool_only=None, skipna=True)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `skipna`.", "question_id": 6103},
{"snippet": "Series.any(**kwargs, bool_only=None, level=None)", "intent": "Return whether any element is True , potentially over an `axis` . With arguments `**kwargs`, `bool_only`, `level`.", "question_id": 6104},
{"snippet": "Series.append(to_append)", "intent": "Concatenate two or more Series . With arguments `to_append`.", "question_id": 6105},
{"snippet": "Series.append(to_append, ignore_index=False)", "intent": "Concatenate two or more Series . With `ignore_index` set to True : With arguments `to_append`.", "question_id": 6106},
{"snippet": "Series.append(to_append, verify_integrity=False)", "intent": "Concatenate two or more Series . With `verify_integrity` set to True : With arguments `to_append`.", "question_id": 6107},
{"snippet": "Series.append(to_append, ignore_index=False, verify_integrity=False)", "intent": "Concatenate two or more Series . With `ignore_index` set to True : With `verify_integrity` set to True : With arguments `to_append`.", "question_id": 6108},
{"snippet": "Series.append(to_append)", "intent": "Concatenate two or more Series . With arguments `to_append`.", "question_id": 6109},
{"snippet": "Series.append(to_append, ignore_index=False)", "intent": "Concatenate two or more Series . With `ignore_index` set to True : With arguments `to_append`.", "question_id": 6110},
{"snippet": "Series.append(to_append, verify_integrity=False)", "intent": "Concatenate two or more Series . With `verify_integrity` set to True : With arguments `to_append`.", "question_id": 6111},
{"snippet": "Series.append(to_append, ignore_index=False, verify_integrity=False)", "intent": "Concatenate two or more Series . With `ignore_index` set to True : With `verify_integrity` set to True : With arguments `to_append`.", "question_id": 6112},
{"snippet": "Series.append(to_append)", "intent": "Concatenate two or more Series . With arguments `to_append`.", "question_id": 6113},
{"snippet": "Series.append(to_append, ignore_index=False)", "intent": "Concatenate two or more Series . With `ignore_index` set to True : With arguments `to_append`.", "question_id": 6114},
{"snippet": "Series.append(to_append, verify_integrity=False)", "intent": "Concatenate two or more Series . With `verify_integrity` set to True : With arguments `to_append`.", "question_id": 6115},
{"snippet": "Series.append(to_append, ignore_index=False, verify_integrity=False)", "intent": "Concatenate two or more Series . With `ignore_index` set to True : With `verify_integrity` set to True : With arguments `to_append`.", "question_id": 6116},
{"snippet": "Series.apply(func, **kwargs)", "intent": "Invoke function on values of Series . With arguments `func`, `**kwargs`.", "question_id": 6117},
{"snippet": "Series.apply(func, **kwargs, convert_dtype=True)", "intent": "Invoke function on values of Series . With arguments `func`, `**kwargs`, `convert_dtype`.", "question_id": 6118},
{"snippet": "Series.apply(func, **kwargs, args=())", "intent": "Invoke function on values of Series . Define a custom function that needs additional positional arguments and pass these additional arguments using the `args` keyword . With arguments `func`, `**kwargs`.", "question_id": 6119},
{"snippet": "Series.apply(func, **kwargs, convert_dtype=True, args=())", "intent": "Invoke function on values of Series . Define a custom function that needs additional positional arguments and pass these additional arguments using the `args` keyword . With arguments `func`, `**kwargs`, `convert_dtype`.", "question_id": 6120},
{"snippet": "Series.apply(func, **kwargs)", "intent": "Invoke function on values of Series . With arguments `func`, `**kwargs`.", "question_id": 6121},
{"snippet": "Series.apply(func, **kwargs, convert_dtype=True)", "intent": "Invoke function on values of Series . With arguments `func`, `**kwargs`, `convert_dtype`.", "question_id": 6122},
{"snippet": "Series.apply(func, **kwargs, args=())", "intent": "Invoke function on values of Series . Define a custom function that needs additional positional arguments and pass these additional arguments using the `args` keyword . With arguments `func`, `**kwargs`.", "question_id": 6123},
{"snippet": "Series.apply(func, **kwargs, convert_dtype=True, args=())", "intent": "Invoke function on values of Series . Define a custom function that needs additional positional arguments and pass these additional arguments using the `args` keyword . With arguments `func`, `**kwargs`, `convert_dtype`.", "question_id": 6124},
{"snippet": "Series.apply(func, **kwargs)", "intent": "Invoke function on values of Series . With arguments `func`, `**kwargs`.", "question_id": 6125},
{"snippet": "Series.apply(func, **kwargs, convert_dtype=True)", "intent": "Invoke function on values of Series . With arguments `func`, `**kwargs`, `convert_dtype`.", "question_id": 6126},
{"snippet": "Series.apply(func, **kwargs, args=())", "intent": "Invoke function on values of Series . Define a custom function that needs additional positional arguments and pass these additional arguments using the `args` keyword . With arguments `func`, `**kwargs`.", "question_id": 6127},
{"snippet": "Series.apply(func, **kwargs, convert_dtype=True, args=())", "intent": "Invoke function on values of Series . Define a custom function that needs additional positional arguments and pass these additional arguments using the `args` keyword . With arguments `func`, `**kwargs`, `convert_dtype`.", "question_id": 6128},
{"snippet": "Series.argmax(*args, **kwargs)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`.", "question_id": 6129},
{"snippet": "Series.argmax(*args, **kwargs, axis=None)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 6130},
{"snippet": "Series.argmax(*args, **kwargs, skipna=True)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6131},
{"snippet": "Series.argmax(*args, **kwargs, axis=None, skipna=True)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 6132},
{"snippet": "Series.argmax(*args, **kwargs)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`.", "question_id": 6133},
{"snippet": "Series.argmax(*args, **kwargs, axis=None)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 6134},
{"snippet": "Series.argmax(*args, **kwargs, skipna=True)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6135},
{"snippet": "Series.argmax(*args, **kwargs, axis=None, skipna=True)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 6136},
{"snippet": "Series.argmax(*args, **kwargs)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`.", "question_id": 6137},
{"snippet": "Series.argmax(*args, **kwargs, axis=None)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 6138},
{"snippet": "Series.argmax(*args, **kwargs, skipna=True)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6139},
{"snippet": "Series.argmax(*args, **kwargs, axis=None, skipna=True)", "intent": "Return int position of the largest value in the Series . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 6140},
{"snippet": "Series.argmin(*args, **kwargs)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`.", "question_id": 6141},
{"snippet": "Series.argmin(*args, **kwargs, axis=None)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 6142},
{"snippet": "Series.argmin(*args, **kwargs, skipna=True)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6143},
{"snippet": "Series.argmin(*args, **kwargs, axis=None, skipna=True)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 6144},
{"snippet": "Series.argmin(*args, **kwargs)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`.", "question_id": 6145},
{"snippet": "Series.argmin(*args, **kwargs, axis=None)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 6146},
{"snippet": "Series.argmin(*args, **kwargs, skipna=True)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6147},
{"snippet": "Series.argmin(*args, **kwargs, axis=None, skipna=True)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 6148},
{"snippet": "Series.argmin(*args, **kwargs)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`.", "question_id": 6149},
{"snippet": "Series.argmin(*args, **kwargs, axis=None)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 6150},
{"snippet": "Series.argmin(*args, **kwargs, skipna=True)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6151},
{"snippet": "Series.argmin(*args, **kwargs, axis=None, skipna=True)", "intent": "Return int position of the smallest value in the Series . With arguments `*args`, `**kwargs`, `axis`, `skipna`.", "question_id": 6152},
{"snippet": "Series.argsort()", "intent": "Return the integer indices that would sort the Series values .", "question_id": 6153},
{"snippet": "Series.argsort(axis=0)", "intent": "Return the integer indices that would sort the Series values . With arguments `axis`.", "question_id": 6154},
{"snippet": "Series.argsort(kind='quicksort')", "intent": "Return the integer indices that would sort the Series values . With arguments `kind`.", "question_id": 6155},
{"snippet": "Series.argsort(order=None)", "intent": "Return the integer indices that would sort the Series values . With arguments `order`.", "question_id": 6156},
{"snippet": "Series.argsort(axis=0, kind='quicksort')", "intent": "Return the integer indices that would sort the Series values . With arguments `axis`, `kind`.", "question_id": 6157},
{"snippet": "Series.argsort(axis=0, order=None)", "intent": "Return the integer indices that would sort the Series values . With arguments `axis`, `order`.", "question_id": 6158},
{"snippet": "Series.argsort(kind='quicksort', order=None)", "intent": "Return the integer indices that would sort the Series values . With arguments `kind`, `order`.", "question_id": 6159},
{"snippet": "Series.argsort(axis=0, kind='quicksort', order=None)", "intent": "Return the integer indices that would sort the Series values . With arguments `axis`, `kind`, `order`.", "question_id": 6160},
{"snippet": "Series.argsort()", "intent": "Return the integer indices that would sort the Series values .", "question_id": 6161},
{"snippet": "Series.argsort(axis=0)", "intent": "Return the integer indices that would sort the Series values . With arguments `axis`.", "question_id": 6162},
{"snippet": "Series.argsort(kind='quicksort')", "intent": "Return the integer indices that would sort the Series values . With arguments `kind`.", "question_id": 6163},
{"snippet": "Series.argsort(order=None)", "intent": "Return the integer indices that would sort the Series values . With arguments `order`.", "question_id": 6164},
{"snippet": "Series.argsort(axis=0, kind='quicksort')", "intent": "Return the integer indices that would sort the Series values . With arguments `axis`, `kind`.", "question_id": 6165},
{"snippet": "Series.argsort(axis=0, order=None)", "intent": "Return the integer indices that would sort the Series values . With arguments `axis`, `order`.", "question_id": 6166},
{"snippet": "Series.argsort(kind='quicksort', order=None)", "intent": "Return the integer indices that would sort the Series values . With arguments `kind`, `order`.", "question_id": 6167},
{"snippet": "Series.argsort(axis=0, kind='quicksort', order=None)", "intent": "Return the integer indices that would sort the Series values . With arguments `axis`, `kind`, `order`.", "question_id": 6168},
{"snippet": "Series.argsort()", "intent": "Return the integer indices that would sort the Series values .", "question_id": 6169},
{"snippet": "Series.argsort(axis=0)", "intent": "Return the integer indices that would sort the Series values . With arguments `axis`.", "question_id": 6170},
{"snippet": "Series.argsort(kind='quicksort')", "intent": "Return the integer indices that would sort the Series values . With arguments `kind`.", "question_id": 6171},
{"snippet": "Series.argsort(order=None)", "intent": "Return the integer indices that would sort the Series values . With arguments `order`.", "question_id": 6172},
{"snippet": "Series.argsort(axis=0, kind='quicksort')", "intent": "Return the integer indices that would sort the Series values . With arguments `axis`, `kind`.", "question_id": 6173},
{"snippet": "Series.argsort(axis=0, order=None)", "intent": "Return the integer indices that would sort the Series values . With arguments `axis`, `order`.", "question_id": 6174},
{"snippet": "Series.argsort(kind='quicksort', order=None)", "intent": "Return the integer indices that would sort the Series values . With arguments `kind`, `order`.", "question_id": 6175},
{"snippet": "Series.argsort(axis=0, kind='quicksort', order=None)", "intent": "Return the integer indices that would sort the Series values . With arguments `axis`, `kind`, `order`.", "question_id": 6176},
{"snippet": "Series.asfreq(freq)", "intent": "Convert time series to specified frequency . With arguments `freq`.", "question_id": 6177},
{"snippet": "Series.asfreq(freq, method=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`.", "question_id": 6178},
{"snippet": "Series.asfreq(freq, how=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`.", "question_id": 6179},
{"snippet": "Series.asfreq(freq, normalize=False)", "intent": "Convert time series to specified frequency . With arguments `freq`, `normalize`.", "question_id": 6180},
{"snippet": "Series.asfreq(freq, fill_value=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `fill_value`.", "question_id": 6181},
{"snippet": "Series.asfreq(freq, method=None, how=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `how`.", "question_id": 6182},
{"snippet": "Series.asfreq(freq, method=None, normalize=False)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `normalize`.", "question_id": 6183},
{"snippet": "Series.asfreq(freq, method=None, fill_value=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `fill_value`.", "question_id": 6184},
{"snippet": "Series.asfreq(freq, how=None, normalize=False)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`, `normalize`.", "question_id": 6185},
{"snippet": "Series.asfreq(freq, how=None, fill_value=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`, `fill_value`.", "question_id": 6186},
{"snippet": "Series.asfreq(freq)", "intent": "Convert time series to specified frequency . With arguments `freq`.", "question_id": 6187},
{"snippet": "Series.asfreq(freq, method=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`.", "question_id": 6188},
{"snippet": "Series.asfreq(freq, how=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`.", "question_id": 6189},
{"snippet": "Series.asfreq(freq, normalize=False)", "intent": "Convert time series to specified frequency . With arguments `freq`, `normalize`.", "question_id": 6190},
{"snippet": "Series.asfreq(freq, fill_value=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `fill_value`.", "question_id": 6191},
{"snippet": "Series.asfreq(freq, method=None, how=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `how`.", "question_id": 6192},
{"snippet": "Series.asfreq(freq, method=None, normalize=False)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `normalize`.", "question_id": 6193},
{"snippet": "Series.asfreq(freq, method=None, fill_value=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `fill_value`.", "question_id": 6194},
{"snippet": "Series.asfreq(freq, how=None, normalize=False)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`, `normalize`.", "question_id": 6195},
{"snippet": "Series.asfreq(freq, how=None, fill_value=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`, `fill_value`.", "question_id": 6196},
{"snippet": "Series.asfreq(freq)", "intent": "Convert time series to specified frequency . With arguments `freq`.", "question_id": 6197},
{"snippet": "Series.asfreq(freq, method=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`.", "question_id": 6198},
{"snippet": "Series.asfreq(freq, how=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`.", "question_id": 6199},
{"snippet": "Series.asfreq(freq, normalize=False)", "intent": "Convert time series to specified frequency . With arguments `freq`, `normalize`.", "question_id": 6200},
{"snippet": "Series.asfreq(freq, fill_value=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `fill_value`.", "question_id": 6201},
{"snippet": "Series.asfreq(freq, method=None, how=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `how`.", "question_id": 6202},
{"snippet": "Series.asfreq(freq, method=None, normalize=False)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `normalize`.", "question_id": 6203},
{"snippet": "Series.asfreq(freq, method=None, fill_value=None)", "intent": "Convert time series to specified frequency . The values corresponding to any timesteps in the new index which were not present in the original index will be null ( NaN ) , unless a `method` for filling such unknowns is provided ( see the method parameter below ) . With arguments `freq`, `fill_value`.", "question_id": 6204},
{"snippet": "Series.asfreq(freq, how=None, normalize=False)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`, `normalize`.", "question_id": 6205},
{"snippet": "Series.asfreq(freq, how=None, fill_value=None)", "intent": "Convert time series to specified frequency . With arguments `freq`, `how`, `fill_value`.", "question_id": 6206},
{"snippet": "Series.asof(where)", "intent": "Return the last row ( s ) without any NaNs before `where` .", "question_id": 6207},
{"snippet": "Series.asof(where, subset=None)", "intent": "Return the last row ( s ) without any NaNs before `where` . In case of a DataFrame , the last row without NaN considering only the `subset` of columns ( if not None )", "question_id": 6208},
{"snippet": "Series.asof(where)", "intent": "Return the last row ( s ) without any NaNs before `where` .", "question_id": 6209},
{"snippet": "Series.asof(where, subset=None)", "intent": "Return the last row ( s ) without any NaNs before `where` . In case of a DataFrame , the last row without NaN considering only the `subset` of columns ( if not None )", "question_id": 6210},
{"snippet": "Series.asof(where)", "intent": "Return the last row ( s ) without any NaNs before `where` .", "question_id": 6211},
{"snippet": "Series.asof(where, subset=None)", "intent": "Return the last row ( s ) without any NaNs before `where` . In case of a DataFrame , the last row without NaN considering only the `subset` of columns ( if not None )", "question_id": 6212},
{"snippet": "Series.astype(dtype)", "intent": "Cast a pandas object to a specified `dtype` dtype .", "question_id": 6213},
{"snippet": "Series.astype(dtype, copy=True)", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `copy`.", "question_id": 6214},
{"snippet": "Series.astype(dtype, errors='raise')", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `errors`.", "question_id": 6215},
{"snippet": "Series.astype(dtype, copy=True, errors='raise')", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `copy`, `errors`.", "question_id": 6216},
{"snippet": "Series.astype(dtype)", "intent": "Cast a pandas object to a specified `dtype` dtype .", "question_id": 6217},
{"snippet": "Series.astype(dtype, copy=True)", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `copy`.", "question_id": 6218},
{"snippet": "Series.astype(dtype, errors='raise')", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `errors`.", "question_id": 6219},
{"snippet": "Series.astype(dtype, copy=True, errors='raise')", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `copy`, `errors`.", "question_id": 6220},
{"snippet": "Series.astype(dtype)", "intent": "Cast a pandas object to a specified `dtype` dtype .", "question_id": 6221},
{"snippet": "Series.astype(dtype, copy=True)", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `copy`.", "question_id": 6222},
{"snippet": "Series.astype(dtype, errors='raise')", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `errors`.", "question_id": 6223},
{"snippet": "Series.astype(dtype, copy=True, errors='raise')", "intent": "Cast a pandas object to a specified `dtype` dtype . With arguments `copy`, `errors`.", "question_id": 6224},
{"snippet": "Series.at_time(time)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) .", "question_id": 6225},
{"snippet": "Series.at_time(time, asof=False)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `asof`.", "question_id": 6226},
{"snippet": "Series.at_time(time, axis=None)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `axis`.", "question_id": 6227},
{"snippet": "Series.at_time(time, asof=False, axis=None)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `asof`, `axis`.", "question_id": 6228},
{"snippet": "Series.at_time(time)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) .", "question_id": 6229},
{"snippet": "Series.at_time(time, asof=False)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `asof`.", "question_id": 6230},
{"snippet": "Series.at_time(time, axis=None)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `axis`.", "question_id": 6231},
{"snippet": "Series.at_time(time, asof=False, axis=None)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `asof`, `axis`.", "question_id": 6232},
{"snippet": "Series.at_time(time)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) .", "question_id": 6233},
{"snippet": "Series.at_time(time, asof=False)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `asof`.", "question_id": 6234},
{"snippet": "Series.at_time(time, axis=None)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `axis`.", "question_id": 6235},
{"snippet": "Series.at_time(time, asof=False, axis=None)", "intent": "Select values at particular `time` of day ( e.g. , 9:30AM ) . With arguments `asof`, `axis`.", "question_id": 6236},
{"snippet": "Series.autocorr()", "intent": "Compute the lag-N autocorrelation .", "question_id": 6237},
{"snippet": "Series.autocorr(lag=1)", "intent": "Compute the lag-N autocorrelation . With arguments `lag`.", "question_id": 6238},
{"snippet": "Series.autocorr()", "intent": "Compute the lag-N autocorrelation .", "question_id": 6239},
{"snippet": "Series.autocorr(lag=1)", "intent": "Compute the lag-N autocorrelation . With arguments `lag`.", "question_id": 6240},
{"snippet": "Series.autocorr()", "intent": "Compute the lag-N autocorrelation .", "question_id": 6241},
{"snippet": "Series.autocorr(lag=1)", "intent": "Compute the lag-N autocorrelation . With arguments `lag`.", "question_id": 6242},
{"snippet": "Series.backfill()", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' .", "question_id": 6243},
{"snippet": "Series.backfill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`.", "question_id": 6244},
{"snippet": "Series.backfill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`.", "question_id": 6245},
{"snippet": "Series.backfill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `limit`.", "question_id": 6246},
{"snippet": "Series.backfill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `downcast`.", "question_id": 6247},
{"snippet": "Series.backfill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `inplace`.", "question_id": 6248},
{"snippet": "Series.backfill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `limit`.", "question_id": 6249},
{"snippet": "Series.backfill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `downcast`.", "question_id": 6250},
{"snippet": "Series.backfill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `limit`.", "question_id": 6251},
{"snippet": "Series.backfill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `downcast`.", "question_id": 6252},
{"snippet": "Series.backfill()", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' .", "question_id": 6253},
{"snippet": "Series.backfill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`.", "question_id": 6254},
{"snippet": "Series.backfill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`.", "question_id": 6255},
{"snippet": "Series.backfill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `limit`.", "question_id": 6256},
{"snippet": "Series.backfill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `downcast`.", "question_id": 6257},
{"snippet": "Series.backfill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `inplace`.", "question_id": 6258},
{"snippet": "Series.backfill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `limit`.", "question_id": 6259},
{"snippet": "Series.backfill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `downcast`.", "question_id": 6260},
{"snippet": "Series.backfill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `limit`.", "question_id": 6261},
{"snippet": "Series.backfill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `downcast`.", "question_id": 6262},
{"snippet": "Series.backfill()", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' .", "question_id": 6263},
{"snippet": "Series.backfill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`.", "question_id": 6264},
{"snippet": "Series.backfill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`.", "question_id": 6265},
{"snippet": "Series.backfill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `limit`.", "question_id": 6266},
{"snippet": "Series.backfill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `downcast`.", "question_id": 6267},
{"snippet": "Series.backfill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `inplace`.", "question_id": 6268},
{"snippet": "Series.backfill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `limit`.", "question_id": 6269},
{"snippet": "Series.backfill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `downcast`.", "question_id": 6270},
{"snippet": "Series.backfill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `limit`.", "question_id": 6271},
{"snippet": "Series.backfill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `downcast`.", "question_id": 6272},
{"snippet": "Series.between(left, right)", "intent": "Return boolean Series equivalent to `left` < = series < = `right` .", "question_id": 6273},
{"snippet": "Series.between(left, right, inclusive='both')", "intent": "Return boolean Series equivalent to `left` < = series < = `right` . With `inclusive` set to `` neither '' boundary values are excluded :", "question_id": 6274},
{"snippet": "Series.between(left, right)", "intent": "Return boolean Series equivalent to `left` < = series < = `right` .", "question_id": 6275},
{"snippet": "Series.between(left, right, inclusive='both')", "intent": "Return boolean Series equivalent to `left` < = series < = `right` . With `inclusive` set to `` neither '' boundary values are excluded :", "question_id": 6276},
{"snippet": "Series.between(left, right)", "intent": "Return boolean Series equivalent to `left` < = series < = `right` .", "question_id": 6277},
{"snippet": "Series.between(left, right, inclusive='both')", "intent": "Return boolean Series equivalent to `left` < = series < = `right` . With `inclusive` set to `` neither '' boundary values are excluded :", "question_id": 6278},
{"snippet": "Series.between_time(start_time, end_time)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times .", "question_id": 6279},
{"snippet": "Series.between_time(start_time, end_time, include_start=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`.", "question_id": 6280},
{"snippet": "Series.between_time(start_time, end_time, include_end=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_end`.", "question_id": 6281},
{"snippet": "Series.between_time(start_time, end_time, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `axis`.", "question_id": 6282},
{"snippet": "Series.between_time(start_time, end_time, include_start=True, include_end=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `include_end`.", "question_id": 6283},
{"snippet": "Series.between_time(start_time, end_time, include_start=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `axis`.", "question_id": 6284},
{"snippet": "Series.between_time(start_time, end_time, include_end=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_end`, `axis`.", "question_id": 6285},
{"snippet": "Series.between_time(start_time, end_time, include_start=True, include_end=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `include_end`, `axis`.", "question_id": 6286},
{"snippet": "Series.between_time(start_time, end_time)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times .", "question_id": 6287},
{"snippet": "Series.between_time(start_time, end_time, include_start=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`.", "question_id": 6288},
{"snippet": "Series.between_time(start_time, end_time, include_end=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_end`.", "question_id": 6289},
{"snippet": "Series.between_time(start_time, end_time, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `axis`.", "question_id": 6290},
{"snippet": "Series.between_time(start_time, end_time, include_start=True, include_end=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `include_end`.", "question_id": 6291},
{"snippet": "Series.between_time(start_time, end_time, include_start=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `axis`.", "question_id": 6292},
{"snippet": "Series.between_time(start_time, end_time, include_end=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_end`, `axis`.", "question_id": 6293},
{"snippet": "Series.between_time(start_time, end_time, include_start=True, include_end=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `include_end`, `axis`.", "question_id": 6294},
{"snippet": "Series.between_time(start_time, end_time)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times .", "question_id": 6295},
{"snippet": "Series.between_time(start_time, end_time, include_start=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`.", "question_id": 6296},
{"snippet": "Series.between_time(start_time, end_time, include_end=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_end`.", "question_id": 6297},
{"snippet": "Series.between_time(start_time, end_time, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `axis`.", "question_id": 6298},
{"snippet": "Series.between_time(start_time, end_time, include_start=True, include_end=True)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `include_end`.", "question_id": 6299},
{"snippet": "Series.between_time(start_time, end_time, include_start=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `axis`.", "question_id": 6300},
{"snippet": "Series.between_time(start_time, end_time, include_end=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_end`, `axis`.", "question_id": 6301},
{"snippet": "Series.between_time(start_time, end_time, include_start=True, include_end=True, axis=None)", "intent": "Select values between particular times of the day ( e.g. , 9:00-9:30 AM ) . By setting `start_time` to be later than `end_time` , you can get the times that are not between the two times . With arguments `include_start`, `include_end`, `axis`.", "question_id": 6302},
{"snippet": "Series.bfill()", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' .", "question_id": 6303},
{"snippet": "Series.bfill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`.", "question_id": 6304},
{"snippet": "Series.bfill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`.", "question_id": 6305},
{"snippet": "Series.bfill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `limit`.", "question_id": 6306},
{"snippet": "Series.bfill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `downcast`.", "question_id": 6307},
{"snippet": "Series.bfill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `inplace`.", "question_id": 6308},
{"snippet": "Series.bfill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `limit`.", "question_id": 6309},
{"snippet": "Series.bfill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `downcast`.", "question_id": 6310},
{"snippet": "Series.bfill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `limit`.", "question_id": 6311},
{"snippet": "Series.bfill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `downcast`.", "question_id": 6312},
{"snippet": "Series.bfill()", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' .", "question_id": 6313},
{"snippet": "Series.bfill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`.", "question_id": 6314},
{"snippet": "Series.bfill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`.", "question_id": 6315},
{"snippet": "Series.bfill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `limit`.", "question_id": 6316},
{"snippet": "Series.bfill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `downcast`.", "question_id": 6317},
{"snippet": "Series.bfill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `inplace`.", "question_id": 6318},
{"snippet": "Series.bfill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `limit`.", "question_id": 6319},
{"snippet": "Series.bfill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `downcast`.", "question_id": 6320},
{"snippet": "Series.bfill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `limit`.", "question_id": 6321},
{"snippet": "Series.bfill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `downcast`.", "question_id": 6322},
{"snippet": "Series.bfill()", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' .", "question_id": 6323},
{"snippet": "Series.bfill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`.", "question_id": 6324},
{"snippet": "Series.bfill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`.", "question_id": 6325},
{"snippet": "Series.bfill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `limit`.", "question_id": 6326},
{"snippet": "Series.bfill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `downcast`.", "question_id": 6327},
{"snippet": "Series.bfill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `inplace`.", "question_id": 6328},
{"snippet": "Series.bfill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `limit`.", "question_id": 6329},
{"snippet": "Series.bfill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `axis`, `downcast`.", "question_id": 6330},
{"snippet": "Series.bfill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `limit`.", "question_id": 6331},
{"snippet": "Series.bfill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='bfill ' . With arguments `inplace`, `downcast`.", "question_id": 6332},
{"snippet": "Series.bool()", "intent": "Return the bool of a single element Series or DataFrame .", "question_id": 6333},
{"snippet": "Series.bool()", "intent": "Return the bool of a single element Series or DataFrame .", "question_id": 6334},
{"snippet": "Series.bool()", "intent": "Return the bool of a single element Series or DataFrame .", "question_id": 6335},
{"snippet": "Series.cat.add_categories(*args, **kwargs)", "intent": "Add new categories . With arguments `*args`, `**kwargs`.", "question_id": 6336},
{"snippet": "Series.cat.add_categories(*args, **kwargs)", "intent": "Add new categories . With arguments `*args`, `**kwargs`.", "question_id": 6337},
{"snippet": "Series.cat.add_categories(*args, **kwargs)", "intent": "Add new categories . With arguments `*args`, `**kwargs`.", "question_id": 6338},
{"snippet": "Series.cat.as_ordered(*args, **kwargs)", "intent": "Set the Categorical to be ordered . With arguments `*args`, `**kwargs`.", "question_id": 6339},
{"snippet": "Series.cat.as_ordered(*args, **kwargs)", "intent": "Set the Categorical to be ordered . With arguments `*args`, `**kwargs`.", "question_id": 6340},
{"snippet": "Series.cat.as_ordered(*args, **kwargs)", "intent": "Set the Categorical to be ordered . With arguments `*args`, `**kwargs`.", "question_id": 6341},
{"snippet": "Series.cat.as_unordered(*args, **kwargs)", "intent": "Set the Categorical to be unordered . With arguments `*args`, `**kwargs`.", "question_id": 6342},
{"snippet": "Series.cat.as_unordered(*args, **kwargs)", "intent": "Set the Categorical to be unordered . With arguments `*args`, `**kwargs`.", "question_id": 6343},
{"snippet": "Series.cat.as_unordered(*args, **kwargs)", "intent": "Set the Categorical to be unordered . With arguments `*args`, `**kwargs`.", "question_id": 6344},
{"snippet": "Series.cat.categories", "intent": "The categories of this categorical.", "question_id": 6345},
{"snippet": "Series.cat.categories", "intent": "The categories of this categorical.", "question_id": 6346},
{"snippet": "Series.cat.categories", "intent": "The categories of this categorical.", "question_id": 6347},
{"snippet": "Series.cat.codes", "intent": "Return Series of codes as well as the index.", "question_id": 6348},
{"snippet": "Series.cat.codes", "intent": "Return Series of codes as well as the index.", "question_id": 6349},
{"snippet": "Series.cat.codes", "intent": "Return Series of codes as well as the index.", "question_id": 6350},
{"snippet": "Series.cat()", "intent": "Accessor object for categorical properties of the Series values .", "question_id": 6351},
{"snippet": "Series.cat()", "intent": "Accessor object for categorical properties of the Series values .", "question_id": 6352},
{"snippet": "Series.cat()", "intent": "Accessor object for categorical properties of the Series values .", "question_id": 6353},
{"snippet": "Series.cat.ordered", "intent": "Whether the categories have an ordered relationship.", "question_id": 6354},
{"snippet": "Series.cat.ordered", "intent": "Whether the categories have an ordered relationship.", "question_id": 6355},
{"snippet": "Series.cat.ordered", "intent": "Whether the categories have an ordered relationship.", "question_id": 6356},
{"snippet": "Series.cat.remove_categories(*args, **kwargs)", "intent": "Remove the specified categories . With arguments `*args`, `**kwargs`.", "question_id": 6357},
{"snippet": "Series.cat.remove_categories(*args, **kwargs)", "intent": "Remove the specified categories . With arguments `*args`, `**kwargs`.", "question_id": 6358},
{"snippet": "Series.cat.remove_categories(*args, **kwargs)", "intent": "Remove the specified categories . With arguments `*args`, `**kwargs`.", "question_id": 6359},
{"snippet": "Series.cat.remove_unused_categories(*args, **kwargs)", "intent": "Remove categories which are not used . With arguments `*args`, `**kwargs`.", "question_id": 6360},
{"snippet": "Series.cat.remove_unused_categories(*args, **kwargs)", "intent": "Remove categories which are not used . With arguments `*args`, `**kwargs`.", "question_id": 6361},
{"snippet": "Series.cat.remove_unused_categories(*args, **kwargs)", "intent": "Remove categories which are not used . With arguments `*args`, `**kwargs`.", "question_id": 6362},
{"snippet": "Series.cat.rename_categories(*args, **kwargs)", "intent": "Rename categories . With arguments `*args`, `**kwargs`.", "question_id": 6363},
{"snippet": "Series.cat.rename_categories(*args, **kwargs)", "intent": "Rename categories . With arguments `*args`, `**kwargs`.", "question_id": 6364},
{"snippet": "Series.cat.rename_categories(*args, **kwargs)", "intent": "Rename categories . With arguments `*args`, `**kwargs`.", "question_id": 6365},
{"snippet": "Series.cat.reorder_categories(*args, **kwargs)", "intent": "Reorder categories as specified in new_categories . With arguments `*args`, `**kwargs`.", "question_id": 6366},
{"snippet": "Series.cat.reorder_categories(*args, **kwargs)", "intent": "Reorder categories as specified in new_categories . With arguments `*args`, `**kwargs`.", "question_id": 6367},
{"snippet": "Series.cat.reorder_categories(*args, **kwargs)", "intent": "Reorder categories as specified in new_categories . With arguments `*args`, `**kwargs`.", "question_id": 6368},
{"snippet": "Series.cat.set_categories(*args, **kwargs)", "intent": "Set the categories to the specified new_categories . With arguments `*args`, `**kwargs`.", "question_id": 6369},
{"snippet": "Series.cat.set_categories(*args, **kwargs)", "intent": "Set the categories to the specified new_categories . With arguments `*args`, `**kwargs`.", "question_id": 6370},
{"snippet": "Series.cat.set_categories(*args, **kwargs)", "intent": "Set the categories to the specified new_categories . With arguments `*args`, `**kwargs`.", "question_id": 6371},
{"snippet": "Series.clip(*args, **kwargs)", "intent": "Trim values at input threshold ( s ) . With arguments `*args`, `**kwargs`.", "question_id": 6372},
{"snippet": "Series.clip(*args, **kwargs, lower=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 6373},
{"snippet": "Series.clip(*args, **kwargs, upper=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 6374},
{"snippet": "Series.clip(*args, **kwargs, axis=None)", "intent": "Trim values at input threshold ( s ) . Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6375},
{"snippet": "Series.clip(*args, **kwargs, inplace=False)", "intent": "Trim values at input threshold ( s ) . With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 6376},
{"snippet": "Series.clip(*args, **kwargs, lower=None, upper=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 6377},
{"snippet": "Series.clip(*args, **kwargs, lower=None, axis=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6378},
{"snippet": "Series.clip(*args, **kwargs, lower=None, inplace=False)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 6379},
{"snippet": "Series.clip(*args, **kwargs, upper=None, axis=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6380},
{"snippet": "Series.clip(*args, **kwargs, upper=None, inplace=False)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 6381},
{"snippet": "Series.clip(*args, **kwargs)", "intent": "Trim values at input threshold ( s ) . With arguments `*args`, `**kwargs`.", "question_id": 6382},
{"snippet": "Series.clip(*args, **kwargs, lower=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 6383},
{"snippet": "Series.clip(*args, **kwargs, upper=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 6384},
{"snippet": "Series.clip(*args, **kwargs, axis=None)", "intent": "Trim values at input threshold ( s ) . Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6385},
{"snippet": "Series.clip(*args, **kwargs, inplace=False)", "intent": "Trim values at input threshold ( s ) . With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 6386},
{"snippet": "Series.clip(*args, **kwargs, lower=None, upper=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 6387},
{"snippet": "Series.clip(*args, **kwargs, lower=None, axis=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6388},
{"snippet": "Series.clip(*args, **kwargs, lower=None, inplace=False)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 6389},
{"snippet": "Series.clip(*args, **kwargs, upper=None, axis=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6390},
{"snippet": "Series.clip(*args, **kwargs, upper=None, inplace=False)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 6391},
{"snippet": "Series.clip(*args, **kwargs)", "intent": "Trim values at input threshold ( s ) . With arguments `*args`, `**kwargs`.", "question_id": 6392},
{"snippet": "Series.clip(*args, **kwargs, lower=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 6393},
{"snippet": "Series.clip(*args, **kwargs, upper=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 6394},
{"snippet": "Series.clip(*args, **kwargs, axis=None)", "intent": "Trim values at input threshold ( s ) . Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6395},
{"snippet": "Series.clip(*args, **kwargs, inplace=False)", "intent": "Trim values at input threshold ( s ) . With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 6396},
{"snippet": "Series.clip(*args, **kwargs, lower=None, upper=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`.", "question_id": 6397},
{"snippet": "Series.clip(*args, **kwargs, lower=None, axis=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6398},
{"snippet": "Series.clip(*args, **kwargs, lower=None, inplace=False)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 6399},
{"snippet": "Series.clip(*args, **kwargs, upper=None, axis=None)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : Thresholds can be singular values or array like , and in the latter case the clipping is performed element-wise in the specified `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6400},
{"snippet": "Series.clip(*args, **kwargs, upper=None, inplace=False)", "intent": "Trim values at input threshold ( s ) . Clips per column using `lower` and `upper` thresholds : With arguments `*args`, `**kwargs`, `inplace`.", "question_id": 6401},
{"snippet": "Series.combine(other, func)", "intent": "Combine the Series with a Series or scalar according to `func` . Combine the Series and `other` using func to perform elementwise selection for combined Series .", "question_id": 6402},
{"snippet": "Series.combine(other, func, fill_value=None)", "intent": "Combine the Series with a Series or scalar according to `func` . Combine the Series and `other` using func to perform elementwise selection for combined Series . `fill_value` is assumed when value is missing at some index from one of the two objects being combined .", "question_id": 6403},
{"snippet": "Series.combine(other, func)", "intent": "Combine the Series with a Series or scalar according to `func` . Combine the Series and `other` using func to perform elementwise selection for combined Series .", "question_id": 6404},
{"snippet": "Series.combine(other, func, fill_value=None)", "intent": "Combine the Series with a Series or scalar according to `func` . Combine the Series and `other` using func to perform elementwise selection for combined Series . `fill_value` is assumed when value is missing at some index from one of the two objects being combined .", "question_id": 6405},
{"snippet": "Series.combine(other, func)", "intent": "Combine the Series with a Series or scalar according to `func` . Combine the Series and `other` using func to perform elementwise selection for combined Series .", "question_id": 6406},
{"snippet": "Series.combine(other, func, fill_value=None)", "intent": "Combine the Series with a Series or scalar according to `func` . Combine the Series and `other` using func to perform elementwise selection for combined Series . `fill_value` is assumed when value is missing at some index from one of the two objects being combined .", "question_id": 6407},
{"snippet": "Series.combine_first(other)", "intent": "Update null elements with value in the same location in \u2018 `other` \u2019 .", "question_id": 6408},
{"snippet": "Series.combine_first(other)", "intent": "Update null elements with value in the same location in \u2018 `other` \u2019 .", "question_id": 6409},
{"snippet": "Series.combine_first(other)", "intent": "Update null elements with value in the same location in \u2018 `other` \u2019 .", "question_id": 6410},
{"snippet": "Series.compare(other)", "intent": "Compare to another Series and show the differences . With arguments `other`.", "question_id": 6411},
{"snippet": "Series.compare(other, align_axis=1)", "intent": "Compare to another Series and show the differences . With arguments `other`, `align_axis`.", "question_id": 6412},
{"snippet": "Series.compare(other, keep_shape=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `keep_shape`.", "question_id": 6413},
{"snippet": "Series.compare(other, keep_equal=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `keep_equal`.", "question_id": 6414},
{"snippet": "Series.compare(other, align_axis=1, keep_shape=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `align_axis`, `keep_shape`.", "question_id": 6415},
{"snippet": "Series.compare(other, align_axis=1, keep_equal=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `align_axis`, `keep_equal`.", "question_id": 6416},
{"snippet": "Series.compare(other, keep_shape=False, keep_equal=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `keep_shape`, `keep_equal`.", "question_id": 6417},
{"snippet": "Series.compare(other, align_axis=1, keep_shape=False, keep_equal=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `align_axis`, `keep_shape`, `keep_equal`.", "question_id": 6418},
{"snippet": "Series.compare(other)", "intent": "Compare to another Series and show the differences . With arguments `other`.", "question_id": 6419},
{"snippet": "Series.compare(other, align_axis=1)", "intent": "Compare to another Series and show the differences . With arguments `other`, `align_axis`.", "question_id": 6420},
{"snippet": "Series.compare(other, keep_shape=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `keep_shape`.", "question_id": 6421},
{"snippet": "Series.compare(other, keep_equal=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `keep_equal`.", "question_id": 6422},
{"snippet": "Series.compare(other, align_axis=1, keep_shape=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `align_axis`, `keep_shape`.", "question_id": 6423},
{"snippet": "Series.compare(other, align_axis=1, keep_equal=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `align_axis`, `keep_equal`.", "question_id": 6424},
{"snippet": "Series.compare(other, keep_shape=False, keep_equal=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `keep_shape`, `keep_equal`.", "question_id": 6425},
{"snippet": "Series.compare(other, align_axis=1, keep_shape=False, keep_equal=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `align_axis`, `keep_shape`, `keep_equal`.", "question_id": 6426},
{"snippet": "Series.compare(other)", "intent": "Compare to another Series and show the differences . With arguments `other`.", "question_id": 6427},
{"snippet": "Series.compare(other, align_axis=1)", "intent": "Compare to another Series and show the differences . With arguments `other`, `align_axis`.", "question_id": 6428},
{"snippet": "Series.compare(other, keep_shape=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `keep_shape`.", "question_id": 6429},
{"snippet": "Series.compare(other, keep_equal=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `keep_equal`.", "question_id": 6430},
{"snippet": "Series.compare(other, align_axis=1, keep_shape=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `align_axis`, `keep_shape`.", "question_id": 6431},
{"snippet": "Series.compare(other, align_axis=1, keep_equal=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `align_axis`, `keep_equal`.", "question_id": 6432},
{"snippet": "Series.compare(other, keep_shape=False, keep_equal=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `keep_shape`, `keep_equal`.", "question_id": 6433},
{"snippet": "Series.compare(other, align_axis=1, keep_shape=False, keep_equal=False)", "intent": "Compare to another Series and show the differences . With arguments `other`, `align_axis`, `keep_shape`, `keep_equal`.", "question_id": 6434},
{"snippet": "Series.convert_dtypes()", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA .", "question_id": 6435},
{"snippet": "Series.convert_dtypes(infer_objects=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction .", "question_id": 6436},
{"snippet": "Series.convert_dtypes(convert_string=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6437},
{"snippet": "Series.convert_dtypes(convert_integer=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6438},
{"snippet": "Series.convert_dtypes(convert_boolean=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6439},
{"snippet": "Series.convert_dtypes(convert_floating=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . With arguments `convert_floating`.", "question_id": 6440},
{"snippet": "Series.convert_dtypes(infer_objects=True, convert_string=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6441},
{"snippet": "Series.convert_dtypes(infer_objects=True, convert_integer=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6442},
{"snippet": "Series.convert_dtypes(infer_objects=True, convert_boolean=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6443},
{"snippet": "Series.convert_dtypes(infer_objects=True, convert_floating=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . With arguments `convert_floating`.", "question_id": 6444},
{"snippet": "Series.convert_dtypes()", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA .", "question_id": 6445},
{"snippet": "Series.convert_dtypes(infer_objects=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction .", "question_id": 6446},
{"snippet": "Series.convert_dtypes(convert_string=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6447},
{"snippet": "Series.convert_dtypes(convert_integer=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6448},
{"snippet": "Series.convert_dtypes(convert_boolean=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6449},
{"snippet": "Series.convert_dtypes(convert_floating=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . With arguments `convert_floating`.", "question_id": 6450},
{"snippet": "Series.convert_dtypes(infer_objects=True, convert_string=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6451},
{"snippet": "Series.convert_dtypes(infer_objects=True, convert_integer=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6452},
{"snippet": "Series.convert_dtypes(infer_objects=True, convert_boolean=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6453},
{"snippet": "Series.convert_dtypes(infer_objects=True, convert_floating=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . With arguments `convert_floating`.", "question_id": 6454},
{"snippet": "Series.convert_dtypes()", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA .", "question_id": 6455},
{"snippet": "Series.convert_dtypes(infer_objects=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction .", "question_id": 6456},
{"snippet": "Series.convert_dtypes(convert_string=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6457},
{"snippet": "Series.convert_dtypes(convert_integer=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6458},
{"snippet": "Series.convert_dtypes(convert_boolean=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6459},
{"snippet": "Series.convert_dtypes(convert_floating=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . With arguments `convert_floating`.", "question_id": 6460},
{"snippet": "Series.convert_dtypes(infer_objects=True, convert_string=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6461},
{"snippet": "Series.convert_dtypes(infer_objects=True, convert_integer=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6462},
{"snippet": "Series.convert_dtypes(infer_objects=True, convert_boolean=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . By using the options `convert_string` , `convert_integer` , `convert_boolean` and convert_boolean , it is possible to turn off individual conversions to StringDtype , the integer extension types , BooleanDtype or floating extension types , respectively .", "question_id": 6463},
{"snippet": "Series.convert_dtypes(infer_objects=True, convert_floating=True)", "intent": "Convert columns to best possible dtypes using dtypes supporting pd.NA . For object-dtyped columns , if `infer_objects` is True , use the inference rules as during normal Series/DataFrame construction . With arguments `convert_floating`.", "question_id": 6464},
{"snippet": "Series.copy()", "intent": "Make a copy of this object \u2019 s indices and data .", "question_id": 6465},
{"snippet": "Series.copy(deep=True)", "intent": "Make a copy of this object \u2019 s indices and data . Shallow copy versus default ( `deep` ) copy :", "question_id": 6466},
{"snippet": "Series.copy()", "intent": "Make a copy of this object \u2019 s indices and data .", "question_id": 6467},
{"snippet": "Series.copy(deep=True)", "intent": "Make a copy of this object \u2019 s indices and data . Shallow copy versus default ( `deep` ) copy :", "question_id": 6468},
{"snippet": "Series.copy()", "intent": "Make a copy of this object \u2019 s indices and data .", "question_id": 6469},
{"snippet": "Series.copy(deep=True)", "intent": "Make a copy of this object \u2019 s indices and data . Shallow copy versus default ( `deep` ) copy :", "question_id": 6470},
{"snippet": "Series.corr(other)", "intent": "Compute correlation with `other` Series , excluding missing values .", "question_id": 6471},
{"snippet": "Series.corr(other, method='pearson')", "intent": "Compute correlation with `other` Series , excluding missing values . With arguments `method`.", "question_id": 6472},
{"snippet": "Series.corr(other, min_periods=None)", "intent": "Compute correlation with `other` Series , excluding missing values . With arguments `min_periods`.", "question_id": 6473},
{"snippet": "Series.corr(other, method='pearson', min_periods=None)", "intent": "Compute correlation with `other` Series , excluding missing values . With arguments `method`, `min_periods`.", "question_id": 6474},
{"snippet": "Series.corr(other)", "intent": "Compute correlation with `other` Series , excluding missing values .", "question_id": 6475},
{"snippet": "Series.corr(other, method='pearson')", "intent": "Compute correlation with `other` Series , excluding missing values . With arguments `method`.", "question_id": 6476},
{"snippet": "Series.corr(other, min_periods=None)", "intent": "Compute correlation with `other` Series , excluding missing values . With arguments `min_periods`.", "question_id": 6477},
{"snippet": "Series.corr(other, method='pearson', min_periods=None)", "intent": "Compute correlation with `other` Series , excluding missing values . With arguments `method`, `min_periods`.", "question_id": 6478},
{"snippet": "Series.corr(other)", "intent": "Compute correlation with `other` Series , excluding missing values .", "question_id": 6479},
{"snippet": "Series.corr(other, method='pearson')", "intent": "Compute correlation with `other` Series , excluding missing values . With arguments `method`.", "question_id": 6480},
{"snippet": "Series.corr(other, min_periods=None)", "intent": "Compute correlation with `other` Series , excluding missing values . With arguments `min_periods`.", "question_id": 6481},
{"snippet": "Series.corr(other, method='pearson', min_periods=None)", "intent": "Compute correlation with `other` Series , excluding missing values . With arguments `method`, `min_periods`.", "question_id": 6482},
{"snippet": "Series.count()", "intent": "Return number of non-NA/null observations in the Series .", "question_id": 6483},
{"snippet": "Series.count(level=None)", "intent": "Return number of non-NA/null observations in the Series . With arguments `level`.", "question_id": 6484},
{"snippet": "Series.count()", "intent": "Return number of non-NA/null observations in the Series .", "question_id": 6485},
{"snippet": "Series.count(level=None)", "intent": "Return number of non-NA/null observations in the Series . With arguments `level`.", "question_id": 6486},
{"snippet": "Series.count()", "intent": "Return number of non-NA/null observations in the Series .", "question_id": 6487},
{"snippet": "Series.count(level=None)", "intent": "Return number of non-NA/null observations in the Series . With arguments `level`.", "question_id": 6488},
{"snippet": "Series.cov(other)", "intent": "Compute covariance with Series , excluding missing values . With arguments `other`.", "question_id": 6489},
{"snippet": "Series.cov(other, min_periods=None)", "intent": "Compute covariance with Series , excluding missing values . With arguments `other`, `min_periods`.", "question_id": 6490},
{"snippet": "Series.cov(other, ddof=1)", "intent": "Compute covariance with Series , excluding missing values . With arguments `other`, `ddof`.", "question_id": 6491},
{"snippet": "Series.cov(other, min_periods=None, ddof=1)", "intent": "Compute covariance with Series , excluding missing values . With arguments `other`, `min_periods`, `ddof`.", "question_id": 6492},
{"snippet": "Series.cov(other)", "intent": "Compute covariance with Series , excluding missing values . With arguments `other`.", "question_id": 6493},
{"snippet": "Series.cov(other, min_periods=None)", "intent": "Compute covariance with Series , excluding missing values . With arguments `other`, `min_periods`.", "question_id": 6494},
{"snippet": "Series.cov(other, ddof=1)", "intent": "Compute covariance with Series , excluding missing values . With arguments `other`, `ddof`.", "question_id": 6495},
{"snippet": "Series.cov(other, min_periods=None, ddof=1)", "intent": "Compute covariance with Series , excluding missing values . With arguments `other`, `min_periods`, `ddof`.", "question_id": 6496},
{"snippet": "Series.cov(other)", "intent": "Compute covariance with Series , excluding missing values . With arguments `other`.", "question_id": 6497},
{"snippet": "Series.cov(other, min_periods=None)", "intent": "Compute covariance with Series , excluding missing values . With arguments `other`, `min_periods`.", "question_id": 6498},
{"snippet": "Series.cov(other, ddof=1)", "intent": "Compute covariance with Series , excluding missing values . With arguments `other`, `ddof`.", "question_id": 6499},
{"snippet": "Series.cov(other, min_periods=None, ddof=1)", "intent": "Compute covariance with Series , excluding missing values . With arguments `other`, `min_periods`, `ddof`.", "question_id": 6500},
{"snippet": "Series.cummax(*args, **kwargs)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6501},
{"snippet": "Series.cummax(*args, **kwargs, axis=None)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6502},
{"snippet": "Series.cummax(*args, **kwargs, skipna=True)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6503},
{"snippet": "Series.cummax(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6504},
{"snippet": "Series.cummax(*args, **kwargs)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6505},
{"snippet": "Series.cummax(*args, **kwargs, axis=None)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6506},
{"snippet": "Series.cummax(*args, **kwargs, skipna=True)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6507},
{"snippet": "Series.cummax(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6508},
{"snippet": "Series.cummax(*args, **kwargs)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6509},
{"snippet": "Series.cummax(*args, **kwargs, axis=None)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6510},
{"snippet": "Series.cummax(*args, **kwargs, skipna=True)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6511},
{"snippet": "Series.cummax(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative maximum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6512},
{"snippet": "Series.cummin(*args, **kwargs)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6513},
{"snippet": "Series.cummin(*args, **kwargs, axis=None)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6514},
{"snippet": "Series.cummin(*args, **kwargs, skipna=True)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6515},
{"snippet": "Series.cummin(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6516},
{"snippet": "Series.cummin(*args, **kwargs)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6517},
{"snippet": "Series.cummin(*args, **kwargs, axis=None)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6518},
{"snippet": "Series.cummin(*args, **kwargs, skipna=True)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6519},
{"snippet": "Series.cummin(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6520},
{"snippet": "Series.cummin(*args, **kwargs)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6521},
{"snippet": "Series.cummin(*args, **kwargs, axis=None)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6522},
{"snippet": "Series.cummin(*args, **kwargs, skipna=True)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6523},
{"snippet": "Series.cummin(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative minimum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6524},
{"snippet": "Series.cumprod(*args, **kwargs)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6525},
{"snippet": "Series.cumprod(*args, **kwargs, axis=None)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6526},
{"snippet": "Series.cumprod(*args, **kwargs, skipna=True)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6527},
{"snippet": "Series.cumprod(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6528},
{"snippet": "Series.cumprod(*args, **kwargs)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6529},
{"snippet": "Series.cumprod(*args, **kwargs, axis=None)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6530},
{"snippet": "Series.cumprod(*args, **kwargs, skipna=True)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6531},
{"snippet": "Series.cumprod(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6532},
{"snippet": "Series.cumprod(*args, **kwargs)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6533},
{"snippet": "Series.cumprod(*args, **kwargs, axis=None)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6534},
{"snippet": "Series.cumprod(*args, **kwargs, skipna=True)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6535},
{"snippet": "Series.cumprod(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative product over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6536},
{"snippet": "Series.cumsum(*args, **kwargs)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6537},
{"snippet": "Series.cumsum(*args, **kwargs, axis=None)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6538},
{"snippet": "Series.cumsum(*args, **kwargs, skipna=True)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6539},
{"snippet": "Series.cumsum(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6540},
{"snippet": "Series.cumsum(*args, **kwargs)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6541},
{"snippet": "Series.cumsum(*args, **kwargs, axis=None)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6542},
{"snippet": "Series.cumsum(*args, **kwargs, skipna=True)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6543},
{"snippet": "Series.cumsum(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6544},
{"snippet": "Series.cumsum(*args, **kwargs)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6545},
{"snippet": "Series.cumsum(*args, **kwargs, axis=None)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`.", "question_id": 6546},
{"snippet": "Series.cumsum(*args, **kwargs, skipna=True)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6547},
{"snippet": "Series.cumsum(*args, **kwargs, axis=None, skipna=True)", "intent": "Return cumulative sum over a DataFrame or Series `axis` . With arguments `*args`, `**kwargs`, `skipna`.", "question_id": 6548},
{"snippet": "Series.describe()", "intent": "Generate descriptive statistics .", "question_id": 6549},
{"snippet": "Series.describe(percentiles=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` .", "question_id": 6550},
{"snippet": "Series.describe(include=None)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values .", "question_id": 6551},
{"snippet": "Series.describe(exclude=None)", "intent": "Generate descriptive statistics . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 6552},
{"snippet": "Series.describe(datetime_is_numeric=False)", "intent": "Generate descriptive statistics . With arguments `datetime_is_numeric`.", "question_id": 6553},
{"snippet": "Series.describe(percentiles=None, include=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values .", "question_id": 6554},
{"snippet": "Series.describe(percentiles=None, exclude=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 6555},
{"snippet": "Series.describe(percentiles=None, datetime_is_numeric=False)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . With arguments `datetime_is_numeric`.", "question_id": 6556},
{"snippet": "Series.describe(include=None, exclude=None)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 6557},
{"snippet": "Series.describe(include=None, datetime_is_numeric=False)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values . With arguments `datetime_is_numeric`.", "question_id": 6558},
{"snippet": "Series.describe()", "intent": "Generate descriptive statistics .", "question_id": 6559},
{"snippet": "Series.describe(percentiles=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` .", "question_id": 6560},
{"snippet": "Series.describe(include=None)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values .", "question_id": 6561},
{"snippet": "Series.describe(exclude=None)", "intent": "Generate descriptive statistics . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 6562},
{"snippet": "Series.describe(datetime_is_numeric=False)", "intent": "Generate descriptive statistics . With arguments `datetime_is_numeric`.", "question_id": 6563},
{"snippet": "Series.describe(percentiles=None, include=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values .", "question_id": 6564},
{"snippet": "Series.describe(percentiles=None, exclude=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 6565},
{"snippet": "Series.describe(percentiles=None, datetime_is_numeric=False)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . With arguments `datetime_is_numeric`.", "question_id": 6566},
{"snippet": "Series.describe(include=None, exclude=None)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 6567},
{"snippet": "Series.describe(include=None, datetime_is_numeric=False)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values . With arguments `datetime_is_numeric`.", "question_id": 6568},
{"snippet": "Series.describe()", "intent": "Generate descriptive statistics .", "question_id": 6569},
{"snippet": "Series.describe(percentiles=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` .", "question_id": 6570},
{"snippet": "Series.describe(include=None)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values .", "question_id": 6571},
{"snippet": "Series.describe(exclude=None)", "intent": "Generate descriptive statistics . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 6572},
{"snippet": "Series.describe(datetime_is_numeric=False)", "intent": "Generate descriptive statistics . With arguments `datetime_is_numeric`.", "question_id": 6573},
{"snippet": "Series.describe(percentiles=None, include=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values .", "question_id": 6574},
{"snippet": "Series.describe(percentiles=None, exclude=None)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 6575},
{"snippet": "Series.describe(percentiles=None, datetime_is_numeric=False)", "intent": "Generate descriptive statistics . For numeric data , the result \u2019 s index will include count , mean , std , min , max as well as lower , 50 and upper `percentiles` . With arguments `datetime_is_numeric`.", "question_id": 6576},
{"snippet": "Series.describe(include=None, exclude=None)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values . The include and `exclude` parameters can be used to limit which columns in a DataFrame are analyzed for the output .", "question_id": 6577},
{"snippet": "Series.describe(include=None, datetime_is_numeric=False)", "intent": "Generate descriptive statistics . Descriptive statistics `include` those that summarize the central tendency , dispersion and shape of a dataset \u2019 s distribution , excluding NaN values . With arguments `datetime_is_numeric`.", "question_id": 6578},
{"snippet": "Series.diff()", "intent": "First discrete difference of element .", "question_id": 6579},
{"snippet": "Series.diff(periods=1)", "intent": "First discrete difference of element . With arguments `periods`.", "question_id": 6580},
{"snippet": "Series.diff()", "intent": "First discrete difference of element .", "question_id": 6581},
{"snippet": "Series.diff(periods=1)", "intent": "First discrete difference of element . With arguments `periods`.", "question_id": 6582},
{"snippet": "Series.diff()", "intent": "First discrete difference of element .", "question_id": 6583},
{"snippet": "Series.diff(periods=1)", "intent": "First discrete difference of element . With arguments `periods`.", "question_id": 6584},
{"snippet": "Series.div(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) .", "question_id": 6585},
{"snippet": "Series.div(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`.", "question_id": 6586},
{"snippet": "Series.div(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 6587},
{"snippet": "Series.div(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `axis`.", "question_id": 6588},
{"snippet": "Series.div(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 6589},
{"snippet": "Series.div(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`, `axis`.", "question_id": 6590},
{"snippet": "Series.div(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 6591},
{"snippet": "Series.div(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 6592},
{"snippet": "Series.div(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) .", "question_id": 6593},
{"snippet": "Series.div(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`.", "question_id": 6594},
{"snippet": "Series.div(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 6595},
{"snippet": "Series.div(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `axis`.", "question_id": 6596},
{"snippet": "Series.div(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 6597},
{"snippet": "Series.div(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`, `axis`.", "question_id": 6598},
{"snippet": "Series.div(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 6599},
{"snippet": "Series.div(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 6600},
{"snippet": "Series.div(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) .", "question_id": 6601},
{"snippet": "Series.div(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`.", "question_id": 6602},
{"snippet": "Series.div(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 6603},
{"snippet": "Series.div(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `axis`.", "question_id": 6604},
{"snippet": "Series.div(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 6605},
{"snippet": "Series.div(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`, `axis`.", "question_id": 6606},
{"snippet": "Series.div(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 6607},
{"snippet": "Series.div(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 6608},
{"snippet": "Series.divide(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) .", "question_id": 6609},
{"snippet": "Series.divide(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`.", "question_id": 6610},
{"snippet": "Series.divide(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 6611},
{"snippet": "Series.divide(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `axis`.", "question_id": 6612},
{"snippet": "Series.divide(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 6613},
{"snippet": "Series.divide(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`, `axis`.", "question_id": 6614},
{"snippet": "Series.divide(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 6615},
{"snippet": "Series.divide(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 6616},
{"snippet": "Series.divide(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) .", "question_id": 6617},
{"snippet": "Series.divide(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`.", "question_id": 6618},
{"snippet": "Series.divide(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 6619},
{"snippet": "Series.divide(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `axis`.", "question_id": 6620},
{"snippet": "Series.divide(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 6621},
{"snippet": "Series.divide(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`, `axis`.", "question_id": 6622},
{"snippet": "Series.divide(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 6623},
{"snippet": "Series.divide(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 6624},
{"snippet": "Series.divide(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) .", "question_id": 6625},
{"snippet": "Series.divide(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`.", "question_id": 6626},
{"snippet": "Series.divide(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 6627},
{"snippet": "Series.divide(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `axis`.", "question_id": 6628},
{"snippet": "Series.divide(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 6629},
{"snippet": "Series.divide(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`, `axis`.", "question_id": 6630},
{"snippet": "Series.divide(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 6631},
{"snippet": "Series.divide(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 6632},
{"snippet": "Series.divmod(other)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) .", "question_id": 6633},
{"snippet": "Series.divmod(other, level=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . With arguments `level`.", "question_id": 6634},
{"snippet": "Series.divmod(other, fill_value=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . Equivalent to divmod ( series , other ) , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 6635},
{"snippet": "Series.divmod(other, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . With arguments `axis`.", "question_id": 6636},
{"snippet": "Series.divmod(other, level=None, fill_value=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . Equivalent to divmod ( series , other ) , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 6637},
{"snippet": "Series.divmod(other, level=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . With arguments `level`, `axis`.", "question_id": 6638},
{"snippet": "Series.divmod(other, fill_value=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . Equivalent to divmod ( series , other ) , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 6639},
{"snippet": "Series.divmod(other, level=None, fill_value=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . Equivalent to divmod ( series , other ) , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 6640},
{"snippet": "Series.divmod(other)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) .", "question_id": 6641},
{"snippet": "Series.divmod(other, level=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . With arguments `level`.", "question_id": 6642},
{"snippet": "Series.divmod(other, fill_value=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . Equivalent to divmod ( series , other ) , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 6643},
{"snippet": "Series.divmod(other, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . With arguments `axis`.", "question_id": 6644},
{"snippet": "Series.divmod(other, level=None, fill_value=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . Equivalent to divmod ( series , other ) , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 6645},
{"snippet": "Series.divmod(other, level=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . With arguments `level`, `axis`.", "question_id": 6646},
{"snippet": "Series.divmod(other, fill_value=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . Equivalent to divmod ( series , other ) , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 6647},
{"snippet": "Series.divmod(other, level=None, fill_value=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . Equivalent to divmod ( series , other ) , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 6648},
{"snippet": "Series.divmod(other)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) .", "question_id": 6649},
{"snippet": "Series.divmod(other, level=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . With arguments `level`.", "question_id": 6650},
{"snippet": "Series.divmod(other, fill_value=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . Equivalent to divmod ( series , other ) , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 6651},
{"snippet": "Series.divmod(other, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . With arguments `axis`.", "question_id": 6652},
{"snippet": "Series.divmod(other, level=None, fill_value=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . Equivalent to divmod ( series , other ) , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 6653},
{"snippet": "Series.divmod(other, level=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . With arguments `level`, `axis`.", "question_id": 6654},
{"snippet": "Series.divmod(other, fill_value=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . Equivalent to divmod ( series , other ) , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 6655},
{"snippet": "Series.divmod(other, level=None, fill_value=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator divmod ) . Equivalent to divmod ( series , other ) , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 6656},
{"snippet": "Series.dot(other)", "intent": "Compute the dot product between the Series and the columns of `other` .", "question_id": 6657},
{"snippet": "Series.dot(other)", "intent": "Compute the dot product between the Series and the columns of `other` .", "question_id": 6658},
{"snippet": "Series.dot(other)", "intent": "Compute the dot product between the Series and the columns of `other` .", "question_id": 6659},
{"snippet": "Series.drop()", "intent": "Return Series with specified `index` `labels` removed .", "question_id": 6660},
{"snippet": "Series.drop(labels=None)", "intent": "Return Series with specified `index` `labels` removed .", "question_id": 6661},
{"snippet": "Series.drop(axis=0)", "intent": "Return Series with specified `index` `labels` removed . With arguments `axis`.", "question_id": 6662},
{"snippet": "Series.drop(index=None)", "intent": "Return Series with specified `index` `labels` removed .", "question_id": 6663},
{"snippet": "Series.drop(columns=None)", "intent": "Return Series with specified `index` `labels` removed . With arguments `columns`.", "question_id": 6664},
{"snippet": "Series.drop(level=None)", "intent": "Return Series with specified `index` `labels` removed . When using a multi-index , labels on different levels can be removed by specifying the `level` .", "question_id": 6665},
{"snippet": "Series.drop(inplace=False)", "intent": "Return Series with specified `index` `labels` removed . With arguments `inplace`.", "question_id": 6666},
{"snippet": "Series.drop(errors='raise')", "intent": "Return Series with specified `index` `labels` removed . With arguments `errors`.", "question_id": 6667},
{"snippet": "Series.drop(labels=None, axis=0)", "intent": "Return Series with specified `index` `labels` removed . With arguments `axis`.", "question_id": 6668},
{"snippet": "Series.drop(labels=None, index=None)", "intent": "Return Series with specified `index` `labels` removed .", "question_id": 6669},
{"snippet": "Series.drop()", "intent": "Return Series with specified `index` `labels` removed .", "question_id": 6670},
{"snippet": "Series.drop(labels=None)", "intent": "Return Series with specified `index` `labels` removed .", "question_id": 6671},
{"snippet": "Series.drop(axis=0)", "intent": "Return Series with specified `index` `labels` removed . With arguments `axis`.", "question_id": 6672},
{"snippet": "Series.drop(index=None)", "intent": "Return Series with specified `index` `labels` removed .", "question_id": 6673},
{"snippet": "Series.drop(columns=None)", "intent": "Return Series with specified `index` `labels` removed . With arguments `columns`.", "question_id": 6674},
{"snippet": "Series.drop(level=None)", "intent": "Return Series with specified `index` `labels` removed . When using a multi-index , labels on different levels can be removed by specifying the `level` .", "question_id": 6675},
{"snippet": "Series.drop(inplace=False)", "intent": "Return Series with specified `index` `labels` removed . With arguments `inplace`.", "question_id": 6676},
{"snippet": "Series.drop(errors='raise')", "intent": "Return Series with specified `index` `labels` removed . With arguments `errors`.", "question_id": 6677},
{"snippet": "Series.drop(labels=None, axis=0)", "intent": "Return Series with specified `index` `labels` removed . With arguments `axis`.", "question_id": 6678},
{"snippet": "Series.drop(labels=None, index=None)", "intent": "Return Series with specified `index` `labels` removed .", "question_id": 6679},
{"snippet": "Series.drop()", "intent": "Return Series with specified `index` `labels` removed .", "question_id": 6680},
{"snippet": "Series.drop(labels=None)", "intent": "Return Series with specified `index` `labels` removed .", "question_id": 6681},
{"snippet": "Series.drop(axis=0)", "intent": "Return Series with specified `index` `labels` removed . With arguments `axis`.", "question_id": 6682},
{"snippet": "Series.drop(index=None)", "intent": "Return Series with specified `index` `labels` removed .", "question_id": 6683},
{"snippet": "Series.drop(columns=None)", "intent": "Return Series with specified `index` `labels` removed . With arguments `columns`.", "question_id": 6684},
{"snippet": "Series.drop(level=None)", "intent": "Return Series with specified `index` `labels` removed . When using a multi-index , labels on different levels can be removed by specifying the `level` .", "question_id": 6685},
{"snippet": "Series.drop(inplace=False)", "intent": "Return Series with specified `index` `labels` removed . With arguments `inplace`.", "question_id": 6686},
{"snippet": "Series.drop(errors='raise')", "intent": "Return Series with specified `index` `labels` removed . With arguments `errors`.", "question_id": 6687},
{"snippet": "Series.drop(labels=None, axis=0)", "intent": "Return Series with specified `index` `labels` removed . With arguments `axis`.", "question_id": 6688},
{"snippet": "Series.drop(labels=None, index=None)", "intent": "Return Series with specified `index` `labels` removed .", "question_id": 6689},
{"snippet": "Series.drop_duplicates()", "intent": "Return Series with duplicate values removed .", "question_id": 6690},
{"snippet": "Series.drop_duplicates(keep='first')", "intent": "Return Series with duplicate values removed . With the \u2018 `keep` \u2019 parameter , the selection behaviour of duplicated values can be changed .", "question_id": 6691},
{"snippet": "Series.drop_duplicates(inplace=False)", "intent": "Return Series with duplicate values removed . Setting the value of \u2018 `inplace` \u2019 to True performs the operation inplace and returns None .", "question_id": 6692},
{"snippet": "Series.drop_duplicates(keep='first', inplace=False)", "intent": "Return Series with duplicate values removed . With the \u2018 `keep` \u2019 parameter , the selection behaviour of duplicated values can be changed . Setting the value of \u2018 `inplace` \u2019 to True performs the operation inplace and returns None .", "question_id": 6693},
{"snippet": "Series.drop_duplicates()", "intent": "Return Series with duplicate values removed .", "question_id": 6694},
{"snippet": "Series.drop_duplicates(keep='first')", "intent": "Return Series with duplicate values removed . With the \u2018 `keep` \u2019 parameter , the selection behaviour of duplicated values can be changed .", "question_id": 6695},
{"snippet": "Series.drop_duplicates(inplace=False)", "intent": "Return Series with duplicate values removed . Setting the value of \u2018 `inplace` \u2019 to True performs the operation inplace and returns None .", "question_id": 6696},
{"snippet": "Series.drop_duplicates(keep='first', inplace=False)", "intent": "Return Series with duplicate values removed . With the \u2018 `keep` \u2019 parameter , the selection behaviour of duplicated values can be changed . Setting the value of \u2018 `inplace` \u2019 to True performs the operation inplace and returns None .", "question_id": 6697},
{"snippet": "Series.drop_duplicates()", "intent": "Return Series with duplicate values removed .", "question_id": 6698},
{"snippet": "Series.drop_duplicates(keep='first')", "intent": "Return Series with duplicate values removed . With the \u2018 `keep` \u2019 parameter , the selection behaviour of duplicated values can be changed .", "question_id": 6699},
{"snippet": "Series.drop_duplicates(inplace=False)", "intent": "Return Series with duplicate values removed . Setting the value of \u2018 `inplace` \u2019 to True performs the operation inplace and returns None .", "question_id": 6700},
{"snippet": "Series.drop_duplicates(keep='first', inplace=False)", "intent": "Return Series with duplicate values removed . With the \u2018 `keep` \u2019 parameter , the selection behaviour of duplicated values can be changed . Setting the value of \u2018 `inplace` \u2019 to True performs the operation inplace and returns None .", "question_id": 6701},
{"snippet": "Series.droplevel(level)", "intent": "Return Series/DataFrame with requested index / column `level` ( s ) removed .", "question_id": 6702},
{"snippet": "Series.droplevel(level, axis=0)", "intent": "Return Series/DataFrame with requested index / column `level` ( s ) removed . With arguments `axis`.", "question_id": 6703},
{"snippet": "Series.droplevel(level)", "intent": "Return Series/DataFrame with requested index / column `level` ( s ) removed .", "question_id": 6704},
{"snippet": "Series.droplevel(level, axis=0)", "intent": "Return Series/DataFrame with requested index / column `level` ( s ) removed . With arguments `axis`.", "question_id": 6705},
{"snippet": "Series.droplevel(level)", "intent": "Return Series/DataFrame with requested index / column `level` ( s ) removed .", "question_id": 6706},
{"snippet": "Series.droplevel(level, axis=0)", "intent": "Return Series/DataFrame with requested index / column `level` ( s ) removed . With arguments `axis`.", "question_id": 6707},
{"snippet": "Series.dropna()", "intent": "Return a new Series with missing values removed .", "question_id": 6708},
{"snippet": "Series.dropna(axis=0)", "intent": "Return a new Series with missing values removed . With arguments `axis`.", "question_id": 6709},
{"snippet": "Series.dropna(inplace=False)", "intent": "Return a new Series with missing values removed . With arguments `inplace`.", "question_id": 6710},
{"snippet": "Series.dropna(how=None)", "intent": "Return a new Series with missing values removed . See the User Guide for more on which values are considered missing , and `how` to work with missing data .", "question_id": 6711},
{"snippet": "Series.dropna(axis=0, inplace=False)", "intent": "Return a new Series with missing values removed . With arguments `axis`, `inplace`.", "question_id": 6712},
{"snippet": "Series.dropna(axis=0, how=None)", "intent": "Return a new Series with missing values removed . See the User Guide for more on which values are considered missing , and `how` to work with missing data . With arguments `axis`.", "question_id": 6713},
{"snippet": "Series.dropna(inplace=False, how=None)", "intent": "Return a new Series with missing values removed . See the User Guide for more on which values are considered missing , and `how` to work with missing data . With arguments `inplace`.", "question_id": 6714},
{"snippet": "Series.dropna(axis=0, inplace=False, how=None)", "intent": "Return a new Series with missing values removed . See the User Guide for more on which values are considered missing , and `how` to work with missing data . With arguments `axis`, `inplace`.", "question_id": 6715},
{"snippet": "Series.dropna()", "intent": "Return a new Series with missing values removed .", "question_id": 6716},
{"snippet": "Series.dropna(axis=0)", "intent": "Return a new Series with missing values removed . With arguments `axis`.", "question_id": 6717},
{"snippet": "Series.dropna(inplace=False)", "intent": "Return a new Series with missing values removed . With arguments `inplace`.", "question_id": 6718},
{"snippet": "Series.dropna(how=None)", "intent": "Return a new Series with missing values removed . See the User Guide for more on which values are considered missing , and `how` to work with missing data .", "question_id": 6719},
{"snippet": "Series.dropna(axis=0, inplace=False)", "intent": "Return a new Series with missing values removed . With arguments `axis`, `inplace`.", "question_id": 6720},
{"snippet": "Series.dropna(axis=0, how=None)", "intent": "Return a new Series with missing values removed . See the User Guide for more on which values are considered missing , and `how` to work with missing data . With arguments `axis`.", "question_id": 6721},
{"snippet": "Series.dropna(inplace=False, how=None)", "intent": "Return a new Series with missing values removed . See the User Guide for more on which values are considered missing , and `how` to work with missing data . With arguments `inplace`.", "question_id": 6722},
{"snippet": "Series.dropna(axis=0, inplace=False, how=None)", "intent": "Return a new Series with missing values removed . See the User Guide for more on which values are considered missing , and `how` to work with missing data . With arguments `axis`, `inplace`.", "question_id": 6723},
{"snippet": "Series.dropna()", "intent": "Return a new Series with missing values removed .", "question_id": 6724},
{"snippet": "Series.dropna(axis=0)", "intent": "Return a new Series with missing values removed . With arguments `axis`.", "question_id": 6725},
{"snippet": "Series.dropna(inplace=False)", "intent": "Return a new Series with missing values removed . With arguments `inplace`.", "question_id": 6726},
{"snippet": "Series.dropna(how=None)", "intent": "Return a new Series with missing values removed . See the User Guide for more on which values are considered missing , and `how` to work with missing data .", "question_id": 6727},
{"snippet": "Series.dropna(axis=0, inplace=False)", "intent": "Return a new Series with missing values removed . With arguments `axis`, `inplace`.", "question_id": 6728},
{"snippet": "Series.dropna(axis=0, how=None)", "intent": "Return a new Series with missing values removed . See the User Guide for more on which values are considered missing , and `how` to work with missing data . With arguments `axis`.", "question_id": 6729},
{"snippet": "Series.dropna(inplace=False, how=None)", "intent": "Return a new Series with missing values removed . See the User Guide for more on which values are considered missing , and `how` to work with missing data . With arguments `inplace`.", "question_id": 6730},
{"snippet": "Series.dropna(axis=0, inplace=False, how=None)", "intent": "Return a new Series with missing values removed . See the User Guide for more on which values are considered missing , and `how` to work with missing data . With arguments `axis`, `inplace`.", "question_id": 6731},
{"snippet": "Series.dt.ceil(*args, **kwargs)", "intent": "Perform ceil operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 6732},
{"snippet": "Series.dt.ceil(*args, **kwargs)", "intent": "Perform ceil operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 6733},
{"snippet": "Series.dt.ceil(*args, **kwargs)", "intent": "Perform ceil operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 6734},
{"snippet": "Series.dt.components", "intent": "Return a Dataframe of the components of the Timedeltas.", "question_id": 6735},
{"snippet": "Series.dt.components", "intent": "Return a Dataframe of the components of the Timedeltas.", "question_id": 6736},
{"snippet": "Series.dt.components", "intent": "Return a Dataframe of the components of the Timedeltas.", "question_id": 6737},
{"snippet": "Series.dt.date", "intent": "Returns numpy array of python datetime.date objects (namely, the date part of Timestamps without timezone information).", "question_id": 6738},
{"snippet": "Series.dt.date", "intent": "Returns numpy array of python datetime.date objects (namely, the date part of Timestamps without timezone information).", "question_id": 6739},
{"snippet": "Series.dt.date", "intent": "Returns numpy array of python datetime.date objects (namely, the date part of Timestamps without timezone information).", "question_id": 6740},
{"snippet": "Series.dt.day", "intent": "The day of the datetime.", "question_id": 6741},
{"snippet": "Series.dt.day", "intent": "The day of the datetime.", "question_id": 6742},
{"snippet": "Series.dt.day", "intent": "The day of the datetime.", "question_id": 6743},
{"snippet": "Series.dt.day_name(*args, **kwargs)", "intent": "Return the day names of the DateTimeIndex with specified locale . With arguments `*args`, `**kwargs`.", "question_id": 6744},
{"snippet": "Series.dt.day_name(*args, **kwargs)", "intent": "Return the day names of the DateTimeIndex with specified locale . With arguments `*args`, `**kwargs`.", "question_id": 6745},
{"snippet": "Series.dt.day_name(*args, **kwargs)", "intent": "Return the day names of the DateTimeIndex with specified locale . With arguments `*args`, `**kwargs`.", "question_id": 6746},
{"snippet": "Series.dt.day_of_week", "intent": "The day of the week with Monday=0, Sunday=6.", "question_id": 6747},
{"snippet": "Series.dt.day_of_week", "intent": "The day of the week with Monday=0, Sunday=6.", "question_id": 6748},
{"snippet": "Series.dt.day_of_week", "intent": "The day of the week with Monday=0, Sunday=6.", "question_id": 6749},
{"snippet": "Series.dt.day_of_year", "intent": "The ordinal day of the year.", "question_id": 6750},
{"snippet": "Series.dt.day_of_year", "intent": "The ordinal day of the year.", "question_id": 6751},
{"snippet": "Series.dt.day_of_year", "intent": "The ordinal day of the year.", "question_id": 6752},
{"snippet": "Series.dt.dayofweek", "intent": "The day of the week with Monday=0, Sunday=6.", "question_id": 6753},
{"snippet": "Series.dt.dayofweek", "intent": "The day of the week with Monday=0, Sunday=6.", "question_id": 6754},
{"snippet": "Series.dt.dayofweek", "intent": "The day of the week with Monday=0, Sunday=6.", "question_id": 6755},
{"snippet": "Series.dt.dayofyear", "intent": "The ordinal day of the year.", "question_id": 6756},
{"snippet": "Series.dt.dayofyear", "intent": "The ordinal day of the year.", "question_id": 6757},
{"snippet": "Series.dt.dayofyear", "intent": "The ordinal day of the year.", "question_id": 6758},
{"snippet": "Series.dt.days", "intent": "Number of days for each element.", "question_id": 6759},
{"snippet": "Series.dt.days", "intent": "Number of days for each element.", "question_id": 6760},
{"snippet": "Series.dt.days", "intent": "Number of days for each element.", "question_id": 6761},
{"snippet": "Series.dt.days_in_month", "intent": "The number of days in the month.", "question_id": 6762},
{"snippet": "Series.dt.days_in_month", "intent": "The number of days in the month.", "question_id": 6763},
{"snippet": "Series.dt.days_in_month", "intent": "The number of days in the month.", "question_id": 6764},
{"snippet": "Series.dt.daysinmonth", "intent": "The number of days in the month.", "question_id": 6765},
{"snippet": "Series.dt.daysinmonth", "intent": "The number of days in the month.", "question_id": 6766},
{"snippet": "Series.dt.daysinmonth", "intent": "The number of days in the month.", "question_id": 6767},
{"snippet": "Series.dt.floor(*args, **kwargs)", "intent": "Perform floor operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 6768},
{"snippet": "Series.dt.floor(*args, **kwargs)", "intent": "Perform floor operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 6769},
{"snippet": "Series.dt.floor(*args, **kwargs)", "intent": "Perform floor operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 6770},
{"snippet": "Series.dt.hour", "intent": "The hours of the datetime.", "question_id": 6771},
{"snippet": "Series.dt.hour", "intent": "The hours of the datetime.", "question_id": 6772},
{"snippet": "Series.dt.hour", "intent": "The hours of the datetime.", "question_id": 6773},
{"snippet": "Series.dt()", "intent": "Accessor object for datetimelike properties of the Series values .", "question_id": 6774},
{"snippet": "Series.dt()", "intent": "Accessor object for datetimelike properties of the Series values .", "question_id": 6775},
{"snippet": "Series.dt()", "intent": "Accessor object for datetimelike properties of the Series values .", "question_id": 6776},
{"snippet": "Series.dt.is_leap_year", "intent": "Boolean indicator if the date belongs to a leap year.", "question_id": 6777},
{"snippet": "Series.dt.is_leap_year", "intent": "Boolean indicator if the date belongs to a leap year.", "question_id": 6778},
{"snippet": "Series.dt.is_leap_year", "intent": "Boolean indicator if the date belongs to a leap year.", "question_id": 6779},
{"snippet": "Series.dt.is_month_end", "intent": "Indicates whether the date is the last day of the month.", "question_id": 6780},
{"snippet": "Series.dt.is_month_end", "intent": "Indicates whether the date is the last day of the month.", "question_id": 6781},
{"snippet": "Series.dt.is_month_end", "intent": "Indicates whether the date is the last day of the month.", "question_id": 6782},
{"snippet": "Series.dt.is_month_start", "intent": "Indicates whether the date is the first day of the month.", "question_id": 6783},
{"snippet": "Series.dt.is_month_start", "intent": "Indicates whether the date is the first day of the month.", "question_id": 6784},
{"snippet": "Series.dt.is_month_start", "intent": "Indicates whether the date is the first day of the month.", "question_id": 6785},
{"snippet": "Series.dt.is_quarter_end", "intent": "Indicator for whether the date is the last day of a quarter.", "question_id": 6786},
{"snippet": "Series.dt.is_quarter_end", "intent": "Indicator for whether the date is the last day of a quarter.", "question_id": 6787},
{"snippet": "Series.dt.is_quarter_end", "intent": "Indicator for whether the date is the last day of a quarter.", "question_id": 6788},
{"snippet": "Series.dt.is_quarter_start", "intent": "Indicator for whether the date is the first day of a quarter.", "question_id": 6789},
{"snippet": "Series.dt.is_quarter_start", "intent": "Indicator for whether the date is the first day of a quarter.", "question_id": 6790},
{"snippet": "Series.dt.is_quarter_start", "intent": "Indicator for whether the date is the first day of a quarter.", "question_id": 6791},
{"snippet": "Series.dt.is_year_end", "intent": "Indicate whether the date is the last day of the year.", "question_id": 6792},
{"snippet": "Series.dt.is_year_end", "intent": "Indicate whether the date is the last day of the year.", "question_id": 6793},
{"snippet": "Series.dt.is_year_end", "intent": "Indicate whether the date is the last day of the year.", "question_id": 6794},
{"snippet": "Series.dt.is_year_start", "intent": "Indicate whether the date is the first day of a year.", "question_id": 6795},
{"snippet": "Series.dt.is_year_start", "intent": "Indicate whether the date is the first day of a year.", "question_id": 6796},
{"snippet": "Series.dt.is_year_start", "intent": "Indicate whether the date is the first day of a year.", "question_id": 6797},
{"snippet": "Series.dt.microsecond", "intent": "The microseconds of the datetime.", "question_id": 6798},
{"snippet": "Series.dt.microsecond", "intent": "The microseconds of the datetime.", "question_id": 6799},
{"snippet": "Series.dt.microsecond", "intent": "The microseconds of the datetime.", "question_id": 6800},
{"snippet": "Series.dt.microseconds", "intent": "Number of microseconds (>= 0 and less than 1 second) for each element.", "question_id": 6801},
{"snippet": "Series.dt.microseconds", "intent": "Number of microseconds (>= 0 and less than 1 second) for each element.", "question_id": 6802},
{"snippet": "Series.dt.microseconds", "intent": "Number of microseconds (>= 0 and less than 1 second) for each element.", "question_id": 6803},
{"snippet": "Series.dt.minute", "intent": "The minutes of the datetime.", "question_id": 6804},
{"snippet": "Series.dt.minute", "intent": "The minutes of the datetime.", "question_id": 6805},
{"snippet": "Series.dt.minute", "intent": "The minutes of the datetime.", "question_id": 6806},
{"snippet": "Series.dt.month", "intent": "The month as January=1, December=12.", "question_id": 6807},
{"snippet": "Series.dt.month", "intent": "The month as January=1, December=12.", "question_id": 6808},
{"snippet": "Series.dt.month", "intent": "The month as January=1, December=12.", "question_id": 6809},
{"snippet": "Series.dt.month_name(*args, **kwargs)", "intent": "Return the month names of the DateTimeIndex with specified locale . With arguments `*args`, `**kwargs`.", "question_id": 6810},
{"snippet": "Series.dt.month_name(*args, **kwargs)", "intent": "Return the month names of the DateTimeIndex with specified locale . With arguments `*args`, `**kwargs`.", "question_id": 6811},
{"snippet": "Series.dt.month_name(*args, **kwargs)", "intent": "Return the month names of the DateTimeIndex with specified locale . With arguments `*args`, `**kwargs`.", "question_id": 6812},
{"snippet": "Series.dt.nanosecond", "intent": "The nanoseconds of the datetime.", "question_id": 6813},
{"snippet": "Series.dt.nanosecond", "intent": "The nanoseconds of the datetime.", "question_id": 6814},
{"snippet": "Series.dt.nanosecond", "intent": "The nanoseconds of the datetime.", "question_id": 6815},
{"snippet": "Series.dt.nanoseconds", "intent": "Number of nanoseconds (>= 0 and less than 1 microsecond) for each element.", "question_id": 6816},
{"snippet": "Series.dt.nanoseconds", "intent": "Number of nanoseconds (>= 0 and less than 1 microsecond) for each element.", "question_id": 6817},
{"snippet": "Series.dt.nanoseconds", "intent": "Number of nanoseconds (>= 0 and less than 1 microsecond) for each element.", "question_id": 6818},
{"snippet": "Series.dt.normalize(*args, **kwargs)", "intent": "Convert times to midnight . With arguments `*args`, `**kwargs`.", "question_id": 6819},
{"snippet": "Series.dt.normalize(*args, **kwargs)", "intent": "Convert times to midnight . With arguments `*args`, `**kwargs`.", "question_id": 6820},
{"snippet": "Series.dt.normalize(*args, **kwargs)", "intent": "Convert times to midnight . With arguments `*args`, `**kwargs`.", "question_id": 6821},
{"snippet": "Series.dt.quarter", "intent": "The quarter of the date.", "question_id": 6822},
{"snippet": "Series.dt.quarter", "intent": "The quarter of the date.", "question_id": 6823},
{"snippet": "Series.dt.quarter", "intent": "The quarter of the date.", "question_id": 6824},
{"snippet": "Series.dt.round(*args, **kwargs)", "intent": "Perform round operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 6825},
{"snippet": "Series.dt.round(*args, **kwargs)", "intent": "Perform round operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 6826},
{"snippet": "Series.dt.round(*args, **kwargs)", "intent": "Perform round operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 6827},
{"snippet": "Series.dt.second", "intent": "The seconds of the datetime.", "question_id": 6828},
{"snippet": "Series.dt.second", "intent": "The seconds of the datetime.", "question_id": 6829},
{"snippet": "Series.dt.second", "intent": "The seconds of the datetime.", "question_id": 6830},
{"snippet": "Series.dt.seconds", "intent": "Number of seconds (>= 0 and less than 1 day) for each element.", "question_id": 6831},
{"snippet": "Series.dt.seconds", "intent": "Number of seconds (>= 0 and less than 1 day) for each element.", "question_id": 6832},
{"snippet": "Series.dt.seconds", "intent": "Number of seconds (>= 0 and less than 1 day) for each element.", "question_id": 6833},
{"snippet": "Series.dt.strftime(*args, **kwargs)", "intent": "Convert to Index using specified date_format . With arguments `*args`, `**kwargs`.", "question_id": 6834},
{"snippet": "Series.dt.strftime(*args, **kwargs)", "intent": "Convert to Index using specified date_format . With arguments `*args`, `**kwargs`.", "question_id": 6835},
{"snippet": "Series.dt.strftime(*args, **kwargs)", "intent": "Convert to Index using specified date_format . With arguments `*args`, `**kwargs`.", "question_id": 6836},
{"snippet": "Series.dt.time", "intent": "Returns numpy array of datetime.time.", "question_id": 6837},
{"snippet": "Series.dt.time", "intent": "Returns numpy array of datetime.time.", "question_id": 6838},
{"snippet": "Series.dt.time", "intent": "Returns numpy array of datetime.time.", "question_id": 6839},
{"snippet": "Series.dt.timetz", "intent": "Returns numpy array of datetime.time also containing timezone information.", "question_id": 6840},
{"snippet": "Series.dt.timetz", "intent": "Returns numpy array of datetime.time also containing timezone information.", "question_id": 6841},
{"snippet": "Series.dt.timetz", "intent": "Returns numpy array of datetime.time also containing timezone information.", "question_id": 6842},
{"snippet": "Series.dt.to_period(*args, **kwargs)", "intent": "Cast to PeriodArray/Index at a particular frequency . With arguments `*args`, `**kwargs`.", "question_id": 6843},
{"snippet": "Series.dt.to_period(*args, **kwargs)", "intent": "Cast to PeriodArray/Index at a particular frequency . With arguments `*args`, `**kwargs`.", "question_id": 6844},
{"snippet": "Series.dt.to_period(*args, **kwargs)", "intent": "Cast to PeriodArray/Index at a particular frequency . With arguments `*args`, `**kwargs`.", "question_id": 6845},
{"snippet": "Series.dt.to_pydatetime()", "intent": "Return the data as an array of native Python datetime objects .", "question_id": 6846},
{"snippet": "Series.dt.to_pydatetime()", "intent": "Return the data as an array of native Python datetime objects .", "question_id": 6847},
{"snippet": "Series.dt.to_pydatetime()", "intent": "Return the data as an array of native Python datetime objects .", "question_id": 6848},
{"snippet": "Series.dt.to_pytimedelta()", "intent": "Return an array of native datetime.timedelta objects .", "question_id": 6849},
{"snippet": "Series.dt.to_pytimedelta()", "intent": "Return an array of native datetime.timedelta objects .", "question_id": 6850},
{"snippet": "Series.dt.to_pytimedelta()", "intent": "Return an array of native datetime.timedelta objects .", "question_id": 6851},
{"snippet": "Series.dt.total_seconds(*args, **kwargs)", "intent": "Return total duration of each element expressed in seconds . With arguments `*args`, `**kwargs`.", "question_id": 6852},
{"snippet": "Series.dt.total_seconds(*args, **kwargs)", "intent": "Return total duration of each element expressed in seconds . With arguments `*args`, `**kwargs`.", "question_id": 6853},
{"snippet": "Series.dt.total_seconds(*args, **kwargs)", "intent": "Return total duration of each element expressed in seconds . With arguments `*args`, `**kwargs`.", "question_id": 6854},
{"snippet": "Series.dt.tz", "intent": "Return timezone, if any.", "question_id": 6855},
{"snippet": "Series.dt.tz", "intent": "Return timezone, if any.", "question_id": 6856},
{"snippet": "Series.dt.tz", "intent": "Return timezone, if any.", "question_id": 6857},
{"snippet": "Series.dt.tz_convert(*args, **kwargs)", "intent": "Convert tz-aware Datetime Array/Index from one time zone to another . With arguments `*args`, `**kwargs`.", "question_id": 6858},
{"snippet": "Series.dt.tz_convert(*args, **kwargs)", "intent": "Convert tz-aware Datetime Array/Index from one time zone to another . With arguments `*args`, `**kwargs`.", "question_id": 6859},
{"snippet": "Series.dt.tz_convert(*args, **kwargs)", "intent": "Convert tz-aware Datetime Array/Index from one time zone to another . With arguments `*args`, `**kwargs`.", "question_id": 6860},
{"snippet": "Series.dt.tz_localize(*args, **kwargs)", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . With arguments `*args`, `**kwargs`.", "question_id": 6861},
{"snippet": "Series.dt.tz_localize(*args, **kwargs)", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . With arguments `*args`, `**kwargs`.", "question_id": 6862},
{"snippet": "Series.dt.tz_localize(*args, **kwargs)", "intent": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index . With arguments `*args`, `**kwargs`.", "question_id": 6863},
{"snippet": "Series.dt.week", "intent": "The week ordinal of the year.", "question_id": 6864},
{"snippet": "Series.dt.week", "intent": "The week ordinal of the year.", "question_id": 6865},
{"snippet": "Series.dt.week", "intent": "The week ordinal of the year.", "question_id": 6866},
{"snippet": "Series.dt.weekday", "intent": "The day of the week with Monday=0, Sunday=6.", "question_id": 6867},
{"snippet": "Series.dt.weekday", "intent": "The day of the week with Monday=0, Sunday=6.", "question_id": 6868},
{"snippet": "Series.dt.weekday", "intent": "The day of the week with Monday=0, Sunday=6.", "question_id": 6869},
{"snippet": "Series.dt.weekofyear", "intent": "The week ordinal of the year.", "question_id": 6870},
{"snippet": "Series.dt.weekofyear", "intent": "The week ordinal of the year.", "question_id": 6871},
{"snippet": "Series.dt.weekofyear", "intent": "The week ordinal of the year.", "question_id": 6872},
{"snippet": "Series.dt.year", "intent": "The year of the datetime.", "question_id": 6873},
{"snippet": "Series.dt.year", "intent": "The year of the datetime.", "question_id": 6874},
{"snippet": "Series.dt.year", "intent": "The year of the datetime.", "question_id": 6875},
{"snippet": "Series.duplicated()", "intent": "Indicate duplicate Series values .", "question_id": 6876},
{"snippet": "Series.duplicated(keep='first')", "intent": "Indicate duplicate Series values . By setting `keep` on False , all duplicates are True :", "question_id": 6877},
{"snippet": "Series.duplicated()", "intent": "Indicate duplicate Series values .", "question_id": 6878},
{"snippet": "Series.duplicated(keep='first')", "intent": "Indicate duplicate Series values . By setting `keep` on False , all duplicates are True :", "question_id": 6879},
{"snippet": "Series.duplicated()", "intent": "Indicate duplicate Series values .", "question_id": 6880},
{"snippet": "Series.duplicated(keep='first')", "intent": "Indicate duplicate Series values . By setting `keep` on False , all duplicates are True :", "question_id": 6881},
{"snippet": "Series.eq(other)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) .", "question_id": 6882},
{"snippet": "Series.eq(other, level=None)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . With arguments `level`.", "question_id": 6883},
{"snippet": "Series.eq(other, fill_value=None)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . Equivalent to series == other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 6884},
{"snippet": "Series.eq(other, axis=0)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . With arguments `axis`.", "question_id": 6885},
{"snippet": "Series.eq(other, level=None, fill_value=None)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . Equivalent to series == other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 6886},
{"snippet": "Series.eq(other, level=None, axis=0)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . With arguments `level`, `axis`.", "question_id": 6887},
{"snippet": "Series.eq(other, fill_value=None, axis=0)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . Equivalent to series == other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 6888},
{"snippet": "Series.eq(other, level=None, fill_value=None, axis=0)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . Equivalent to series == other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 6889},
{"snippet": "Series.eq(other)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) .", "question_id": 6890},
{"snippet": "Series.eq(other, level=None)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . With arguments `level`.", "question_id": 6891},
{"snippet": "Series.eq(other, fill_value=None)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . Equivalent to series == other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 6892},
{"snippet": "Series.eq(other, axis=0)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . With arguments `axis`.", "question_id": 6893},
{"snippet": "Series.eq(other, level=None, fill_value=None)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . Equivalent to series == other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 6894},
{"snippet": "Series.eq(other, level=None, axis=0)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . With arguments `level`, `axis`.", "question_id": 6895},
{"snippet": "Series.eq(other, fill_value=None, axis=0)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . Equivalent to series == other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 6896},
{"snippet": "Series.eq(other, level=None, fill_value=None, axis=0)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . Equivalent to series == other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 6897},
{"snippet": "Series.eq(other)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) .", "question_id": 6898},
{"snippet": "Series.eq(other, level=None)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . With arguments `level`.", "question_id": 6899},
{"snippet": "Series.eq(other, fill_value=None)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . Equivalent to series == other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 6900},
{"snippet": "Series.eq(other, axis=0)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . With arguments `axis`.", "question_id": 6901},
{"snippet": "Series.eq(other, level=None, fill_value=None)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . Equivalent to series == other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 6902},
{"snippet": "Series.eq(other, level=None, axis=0)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . With arguments `level`, `axis`.", "question_id": 6903},
{"snippet": "Series.eq(other, fill_value=None, axis=0)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . Equivalent to series == other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 6904},
{"snippet": "Series.eq(other, level=None, fill_value=None, axis=0)", "intent": "Return Equal to of series and `other` , element-wise ( binary operator eq ) . Equivalent to series == other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 6905},
{"snippet": "Series.equals(other)", "intent": "Test whether two objects contain the same elements . This function allows two Series or DataFrames to be compared against each `other` to see if they have the same shape and elements .", "question_id": 6906},
{"snippet": "Series.equals(other)", "intent": "Test whether two objects contain the same elements . This function allows two Series or DataFrames to be compared against each `other` to see if they have the same shape and elements .", "question_id": 6907},
{"snippet": "Series.equals(other)", "intent": "Test whether two objects contain the same elements . This function allows two Series or DataFrames to be compared against each `other` to see if they have the same shape and elements .", "question_id": 6908},
{"snippet": "Series.ewm()", "intent": "Provide exponential weighted ( EW ) functions .", "question_id": 6909},
{"snippet": "Series.ewm(com=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 6910},
{"snippet": "Series.ewm(span=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 6911},
{"snippet": "Series.ewm(halflife=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 6912},
{"snippet": "Series.ewm(alpha=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 6913},
{"snippet": "Series.ewm(min_periods=0)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `min_periods`.", "question_id": 6914},
{"snippet": "Series.ewm(adjust=True)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `adjust`.", "question_id": 6915},
{"snippet": "Series.ewm(ignore_na=False)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `ignore_na`.", "question_id": 6916},
{"snippet": "Series.ewm(axis=0)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `axis`.", "question_id": 6917},
{"snippet": "Series.ewm(times=None)", "intent": "Provide exponential weighted ( EW ) functions . Specifying `times` with a timedelta halflife when computing mean .", "question_id": 6918},
{"snippet": "Series.ewm()", "intent": "Provide exponential weighted ( EW ) functions .", "question_id": 6919},
{"snippet": "Series.ewm(com=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 6920},
{"snippet": "Series.ewm(span=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 6921},
{"snippet": "Series.ewm(halflife=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 6922},
{"snippet": "Series.ewm(alpha=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 6923},
{"snippet": "Series.ewm(min_periods=0)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `min_periods`.", "question_id": 6924},
{"snippet": "Series.ewm(adjust=True)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `adjust`.", "question_id": 6925},
{"snippet": "Series.ewm(ignore_na=False)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `ignore_na`.", "question_id": 6926},
{"snippet": "Series.ewm(axis=0)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `axis`.", "question_id": 6927},
{"snippet": "Series.ewm(times=None)", "intent": "Provide exponential weighted ( EW ) functions . Specifying `times` with a timedelta halflife when computing mean .", "question_id": 6928},
{"snippet": "Series.ewm()", "intent": "Provide exponential weighted ( EW ) functions .", "question_id": 6929},
{"snippet": "Series.ewm(com=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 6930},
{"snippet": "Series.ewm(span=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 6931},
{"snippet": "Series.ewm(halflife=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 6932},
{"snippet": "Series.ewm(alpha=None)", "intent": "Provide exponential weighted ( EW ) functions . Exactly one parameter : `com` , `span` , `halflife` , or `alpha` must be provided .", "question_id": 6933},
{"snippet": "Series.ewm(min_periods=0)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `min_periods`.", "question_id": 6934},
{"snippet": "Series.ewm(adjust=True)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `adjust`.", "question_id": 6935},
{"snippet": "Series.ewm(ignore_na=False)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `ignore_na`.", "question_id": 6936},
{"snippet": "Series.ewm(axis=0)", "intent": "Provide exponential weighted ( EW ) functions . With arguments `axis`.", "question_id": 6937},
{"snippet": "Series.ewm(times=None)", "intent": "Provide exponential weighted ( EW ) functions . Specifying `times` with a timedelta halflife when computing mean .", "question_id": 6938},
{"snippet": "Series.expanding()", "intent": "Provide expanding transformations .", "question_id": 6939},
{"snippet": "Series.expanding(min_periods=1)", "intent": "Provide expanding transformations . With arguments `min_periods`.", "question_id": 6940},
{"snippet": "Series.expanding(center=None)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True .", "question_id": 6941},
{"snippet": "Series.expanding(axis=0)", "intent": "Provide expanding transformations . With arguments `axis`.", "question_id": 6942},
{"snippet": "Series.expanding(method='single')", "intent": "Provide expanding transformations . With arguments `method`.", "question_id": 6943},
{"snippet": "Series.expanding(min_periods=1, center=None)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `min_periods`.", "question_id": 6944},
{"snippet": "Series.expanding(min_periods=1, axis=0)", "intent": "Provide expanding transformations . With arguments `min_periods`, `axis`.", "question_id": 6945},
{"snippet": "Series.expanding(min_periods=1, method='single')", "intent": "Provide expanding transformations . With arguments `min_periods`, `method`.", "question_id": 6946},
{"snippet": "Series.expanding(center=None, axis=0)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `axis`.", "question_id": 6947},
{"snippet": "Series.expanding(center=None, method='single')", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `method`.", "question_id": 6948},
{"snippet": "Series.expanding()", "intent": "Provide expanding transformations .", "question_id": 6949},
{"snippet": "Series.expanding(min_periods=1)", "intent": "Provide expanding transformations . With arguments `min_periods`.", "question_id": 6950},
{"snippet": "Series.expanding(center=None)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True .", "question_id": 6951},
{"snippet": "Series.expanding(axis=0)", "intent": "Provide expanding transformations . With arguments `axis`.", "question_id": 6952},
{"snippet": "Series.expanding(method='single')", "intent": "Provide expanding transformations . With arguments `method`.", "question_id": 6953},
{"snippet": "Series.expanding(min_periods=1, center=None)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `min_periods`.", "question_id": 6954},
{"snippet": "Series.expanding(min_periods=1, axis=0)", "intent": "Provide expanding transformations . With arguments `min_periods`, `axis`.", "question_id": 6955},
{"snippet": "Series.expanding(min_periods=1, method='single')", "intent": "Provide expanding transformations . With arguments `min_periods`, `method`.", "question_id": 6956},
{"snippet": "Series.expanding(center=None, axis=0)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `axis`.", "question_id": 6957},
{"snippet": "Series.expanding(center=None, method='single')", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `method`.", "question_id": 6958},
{"snippet": "Series.expanding()", "intent": "Provide expanding transformations .", "question_id": 6959},
{"snippet": "Series.expanding(min_periods=1)", "intent": "Provide expanding transformations . With arguments `min_periods`.", "question_id": 6960},
{"snippet": "Series.expanding(center=None)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True .", "question_id": 6961},
{"snippet": "Series.expanding(axis=0)", "intent": "Provide expanding transformations . With arguments `axis`.", "question_id": 6962},
{"snippet": "Series.expanding(method='single')", "intent": "Provide expanding transformations . With arguments `method`.", "question_id": 6963},
{"snippet": "Series.expanding(min_periods=1, center=None)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `min_periods`.", "question_id": 6964},
{"snippet": "Series.expanding(min_periods=1, axis=0)", "intent": "Provide expanding transformations . With arguments `min_periods`, `axis`.", "question_id": 6965},
{"snippet": "Series.expanding(min_periods=1, method='single')", "intent": "Provide expanding transformations . With arguments `min_periods`, `method`.", "question_id": 6966},
{"snippet": "Series.expanding(center=None, axis=0)", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `axis`.", "question_id": 6967},
{"snippet": "Series.expanding(center=None, method='single')", "intent": "Provide expanding transformations . This can be changed to the `center` of the window by setting center=True . With arguments `method`.", "question_id": 6968},
{"snippet": "Series.explode()", "intent": "Transform each element of a list-like to a row .", "question_id": 6969},
{"snippet": "Series.explode(ignore_index=False)", "intent": "Transform each element of a list-like to a row . With arguments `ignore_index`.", "question_id": 6970},
{"snippet": "Series.explode()", "intent": "Transform each element of a list-like to a row .", "question_id": 6971},
{"snippet": "Series.explode(ignore_index=False)", "intent": "Transform each element of a list-like to a row . With arguments `ignore_index`.", "question_id": 6972},
{"snippet": "Series.explode()", "intent": "Transform each element of a list-like to a row .", "question_id": 6973},
{"snippet": "Series.explode(ignore_index=False)", "intent": "Transform each element of a list-like to a row . With arguments `ignore_index`.", "question_id": 6974},
{"snippet": "Series.factorize()", "intent": "Encode the object as an enumerated type or categorical variable .", "question_id": 6975},
{"snippet": "Series.factorize(sort=False)", "intent": "Encode the object as an enumerated type or categorical variable . With arguments `sort`.", "question_id": 6976},
{"snippet": "Series.factorize(na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) .", "question_id": 6977},
{"snippet": "Series.factorize(sort=False, na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `sort`.", "question_id": 6978},
{"snippet": "Series.factorize()", "intent": "Encode the object as an enumerated type or categorical variable .", "question_id": 6979},
{"snippet": "Series.factorize(sort=False)", "intent": "Encode the object as an enumerated type or categorical variable . With arguments `sort`.", "question_id": 6980},
{"snippet": "Series.factorize(na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) .", "question_id": 6981},
{"snippet": "Series.factorize(sort=False, na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `sort`.", "question_id": 6982},
{"snippet": "Series.factorize()", "intent": "Encode the object as an enumerated type or categorical variable .", "question_id": 6983},
{"snippet": "Series.factorize(sort=False)", "intent": "Encode the object as an enumerated type or categorical variable . With arguments `sort`.", "question_id": 6984},
{"snippet": "Series.factorize(na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) .", "question_id": 6985},
{"snippet": "Series.factorize(sort=False, na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `sort`.", "question_id": 6986},
{"snippet": "Series.ffill()", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' .", "question_id": 6987},
{"snippet": "Series.ffill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`.", "question_id": 6988},
{"snippet": "Series.ffill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`.", "question_id": 6989},
{"snippet": "Series.ffill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `limit`.", "question_id": 6990},
{"snippet": "Series.ffill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `downcast`.", "question_id": 6991},
{"snippet": "Series.ffill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `inplace`.", "question_id": 6992},
{"snippet": "Series.ffill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `limit`.", "question_id": 6993},
{"snippet": "Series.ffill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `downcast`.", "question_id": 6994},
{"snippet": "Series.ffill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `limit`.", "question_id": 6995},
{"snippet": "Series.ffill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `downcast`.", "question_id": 6996},
{"snippet": "Series.ffill()", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' .", "question_id": 6997},
{"snippet": "Series.ffill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`.", "question_id": 6998},
{"snippet": "Series.ffill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`.", "question_id": 6999},
{"snippet": "Series.ffill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `limit`.", "question_id": 7000},
{"snippet": "Series.ffill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `downcast`.", "question_id": 7001},
{"snippet": "Series.ffill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `inplace`.", "question_id": 7002},
{"snippet": "Series.ffill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `limit`.", "question_id": 7003},
{"snippet": "Series.ffill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `downcast`.", "question_id": 7004},
{"snippet": "Series.ffill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `limit`.", "question_id": 7005},
{"snippet": "Series.ffill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `downcast`.", "question_id": 7006},
{"snippet": "Series.ffill()", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' .", "question_id": 7007},
{"snippet": "Series.ffill(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`.", "question_id": 7008},
{"snippet": "Series.ffill(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`.", "question_id": 7009},
{"snippet": "Series.ffill(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `limit`.", "question_id": 7010},
{"snippet": "Series.ffill(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `downcast`.", "question_id": 7011},
{"snippet": "Series.ffill(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `inplace`.", "question_id": 7012},
{"snippet": "Series.ffill(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `limit`.", "question_id": 7013},
{"snippet": "Series.ffill(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `downcast`.", "question_id": 7014},
{"snippet": "Series.ffill(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `limit`.", "question_id": 7015},
{"snippet": "Series.ffill(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `downcast`.", "question_id": 7016},
{"snippet": "Series.fillna()", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 7017},
{"snippet": "Series.fillna(value=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 7018},
{"snippet": "Series.fillna(method=None)", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 7019},
{"snippet": "Series.fillna(axis=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `axis`.", "question_id": 7020},
{"snippet": "Series.fillna(inplace=False)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `inplace`.", "question_id": 7021},
{"snippet": "Series.fillna(limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `limit`.", "question_id": 7022},
{"snippet": "Series.fillna(downcast=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `downcast`.", "question_id": 7023},
{"snippet": "Series.fillna(value=None, method=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 7024},
{"snippet": "Series.fillna(value=None, axis=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `axis`.", "question_id": 7025},
{"snippet": "Series.fillna(value=None, inplace=False)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `inplace`.", "question_id": 7026},
{"snippet": "Series.fillna()", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 7027},
{"snippet": "Series.fillna(value=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 7028},
{"snippet": "Series.fillna(method=None)", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 7029},
{"snippet": "Series.fillna(axis=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `axis`.", "question_id": 7030},
{"snippet": "Series.fillna(inplace=False)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `inplace`.", "question_id": 7031},
{"snippet": "Series.fillna(limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `limit`.", "question_id": 7032},
{"snippet": "Series.fillna(downcast=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `downcast`.", "question_id": 7033},
{"snippet": "Series.fillna(value=None, method=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 7034},
{"snippet": "Series.fillna(value=None, axis=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `axis`.", "question_id": 7035},
{"snippet": "Series.fillna(value=None, inplace=False)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `inplace`.", "question_id": 7036},
{"snippet": "Series.fillna()", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 7037},
{"snippet": "Series.fillna(value=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 7038},
{"snippet": "Series.fillna(method=None)", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 7039},
{"snippet": "Series.fillna(axis=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `axis`.", "question_id": 7040},
{"snippet": "Series.fillna(inplace=False)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `inplace`.", "question_id": 7041},
{"snippet": "Series.fillna(limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `limit`.", "question_id": 7042},
{"snippet": "Series.fillna(downcast=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `downcast`.", "question_id": 7043},
{"snippet": "Series.fillna(value=None, method=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 7044},
{"snippet": "Series.fillna(value=None, axis=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `axis`.", "question_id": 7045},
{"snippet": "Series.fillna(value=None, inplace=False)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `inplace`.", "question_id": 7046},
{"snippet": "Series.filter()", "intent": "Subset the dataframe rows or columns according to the specified index labels .", "question_id": 7047},
{"snippet": "Series.filter(items=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7048},
{"snippet": "Series.filter(like=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7049},
{"snippet": "Series.filter(regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7050},
{"snippet": "Series.filter(axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 7051},
{"snippet": "Series.filter(items=None, like=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7052},
{"snippet": "Series.filter(items=None, regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7053},
{"snippet": "Series.filter(items=None, axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 7054},
{"snippet": "Series.filter(like=None, regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7055},
{"snippet": "Series.filter(like=None, axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 7056},
{"snippet": "Series.filter()", "intent": "Subset the dataframe rows or columns according to the specified index labels .", "question_id": 7057},
{"snippet": "Series.filter(items=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7058},
{"snippet": "Series.filter(like=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7059},
{"snippet": "Series.filter(regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7060},
{"snippet": "Series.filter(axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 7061},
{"snippet": "Series.filter(items=None, like=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7062},
{"snippet": "Series.filter(items=None, regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7063},
{"snippet": "Series.filter(items=None, axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 7064},
{"snippet": "Series.filter(like=None, regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7065},
{"snippet": "Series.filter(like=None, axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 7066},
{"snippet": "Series.filter()", "intent": "Subset the dataframe rows or columns according to the specified index labels .", "question_id": 7067},
{"snippet": "Series.filter(items=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7068},
{"snippet": "Series.filter(like=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7069},
{"snippet": "Series.filter(regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7070},
{"snippet": "Series.filter(axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 7071},
{"snippet": "Series.filter(items=None, like=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7072},
{"snippet": "Series.filter(items=None, regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7073},
{"snippet": "Series.filter(items=None, axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 7074},
{"snippet": "Series.filter(like=None, regex=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive .", "question_id": 7075},
{"snippet": "Series.filter(like=None, axis=None)", "intent": "Subset the dataframe rows or columns according to the specified index labels . The `items` , `like` , and `regex` parameters are enforced to be mutually exclusive . `axis` defaults to the info axis that is used when indexing with [ ] .", "question_id": 7076},
{"snippet": "Series.first(offset)", "intent": "Select initial periods of time series data based on a date `offset` .", "question_id": 7077},
{"snippet": "Series.first(offset)", "intent": "Select initial periods of time series data based on a date `offset` .", "question_id": 7078},
{"snippet": "Series.first(offset)", "intent": "Select initial periods of time series data based on a date `offset` .", "question_id": 7079},
{"snippet": "Series.first_valid_index()", "intent": "Return index for first non-NA value or None , if no NA value is found .", "question_id": 7080},
{"snippet": "Series.first_valid_index()", "intent": "Return index for first non-NA value or None , if no NA value is found .", "question_id": 7081},
{"snippet": "Series.first_valid_index()", "intent": "Return index for first non-NA value or None , if no NA value is found .", "question_id": 7082},
{"snippet": "Series.floordiv(other)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) .", "question_id": 7083},
{"snippet": "Series.floordiv(other, level=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . With arguments `level`.", "question_id": 7084},
{"snippet": "Series.floordiv(other, fill_value=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . Equivalent to series // other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7085},
{"snippet": "Series.floordiv(other, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . With arguments `axis`.", "question_id": 7086},
{"snippet": "Series.floordiv(other, level=None, fill_value=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . Equivalent to series // other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7087},
{"snippet": "Series.floordiv(other, level=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . With arguments `level`, `axis`.", "question_id": 7088},
{"snippet": "Series.floordiv(other, fill_value=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . Equivalent to series // other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7089},
{"snippet": "Series.floordiv(other, level=None, fill_value=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . Equivalent to series // other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7090},
{"snippet": "Series.floordiv(other)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) .", "question_id": 7091},
{"snippet": "Series.floordiv(other, level=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . With arguments `level`.", "question_id": 7092},
{"snippet": "Series.floordiv(other, fill_value=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . Equivalent to series // other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7093},
{"snippet": "Series.floordiv(other, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . With arguments `axis`.", "question_id": 7094},
{"snippet": "Series.floordiv(other, level=None, fill_value=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . Equivalent to series // other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7095},
{"snippet": "Series.floordiv(other, level=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . With arguments `level`, `axis`.", "question_id": 7096},
{"snippet": "Series.floordiv(other, fill_value=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . Equivalent to series // other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7097},
{"snippet": "Series.floordiv(other, level=None, fill_value=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . Equivalent to series // other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7098},
{"snippet": "Series.floordiv(other)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) .", "question_id": 7099},
{"snippet": "Series.floordiv(other, level=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . With arguments `level`.", "question_id": 7100},
{"snippet": "Series.floordiv(other, fill_value=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . Equivalent to series // other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7101},
{"snippet": "Series.floordiv(other, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . With arguments `axis`.", "question_id": 7102},
{"snippet": "Series.floordiv(other, level=None, fill_value=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . Equivalent to series // other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7103},
{"snippet": "Series.floordiv(other, level=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . With arguments `level`, `axis`.", "question_id": 7104},
{"snippet": "Series.floordiv(other, fill_value=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . Equivalent to series // other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7105},
{"snippet": "Series.floordiv(other, level=None, fill_value=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator floordiv ) . Equivalent to series // other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7106},
{"snippet": "Series.ge(other)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) .", "question_id": 7107},
{"snippet": "Series.ge(other, level=None)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . With arguments `level`.", "question_id": 7108},
{"snippet": "Series.ge(other, fill_value=None)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . Equivalent to series > = other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7109},
{"snippet": "Series.ge(other, axis=0)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . With arguments `axis`.", "question_id": 7110},
{"snippet": "Series.ge(other, level=None, fill_value=None)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . Equivalent to series > = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7111},
{"snippet": "Series.ge(other, level=None, axis=0)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . With arguments `level`, `axis`.", "question_id": 7112},
{"snippet": "Series.ge(other, fill_value=None, axis=0)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . Equivalent to series > = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7113},
{"snippet": "Series.ge(other, level=None, fill_value=None, axis=0)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . Equivalent to series > = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7114},
{"snippet": "Series.ge(other)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) .", "question_id": 7115},
{"snippet": "Series.ge(other, level=None)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . With arguments `level`.", "question_id": 7116},
{"snippet": "Series.ge(other, fill_value=None)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . Equivalent to series > = other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7117},
{"snippet": "Series.ge(other, axis=0)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . With arguments `axis`.", "question_id": 7118},
{"snippet": "Series.ge(other, level=None, fill_value=None)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . Equivalent to series > = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7119},
{"snippet": "Series.ge(other, level=None, axis=0)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . With arguments `level`, `axis`.", "question_id": 7120},
{"snippet": "Series.ge(other, fill_value=None, axis=0)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . Equivalent to series > = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7121},
{"snippet": "Series.ge(other, level=None, fill_value=None, axis=0)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . Equivalent to series > = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7122},
{"snippet": "Series.ge(other)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) .", "question_id": 7123},
{"snippet": "Series.ge(other, level=None)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . With arguments `level`.", "question_id": 7124},
{"snippet": "Series.ge(other, fill_value=None)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . Equivalent to series > = other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7125},
{"snippet": "Series.ge(other, axis=0)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . With arguments `axis`.", "question_id": 7126},
{"snippet": "Series.ge(other, level=None, fill_value=None)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . Equivalent to series > = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7127},
{"snippet": "Series.ge(other, level=None, axis=0)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . With arguments `level`, `axis`.", "question_id": 7128},
{"snippet": "Series.ge(other, fill_value=None, axis=0)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . Equivalent to series > = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7129},
{"snippet": "Series.ge(other, level=None, fill_value=None, axis=0)", "intent": "Return Greater than or equal to of series and `other` , element-wise ( binary operator ge ) . Equivalent to series > = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7130},
{"snippet": "Series.get(key)", "intent": "Get item from object for given `key` ( ex : DataFrame column ) .", "question_id": 7131},
{"snippet": "Series.get(key, default=None)", "intent": "Get item from object for given `key` ( ex : DataFrame column ) . Returns `default` value if not found .", "question_id": 7132},
{"snippet": "Series.get(key)", "intent": "Get item from object for given `key` ( ex : DataFrame column ) .", "question_id": 7133},
{"snippet": "Series.get(key, default=None)", "intent": "Get item from object for given `key` ( ex : DataFrame column ) . Returns `default` value if not found .", "question_id": 7134},
{"snippet": "Series.get(key)", "intent": "Get item from object for given `key` ( ex : DataFrame column ) .", "question_id": 7135},
{"snippet": "Series.get(key, default=None)", "intent": "Get item from object for given `key` ( ex : DataFrame column ) . Returns `default` value if not found .", "question_id": 7136},
{"snippet": "Series.groupby()", "intent": "Group Series using a mapper or `by` a Series of columns .", "question_id": 7137},
{"snippet": "Series.groupby(by=None)", "intent": "Group Series using a mapper or `by` a Series of columns .", "question_id": 7138},
{"snippet": "Series.groupby(axis=0)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `axis`.", "question_id": 7139},
{"snippet": "Series.groupby(level=None)", "intent": "Group Series using a mapper or `by` a Series of columns . We can groupby different levels of a hierarchical index using the `level` parameter :", "question_id": 7140},
{"snippet": "Series.groupby(as_index=True)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `as_index`.", "question_id": 7141},
{"snippet": "Series.groupby(sort=True)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `sort`.", "question_id": 7142},
{"snippet": "Series.groupby(group_keys=True)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `group_keys`.", "question_id": 7143},
{"snippet": "Series.groupby(squeeze=NoDefault.no_default)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `squeeze`.", "question_id": 7144},
{"snippet": "Series.groupby(observed=False)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `observed`.", "question_id": 7145},
{"snippet": "Series.groupby(dropna=True)", "intent": "Group Series using a mapper or `by` a Series of columns . We can also choose to include NA in group keys or not by defining `dropna` parameter , the default setting is True :", "question_id": 7146},
{"snippet": "Series.groupby()", "intent": "Group Series using a mapper or `by` a Series of columns .", "question_id": 7147},
{"snippet": "Series.groupby(by=None)", "intent": "Group Series using a mapper or `by` a Series of columns .", "question_id": 7148},
{"snippet": "Series.groupby(axis=0)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `axis`.", "question_id": 7149},
{"snippet": "Series.groupby(level=None)", "intent": "Group Series using a mapper or `by` a Series of columns . We can groupby different levels of a hierarchical index using the `level` parameter :", "question_id": 7150},
{"snippet": "Series.groupby(as_index=True)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `as_index`.", "question_id": 7151},
{"snippet": "Series.groupby(sort=True)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `sort`.", "question_id": 7152},
{"snippet": "Series.groupby(group_keys=True)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `group_keys`.", "question_id": 7153},
{"snippet": "Series.groupby(squeeze=NoDefault.no_default)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `squeeze`.", "question_id": 7154},
{"snippet": "Series.groupby(observed=False)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `observed`.", "question_id": 7155},
{"snippet": "Series.groupby(dropna=True)", "intent": "Group Series using a mapper or `by` a Series of columns . We can also choose to include NA in group keys or not by defining `dropna` parameter , the default setting is True :", "question_id": 7156},
{"snippet": "Series.groupby()", "intent": "Group Series using a mapper or `by` a Series of columns .", "question_id": 7157},
{"snippet": "Series.groupby(by=None)", "intent": "Group Series using a mapper or `by` a Series of columns .", "question_id": 7158},
{"snippet": "Series.groupby(axis=0)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `axis`.", "question_id": 7159},
{"snippet": "Series.groupby(level=None)", "intent": "Group Series using a mapper or `by` a Series of columns . We can groupby different levels of a hierarchical index using the `level` parameter :", "question_id": 7160},
{"snippet": "Series.groupby(as_index=True)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `as_index`.", "question_id": 7161},
{"snippet": "Series.groupby(sort=True)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `sort`.", "question_id": 7162},
{"snippet": "Series.groupby(group_keys=True)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `group_keys`.", "question_id": 7163},
{"snippet": "Series.groupby(squeeze=NoDefault.no_default)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `squeeze`.", "question_id": 7164},
{"snippet": "Series.groupby(observed=False)", "intent": "Group Series using a mapper or `by` a Series of columns . With arguments `observed`.", "question_id": 7165},
{"snippet": "Series.groupby(dropna=True)", "intent": "Group Series using a mapper or `by` a Series of columns . We can also choose to include NA in group keys or not by defining `dropna` parameter , the default setting is True :", "question_id": 7166},
{"snippet": "Series.gt(other)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) .", "question_id": 7167},
{"snippet": "Series.gt(other, level=None)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . With arguments `level`.", "question_id": 7168},
{"snippet": "Series.gt(other, fill_value=None)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . Equivalent to series > other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7169},
{"snippet": "Series.gt(other, axis=0)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . With arguments `axis`.", "question_id": 7170},
{"snippet": "Series.gt(other, level=None, fill_value=None)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . Equivalent to series > other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7171},
{"snippet": "Series.gt(other, level=None, axis=0)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . With arguments `level`, `axis`.", "question_id": 7172},
{"snippet": "Series.gt(other, fill_value=None, axis=0)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . Equivalent to series > other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7173},
{"snippet": "Series.gt(other, level=None, fill_value=None, axis=0)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . Equivalent to series > other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7174},
{"snippet": "Series.gt(other)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) .", "question_id": 7175},
{"snippet": "Series.gt(other, level=None)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . With arguments `level`.", "question_id": 7176},
{"snippet": "Series.gt(other, fill_value=None)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . Equivalent to series > other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7177},
{"snippet": "Series.gt(other, axis=0)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . With arguments `axis`.", "question_id": 7178},
{"snippet": "Series.gt(other, level=None, fill_value=None)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . Equivalent to series > other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7179},
{"snippet": "Series.gt(other, level=None, axis=0)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . With arguments `level`, `axis`.", "question_id": 7180},
{"snippet": "Series.gt(other, fill_value=None, axis=0)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . Equivalent to series > other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7181},
{"snippet": "Series.gt(other, level=None, fill_value=None, axis=0)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . Equivalent to series > other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7182},
{"snippet": "Series.gt(other)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) .", "question_id": 7183},
{"snippet": "Series.gt(other, level=None)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . With arguments `level`.", "question_id": 7184},
{"snippet": "Series.gt(other, fill_value=None)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . Equivalent to series > other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7185},
{"snippet": "Series.gt(other, axis=0)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . With arguments `axis`.", "question_id": 7186},
{"snippet": "Series.gt(other, level=None, fill_value=None)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . Equivalent to series > other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7187},
{"snippet": "Series.gt(other, level=None, axis=0)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . With arguments `level`, `axis`.", "question_id": 7188},
{"snippet": "Series.gt(other, fill_value=None, axis=0)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . Equivalent to series > other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7189},
{"snippet": "Series.gt(other, level=None, fill_value=None, axis=0)", "intent": "Return Greater than of series and `other` , element-wise ( binary operator gt ) . Equivalent to series > other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7190},
{"snippet": "Series.head()", "intent": "Return the first `n` rows .", "question_id": 7191},
{"snippet": "Series.head(n=5)", "intent": "Return the first `n` rows .", "question_id": 7192},
{"snippet": "Series.head()", "intent": "Return the first `n` rows .", "question_id": 7193},
{"snippet": "Series.head(n=5)", "intent": "Return the first `n` rows .", "question_id": 7194},
{"snippet": "Series.head()", "intent": "Return the first `n` rows .", "question_id": 7195},
{"snippet": "Series.head(n=5)", "intent": "Return the first `n` rows .", "question_id": 7196},
{"snippet": "Series.hist(**kwargs)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`.", "question_id": 7197},
{"snippet": "Series.hist(**kwargs, by=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `by`.", "question_id": 7198},
{"snippet": "Series.hist(**kwargs, ax=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `ax`.", "question_id": 7199},
{"snippet": "Series.hist(**kwargs, grid=True)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `grid`.", "question_id": 7200},
{"snippet": "Series.hist(**kwargs, xlabelsize=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `xlabelsize`.", "question_id": 7201},
{"snippet": "Series.hist(**kwargs, xrot=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `xrot`.", "question_id": 7202},
{"snippet": "Series.hist(**kwargs, ylabelsize=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `ylabelsize`.", "question_id": 7203},
{"snippet": "Series.hist(**kwargs, yrot=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `yrot`.", "question_id": 7204},
{"snippet": "Series.hist(**kwargs, figsize=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `figsize`.", "question_id": 7205},
{"snippet": "Series.hist(**kwargs, bins=10)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `bins`.", "question_id": 7206},
{"snippet": "Series.hist(**kwargs)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`.", "question_id": 7207},
{"snippet": "Series.hist(**kwargs, by=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `by`.", "question_id": 7208},
{"snippet": "Series.hist(**kwargs, ax=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `ax`.", "question_id": 7209},
{"snippet": "Series.hist(**kwargs, grid=True)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `grid`.", "question_id": 7210},
{"snippet": "Series.hist(**kwargs, xlabelsize=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `xlabelsize`.", "question_id": 7211},
{"snippet": "Series.hist(**kwargs, xrot=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `xrot`.", "question_id": 7212},
{"snippet": "Series.hist(**kwargs, ylabelsize=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `ylabelsize`.", "question_id": 7213},
{"snippet": "Series.hist(**kwargs, yrot=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `yrot`.", "question_id": 7214},
{"snippet": "Series.hist(**kwargs, figsize=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `figsize`.", "question_id": 7215},
{"snippet": "Series.hist(**kwargs, bins=10)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `bins`.", "question_id": 7216},
{"snippet": "Series.hist(**kwargs)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`.", "question_id": 7217},
{"snippet": "Series.hist(**kwargs, by=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `by`.", "question_id": 7218},
{"snippet": "Series.hist(**kwargs, ax=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `ax`.", "question_id": 7219},
{"snippet": "Series.hist(**kwargs, grid=True)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `grid`.", "question_id": 7220},
{"snippet": "Series.hist(**kwargs, xlabelsize=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `xlabelsize`.", "question_id": 7221},
{"snippet": "Series.hist(**kwargs, xrot=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `xrot`.", "question_id": 7222},
{"snippet": "Series.hist(**kwargs, ylabelsize=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `ylabelsize`.", "question_id": 7223},
{"snippet": "Series.hist(**kwargs, yrot=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `yrot`.", "question_id": 7224},
{"snippet": "Series.hist(**kwargs, figsize=None)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `figsize`.", "question_id": 7225},
{"snippet": "Series.hist(**kwargs, bins=10)", "intent": "Draw histogram of the input series using matplotlib . With arguments `**kwargs`, `bins`.", "question_id": 7226},
{"snippet": "pandas.Series()", "intent": "One-dimensional ndarray with axis labels ( including time series ) .", "question_id": 7227},
{"snippet": "pandas.Series(data=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Statistical methods from ndarray have been overridden to automatically exclude missing `data` ( currently represented as NaN ) .", "question_id": 7228},
{"snippet": "pandas.Series(index=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . The object supports both integer- and label-based indexing and provides a host of methods for performing operations involving the `index` .", "question_id": 7229},
{"snippet": "pandas.Series(dtype=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . With arguments `dtype`.", "question_id": 7230},
{"snippet": "pandas.Series(name=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . With arguments `name`.", "question_id": 7231},
{"snippet": "pandas.Series(copy=False)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Due to input data type the Series has a `copy` of the original data even though copy=False , so the data is unchanged .", "question_id": 7232},
{"snippet": "pandas.Series(fastpath=False)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . With arguments `fastpath`.", "question_id": 7233},
{"snippet": "pandas.Series(data=None, index=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Statistical methods from ndarray have been overridden to automatically exclude missing `data` ( currently represented as NaN ) . The object supports both integer- and label-based indexing and provides a host of methods for performing operations involving the `index` .", "question_id": 7234},
{"snippet": "pandas.Series(data=None, dtype=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Statistical methods from ndarray have been overridden to automatically exclude missing `data` ( currently represented as NaN ) . With arguments `dtype`.", "question_id": 7235},
{"snippet": "pandas.Series(data=None, name=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Statistical methods from ndarray have been overridden to automatically exclude missing `data` ( currently represented as NaN ) . With arguments `name`.", "question_id": 7236},
{"snippet": "pandas.Series()", "intent": "One-dimensional ndarray with axis labels ( including time series ) .", "question_id": 7237},
{"snippet": "pandas.Series(data=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Statistical methods from ndarray have been overridden to automatically exclude missing `data` ( currently represented as NaN ) .", "question_id": 7238},
{"snippet": "pandas.Series(index=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . The object supports both integer- and label-based indexing and provides a host of methods for performing operations involving the `index` .", "question_id": 7239},
{"snippet": "pandas.Series(dtype=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . With arguments `dtype`.", "question_id": 7240},
{"snippet": "pandas.Series(name=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . With arguments `name`.", "question_id": 7241},
{"snippet": "pandas.Series(copy=False)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Due to input data type the Series has a `copy` of the original data even though copy=False , so the data is unchanged .", "question_id": 7242},
{"snippet": "pandas.Series(fastpath=False)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . With arguments `fastpath`.", "question_id": 7243},
{"snippet": "pandas.Series(data=None, index=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Statistical methods from ndarray have been overridden to automatically exclude missing `data` ( currently represented as NaN ) . The object supports both integer- and label-based indexing and provides a host of methods for performing operations involving the `index` .", "question_id": 7244},
{"snippet": "pandas.Series(data=None, dtype=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Statistical methods from ndarray have been overridden to automatically exclude missing `data` ( currently represented as NaN ) . With arguments `dtype`.", "question_id": 7245},
{"snippet": "pandas.Series(data=None, name=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Statistical methods from ndarray have been overridden to automatically exclude missing `data` ( currently represented as NaN ) . With arguments `name`.", "question_id": 7246},
{"snippet": "pandas.Series()", "intent": "One-dimensional ndarray with axis labels ( including time series ) .", "question_id": 7247},
{"snippet": "pandas.Series(data=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Statistical methods from ndarray have been overridden to automatically exclude missing `data` ( currently represented as NaN ) .", "question_id": 7248},
{"snippet": "pandas.Series(index=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . The object supports both integer- and label-based indexing and provides a host of methods for performing operations involving the `index` .", "question_id": 7249},
{"snippet": "pandas.Series(dtype=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . With arguments `dtype`.", "question_id": 7250},
{"snippet": "pandas.Series(name=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . With arguments `name`.", "question_id": 7251},
{"snippet": "pandas.Series(copy=False)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Due to input data type the Series has a `copy` of the original data even though copy=False , so the data is unchanged .", "question_id": 7252},
{"snippet": "pandas.Series(fastpath=False)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . With arguments `fastpath`.", "question_id": 7253},
{"snippet": "pandas.Series(data=None, index=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Statistical methods from ndarray have been overridden to automatically exclude missing `data` ( currently represented as NaN ) . The object supports both integer- and label-based indexing and provides a host of methods for performing operations involving the `index` .", "question_id": 7254},
{"snippet": "pandas.Series(data=None, dtype=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Statistical methods from ndarray have been overridden to automatically exclude missing `data` ( currently represented as NaN ) . With arguments `dtype`.", "question_id": 7255},
{"snippet": "pandas.Series(data=None, name=None)", "intent": "One-dimensional ndarray with axis labels ( including time series ) . Statistical methods from ndarray have been overridden to automatically exclude missing `data` ( currently represented as NaN ) . With arguments `name`.", "question_id": 7256},
{"snippet": "Series.idxmax(*args, **kwargs)", "intent": "Return the row label of the maximum value . With arguments `*args`, `**kwargs`.", "question_id": 7257},
{"snippet": "Series.idxmax(*args, **kwargs, axis=0)", "intent": "Return the row label of the maximum value . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 7258},
{"snippet": "Series.idxmax(*args, **kwargs, skipna=True)", "intent": "Return the row label of the maximum value . If `skipna` is False and there is an NA value in the data , the function returns nan . With arguments `*args`, `**kwargs`.", "question_id": 7259},
{"snippet": "Series.idxmax(*args, **kwargs, axis=0, skipna=True)", "intent": "Return the row label of the maximum value . If `skipna` is False and there is an NA value in the data , the function returns nan . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 7260},
{"snippet": "Series.idxmax(*args, **kwargs)", "intent": "Return the row label of the maximum value . With arguments `*args`, `**kwargs`.", "question_id": 7261},
{"snippet": "Series.idxmax(*args, **kwargs, axis=0)", "intent": "Return the row label of the maximum value . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 7262},
{"snippet": "Series.idxmax(*args, **kwargs, skipna=True)", "intent": "Return the row label of the maximum value . If `skipna` is False and there is an NA value in the data , the function returns nan . With arguments `*args`, `**kwargs`.", "question_id": 7263},
{"snippet": "Series.idxmax(*args, **kwargs, axis=0, skipna=True)", "intent": "Return the row label of the maximum value . If `skipna` is False and there is an NA value in the data , the function returns nan . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 7264},
{"snippet": "Series.idxmax(*args, **kwargs)", "intent": "Return the row label of the maximum value . With arguments `*args`, `**kwargs`.", "question_id": 7265},
{"snippet": "Series.idxmax(*args, **kwargs, axis=0)", "intent": "Return the row label of the maximum value . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 7266},
{"snippet": "Series.idxmax(*args, **kwargs, skipna=True)", "intent": "Return the row label of the maximum value . If `skipna` is False and there is an NA value in the data , the function returns nan . With arguments `*args`, `**kwargs`.", "question_id": 7267},
{"snippet": "Series.idxmax(*args, **kwargs, axis=0, skipna=True)", "intent": "Return the row label of the maximum value . If `skipna` is False and there is an NA value in the data , the function returns nan . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 7268},
{"snippet": "Series.idxmin(*args, **kwargs)", "intent": "Return the row label of the minimum value . With arguments `*args`, `**kwargs`.", "question_id": 7269},
{"snippet": "Series.idxmin(*args, **kwargs, axis=0)", "intent": "Return the row label of the minimum value . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 7270},
{"snippet": "Series.idxmin(*args, **kwargs, skipna=True)", "intent": "Return the row label of the minimum value . If `skipna` is False and there is an NA value in the data , the function returns nan . With arguments `*args`, `**kwargs`.", "question_id": 7271},
{"snippet": "Series.idxmin(*args, **kwargs, axis=0, skipna=True)", "intent": "Return the row label of the minimum value . If `skipna` is False and there is an NA value in the data , the function returns nan . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 7272},
{"snippet": "Series.idxmin(*args, **kwargs)", "intent": "Return the row label of the minimum value . With arguments `*args`, `**kwargs`.", "question_id": 7273},
{"snippet": "Series.idxmin(*args, **kwargs, axis=0)", "intent": "Return the row label of the minimum value . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 7274},
{"snippet": "Series.idxmin(*args, **kwargs, skipna=True)", "intent": "Return the row label of the minimum value . If `skipna` is False and there is an NA value in the data , the function returns nan . With arguments `*args`, `**kwargs`.", "question_id": 7275},
{"snippet": "Series.idxmin(*args, **kwargs, axis=0, skipna=True)", "intent": "Return the row label of the minimum value . If `skipna` is False and there is an NA value in the data , the function returns nan . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 7276},
{"snippet": "Series.idxmin(*args, **kwargs)", "intent": "Return the row label of the minimum value . With arguments `*args`, `**kwargs`.", "question_id": 7277},
{"snippet": "Series.idxmin(*args, **kwargs, axis=0)", "intent": "Return the row label of the minimum value . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 7278},
{"snippet": "Series.idxmin(*args, **kwargs, skipna=True)", "intent": "Return the row label of the minimum value . If `skipna` is False and there is an NA value in the data , the function returns nan . With arguments `*args`, `**kwargs`.", "question_id": 7279},
{"snippet": "Series.idxmin(*args, **kwargs, axis=0, skipna=True)", "intent": "Return the row label of the minimum value . If `skipna` is False and there is an NA value in the data , the function returns nan . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 7280},
{"snippet": "Series.index", "intent": "The index (axis labels) of the Series.", "question_id": 7281},
{"snippet": "Series.index", "intent": "The index (axis labels) of the Series.", "question_id": 7282},
{"snippet": "Series.index", "intent": "The index (axis labels) of the Series.", "question_id": 7283},
{"snippet": "Series.infer_objects()", "intent": "Attempt to infer better dtypes for object columns .", "question_id": 7284},
{"snippet": "Series.infer_objects()", "intent": "Attempt to infer better dtypes for object columns .", "question_id": 7285},
{"snippet": "Series.infer_objects()", "intent": "Attempt to infer better dtypes for object columns .", "question_id": 7286},
{"snippet": "Series.interpolate(**kwargs)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 7287},
{"snippet": "Series.interpolate(**kwargs, method='linear')", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 7288},
{"snippet": "Series.interpolate(**kwargs, axis=0)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 7289},
{"snippet": "Series.interpolate(**kwargs, limit=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 7290},
{"snippet": "Series.interpolate(**kwargs, inplace=False)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `inplace`.", "question_id": 7291},
{"snippet": "Series.interpolate(**kwargs, limit_direction=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit_direction`.", "question_id": 7292},
{"snippet": "Series.interpolate(**kwargs, limit_area=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit_area`.", "question_id": 7293},
{"snippet": "Series.interpolate(**kwargs, downcast=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `downcast`.", "question_id": 7294},
{"snippet": "Series.interpolate(**kwargs, method='linear', axis=0)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 7295},
{"snippet": "Series.interpolate(**kwargs, method='linear', limit=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 7296},
{"snippet": "Series.interpolate(**kwargs)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 7297},
{"snippet": "Series.interpolate(**kwargs, method='linear')", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 7298},
{"snippet": "Series.interpolate(**kwargs, axis=0)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 7299},
{"snippet": "Series.interpolate(**kwargs, limit=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 7300},
{"snippet": "Series.interpolate(**kwargs, inplace=False)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `inplace`.", "question_id": 7301},
{"snippet": "Series.interpolate(**kwargs, limit_direction=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit_direction`.", "question_id": 7302},
{"snippet": "Series.interpolate(**kwargs, limit_area=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit_area`.", "question_id": 7303},
{"snippet": "Series.interpolate(**kwargs, downcast=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `downcast`.", "question_id": 7304},
{"snippet": "Series.interpolate(**kwargs, method='linear', axis=0)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 7305},
{"snippet": "Series.interpolate(**kwargs, method='linear', limit=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 7306},
{"snippet": "Series.interpolate(**kwargs)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 7307},
{"snippet": "Series.interpolate(**kwargs, method='linear')", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 7308},
{"snippet": "Series.interpolate(**kwargs, axis=0)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 7309},
{"snippet": "Series.interpolate(**kwargs, limit=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 7310},
{"snippet": "Series.interpolate(**kwargs, inplace=False)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `inplace`.", "question_id": 7311},
{"snippet": "Series.interpolate(**kwargs, limit_direction=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit_direction`.", "question_id": 7312},
{"snippet": "Series.interpolate(**kwargs, limit_area=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit_area`.", "question_id": 7313},
{"snippet": "Series.interpolate(**kwargs, downcast=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `downcast`.", "question_id": 7314},
{"snippet": "Series.interpolate(**kwargs, method='linear', axis=0)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 7315},
{"snippet": "Series.interpolate(**kwargs, method='linear', limit=None)", "intent": "Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 7316},
{"snippet": "Series.isin(values)", "intent": "Whether elements in Series are contained in `values` .", "question_id": 7317},
{"snippet": "Series.isin(values)", "intent": "Whether elements in Series are contained in `values` .", "question_id": 7318},
{"snippet": "Series.isin(values)", "intent": "Whether elements in Series are contained in `values` .", "question_id": 7319},
{"snippet": "Series.isna()", "intent": "Detect missing values .", "question_id": 7320},
{"snippet": "Series.isna()", "intent": "Detect missing values .", "question_id": 7321},
{"snippet": "Series.isna()", "intent": "Detect missing values .", "question_id": 7322},
{"snippet": "Series.isnull()", "intent": "Detect missing values .", "question_id": 7323},
{"snippet": "Series.isnull()", "intent": "Detect missing values .", "question_id": 7324},
{"snippet": "Series.isnull()", "intent": "Detect missing values .", "question_id": 7325},
{"snippet": "Series.item()", "intent": "Return the first element of the underlying data as a Python scalar .", "question_id": 7326},
{"snippet": "Series.item()", "intent": "Return the first element of the underlying data as a Python scalar .", "question_id": 7327},
{"snippet": "Series.item()", "intent": "Return the first element of the underlying data as a Python scalar .", "question_id": 7328},
{"snippet": "Series.items()", "intent": "Lazily iterate over ( index , value ) tuples .", "question_id": 7329},
{"snippet": "Series.items()", "intent": "Lazily iterate over ( index , value ) tuples .", "question_id": 7330},
{"snippet": "Series.items()", "intent": "Lazily iterate over ( index , value ) tuples .", "question_id": 7331},
{"snippet": "Series.iteritems()", "intent": "Lazily iterate over ( index , value ) tuples .", "question_id": 7332},
{"snippet": "Series.iteritems()", "intent": "Lazily iterate over ( index , value ) tuples .", "question_id": 7333},
{"snippet": "Series.iteritems()", "intent": "Lazily iterate over ( index , value ) tuples .", "question_id": 7334},
{"snippet": "Series.keys()", "intent": "Return alias for index .", "question_id": 7335},
{"snippet": "Series.keys()", "intent": "Return alias for index .", "question_id": 7336},
{"snippet": "Series.keys()", "intent": "Return alias for index .", "question_id": 7337},
{"snippet": "Series.kurt(**kwargs)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 7338},
{"snippet": "Series.kurt(**kwargs, axis=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 7339},
{"snippet": "Series.kurt(**kwargs, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7340},
{"snippet": "Series.kurt(**kwargs, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7341},
{"snippet": "Series.kurt(**kwargs, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7342},
{"snippet": "Series.kurt(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7343},
{"snippet": "Series.kurt(**kwargs, axis=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7344},
{"snippet": "Series.kurt(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7345},
{"snippet": "Series.kurt(**kwargs, skipna=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7346},
{"snippet": "Series.kurt(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7347},
{"snippet": "Series.kurt(**kwargs)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 7348},
{"snippet": "Series.kurt(**kwargs, axis=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 7349},
{"snippet": "Series.kurt(**kwargs, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7350},
{"snippet": "Series.kurt(**kwargs, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7351},
{"snippet": "Series.kurt(**kwargs, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7352},
{"snippet": "Series.kurt(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7353},
{"snippet": "Series.kurt(**kwargs, axis=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7354},
{"snippet": "Series.kurt(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7355},
{"snippet": "Series.kurt(**kwargs, skipna=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7356},
{"snippet": "Series.kurt(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7357},
{"snippet": "Series.kurt(**kwargs)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 7358},
{"snippet": "Series.kurt(**kwargs, axis=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 7359},
{"snippet": "Series.kurt(**kwargs, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7360},
{"snippet": "Series.kurt(**kwargs, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7361},
{"snippet": "Series.kurt(**kwargs, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7362},
{"snippet": "Series.kurt(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7363},
{"snippet": "Series.kurt(**kwargs, axis=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7364},
{"snippet": "Series.kurt(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7365},
{"snippet": "Series.kurt(**kwargs, skipna=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7366},
{"snippet": "Series.kurt(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7367},
{"snippet": "Series.kurtosis(**kwargs)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 7368},
{"snippet": "Series.kurtosis(**kwargs, axis=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 7369},
{"snippet": "Series.kurtosis(**kwargs, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7370},
{"snippet": "Series.kurtosis(**kwargs, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7371},
{"snippet": "Series.kurtosis(**kwargs, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7372},
{"snippet": "Series.kurtosis(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7373},
{"snippet": "Series.kurtosis(**kwargs, axis=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7374},
{"snippet": "Series.kurtosis(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7375},
{"snippet": "Series.kurtosis(**kwargs, skipna=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7376},
{"snippet": "Series.kurtosis(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7377},
{"snippet": "Series.kurtosis(**kwargs)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 7378},
{"snippet": "Series.kurtosis(**kwargs, axis=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 7379},
{"snippet": "Series.kurtosis(**kwargs, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7380},
{"snippet": "Series.kurtosis(**kwargs, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7381},
{"snippet": "Series.kurtosis(**kwargs, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7382},
{"snippet": "Series.kurtosis(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7383},
{"snippet": "Series.kurtosis(**kwargs, axis=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7384},
{"snippet": "Series.kurtosis(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7385},
{"snippet": "Series.kurtosis(**kwargs, skipna=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7386},
{"snippet": "Series.kurtosis(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7387},
{"snippet": "Series.kurtosis(**kwargs)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 7388},
{"snippet": "Series.kurtosis(**kwargs, axis=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`.", "question_id": 7389},
{"snippet": "Series.kurtosis(**kwargs, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7390},
{"snippet": "Series.kurtosis(**kwargs, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7391},
{"snippet": "Series.kurtosis(**kwargs, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7392},
{"snippet": "Series.kurtosis(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7393},
{"snippet": "Series.kurtosis(**kwargs, axis=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7394},
{"snippet": "Series.kurtosis(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7395},
{"snippet": "Series.kurtosis(**kwargs, skipna=None, level=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7396},
{"snippet": "Series.kurtosis(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased kurtosis over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7397},
{"snippet": "Series.last(offset)", "intent": "Select final periods of time series data based on a date `offset` .", "question_id": 7398},
{"snippet": "Series.last(offset)", "intent": "Select final periods of time series data based on a date `offset` .", "question_id": 7399},
{"snippet": "Series.last(offset)", "intent": "Select final periods of time series data based on a date `offset` .", "question_id": 7400},
{"snippet": "Series.last_valid_index()", "intent": "Return index for last non-NA value or None , if no NA value is found .", "question_id": 7401},
{"snippet": "Series.last_valid_index()", "intent": "Return index for last non-NA value or None , if no NA value is found .", "question_id": 7402},
{"snippet": "Series.last_valid_index()", "intent": "Return index for last non-NA value or None , if no NA value is found .", "question_id": 7403},
{"snippet": "Series.le(other)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) .", "question_id": 7404},
{"snippet": "Series.le(other, level=None)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . With arguments `level`.", "question_id": 7405},
{"snippet": "Series.le(other, fill_value=None)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . Equivalent to series < = other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7406},
{"snippet": "Series.le(other, axis=0)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . With arguments `axis`.", "question_id": 7407},
{"snippet": "Series.le(other, level=None, fill_value=None)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . Equivalent to series < = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7408},
{"snippet": "Series.le(other, level=None, axis=0)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . With arguments `level`, `axis`.", "question_id": 7409},
{"snippet": "Series.le(other, fill_value=None, axis=0)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . Equivalent to series < = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7410},
{"snippet": "Series.le(other, level=None, fill_value=None, axis=0)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . Equivalent to series < = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7411},
{"snippet": "Series.le(other)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) .", "question_id": 7412},
{"snippet": "Series.le(other, level=None)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . With arguments `level`.", "question_id": 7413},
{"snippet": "Series.le(other, fill_value=None)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . Equivalent to series < = other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7414},
{"snippet": "Series.le(other, axis=0)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . With arguments `axis`.", "question_id": 7415},
{"snippet": "Series.le(other, level=None, fill_value=None)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . Equivalent to series < = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7416},
{"snippet": "Series.le(other, level=None, axis=0)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . With arguments `level`, `axis`.", "question_id": 7417},
{"snippet": "Series.le(other, fill_value=None, axis=0)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . Equivalent to series < = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7418},
{"snippet": "Series.le(other, level=None, fill_value=None, axis=0)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . Equivalent to series < = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7419},
{"snippet": "Series.le(other)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) .", "question_id": 7420},
{"snippet": "Series.le(other, level=None)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . With arguments `level`.", "question_id": 7421},
{"snippet": "Series.le(other, fill_value=None)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . Equivalent to series < = other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7422},
{"snippet": "Series.le(other, axis=0)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . With arguments `axis`.", "question_id": 7423},
{"snippet": "Series.le(other, level=None, fill_value=None)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . Equivalent to series < = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7424},
{"snippet": "Series.le(other, level=None, axis=0)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . With arguments `level`, `axis`.", "question_id": 7425},
{"snippet": "Series.le(other, fill_value=None, axis=0)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . Equivalent to series < = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7426},
{"snippet": "Series.le(other, level=None, fill_value=None, axis=0)", "intent": "Return Less than or equal to of series and `other` , element-wise ( binary operator le ) . Equivalent to series < = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7427},
{"snippet": "Series.lt(other)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) .", "question_id": 7428},
{"snippet": "Series.lt(other, level=None)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . With arguments `level`.", "question_id": 7429},
{"snippet": "Series.lt(other, fill_value=None)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . Equivalent to series < other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7430},
{"snippet": "Series.lt(other, axis=0)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . With arguments `axis`.", "question_id": 7431},
{"snippet": "Series.lt(other, level=None, fill_value=None)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . Equivalent to series < other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7432},
{"snippet": "Series.lt(other, level=None, axis=0)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . With arguments `level`, `axis`.", "question_id": 7433},
{"snippet": "Series.lt(other, fill_value=None, axis=0)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . Equivalent to series < other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7434},
{"snippet": "Series.lt(other, level=None, fill_value=None, axis=0)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . Equivalent to series < other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7435},
{"snippet": "Series.lt(other)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) .", "question_id": 7436},
{"snippet": "Series.lt(other, level=None)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . With arguments `level`.", "question_id": 7437},
{"snippet": "Series.lt(other, fill_value=None)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . Equivalent to series < other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7438},
{"snippet": "Series.lt(other, axis=0)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . With arguments `axis`.", "question_id": 7439},
{"snippet": "Series.lt(other, level=None, fill_value=None)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . Equivalent to series < other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7440},
{"snippet": "Series.lt(other, level=None, axis=0)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . With arguments `level`, `axis`.", "question_id": 7441},
{"snippet": "Series.lt(other, fill_value=None, axis=0)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . Equivalent to series < other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7442},
{"snippet": "Series.lt(other, level=None, fill_value=None, axis=0)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . Equivalent to series < other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7443},
{"snippet": "Series.lt(other)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) .", "question_id": 7444},
{"snippet": "Series.lt(other, level=None)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . With arguments `level`.", "question_id": 7445},
{"snippet": "Series.lt(other, fill_value=None)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . Equivalent to series < other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7446},
{"snippet": "Series.lt(other, axis=0)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . With arguments `axis`.", "question_id": 7447},
{"snippet": "Series.lt(other, level=None, fill_value=None)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . Equivalent to series < other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7448},
{"snippet": "Series.lt(other, level=None, axis=0)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . With arguments `level`, `axis`.", "question_id": 7449},
{"snippet": "Series.lt(other, fill_value=None, axis=0)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . Equivalent to series < other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7450},
{"snippet": "Series.lt(other, level=None, fill_value=None, axis=0)", "intent": "Return Less than of series and `other` , element-wise ( binary operator lt ) . Equivalent to series < other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7451},
{"snippet": "Series.mad()", "intent": "Return the mean absolute deviation of the values over the requested `axis` .", "question_id": 7452},
{"snippet": "Series.mad(axis=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` .", "question_id": 7453},
{"snippet": "Series.mad(skipna=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`.", "question_id": 7454},
{"snippet": "Series.mad(level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `level`.", "question_id": 7455},
{"snippet": "Series.mad(axis=None, skipna=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`.", "question_id": 7456},
{"snippet": "Series.mad(axis=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `level`.", "question_id": 7457},
{"snippet": "Series.mad(skipna=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`, `level`.", "question_id": 7458},
{"snippet": "Series.mad(axis=None, skipna=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`, `level`.", "question_id": 7459},
{"snippet": "Series.mad()", "intent": "Return the mean absolute deviation of the values over the requested `axis` .", "question_id": 7460},
{"snippet": "Series.mad(axis=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` .", "question_id": 7461},
{"snippet": "Series.mad(skipna=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`.", "question_id": 7462},
{"snippet": "Series.mad(level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `level`.", "question_id": 7463},
{"snippet": "Series.mad(axis=None, skipna=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`.", "question_id": 7464},
{"snippet": "Series.mad(axis=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `level`.", "question_id": 7465},
{"snippet": "Series.mad(skipna=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`, `level`.", "question_id": 7466},
{"snippet": "Series.mad(axis=None, skipna=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`, `level`.", "question_id": 7467},
{"snippet": "Series.mad()", "intent": "Return the mean absolute deviation of the values over the requested `axis` .", "question_id": 7468},
{"snippet": "Series.mad(axis=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` .", "question_id": 7469},
{"snippet": "Series.mad(skipna=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`.", "question_id": 7470},
{"snippet": "Series.mad(level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `level`.", "question_id": 7471},
{"snippet": "Series.mad(axis=None, skipna=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`.", "question_id": 7472},
{"snippet": "Series.mad(axis=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `level`.", "question_id": 7473},
{"snippet": "Series.mad(skipna=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`, `level`.", "question_id": 7474},
{"snippet": "Series.mad(axis=None, skipna=None, level=None)", "intent": "Return the mean absolute deviation of the values over the requested `axis` . With arguments `skipna`, `level`.", "question_id": 7475},
{"snippet": "Series.map(arg)", "intent": "Map values of Series according to input correspondence . When `arg` is a dictionary , values in Series that are not in the dictionary ( as keys ) are converted to NaN .", "question_id": 7476},
{"snippet": "Series.map(arg, na_action=None)", "intent": "Map values of Series according to input correspondence . When `arg` is a dictionary , values in Series that are not in the dictionary ( as keys ) are converted to NaN . With arguments `na_action`.", "question_id": 7477},
{"snippet": "Series.map(arg)", "intent": "Map values of Series according to input correspondence . When `arg` is a dictionary , values in Series that are not in the dictionary ( as keys ) are converted to NaN .", "question_id": 7478},
{"snippet": "Series.map(arg, na_action=None)", "intent": "Map values of Series according to input correspondence . When `arg` is a dictionary , values in Series that are not in the dictionary ( as keys ) are converted to NaN . With arguments `na_action`.", "question_id": 7479},
{"snippet": "Series.map(arg)", "intent": "Map values of Series according to input correspondence . When `arg` is a dictionary , values in Series that are not in the dictionary ( as keys ) are converted to NaN .", "question_id": 7480},
{"snippet": "Series.map(arg, na_action=None)", "intent": "Map values of Series according to input correspondence . When `arg` is a dictionary , values in Series that are not in the dictionary ( as keys ) are converted to NaN . With arguments `na_action`.", "question_id": 7481},
{"snippet": "Series.mask(cond)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 7482},
{"snippet": "Series.mask(cond, other=nan)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 7483},
{"snippet": "Series.mask(cond, inplace=False)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 7484},
{"snippet": "Series.mask(cond, axis=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 7485},
{"snippet": "Series.mask(cond, level=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 7486},
{"snippet": "Series.mask(cond, errors='raise')", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `errors`.", "question_id": 7487},
{"snippet": "Series.mask(cond, try_cast=NoDefault.no_default)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `try_cast`.", "question_id": 7488},
{"snippet": "Series.mask(cond, other=nan, inplace=False)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 7489},
{"snippet": "Series.mask(cond, other=nan, axis=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 7490},
{"snippet": "Series.mask(cond, other=nan, level=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 7491},
{"snippet": "Series.mask(cond)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 7492},
{"snippet": "Series.mask(cond, other=nan)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 7493},
{"snippet": "Series.mask(cond, inplace=False)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 7494},
{"snippet": "Series.mask(cond, axis=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 7495},
{"snippet": "Series.mask(cond, level=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 7496},
{"snippet": "Series.mask(cond, errors='raise')", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `errors`.", "question_id": 7497},
{"snippet": "Series.mask(cond, try_cast=NoDefault.no_default)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `try_cast`.", "question_id": 7498},
{"snippet": "Series.mask(cond, other=nan, inplace=False)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 7499},
{"snippet": "Series.mask(cond, other=nan, axis=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 7500},
{"snippet": "Series.mask(cond, other=nan, level=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 7501},
{"snippet": "Series.mask(cond)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 7502},
{"snippet": "Series.mask(cond, other=nan)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 7503},
{"snippet": "Series.mask(cond, inplace=False)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 7504},
{"snippet": "Series.mask(cond, axis=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 7505},
{"snippet": "Series.mask(cond, level=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 7506},
{"snippet": "Series.mask(cond, errors='raise')", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `errors`.", "question_id": 7507},
{"snippet": "Series.mask(cond, try_cast=NoDefault.no_default)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `try_cast`.", "question_id": 7508},
{"snippet": "Series.mask(cond, other=nan, inplace=False)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 7509},
{"snippet": "Series.mask(cond, other=nan, axis=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 7510},
{"snippet": "Series.mask(cond, other=nan, level=None)", "intent": "Replace values where the condition is True . For each element in the calling DataFrame , if `cond` is False the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 7511},
{"snippet": "Series.max(**kwargs)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7512},
{"snippet": "Series.max(**kwargs, axis=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7513},
{"snippet": "Series.max(**kwargs, skipna=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7514},
{"snippet": "Series.max(**kwargs, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7515},
{"snippet": "Series.max(**kwargs, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7516},
{"snippet": "Series.max(**kwargs, axis=None, skipna=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7517},
{"snippet": "Series.max(**kwargs, axis=None, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7518},
{"snippet": "Series.max(**kwargs, axis=None, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7519},
{"snippet": "Series.max(**kwargs, skipna=None, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7520},
{"snippet": "Series.max(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7521},
{"snippet": "Series.max(**kwargs)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7522},
{"snippet": "Series.max(**kwargs, axis=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7523},
{"snippet": "Series.max(**kwargs, skipna=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7524},
{"snippet": "Series.max(**kwargs, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7525},
{"snippet": "Series.max(**kwargs, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7526},
{"snippet": "Series.max(**kwargs, axis=None, skipna=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7527},
{"snippet": "Series.max(**kwargs, axis=None, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7528},
{"snippet": "Series.max(**kwargs, axis=None, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7529},
{"snippet": "Series.max(**kwargs, skipna=None, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7530},
{"snippet": "Series.max(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7531},
{"snippet": "Series.max(**kwargs)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7532},
{"snippet": "Series.max(**kwargs, axis=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7533},
{"snippet": "Series.max(**kwargs, skipna=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7534},
{"snippet": "Series.max(**kwargs, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7535},
{"snippet": "Series.max(**kwargs, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7536},
{"snippet": "Series.max(**kwargs, axis=None, skipna=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7537},
{"snippet": "Series.max(**kwargs, axis=None, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7538},
{"snippet": "Series.max(**kwargs, axis=None, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7539},
{"snippet": "Series.max(**kwargs, skipna=None, level=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7540},
{"snippet": "Series.max(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the maximum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7541},
{"snippet": "Series.mean(**kwargs)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7542},
{"snippet": "Series.mean(**kwargs, axis=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7543},
{"snippet": "Series.mean(**kwargs, skipna=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7544},
{"snippet": "Series.mean(**kwargs, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7545},
{"snippet": "Series.mean(**kwargs, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7546},
{"snippet": "Series.mean(**kwargs, axis=None, skipna=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7547},
{"snippet": "Series.mean(**kwargs, axis=None, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7548},
{"snippet": "Series.mean(**kwargs, axis=None, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7549},
{"snippet": "Series.mean(**kwargs, skipna=None, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7550},
{"snippet": "Series.mean(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7551},
{"snippet": "Series.mean(**kwargs)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7552},
{"snippet": "Series.mean(**kwargs, axis=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7553},
{"snippet": "Series.mean(**kwargs, skipna=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7554},
{"snippet": "Series.mean(**kwargs, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7555},
{"snippet": "Series.mean(**kwargs, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7556},
{"snippet": "Series.mean(**kwargs, axis=None, skipna=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7557},
{"snippet": "Series.mean(**kwargs, axis=None, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7558},
{"snippet": "Series.mean(**kwargs, axis=None, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7559},
{"snippet": "Series.mean(**kwargs, skipna=None, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7560},
{"snippet": "Series.mean(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7561},
{"snippet": "Series.mean(**kwargs)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7562},
{"snippet": "Series.mean(**kwargs, axis=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7563},
{"snippet": "Series.mean(**kwargs, skipna=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7564},
{"snippet": "Series.mean(**kwargs, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7565},
{"snippet": "Series.mean(**kwargs, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7566},
{"snippet": "Series.mean(**kwargs, axis=None, skipna=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7567},
{"snippet": "Series.mean(**kwargs, axis=None, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7568},
{"snippet": "Series.mean(**kwargs, axis=None, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7569},
{"snippet": "Series.mean(**kwargs, skipna=None, level=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7570},
{"snippet": "Series.mean(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the mean of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7571},
{"snippet": "Series.median(**kwargs)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7572},
{"snippet": "Series.median(**kwargs, axis=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7573},
{"snippet": "Series.median(**kwargs, skipna=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7574},
{"snippet": "Series.median(**kwargs, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7575},
{"snippet": "Series.median(**kwargs, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7576},
{"snippet": "Series.median(**kwargs, axis=None, skipna=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7577},
{"snippet": "Series.median(**kwargs, axis=None, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7578},
{"snippet": "Series.median(**kwargs, axis=None, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7579},
{"snippet": "Series.median(**kwargs, skipna=None, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7580},
{"snippet": "Series.median(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7581},
{"snippet": "Series.median(**kwargs)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7582},
{"snippet": "Series.median(**kwargs, axis=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7583},
{"snippet": "Series.median(**kwargs, skipna=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7584},
{"snippet": "Series.median(**kwargs, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7585},
{"snippet": "Series.median(**kwargs, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7586},
{"snippet": "Series.median(**kwargs, axis=None, skipna=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7587},
{"snippet": "Series.median(**kwargs, axis=None, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7588},
{"snippet": "Series.median(**kwargs, axis=None, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7589},
{"snippet": "Series.median(**kwargs, skipna=None, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7590},
{"snippet": "Series.median(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7591},
{"snippet": "Series.median(**kwargs)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7592},
{"snippet": "Series.median(**kwargs, axis=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7593},
{"snippet": "Series.median(**kwargs, skipna=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7594},
{"snippet": "Series.median(**kwargs, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7595},
{"snippet": "Series.median(**kwargs, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7596},
{"snippet": "Series.median(**kwargs, axis=None, skipna=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7597},
{"snippet": "Series.median(**kwargs, axis=None, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7598},
{"snippet": "Series.median(**kwargs, axis=None, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7599},
{"snippet": "Series.median(**kwargs, skipna=None, level=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7600},
{"snippet": "Series.median(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the median of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7601},
{"snippet": "Series.memory_usage()", "intent": "Return the memory usage of the Series .", "question_id": 7602},
{"snippet": "Series.memory_usage(index=True)", "intent": "Return the memory usage of the Series . The memory usage can optionally include the contribution of the `index` and of elements of object dtype .", "question_id": 7603},
{"snippet": "Series.memory_usage(deep=False)", "intent": "Return the memory usage of the Series . With arguments `deep`.", "question_id": 7604},
{"snippet": "Series.memory_usage(index=True, deep=False)", "intent": "Return the memory usage of the Series . The memory usage can optionally include the contribution of the `index` and of elements of object dtype . With arguments `deep`.", "question_id": 7605},
{"snippet": "Series.memory_usage()", "intent": "Return the memory usage of the Series .", "question_id": 7606},
{"snippet": "Series.memory_usage(index=True)", "intent": "Return the memory usage of the Series . The memory usage can optionally include the contribution of the `index` and of elements of object dtype .", "question_id": 7607},
{"snippet": "Series.memory_usage(deep=False)", "intent": "Return the memory usage of the Series . With arguments `deep`.", "question_id": 7608},
{"snippet": "Series.memory_usage(index=True, deep=False)", "intent": "Return the memory usage of the Series . The memory usage can optionally include the contribution of the `index` and of elements of object dtype . With arguments `deep`.", "question_id": 7609},
{"snippet": "Series.memory_usage()", "intent": "Return the memory usage of the Series .", "question_id": 7610},
{"snippet": "Series.memory_usage(index=True)", "intent": "Return the memory usage of the Series . The memory usage can optionally include the contribution of the `index` and of elements of object dtype .", "question_id": 7611},
{"snippet": "Series.memory_usage(deep=False)", "intent": "Return the memory usage of the Series . With arguments `deep`.", "question_id": 7612},
{"snippet": "Series.memory_usage(index=True, deep=False)", "intent": "Return the memory usage of the Series . The memory usage can optionally include the contribution of the `index` and of elements of object dtype . With arguments `deep`.", "question_id": 7613},
{"snippet": "Series.min(**kwargs)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7614},
{"snippet": "Series.min(**kwargs, axis=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7615},
{"snippet": "Series.min(**kwargs, skipna=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7616},
{"snippet": "Series.min(**kwargs, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7617},
{"snippet": "Series.min(**kwargs, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7618},
{"snippet": "Series.min(**kwargs, axis=None, skipna=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7619},
{"snippet": "Series.min(**kwargs, axis=None, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7620},
{"snippet": "Series.min(**kwargs, axis=None, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7621},
{"snippet": "Series.min(**kwargs, skipna=None, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7622},
{"snippet": "Series.min(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7623},
{"snippet": "Series.min(**kwargs)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7624},
{"snippet": "Series.min(**kwargs, axis=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7625},
{"snippet": "Series.min(**kwargs, skipna=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7626},
{"snippet": "Series.min(**kwargs, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7627},
{"snippet": "Series.min(**kwargs, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7628},
{"snippet": "Series.min(**kwargs, axis=None, skipna=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7629},
{"snippet": "Series.min(**kwargs, axis=None, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7630},
{"snippet": "Series.min(**kwargs, axis=None, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7631},
{"snippet": "Series.min(**kwargs, skipna=None, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7632},
{"snippet": "Series.min(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7633},
{"snippet": "Series.min(**kwargs)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7634},
{"snippet": "Series.min(**kwargs, axis=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7635},
{"snippet": "Series.min(**kwargs, skipna=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7636},
{"snippet": "Series.min(**kwargs, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7637},
{"snippet": "Series.min(**kwargs, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7638},
{"snippet": "Series.min(**kwargs, axis=None, skipna=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 7639},
{"snippet": "Series.min(**kwargs, axis=None, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7640},
{"snippet": "Series.min(**kwargs, axis=None, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7641},
{"snippet": "Series.min(**kwargs, skipna=None, level=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 7642},
{"snippet": "Series.min(**kwargs, skipna=None, numeric_only=None)", "intent": "Return the minimum of the values over the requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 7643},
{"snippet": "Series.mod(other)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) .", "question_id": 7644},
{"snippet": "Series.mod(other, level=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . With arguments `level`.", "question_id": 7645},
{"snippet": "Series.mod(other, fill_value=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . Equivalent to series % other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7646},
{"snippet": "Series.mod(other, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . With arguments `axis`.", "question_id": 7647},
{"snippet": "Series.mod(other, level=None, fill_value=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . Equivalent to series % other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7648},
{"snippet": "Series.mod(other, level=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . With arguments `level`, `axis`.", "question_id": 7649},
{"snippet": "Series.mod(other, fill_value=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . Equivalent to series % other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7650},
{"snippet": "Series.mod(other, level=None, fill_value=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . Equivalent to series % other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7651},
{"snippet": "Series.mod(other)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) .", "question_id": 7652},
{"snippet": "Series.mod(other, level=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . With arguments `level`.", "question_id": 7653},
{"snippet": "Series.mod(other, fill_value=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . Equivalent to series % other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7654},
{"snippet": "Series.mod(other, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . With arguments `axis`.", "question_id": 7655},
{"snippet": "Series.mod(other, level=None, fill_value=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . Equivalent to series % other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7656},
{"snippet": "Series.mod(other, level=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . With arguments `level`, `axis`.", "question_id": 7657},
{"snippet": "Series.mod(other, fill_value=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . Equivalent to series % other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7658},
{"snippet": "Series.mod(other, level=None, fill_value=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . Equivalent to series % other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7659},
{"snippet": "Series.mod(other)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) .", "question_id": 7660},
{"snippet": "Series.mod(other, level=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . With arguments `level`.", "question_id": 7661},
{"snippet": "Series.mod(other, fill_value=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . Equivalent to series % other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7662},
{"snippet": "Series.mod(other, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . With arguments `axis`.", "question_id": 7663},
{"snippet": "Series.mod(other, level=None, fill_value=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . Equivalent to series % other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7664},
{"snippet": "Series.mod(other, level=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . With arguments `level`, `axis`.", "question_id": 7665},
{"snippet": "Series.mod(other, fill_value=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . Equivalent to series % other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7666},
{"snippet": "Series.mod(other, level=None, fill_value=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator mod ) . Equivalent to series % other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7667},
{"snippet": "Series.mode()", "intent": "Return the mode ( s ) of the Series .", "question_id": 7668},
{"snippet": "Series.mode(dropna=True)", "intent": "Return the mode ( s ) of the Series . With arguments `dropna`.", "question_id": 7669},
{"snippet": "Series.mode()", "intent": "Return the mode ( s ) of the Series .", "question_id": 7670},
{"snippet": "Series.mode(dropna=True)", "intent": "Return the mode ( s ) of the Series . With arguments `dropna`.", "question_id": 7671},
{"snippet": "Series.mode()", "intent": "Return the mode ( s ) of the Series .", "question_id": 7672},
{"snippet": "Series.mode(dropna=True)", "intent": "Return the mode ( s ) of the Series . With arguments `dropna`.", "question_id": 7673},
{"snippet": "Series.mul(other)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) .", "question_id": 7674},
{"snippet": "Series.mul(other, level=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `level`.", "question_id": 7675},
{"snippet": "Series.mul(other, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7676},
{"snippet": "Series.mul(other, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `axis`.", "question_id": 7677},
{"snippet": "Series.mul(other, level=None, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7678},
{"snippet": "Series.mul(other, level=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `level`, `axis`.", "question_id": 7679},
{"snippet": "Series.mul(other, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7680},
{"snippet": "Series.mul(other, level=None, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7681},
{"snippet": "Series.mul(other)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) .", "question_id": 7682},
{"snippet": "Series.mul(other, level=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `level`.", "question_id": 7683},
{"snippet": "Series.mul(other, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7684},
{"snippet": "Series.mul(other, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `axis`.", "question_id": 7685},
{"snippet": "Series.mul(other, level=None, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7686},
{"snippet": "Series.mul(other, level=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `level`, `axis`.", "question_id": 7687},
{"snippet": "Series.mul(other, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7688},
{"snippet": "Series.mul(other, level=None, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7689},
{"snippet": "Series.mul(other)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) .", "question_id": 7690},
{"snippet": "Series.mul(other, level=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `level`.", "question_id": 7691},
{"snippet": "Series.mul(other, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7692},
{"snippet": "Series.mul(other, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `axis`.", "question_id": 7693},
{"snippet": "Series.mul(other, level=None, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7694},
{"snippet": "Series.mul(other, level=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `level`, `axis`.", "question_id": 7695},
{"snippet": "Series.mul(other, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7696},
{"snippet": "Series.mul(other, level=None, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7697},
{"snippet": "Series.multiply(other)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) .", "question_id": 7698},
{"snippet": "Series.multiply(other, level=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `level`.", "question_id": 7699},
{"snippet": "Series.multiply(other, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7700},
{"snippet": "Series.multiply(other, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `axis`.", "question_id": 7701},
{"snippet": "Series.multiply(other, level=None, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7702},
{"snippet": "Series.multiply(other, level=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `level`, `axis`.", "question_id": 7703},
{"snippet": "Series.multiply(other, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7704},
{"snippet": "Series.multiply(other, level=None, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7705},
{"snippet": "Series.multiply(other)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) .", "question_id": 7706},
{"snippet": "Series.multiply(other, level=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `level`.", "question_id": 7707},
{"snippet": "Series.multiply(other, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7708},
{"snippet": "Series.multiply(other, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `axis`.", "question_id": 7709},
{"snippet": "Series.multiply(other, level=None, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7710},
{"snippet": "Series.multiply(other, level=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `level`, `axis`.", "question_id": 7711},
{"snippet": "Series.multiply(other, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7712},
{"snippet": "Series.multiply(other, level=None, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7713},
{"snippet": "Series.multiply(other)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) .", "question_id": 7714},
{"snippet": "Series.multiply(other, level=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `level`.", "question_id": 7715},
{"snippet": "Series.multiply(other, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7716},
{"snippet": "Series.multiply(other, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `axis`.", "question_id": 7717},
{"snippet": "Series.multiply(other, level=None, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7718},
{"snippet": "Series.multiply(other, level=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . With arguments `level`, `axis`.", "question_id": 7719},
{"snippet": "Series.multiply(other, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7720},
{"snippet": "Series.multiply(other, level=None, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator mul ) . Equivalent to series * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7721},
{"snippet": "Series.ne(other)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) .", "question_id": 7722},
{"snippet": "Series.ne(other, level=None)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . With arguments `level`.", "question_id": 7723},
{"snippet": "Series.ne(other, fill_value=None)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . Equivalent to series ! = other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7724},
{"snippet": "Series.ne(other, axis=0)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . With arguments `axis`.", "question_id": 7725},
{"snippet": "Series.ne(other, level=None, fill_value=None)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . Equivalent to series ! = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7726},
{"snippet": "Series.ne(other, level=None, axis=0)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . With arguments `level`, `axis`.", "question_id": 7727},
{"snippet": "Series.ne(other, fill_value=None, axis=0)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . Equivalent to series ! = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7728},
{"snippet": "Series.ne(other, level=None, fill_value=None, axis=0)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . Equivalent to series ! = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7729},
{"snippet": "Series.ne(other)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) .", "question_id": 7730},
{"snippet": "Series.ne(other, level=None)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . With arguments `level`.", "question_id": 7731},
{"snippet": "Series.ne(other, fill_value=None)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . Equivalent to series ! = other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7732},
{"snippet": "Series.ne(other, axis=0)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . With arguments `axis`.", "question_id": 7733},
{"snippet": "Series.ne(other, level=None, fill_value=None)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . Equivalent to series ! = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7734},
{"snippet": "Series.ne(other, level=None, axis=0)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . With arguments `level`, `axis`.", "question_id": 7735},
{"snippet": "Series.ne(other, fill_value=None, axis=0)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . Equivalent to series ! = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7736},
{"snippet": "Series.ne(other, level=None, fill_value=None, axis=0)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . Equivalent to series ! = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7737},
{"snippet": "Series.ne(other)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) .", "question_id": 7738},
{"snippet": "Series.ne(other, level=None)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . With arguments `level`.", "question_id": 7739},
{"snippet": "Series.ne(other, fill_value=None)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . Equivalent to series ! = other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7740},
{"snippet": "Series.ne(other, axis=0)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . With arguments `axis`.", "question_id": 7741},
{"snippet": "Series.ne(other, level=None, fill_value=None)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . Equivalent to series ! = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7742},
{"snippet": "Series.ne(other, level=None, axis=0)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . With arguments `level`, `axis`.", "question_id": 7743},
{"snippet": "Series.ne(other, fill_value=None, axis=0)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . Equivalent to series ! = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7744},
{"snippet": "Series.ne(other, level=None, fill_value=None, axis=0)", "intent": "Return Not equal to of series and `other` , element-wise ( binary operator ne ) . Equivalent to series ! = other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7745},
{"snippet": "Series.nlargest()", "intent": "Return the largest `n` elements .", "question_id": 7746},
{"snippet": "Series.nlargest(n=5)", "intent": "Return the largest `n` elements .", "question_id": 7747},
{"snippet": "Series.nlargest(keep='first')", "intent": "Return the largest `n` elements . Default `keep` value is \u2018 first \u2019 so Malta will be kept .", "question_id": 7748},
{"snippet": "Series.nlargest(n=5, keep='first')", "intent": "Return the largest `n` elements . Default `keep` value is \u2018 first \u2019 so Malta will be kept .", "question_id": 7749},
{"snippet": "Series.nlargest()", "intent": "Return the largest `n` elements .", "question_id": 7750},
{"snippet": "Series.nlargest(n=5)", "intent": "Return the largest `n` elements .", "question_id": 7751},
{"snippet": "Series.nlargest(keep='first')", "intent": "Return the largest `n` elements . Default `keep` value is \u2018 first \u2019 so Malta will be kept .", "question_id": 7752},
{"snippet": "Series.nlargest(n=5, keep='first')", "intent": "Return the largest `n` elements . Default `keep` value is \u2018 first \u2019 so Malta will be kept .", "question_id": 7753},
{"snippet": "Series.nlargest()", "intent": "Return the largest `n` elements .", "question_id": 7754},
{"snippet": "Series.nlargest(n=5)", "intent": "Return the largest `n` elements .", "question_id": 7755},
{"snippet": "Series.nlargest(keep='first')", "intent": "Return the largest `n` elements . Default `keep` value is \u2018 first \u2019 so Malta will be kept .", "question_id": 7756},
{"snippet": "Series.nlargest(n=5, keep='first')", "intent": "Return the largest `n` elements . Default `keep` value is \u2018 first \u2019 so Malta will be kept .", "question_id": 7757},
{"snippet": "Series.notna()", "intent": "Detect existing ( non-missing ) values .", "question_id": 7758},
{"snippet": "Series.notna()", "intent": "Detect existing ( non-missing ) values .", "question_id": 7759},
{"snippet": "Series.notna()", "intent": "Detect existing ( non-missing ) values .", "question_id": 7760},
{"snippet": "Series.notnull()", "intent": "Detect existing ( non-missing ) values .", "question_id": 7761},
{"snippet": "Series.notnull()", "intent": "Detect existing ( non-missing ) values .", "question_id": 7762},
{"snippet": "Series.notnull()", "intent": "Detect existing ( non-missing ) values .", "question_id": 7763},
{"snippet": "Series.nsmallest()", "intent": "Return the smallest `n` elements .", "question_id": 7764},
{"snippet": "Series.nsmallest(n=5)", "intent": "Return the smallest `n` elements .", "question_id": 7765},
{"snippet": "Series.nsmallest(keep='first')", "intent": "Return the smallest `n` elements . Default `keep` value is \u2018 first \u2019 so Nauru and Tuvalu will be kept .", "question_id": 7766},
{"snippet": "Series.nsmallest(n=5, keep='first')", "intent": "Return the smallest `n` elements . Default `keep` value is \u2018 first \u2019 so Nauru and Tuvalu will be kept .", "question_id": 7767},
{"snippet": "Series.nsmallest()", "intent": "Return the smallest `n` elements .", "question_id": 7768},
{"snippet": "Series.nsmallest(n=5)", "intent": "Return the smallest `n` elements .", "question_id": 7769},
{"snippet": "Series.nsmallest(keep='first')", "intent": "Return the smallest `n` elements . Default `keep` value is \u2018 first \u2019 so Nauru and Tuvalu will be kept .", "question_id": 7770},
{"snippet": "Series.nsmallest(n=5, keep='first')", "intent": "Return the smallest `n` elements . Default `keep` value is \u2018 first \u2019 so Nauru and Tuvalu will be kept .", "question_id": 7771},
{"snippet": "Series.nsmallest()", "intent": "Return the smallest `n` elements .", "question_id": 7772},
{"snippet": "Series.nsmallest(n=5)", "intent": "Return the smallest `n` elements .", "question_id": 7773},
{"snippet": "Series.nsmallest(keep='first')", "intent": "Return the smallest `n` elements . Default `keep` value is \u2018 first \u2019 so Nauru and Tuvalu will be kept .", "question_id": 7774},
{"snippet": "Series.nsmallest(n=5, keep='first')", "intent": "Return the smallest `n` elements . Default `keep` value is \u2018 first \u2019 so Nauru and Tuvalu will be kept .", "question_id": 7775},
{"snippet": "Series.nunique()", "intent": "Return number of unique elements in the object .", "question_id": 7776},
{"snippet": "Series.nunique(dropna=True)", "intent": "Return number of unique elements in the object . With arguments `dropna`.", "question_id": 7777},
{"snippet": "Series.nunique()", "intent": "Return number of unique elements in the object .", "question_id": 7778},
{"snippet": "Series.nunique(dropna=True)", "intent": "Return number of unique elements in the object . With arguments `dropna`.", "question_id": 7779},
{"snippet": "Series.nunique()", "intent": "Return number of unique elements in the object .", "question_id": 7780},
{"snippet": "Series.nunique(dropna=True)", "intent": "Return number of unique elements in the object . With arguments `dropna`.", "question_id": 7781},
{"snippet": "Series.pad()", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' .", "question_id": 7782},
{"snippet": "Series.pad(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`.", "question_id": 7783},
{"snippet": "Series.pad(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`.", "question_id": 7784},
{"snippet": "Series.pad(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `limit`.", "question_id": 7785},
{"snippet": "Series.pad(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `downcast`.", "question_id": 7786},
{"snippet": "Series.pad(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `inplace`.", "question_id": 7787},
{"snippet": "Series.pad(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `limit`.", "question_id": 7788},
{"snippet": "Series.pad(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `downcast`.", "question_id": 7789},
{"snippet": "Series.pad(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `limit`.", "question_id": 7790},
{"snippet": "Series.pad(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `downcast`.", "question_id": 7791},
{"snippet": "Series.pad()", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' .", "question_id": 7792},
{"snippet": "Series.pad(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`.", "question_id": 7793},
{"snippet": "Series.pad(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`.", "question_id": 7794},
{"snippet": "Series.pad(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `limit`.", "question_id": 7795},
{"snippet": "Series.pad(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `downcast`.", "question_id": 7796},
{"snippet": "Series.pad(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `inplace`.", "question_id": 7797},
{"snippet": "Series.pad(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `limit`.", "question_id": 7798},
{"snippet": "Series.pad(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `downcast`.", "question_id": 7799},
{"snippet": "Series.pad(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `limit`.", "question_id": 7800},
{"snippet": "Series.pad(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `downcast`.", "question_id": 7801},
{"snippet": "Series.pad()", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' .", "question_id": 7802},
{"snippet": "Series.pad(axis=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`.", "question_id": 7803},
{"snippet": "Series.pad(inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`.", "question_id": 7804},
{"snippet": "Series.pad(limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `limit`.", "question_id": 7805},
{"snippet": "Series.pad(downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `downcast`.", "question_id": 7806},
{"snippet": "Series.pad(axis=None, inplace=False)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `inplace`.", "question_id": 7807},
{"snippet": "Series.pad(axis=None, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `limit`.", "question_id": 7808},
{"snippet": "Series.pad(axis=None, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `axis`, `downcast`.", "question_id": 7809},
{"snippet": "Series.pad(inplace=False, limit=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `limit`.", "question_id": 7810},
{"snippet": "Series.pad(inplace=False, downcast=None)", "intent": "Synonym for DataFrame.fillna ( ) with method='ffill ' . With arguments `inplace`, `downcast`.", "question_id": 7811},
{"snippet": "Series.pct_change(**kwargs)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`.", "question_id": 7812},
{"snippet": "Series.pct_change(**kwargs, periods=1)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`.", "question_id": 7813},
{"snippet": "Series.pct_change(**kwargs, fill_method='pad')", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`.", "question_id": 7814},
{"snippet": "Series.pct_change(**kwargs, limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `limit`.", "question_id": 7815},
{"snippet": "Series.pct_change(**kwargs, freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `freq`.", "question_id": 7816},
{"snippet": "Series.pct_change(**kwargs, periods=1, fill_method='pad')", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `fill_method`.", "question_id": 7817},
{"snippet": "Series.pct_change(**kwargs, periods=1, limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `limit`.", "question_id": 7818},
{"snippet": "Series.pct_change(**kwargs, periods=1, freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `freq`.", "question_id": 7819},
{"snippet": "Series.pct_change(**kwargs, fill_method='pad', limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`, `limit`.", "question_id": 7820},
{"snippet": "Series.pct_change(**kwargs, fill_method='pad', freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`, `freq`.", "question_id": 7821},
{"snippet": "Series.pct_change(**kwargs)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`.", "question_id": 7822},
{"snippet": "Series.pct_change(**kwargs, periods=1)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`.", "question_id": 7823},
{"snippet": "Series.pct_change(**kwargs, fill_method='pad')", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`.", "question_id": 7824},
{"snippet": "Series.pct_change(**kwargs, limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `limit`.", "question_id": 7825},
{"snippet": "Series.pct_change(**kwargs, freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `freq`.", "question_id": 7826},
{"snippet": "Series.pct_change(**kwargs, periods=1, fill_method='pad')", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `fill_method`.", "question_id": 7827},
{"snippet": "Series.pct_change(**kwargs, periods=1, limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `limit`.", "question_id": 7828},
{"snippet": "Series.pct_change(**kwargs, periods=1, freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `freq`.", "question_id": 7829},
{"snippet": "Series.pct_change(**kwargs, fill_method='pad', limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`, `limit`.", "question_id": 7830},
{"snippet": "Series.pct_change(**kwargs, fill_method='pad', freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`, `freq`.", "question_id": 7831},
{"snippet": "Series.pct_change(**kwargs)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`.", "question_id": 7832},
{"snippet": "Series.pct_change(**kwargs, periods=1)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`.", "question_id": 7833},
{"snippet": "Series.pct_change(**kwargs, fill_method='pad')", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`.", "question_id": 7834},
{"snippet": "Series.pct_change(**kwargs, limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `limit`.", "question_id": 7835},
{"snippet": "Series.pct_change(**kwargs, freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `freq`.", "question_id": 7836},
{"snippet": "Series.pct_change(**kwargs, periods=1, fill_method='pad')", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `fill_method`.", "question_id": 7837},
{"snippet": "Series.pct_change(**kwargs, periods=1, limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `limit`.", "question_id": 7838},
{"snippet": "Series.pct_change(**kwargs, periods=1, freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `periods`, `freq`.", "question_id": 7839},
{"snippet": "Series.pct_change(**kwargs, fill_method='pad', limit=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`, `limit`.", "question_id": 7840},
{"snippet": "Series.pct_change(**kwargs, fill_method='pad', freq=None)", "intent": "Percentage change between the current and a prior element . With arguments `**kwargs`, `fill_method`, `freq`.", "question_id": 7841},
{"snippet": "Series.pipe(func, *args, **kwargs)", "intent": "Apply `func` ( self , * args , * * kwargs ) . With arguments `*args`, `**kwargs`.", "question_id": 7842},
{"snippet": "Series.pipe(func, *args, **kwargs)", "intent": "Apply `func` ( self , * args , * * kwargs ) . With arguments `*args`, `**kwargs`.", "question_id": 7843},
{"snippet": "Series.pipe(func, *args, **kwargs)", "intent": "Apply `func` ( self , * args , * * kwargs ) . With arguments `*args`, `**kwargs`.", "question_id": 7844},
{"snippet": "Series.plot.area(**kwargs)", "intent": "Draw a stacked area plot . With arguments `**kwargs`.", "question_id": 7845},
{"snippet": "Series.plot.area(**kwargs, x=None)", "intent": "Draw a stacked area plot . Draw with a different `x` : With arguments `**kwargs`.", "question_id": 7846},
{"snippet": "Series.plot.area(**kwargs, y=None)", "intent": "Draw a stacked area plot . With arguments `**kwargs`, `y`.", "question_id": 7847},
{"snippet": "Series.plot.area(**kwargs, x=None, y=None)", "intent": "Draw a stacked area plot . Draw with a different `x` : With arguments `**kwargs`, `y`.", "question_id": 7848},
{"snippet": "Series.plot.area(**kwargs)", "intent": "Draw a stacked area plot . With arguments `**kwargs`.", "question_id": 7849},
{"snippet": "Series.plot.area(**kwargs, x=None)", "intent": "Draw a stacked area plot . Draw with a different `x` : With arguments `**kwargs`.", "question_id": 7850},
{"snippet": "Series.plot.area(**kwargs, y=None)", "intent": "Draw a stacked area plot . With arguments `**kwargs`, `y`.", "question_id": 7851},
{"snippet": "Series.plot.area(**kwargs, x=None, y=None)", "intent": "Draw a stacked area plot . Draw with a different `x` : With arguments `**kwargs`, `y`.", "question_id": 7852},
{"snippet": "Series.plot.area(**kwargs)", "intent": "Draw a stacked area plot . With arguments `**kwargs`.", "question_id": 7853},
{"snippet": "Series.plot.area(**kwargs, x=None)", "intent": "Draw a stacked area plot . Draw with a different `x` : With arguments `**kwargs`.", "question_id": 7854},
{"snippet": "Series.plot.area(**kwargs, y=None)", "intent": "Draw a stacked area plot . With arguments `**kwargs`, `y`.", "question_id": 7855},
{"snippet": "Series.plot.area(**kwargs, x=None, y=None)", "intent": "Draw a stacked area plot . Draw with a different `x` : With arguments `**kwargs`, `y`.", "question_id": 7856},
{"snippet": "Series.plot.bar(**kwargs)", "intent": "Vertical bar plot . With arguments `**kwargs`.", "question_id": 7857},
{"snippet": "Series.plot.bar(**kwargs, x=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `x`.", "question_id": 7858},
{"snippet": "Series.plot.bar(**kwargs, y=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `y`.", "question_id": 7859},
{"snippet": "Series.plot.bar(**kwargs, x=None, y=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `x`, `y`.", "question_id": 7860},
{"snippet": "Series.plot.bar(**kwargs)", "intent": "Vertical bar plot . With arguments `**kwargs`.", "question_id": 7861},
{"snippet": "Series.plot.bar(**kwargs, x=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `x`.", "question_id": 7862},
{"snippet": "Series.plot.bar(**kwargs, y=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `y`.", "question_id": 7863},
{"snippet": "Series.plot.bar(**kwargs, x=None, y=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `x`, `y`.", "question_id": 7864},
{"snippet": "Series.plot.bar(**kwargs)", "intent": "Vertical bar plot . With arguments `**kwargs`.", "question_id": 7865},
{"snippet": "Series.plot.bar(**kwargs, x=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `x`.", "question_id": 7866},
{"snippet": "Series.plot.bar(**kwargs, y=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `y`.", "question_id": 7867},
{"snippet": "Series.plot.bar(**kwargs, x=None, y=None)", "intent": "Vertical bar plot . With arguments `**kwargs`, `x`, `y`.", "question_id": 7868},
{"snippet": "Series.plot.barh(**kwargs)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`.", "question_id": 7869},
{"snippet": "Series.plot.barh(**kwargs, x=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `x`.", "question_id": 7870},
{"snippet": "Series.plot.barh(**kwargs, y=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `y`.", "question_id": 7871},
{"snippet": "Series.plot.barh(**kwargs, x=None, y=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `x`, `y`.", "question_id": 7872},
{"snippet": "Series.plot.barh(**kwargs)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`.", "question_id": 7873},
{"snippet": "Series.plot.barh(**kwargs, x=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `x`.", "question_id": 7874},
{"snippet": "Series.plot.barh(**kwargs, y=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `y`.", "question_id": 7875},
{"snippet": "Series.plot.barh(**kwargs, x=None, y=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `x`, `y`.", "question_id": 7876},
{"snippet": "Series.plot.barh(**kwargs)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`.", "question_id": 7877},
{"snippet": "Series.plot.barh(**kwargs, x=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `x`.", "question_id": 7878},
{"snippet": "Series.plot.barh(**kwargs, y=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `y`.", "question_id": 7879},
{"snippet": "Series.plot.barh(**kwargs, x=None, y=None)", "intent": "Make a horizontal bar plot . With arguments `**kwargs`, `x`, `y`.", "question_id": 7880},
{"snippet": "Series.plot.box(**kwargs)", "intent": "Make a box plot of the DataFrame columns . With arguments `**kwargs`.", "question_id": 7881},
{"snippet": "Series.plot.box(**kwargs, by=None)", "intent": "Make a box plot of the DataFrame columns . The position of the whiskers is set `by` default to 1.5 * IQR ( IQR = Q3 - Q1 ) from the edges of the box . With arguments `**kwargs`.", "question_id": 7882},
{"snippet": "Series.plot.box(**kwargs)", "intent": "Make a box plot of the DataFrame columns . With arguments `**kwargs`.", "question_id": 7883},
{"snippet": "Series.plot.box(**kwargs, by=None)", "intent": "Make a box plot of the DataFrame columns . The position of the whiskers is set `by` default to 1.5 * IQR ( IQR = Q3 - Q1 ) from the edges of the box . With arguments `**kwargs`.", "question_id": 7884},
{"snippet": "Series.plot.box(**kwargs)", "intent": "Make a box plot of the DataFrame columns . With arguments `**kwargs`.", "question_id": 7885},
{"snippet": "Series.plot.box(**kwargs, by=None)", "intent": "Make a box plot of the DataFrame columns . The position of the whiskers is set `by` default to 1.5 * IQR ( IQR = Q3 - Q1 ) from the edges of the box . With arguments `**kwargs`.", "question_id": 7886},
{"snippet": "Series.plot.density(**kwargs)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`.", "question_id": 7887},
{"snippet": "Series.plot.density(**kwargs, bw_method=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`, `bw_method`.", "question_id": 7888},
{"snippet": "Series.plot.density(**kwargs, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`.", "question_id": 7889},
{"snippet": "Series.plot.density(**kwargs, bw_method=None, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`, `bw_method`.", "question_id": 7890},
{"snippet": "Series.plot.density(**kwargs)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`.", "question_id": 7891},
{"snippet": "Series.plot.density(**kwargs, bw_method=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`, `bw_method`.", "question_id": 7892},
{"snippet": "Series.plot.density(**kwargs, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`.", "question_id": 7893},
{"snippet": "Series.plot.density(**kwargs, bw_method=None, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`, `bw_method`.", "question_id": 7894},
{"snippet": "Series.plot.density(**kwargs)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`.", "question_id": 7895},
{"snippet": "Series.plot.density(**kwargs, bw_method=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`, `bw_method`.", "question_id": 7896},
{"snippet": "Series.plot.density(**kwargs, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`.", "question_id": 7897},
{"snippet": "Series.plot.density(**kwargs, bw_method=None, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`, `bw_method`.", "question_id": 7898},
{"snippet": "Series.plot.hist(**kwargs)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`.", "question_id": 7899},
{"snippet": "Series.plot.hist(**kwargs, by=None)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `by`.", "question_id": 7900},
{"snippet": "Series.plot.hist(**kwargs, bins=10)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . This function groups the values of all given Series in the DataFrame into `bins` and draws all bins in one matplotlib.axes.Axes . With arguments `**kwargs`.", "question_id": 7901},
{"snippet": "Series.plot.hist(**kwargs, by=None, bins=10)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . This function groups the values of all given Series in the DataFrame into `bins` and draws all bins in one matplotlib.axes.Axes . With arguments `**kwargs`, `by`.", "question_id": 7902},
{"snippet": "Series.plot.hist(**kwargs)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`.", "question_id": 7903},
{"snippet": "Series.plot.hist(**kwargs, by=None)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `by`.", "question_id": 7904},
{"snippet": "Series.plot.hist(**kwargs, bins=10)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . This function groups the values of all given Series in the DataFrame into `bins` and draws all bins in one matplotlib.axes.Axes . With arguments `**kwargs`.", "question_id": 7905},
{"snippet": "Series.plot.hist(**kwargs, by=None, bins=10)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . This function groups the values of all given Series in the DataFrame into `bins` and draws all bins in one matplotlib.axes.Axes . With arguments `**kwargs`, `by`.", "question_id": 7906},
{"snippet": "Series.plot.hist(**kwargs)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`.", "question_id": 7907},
{"snippet": "Series.plot.hist(**kwargs, by=None)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . With arguments `**kwargs`, `by`.", "question_id": 7908},
{"snippet": "Series.plot.hist(**kwargs, bins=10)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . This function groups the values of all given Series in the DataFrame into `bins` and draws all bins in one matplotlib.axes.Axes . With arguments `**kwargs`.", "question_id": 7909},
{"snippet": "Series.plot.hist(**kwargs, by=None, bins=10)", "intent": "Draw one histogram of the DataFrame \u2019 s columns . This function groups the values of all given Series in the DataFrame into `bins` and draws all bins in one matplotlib.axes.Axes . With arguments `**kwargs`, `by`.", "question_id": 7910},
{"snippet": "Series.plot(*args, **kwargs)", "intent": "Make plots of Series or DataFrame . With arguments `*args`, `**kwargs`.", "question_id": 7911},
{"snippet": "Series.plot(*args, **kwargs)", "intent": "Make plots of Series or DataFrame . With arguments `*args`, `**kwargs`.", "question_id": 7912},
{"snippet": "Series.plot(*args, **kwargs)", "intent": "Make plots of Series or DataFrame . With arguments `*args`, `**kwargs`.", "question_id": 7913},
{"snippet": "Series.plot.kde(**kwargs)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`.", "question_id": 7914},
{"snippet": "Series.plot.kde(**kwargs, bw_method=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`, `bw_method`.", "question_id": 7915},
{"snippet": "Series.plot.kde(**kwargs, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`.", "question_id": 7916},
{"snippet": "Series.plot.kde(**kwargs, bw_method=None, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`, `bw_method`.", "question_id": 7917},
{"snippet": "Series.plot.kde(**kwargs)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`.", "question_id": 7918},
{"snippet": "Series.plot.kde(**kwargs, bw_method=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`, `bw_method`.", "question_id": 7919},
{"snippet": "Series.plot.kde(**kwargs, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`.", "question_id": 7920},
{"snippet": "Series.plot.kde(**kwargs, bw_method=None, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`, `bw_method`.", "question_id": 7921},
{"snippet": "Series.plot.kde(**kwargs)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`.", "question_id": 7922},
{"snippet": "Series.plot.kde(**kwargs, bw_method=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . With arguments `**kwargs`, `bw_method`.", "question_id": 7923},
{"snippet": "Series.plot.kde(**kwargs, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`.", "question_id": 7924},
{"snippet": "Series.plot.kde(**kwargs, bw_method=None, ind=None)", "intent": "Generate Kernel Density Estimate plot using Gaussian kernels . Finally , the `ind` parameter determines the evaluation points for the plot of the estimated PDF : With arguments `**kwargs`, `bw_method`.", "question_id": 7925},
{"snippet": "Series.plot.line(**kwargs)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`.", "question_id": 7926},
{"snippet": "Series.plot.line(**kwargs, x=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `x`.", "question_id": 7927},
{"snippet": "Series.plot.line(**kwargs, y=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `y`.", "question_id": 7928},
{"snippet": "Series.plot.line(**kwargs, x=None, y=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `x`, `y`.", "question_id": 7929},
{"snippet": "Series.plot.line(**kwargs)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`.", "question_id": 7930},
{"snippet": "Series.plot.line(**kwargs, x=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `x`.", "question_id": 7931},
{"snippet": "Series.plot.line(**kwargs, y=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `y`.", "question_id": 7932},
{"snippet": "Series.plot.line(**kwargs, x=None, y=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `x`, `y`.", "question_id": 7933},
{"snippet": "Series.plot.line(**kwargs)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`.", "question_id": 7934},
{"snippet": "Series.plot.line(**kwargs, x=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `x`.", "question_id": 7935},
{"snippet": "Series.plot.line(**kwargs, y=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `y`.", "question_id": 7936},
{"snippet": "Series.plot.line(**kwargs, x=None, y=None)", "intent": "Plot Series or DataFrame as lines . With arguments `**kwargs`, `x`, `y`.", "question_id": 7937},
{"snippet": "Series.plot.pie(**kwargs)", "intent": "Generate a pie plot . With arguments `**kwargs`.", "question_id": 7938},
{"snippet": "Series.plot.pie(**kwargs)", "intent": "Generate a pie plot . With arguments `**kwargs`.", "question_id": 7939},
{"snippet": "Series.plot.pie(**kwargs)", "intent": "Generate a pie plot . With arguments `**kwargs`.", "question_id": 7940},
{"snippet": "Series.pop(item)", "intent": "Return `item` and drops from series .", "question_id": 7941},
{"snippet": "Series.pop(item)", "intent": "Return `item` and drops from series .", "question_id": 7942},
{"snippet": "Series.pop(item)", "intent": "Return `item` and drops from series .", "question_id": 7943},
{"snippet": "Series.pow(other)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) .", "question_id": 7944},
{"snippet": "Series.pow(other, level=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . With arguments `level`.", "question_id": 7945},
{"snippet": "Series.pow(other, fill_value=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . Equivalent to series * * other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7946},
{"snippet": "Series.pow(other, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . With arguments `axis`.", "question_id": 7947},
{"snippet": "Series.pow(other, level=None, fill_value=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . Equivalent to series * * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7948},
{"snippet": "Series.pow(other, level=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . With arguments `level`, `axis`.", "question_id": 7949},
{"snippet": "Series.pow(other, fill_value=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . Equivalent to series * * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7950},
{"snippet": "Series.pow(other, level=None, fill_value=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . Equivalent to series * * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7951},
{"snippet": "Series.pow(other)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) .", "question_id": 7952},
{"snippet": "Series.pow(other, level=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . With arguments `level`.", "question_id": 7953},
{"snippet": "Series.pow(other, fill_value=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . Equivalent to series * * other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7954},
{"snippet": "Series.pow(other, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . With arguments `axis`.", "question_id": 7955},
{"snippet": "Series.pow(other, level=None, fill_value=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . Equivalent to series * * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7956},
{"snippet": "Series.pow(other, level=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . With arguments `level`, `axis`.", "question_id": 7957},
{"snippet": "Series.pow(other, fill_value=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . Equivalent to series * * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7958},
{"snippet": "Series.pow(other, level=None, fill_value=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . Equivalent to series * * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7959},
{"snippet": "Series.pow(other)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) .", "question_id": 7960},
{"snippet": "Series.pow(other, level=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . With arguments `level`.", "question_id": 7961},
{"snippet": "Series.pow(other, fill_value=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . Equivalent to series * * other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 7962},
{"snippet": "Series.pow(other, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . With arguments `axis`.", "question_id": 7963},
{"snippet": "Series.pow(other, level=None, fill_value=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . Equivalent to series * * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 7964},
{"snippet": "Series.pow(other, level=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . With arguments `level`, `axis`.", "question_id": 7965},
{"snippet": "Series.pow(other, fill_value=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . Equivalent to series * * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 7966},
{"snippet": "Series.pow(other, level=None, fill_value=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator pow ) . Equivalent to series * * other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 7967},
{"snippet": "Series.prod(**kwargs)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7968},
{"snippet": "Series.prod(**kwargs, axis=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7969},
{"snippet": "Series.prod(**kwargs, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 7970},
{"snippet": "Series.prod(**kwargs, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7971},
{"snippet": "Series.prod(**kwargs, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7972},
{"snippet": "Series.prod(**kwargs, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 7973},
{"snippet": "Series.prod(**kwargs, axis=None, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 7974},
{"snippet": "Series.prod(**kwargs, axis=None, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7975},
{"snippet": "Series.prod(**kwargs, axis=None, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7976},
{"snippet": "Series.prod(**kwargs, axis=None, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 7977},
{"snippet": "Series.prod(**kwargs)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7978},
{"snippet": "Series.prod(**kwargs, axis=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7979},
{"snippet": "Series.prod(**kwargs, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 7980},
{"snippet": "Series.prod(**kwargs, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7981},
{"snippet": "Series.prod(**kwargs, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7982},
{"snippet": "Series.prod(**kwargs, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 7983},
{"snippet": "Series.prod(**kwargs, axis=None, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 7984},
{"snippet": "Series.prod(**kwargs, axis=None, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7985},
{"snippet": "Series.prod(**kwargs, axis=None, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7986},
{"snippet": "Series.prod(**kwargs, axis=None, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 7987},
{"snippet": "Series.prod(**kwargs)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7988},
{"snippet": "Series.prod(**kwargs, axis=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7989},
{"snippet": "Series.prod(**kwargs, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 7990},
{"snippet": "Series.prod(**kwargs, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7991},
{"snippet": "Series.prod(**kwargs, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7992},
{"snippet": "Series.prod(**kwargs, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 7993},
{"snippet": "Series.prod(**kwargs, axis=None, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 7994},
{"snippet": "Series.prod(**kwargs, axis=None, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 7995},
{"snippet": "Series.prod(**kwargs, axis=None, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 7996},
{"snippet": "Series.prod(**kwargs, axis=None, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 7997},
{"snippet": "Series.product(**kwargs)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7998},
{"snippet": "Series.product(**kwargs, axis=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 7999},
{"snippet": "Series.product(**kwargs, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 8000},
{"snippet": "Series.product(**kwargs, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8001},
{"snippet": "Series.product(**kwargs, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8002},
{"snippet": "Series.product(**kwargs, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 8003},
{"snippet": "Series.product(**kwargs, axis=None, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 8004},
{"snippet": "Series.product(**kwargs, axis=None, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8005},
{"snippet": "Series.product(**kwargs, axis=None, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8006},
{"snippet": "Series.product(**kwargs, axis=None, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 8007},
{"snippet": "Series.product(**kwargs)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 8008},
{"snippet": "Series.product(**kwargs, axis=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 8009},
{"snippet": "Series.product(**kwargs, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 8010},
{"snippet": "Series.product(**kwargs, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8011},
{"snippet": "Series.product(**kwargs, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8012},
{"snippet": "Series.product(**kwargs, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 8013},
{"snippet": "Series.product(**kwargs, axis=None, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 8014},
{"snippet": "Series.product(**kwargs, axis=None, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8015},
{"snippet": "Series.product(**kwargs, axis=None, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8016},
{"snippet": "Series.product(**kwargs, axis=None, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 8017},
{"snippet": "Series.product(**kwargs)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 8018},
{"snippet": "Series.product(**kwargs, axis=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 8019},
{"snippet": "Series.product(**kwargs, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 8020},
{"snippet": "Series.product(**kwargs, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8021},
{"snippet": "Series.product(**kwargs, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8022},
{"snippet": "Series.product(**kwargs, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 8023},
{"snippet": "Series.product(**kwargs, axis=None, skipna=None)", "intent": "Return the product of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 8024},
{"snippet": "Series.product(**kwargs, axis=None, level=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8025},
{"snippet": "Series.product(**kwargs, axis=None, numeric_only=None)", "intent": "Return the product of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8026},
{"snippet": "Series.product(**kwargs, axis=None, min_count=0)", "intent": "Return the product of the values over the requested `axis` . This can be controlled with the `min_count` parameter With arguments `**kwargs`.", "question_id": 8027},
{"snippet": "Series.quantile()", "intent": "Return value at the given quantile .", "question_id": 8028},
{"snippet": "Series.quantile(q=0.5)", "intent": "Return value at the given quantile . With arguments `q`.", "question_id": 8029},
{"snippet": "Series.quantile(interpolation='linear')", "intent": "Return value at the given quantile . With arguments `interpolation`.", "question_id": 8030},
{"snippet": "Series.quantile(q=0.5, interpolation='linear')", "intent": "Return value at the given quantile . With arguments `q`, `interpolation`.", "question_id": 8031},
{"snippet": "Series.quantile()", "intent": "Return value at the given quantile .", "question_id": 8032},
{"snippet": "Series.quantile(q=0.5)", "intent": "Return value at the given quantile . With arguments `q`.", "question_id": 8033},
{"snippet": "Series.quantile(interpolation='linear')", "intent": "Return value at the given quantile . With arguments `interpolation`.", "question_id": 8034},
{"snippet": "Series.quantile(q=0.5, interpolation='linear')", "intent": "Return value at the given quantile . With arguments `q`, `interpolation`.", "question_id": 8035},
{"snippet": "Series.quantile()", "intent": "Return value at the given quantile .", "question_id": 8036},
{"snippet": "Series.quantile(q=0.5)", "intent": "Return value at the given quantile . With arguments `q`.", "question_id": 8037},
{"snippet": "Series.quantile(interpolation='linear')", "intent": "Return value at the given quantile . With arguments `interpolation`.", "question_id": 8038},
{"snippet": "Series.quantile(q=0.5, interpolation='linear')", "intent": "Return value at the given quantile . With arguments `q`, `interpolation`.", "question_id": 8039},
{"snippet": "Series.radd(other)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) .", "question_id": 8040},
{"snippet": "Series.radd(other, level=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . With arguments `level`.", "question_id": 8041},
{"snippet": "Series.radd(other, fill_value=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . Equivalent to other + series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8042},
{"snippet": "Series.radd(other, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . With arguments `axis`.", "question_id": 8043},
{"snippet": "Series.radd(other, level=None, fill_value=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . Equivalent to other + series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8044},
{"snippet": "Series.radd(other, level=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . With arguments `level`, `axis`.", "question_id": 8045},
{"snippet": "Series.radd(other, fill_value=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . Equivalent to other + series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8046},
{"snippet": "Series.radd(other, level=None, fill_value=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . Equivalent to other + series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8047},
{"snippet": "Series.radd(other)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) .", "question_id": 8048},
{"snippet": "Series.radd(other, level=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . With arguments `level`.", "question_id": 8049},
{"snippet": "Series.radd(other, fill_value=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . Equivalent to other + series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8050},
{"snippet": "Series.radd(other, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . With arguments `axis`.", "question_id": 8051},
{"snippet": "Series.radd(other, level=None, fill_value=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . Equivalent to other + series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8052},
{"snippet": "Series.radd(other, level=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . With arguments `level`, `axis`.", "question_id": 8053},
{"snippet": "Series.radd(other, fill_value=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . Equivalent to other + series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8054},
{"snippet": "Series.radd(other, level=None, fill_value=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . Equivalent to other + series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8055},
{"snippet": "Series.radd(other)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) .", "question_id": 8056},
{"snippet": "Series.radd(other, level=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . With arguments `level`.", "question_id": 8057},
{"snippet": "Series.radd(other, fill_value=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . Equivalent to other + series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8058},
{"snippet": "Series.radd(other, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . With arguments `axis`.", "question_id": 8059},
{"snippet": "Series.radd(other, level=None, fill_value=None)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . Equivalent to other + series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8060},
{"snippet": "Series.radd(other, level=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . With arguments `level`, `axis`.", "question_id": 8061},
{"snippet": "Series.radd(other, fill_value=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . Equivalent to other + series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8062},
{"snippet": "Series.radd(other, level=None, fill_value=None, axis=0)", "intent": "Return Addition of series and `other` , element-wise ( binary operator radd ) . Equivalent to other + series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8063},
{"snippet": "Series.rank()", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` .", "question_id": 8064},
{"snippet": "Series.rank(axis=0)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` .", "question_id": 8065},
{"snippet": "Series.rank(method='average')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . The following example shows how the `method` behaves with the above parameters :", "question_id": 8066},
{"snippet": "Series.rank(numeric_only=None)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `numeric_only`.", "question_id": 8067},
{"snippet": "Series.rank(na_option='keep')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `na_option`.", "question_id": 8068},
{"snippet": "Series.rank(ascending=True)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `ascending`.", "question_id": 8069},
{"snippet": "Series.rank(pct=False)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `pct`.", "question_id": 8070},
{"snippet": "Series.rank(axis=0, method='average')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . The following example shows how the `method` behaves with the above parameters :", "question_id": 8071},
{"snippet": "Series.rank(axis=0, numeric_only=None)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `numeric_only`.", "question_id": 8072},
{"snippet": "Series.rank(axis=0, na_option='keep')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `na_option`.", "question_id": 8073},
{"snippet": "Series.rank()", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` .", "question_id": 8074},
{"snippet": "Series.rank(axis=0)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` .", "question_id": 8075},
{"snippet": "Series.rank(method='average')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . The following example shows how the `method` behaves with the above parameters :", "question_id": 8076},
{"snippet": "Series.rank(numeric_only=None)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `numeric_only`.", "question_id": 8077},
{"snippet": "Series.rank(na_option='keep')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `na_option`.", "question_id": 8078},
{"snippet": "Series.rank(ascending=True)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `ascending`.", "question_id": 8079},
{"snippet": "Series.rank(pct=False)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `pct`.", "question_id": 8080},
{"snippet": "Series.rank(axis=0, method='average')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . The following example shows how the `method` behaves with the above parameters :", "question_id": 8081},
{"snippet": "Series.rank(axis=0, numeric_only=None)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `numeric_only`.", "question_id": 8082},
{"snippet": "Series.rank(axis=0, na_option='keep')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `na_option`.", "question_id": 8083},
{"snippet": "Series.rank()", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` .", "question_id": 8084},
{"snippet": "Series.rank(axis=0)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` .", "question_id": 8085},
{"snippet": "Series.rank(method='average')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . The following example shows how the `method` behaves with the above parameters :", "question_id": 8086},
{"snippet": "Series.rank(numeric_only=None)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `numeric_only`.", "question_id": 8087},
{"snippet": "Series.rank(na_option='keep')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `na_option`.", "question_id": 8088},
{"snippet": "Series.rank(ascending=True)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `ascending`.", "question_id": 8089},
{"snippet": "Series.rank(pct=False)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `pct`.", "question_id": 8090},
{"snippet": "Series.rank(axis=0, method='average')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . The following example shows how the `method` behaves with the above parameters :", "question_id": 8091},
{"snippet": "Series.rank(axis=0, numeric_only=None)", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `numeric_only`.", "question_id": 8092},
{"snippet": "Series.rank(axis=0, na_option='keep')", "intent": "Compute numerical data ranks ( 1 through n ) along `axis` . With arguments `na_option`.", "question_id": 8093},
{"snippet": "Series.ravel()", "intent": "Return the flattened underlying data as an ndarray .", "question_id": 8094},
{"snippet": "Series.ravel(order='C')", "intent": "Return the flattened underlying data as an ndarray . With arguments `order`.", "question_id": 8095},
{"snippet": "Series.ravel()", "intent": "Return the flattened underlying data as an ndarray .", "question_id": 8096},
{"snippet": "Series.ravel(order='C')", "intent": "Return the flattened underlying data as an ndarray . With arguments `order`.", "question_id": 8097},
{"snippet": "Series.ravel()", "intent": "Return the flattened underlying data as an ndarray .", "question_id": 8098},
{"snippet": "Series.ravel(order='C')", "intent": "Return the flattened underlying data as an ndarray . With arguments `order`.", "question_id": 8099},
{"snippet": "Series.rdiv(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) .", "question_id": 8100},
{"snippet": "Series.rdiv(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `level`.", "question_id": 8101},
{"snippet": "Series.rdiv(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8102},
{"snippet": "Series.rdiv(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `axis`.", "question_id": 8103},
{"snippet": "Series.rdiv(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8104},
{"snippet": "Series.rdiv(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `level`, `axis`.", "question_id": 8105},
{"snippet": "Series.rdiv(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8106},
{"snippet": "Series.rdiv(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8107},
{"snippet": "Series.rdiv(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) .", "question_id": 8108},
{"snippet": "Series.rdiv(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `level`.", "question_id": 8109},
{"snippet": "Series.rdiv(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8110},
{"snippet": "Series.rdiv(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `axis`.", "question_id": 8111},
{"snippet": "Series.rdiv(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8112},
{"snippet": "Series.rdiv(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `level`, `axis`.", "question_id": 8113},
{"snippet": "Series.rdiv(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8114},
{"snippet": "Series.rdiv(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8115},
{"snippet": "Series.rdiv(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) .", "question_id": 8116},
{"snippet": "Series.rdiv(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `level`.", "question_id": 8117},
{"snippet": "Series.rdiv(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8118},
{"snippet": "Series.rdiv(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `axis`.", "question_id": 8119},
{"snippet": "Series.rdiv(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8120},
{"snippet": "Series.rdiv(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `level`, `axis`.", "question_id": 8121},
{"snippet": "Series.rdiv(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8122},
{"snippet": "Series.rdiv(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8123},
{"snippet": "Series.rdivmod(other)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) .", "question_id": 8124},
{"snippet": "Series.rdivmod(other, level=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . With arguments `level`.", "question_id": 8125},
{"snippet": "Series.rdivmod(other, fill_value=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . Equivalent to other divmod series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8126},
{"snippet": "Series.rdivmod(other, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . With arguments `axis`.", "question_id": 8127},
{"snippet": "Series.rdivmod(other, level=None, fill_value=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . Equivalent to other divmod series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8128},
{"snippet": "Series.rdivmod(other, level=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . With arguments `level`, `axis`.", "question_id": 8129},
{"snippet": "Series.rdivmod(other, fill_value=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . Equivalent to other divmod series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8130},
{"snippet": "Series.rdivmod(other, level=None, fill_value=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . Equivalent to other divmod series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8131},
{"snippet": "Series.rdivmod(other)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) .", "question_id": 8132},
{"snippet": "Series.rdivmod(other, level=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . With arguments `level`.", "question_id": 8133},
{"snippet": "Series.rdivmod(other, fill_value=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . Equivalent to other divmod series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8134},
{"snippet": "Series.rdivmod(other, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . With arguments `axis`.", "question_id": 8135},
{"snippet": "Series.rdivmod(other, level=None, fill_value=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . Equivalent to other divmod series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8136},
{"snippet": "Series.rdivmod(other, level=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . With arguments `level`, `axis`.", "question_id": 8137},
{"snippet": "Series.rdivmod(other, fill_value=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . Equivalent to other divmod series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8138},
{"snippet": "Series.rdivmod(other, level=None, fill_value=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . Equivalent to other divmod series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8139},
{"snippet": "Series.rdivmod(other)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) .", "question_id": 8140},
{"snippet": "Series.rdivmod(other, level=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . With arguments `level`.", "question_id": 8141},
{"snippet": "Series.rdivmod(other, fill_value=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . Equivalent to other divmod series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8142},
{"snippet": "Series.rdivmod(other, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . With arguments `axis`.", "question_id": 8143},
{"snippet": "Series.rdivmod(other, level=None, fill_value=None)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . Equivalent to other divmod series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8144},
{"snippet": "Series.rdivmod(other, level=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . With arguments `level`, `axis`.", "question_id": 8145},
{"snippet": "Series.rdivmod(other, fill_value=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . Equivalent to other divmod series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8146},
{"snippet": "Series.rdivmod(other, level=None, fill_value=None, axis=0)", "intent": "Return Integer division and modulo of series and `other` , element-wise ( binary operator rdivmod ) . Equivalent to other divmod series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8147},
{"snippet": "Series.reindex(**kwargs)", "intent": "Conform Series to new `index` with optional filling logic . With arguments `**kwargs`.", "question_id": 8148},
{"snippet": "Series.reindex(**kwargs, index=None)", "intent": "Conform Series to new `index` with optional filling logic . With arguments `**kwargs`.", "question_id": 8149},
{"snippet": "Series.reindex(**kwargs)", "intent": "Conform Series to new `index` with optional filling logic . With arguments `**kwargs`.", "question_id": 8150},
{"snippet": "Series.reindex(**kwargs, index=None)", "intent": "Conform Series to new `index` with optional filling logic . With arguments `**kwargs`.", "question_id": 8151},
{"snippet": "Series.reindex(**kwargs)", "intent": "Conform Series to new `index` with optional filling logic . With arguments `**kwargs`.", "question_id": 8152},
{"snippet": "Series.reindex(**kwargs, index=None)", "intent": "Conform Series to new `index` with optional filling logic . With arguments `**kwargs`.", "question_id": 8153},
{"snippet": "Series.reindex_like(other)", "intent": "Return an object with matching indices as `other` object .", "question_id": 8154},
{"snippet": "Series.reindex_like(other, method=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`.", "question_id": 8155},
{"snippet": "Series.reindex_like(other, copy=True)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`.", "question_id": 8156},
{"snippet": "Series.reindex_like(other, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `limit`.", "question_id": 8157},
{"snippet": "Series.reindex_like(other, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `tolerance`.", "question_id": 8158},
{"snippet": "Series.reindex_like(other, method=None, copy=True)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `copy`.", "question_id": 8159},
{"snippet": "Series.reindex_like(other, method=None, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `limit`.", "question_id": 8160},
{"snippet": "Series.reindex_like(other, method=None, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `tolerance`.", "question_id": 8161},
{"snippet": "Series.reindex_like(other, copy=True, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`, `limit`.", "question_id": 8162},
{"snippet": "Series.reindex_like(other, copy=True, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`, `tolerance`.", "question_id": 8163},
{"snippet": "Series.reindex_like(other)", "intent": "Return an object with matching indices as `other` object .", "question_id": 8164},
{"snippet": "Series.reindex_like(other, method=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`.", "question_id": 8165},
{"snippet": "Series.reindex_like(other, copy=True)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`.", "question_id": 8166},
{"snippet": "Series.reindex_like(other, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `limit`.", "question_id": 8167},
{"snippet": "Series.reindex_like(other, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `tolerance`.", "question_id": 8168},
{"snippet": "Series.reindex_like(other, method=None, copy=True)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `copy`.", "question_id": 8169},
{"snippet": "Series.reindex_like(other, method=None, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `limit`.", "question_id": 8170},
{"snippet": "Series.reindex_like(other, method=None, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `tolerance`.", "question_id": 8171},
{"snippet": "Series.reindex_like(other, copy=True, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`, `limit`.", "question_id": 8172},
{"snippet": "Series.reindex_like(other, copy=True, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`, `tolerance`.", "question_id": 8173},
{"snippet": "Series.reindex_like(other)", "intent": "Return an object with matching indices as `other` object .", "question_id": 8174},
{"snippet": "Series.reindex_like(other, method=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`.", "question_id": 8175},
{"snippet": "Series.reindex_like(other, copy=True)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`.", "question_id": 8176},
{"snippet": "Series.reindex_like(other, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `limit`.", "question_id": 8177},
{"snippet": "Series.reindex_like(other, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `tolerance`.", "question_id": 8178},
{"snippet": "Series.reindex_like(other, method=None, copy=True)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `copy`.", "question_id": 8179},
{"snippet": "Series.reindex_like(other, method=None, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `limit`.", "question_id": 8180},
{"snippet": "Series.reindex_like(other, method=None, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `method`, `tolerance`.", "question_id": 8181},
{"snippet": "Series.reindex_like(other, copy=True, limit=None)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`, `limit`.", "question_id": 8182},
{"snippet": "Series.reindex_like(other, copy=True, tolerance=None)", "intent": "Return an object with matching indices as `other` object . With arguments `copy`, `tolerance`.", "question_id": 8183},
{"snippet": "Series.rename()", "intent": "Alter Series `index` labels or name .", "question_id": 8184},
{"snippet": "Series.rename(index=None)", "intent": "Alter Series `index` labels or name .", "question_id": 8185},
{"snippet": "Series.rename(axis=None)", "intent": "Alter Series `index` labels or name . With arguments `axis`.", "question_id": 8186},
{"snippet": "Series.rename(copy=True)", "intent": "Alter Series `index` labels or name . With arguments `copy`.", "question_id": 8187},
{"snippet": "Series.rename(inplace=False)", "intent": "Alter Series `index` labels or name . With arguments `inplace`.", "question_id": 8188},
{"snippet": "Series.rename(level=None)", "intent": "Alter Series `index` labels or name . With arguments `level`.", "question_id": 8189},
{"snippet": "Series.rename(errors='ignore')", "intent": "Alter Series `index` labels or name . With arguments `errors`.", "question_id": 8190},
{"snippet": "Series.rename(index=None, axis=None)", "intent": "Alter Series `index` labels or name . With arguments `axis`.", "question_id": 8191},
{"snippet": "Series.rename(index=None, copy=True)", "intent": "Alter Series `index` labels or name . With arguments `copy`.", "question_id": 8192},
{"snippet": "Series.rename(index=None, inplace=False)", "intent": "Alter Series `index` labels or name . With arguments `inplace`.", "question_id": 8193},
{"snippet": "Series.rename()", "intent": "Alter Series `index` labels or name .", "question_id": 8194},
{"snippet": "Series.rename(index=None)", "intent": "Alter Series `index` labels or name .", "question_id": 8195},
{"snippet": "Series.rename(axis=None)", "intent": "Alter Series `index` labels or name . With arguments `axis`.", "question_id": 8196},
{"snippet": "Series.rename(copy=True)", "intent": "Alter Series `index` labels or name . With arguments `copy`.", "question_id": 8197},
{"snippet": "Series.rename(inplace=False)", "intent": "Alter Series `index` labels or name . With arguments `inplace`.", "question_id": 8198},
{"snippet": "Series.rename(level=None)", "intent": "Alter Series `index` labels or name . With arguments `level`.", "question_id": 8199},
{"snippet": "Series.rename(errors='ignore')", "intent": "Alter Series `index` labels or name . With arguments `errors`.", "question_id": 8200},
{"snippet": "Series.rename(index=None, axis=None)", "intent": "Alter Series `index` labels or name . With arguments `axis`.", "question_id": 8201},
{"snippet": "Series.rename(index=None, copy=True)", "intent": "Alter Series `index` labels or name . With arguments `copy`.", "question_id": 8202},
{"snippet": "Series.rename(index=None, inplace=False)", "intent": "Alter Series `index` labels or name . With arguments `inplace`.", "question_id": 8203},
{"snippet": "Series.rename()", "intent": "Alter Series `index` labels or name .", "question_id": 8204},
{"snippet": "Series.rename(index=None)", "intent": "Alter Series `index` labels or name .", "question_id": 8205},
{"snippet": "Series.rename(axis=None)", "intent": "Alter Series `index` labels or name . With arguments `axis`.", "question_id": 8206},
{"snippet": "Series.rename(copy=True)", "intent": "Alter Series `index` labels or name . With arguments `copy`.", "question_id": 8207},
{"snippet": "Series.rename(inplace=False)", "intent": "Alter Series `index` labels or name . With arguments `inplace`.", "question_id": 8208},
{"snippet": "Series.rename(level=None)", "intent": "Alter Series `index` labels or name . With arguments `level`.", "question_id": 8209},
{"snippet": "Series.rename(errors='ignore')", "intent": "Alter Series `index` labels or name . With arguments `errors`.", "question_id": 8210},
{"snippet": "Series.rename(index=None, axis=None)", "intent": "Alter Series `index` labels or name . With arguments `axis`.", "question_id": 8211},
{"snippet": "Series.rename(index=None, copy=True)", "intent": "Alter Series `index` labels or name . With arguments `copy`.", "question_id": 8212},
{"snippet": "Series.rename(index=None, inplace=False)", "intent": "Alter Series `index` labels or name . With arguments `inplace`.", "question_id": 8213},
{"snippet": "Series.rename_axis()", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 8214},
{"snippet": "Series.rename_axis(mapper=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 8215},
{"snippet": "Series.rename_axis(index=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 8216},
{"snippet": "Series.rename_axis(columns=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 8217},
{"snippet": "Series.rename_axis(axis=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 8218},
{"snippet": "Series.rename_axis(copy=True)", "intent": "Set the name of the `axis` for the `index` or `columns` . In this case , the parameter `copy` is ignored .", "question_id": 8219},
{"snippet": "Series.rename_axis(inplace=False)", "intent": "Set the name of the `axis` for the `index` or `columns` . With arguments `inplace`.", "question_id": 8220},
{"snippet": "Series.rename_axis(mapper=None, index=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 8221},
{"snippet": "Series.rename_axis(mapper=None, columns=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 8222},
{"snippet": "Series.rename_axis(mapper=None, axis=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 8223},
{"snippet": "Series.rename_axis()", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 8224},
{"snippet": "Series.rename_axis(mapper=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 8225},
{"snippet": "Series.rename_axis(index=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 8226},
{"snippet": "Series.rename_axis(columns=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 8227},
{"snippet": "Series.rename_axis(axis=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 8228},
{"snippet": "Series.rename_axis(copy=True)", "intent": "Set the name of the `axis` for the `index` or `columns` . In this case , the parameter `copy` is ignored .", "question_id": 8229},
{"snippet": "Series.rename_axis(inplace=False)", "intent": "Set the name of the `axis` for the `index` or `columns` . With arguments `inplace`.", "question_id": 8230},
{"snippet": "Series.rename_axis(mapper=None, index=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 8231},
{"snippet": "Series.rename_axis(mapper=None, columns=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 8232},
{"snippet": "Series.rename_axis(mapper=None, axis=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 8233},
{"snippet": "Series.rename_axis()", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 8234},
{"snippet": "Series.rename_axis(mapper=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 8235},
{"snippet": "Series.rename_axis(index=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 8236},
{"snippet": "Series.rename_axis(columns=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 8237},
{"snippet": "Series.rename_axis(axis=None)", "intent": "Set the name of the `axis` for the `index` or `columns` .", "question_id": 8238},
{"snippet": "Series.rename_axis(copy=True)", "intent": "Set the name of the `axis` for the `index` or `columns` . In this case , the parameter `copy` is ignored .", "question_id": 8239},
{"snippet": "Series.rename_axis(inplace=False)", "intent": "Set the name of the `axis` for the `index` or `columns` . With arguments `inplace`.", "question_id": 8240},
{"snippet": "Series.rename_axis(mapper=None, index=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 8241},
{"snippet": "Series.rename_axis(mapper=None, columns=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 8242},
{"snippet": "Series.rename_axis(mapper=None, axis=None)", "intent": "Set the name of the `axis` for the `index` or `columns` . The second calling convention will modify the names of the corresponding index if `mapper` is a list or a scalar .", "question_id": 8243},
{"snippet": "Series.reorder_levels(order)", "intent": "Rearrange index levels using input `order` .", "question_id": 8244},
{"snippet": "Series.reorder_levels(order)", "intent": "Rearrange index levels using input `order` .", "question_id": 8245},
{"snippet": "Series.reorder_levels(order)", "intent": "Rearrange index levels using input `order` .", "question_id": 8246},
{"snippet": "Series.repeat(repeats)", "intent": "Repeat elements of a Series . With arguments `repeats`.", "question_id": 8247},
{"snippet": "Series.repeat(repeats, axis=None)", "intent": "Repeat elements of a Series . With arguments `repeats`, `axis`.", "question_id": 8248},
{"snippet": "Series.repeat(repeats)", "intent": "Repeat elements of a Series . With arguments `repeats`.", "question_id": 8249},
{"snippet": "Series.repeat(repeats, axis=None)", "intent": "Repeat elements of a Series . With arguments `repeats`, `axis`.", "question_id": 8250},
{"snippet": "Series.repeat(repeats)", "intent": "Repeat elements of a Series . With arguments `repeats`.", "question_id": 8251},
{"snippet": "Series.repeat(repeats, axis=None)", "intent": "Repeat elements of a Series . With arguments `repeats`, `axis`.", "question_id": 8252},
{"snippet": "Series.replace()", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 8253},
{"snippet": "Series.replace(to_replace=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 8254},
{"snippet": "Series.replace(value=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 8255},
{"snippet": "Series.replace(inplace=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `inplace`.", "question_id": 8256},
{"snippet": "Series.replace(limit=None)", "intent": "Replace values given in `to_replace` with `value` . With arguments `limit`.", "question_id": 8257},
{"snippet": "Series.replace(regex=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `regex`.", "question_id": 8258},
{"snippet": "Series.replace(method='pad')", "intent": "Replace values given in `to_replace` with `value` . When value=None and to_replace is a scalar , list or tuple , replace uses the `method` parameter ( default \u2018 pad \u2019 ) to do the replacement .", "question_id": 8259},
{"snippet": "Series.replace(to_replace=None, value=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 8260},
{"snippet": "Series.replace(to_replace=None, inplace=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `inplace`.", "question_id": 8261},
{"snippet": "Series.replace(to_replace=None, limit=None)", "intent": "Replace values given in `to_replace` with `value` . With arguments `limit`.", "question_id": 8262},
{"snippet": "Series.replace()", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 8263},
{"snippet": "Series.replace(to_replace=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 8264},
{"snippet": "Series.replace(value=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 8265},
{"snippet": "Series.replace(inplace=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `inplace`.", "question_id": 8266},
{"snippet": "Series.replace(limit=None)", "intent": "Replace values given in `to_replace` with `value` . With arguments `limit`.", "question_id": 8267},
{"snippet": "Series.replace(regex=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `regex`.", "question_id": 8268},
{"snippet": "Series.replace(method='pad')", "intent": "Replace values given in `to_replace` with `value` . When value=None and to_replace is a scalar , list or tuple , replace uses the `method` parameter ( default \u2018 pad \u2019 ) to do the replacement .", "question_id": 8269},
{"snippet": "Series.replace(to_replace=None, value=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 8270},
{"snippet": "Series.replace(to_replace=None, inplace=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `inplace`.", "question_id": 8271},
{"snippet": "Series.replace(to_replace=None, limit=None)", "intent": "Replace values given in `to_replace` with `value` . With arguments `limit`.", "question_id": 8272},
{"snippet": "Series.replace()", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 8273},
{"snippet": "Series.replace(to_replace=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 8274},
{"snippet": "Series.replace(value=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 8275},
{"snippet": "Series.replace(inplace=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `inplace`.", "question_id": 8276},
{"snippet": "Series.replace(limit=None)", "intent": "Replace values given in `to_replace` with `value` . With arguments `limit`.", "question_id": 8277},
{"snippet": "Series.replace(regex=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `regex`.", "question_id": 8278},
{"snippet": "Series.replace(method='pad')", "intent": "Replace values given in `to_replace` with `value` . When value=None and to_replace is a scalar , list or tuple , replace uses the `method` parameter ( default \u2018 pad \u2019 ) to do the replacement .", "question_id": 8279},
{"snippet": "Series.replace(to_replace=None, value=None)", "intent": "Replace values given in `to_replace` with `value` .", "question_id": 8280},
{"snippet": "Series.replace(to_replace=None, inplace=False)", "intent": "Replace values given in `to_replace` with `value` . With arguments `inplace`.", "question_id": 8281},
{"snippet": "Series.replace(to_replace=None, limit=None)", "intent": "Replace values given in `to_replace` with `value` . With arguments `limit`.", "question_id": 8282},
{"snippet": "Series.resample(rule)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` .", "question_id": 8283},
{"snippet": "Series.resample(rule, axis=0)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `axis`.", "question_id": 8284},
{"snippet": "Series.resample(rule, closed=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `closed`.", "question_id": 8285},
{"snippet": "Series.resample(rule, label=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . The object must have a datetime-like index ( DatetimeIndex , PeriodIndex , or TimedeltaIndex ) , or the caller must pass the `label` of a datetime-like series/index to the on/level keyword parameter .", "question_id": 8286},
{"snippet": "Series.resample(rule, convention='start')", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` .", "question_id": 8287},
{"snippet": "Series.resample(rule, kind=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `kind`.", "question_id": 8288},
{"snippet": "Series.resample(rule, loffset=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . To replace the use of the deprecated `loffset` argument :", "question_id": 8289},
{"snippet": "Series.resample(rule, base=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . To replace the use of the deprecated `base` argument , you can now use offset , in this example it is equivalent to have base=2 :", "question_id": 8290},
{"snippet": "Series.resample(rule, on=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . For DataFrame objects , the keyword `on` can be used to specify the column instead of the index for resampling .", "question_id": 8291},
{"snippet": "Series.resample(rule, level=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . For a DataFrame with MultiIndex , the keyword `level` can be used to specify on which level the resampling needs to take place .", "question_id": 8292},
{"snippet": "Series.resample(rule)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` .", "question_id": 8293},
{"snippet": "Series.resample(rule, axis=0)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `axis`.", "question_id": 8294},
{"snippet": "Series.resample(rule, closed=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `closed`.", "question_id": 8295},
{"snippet": "Series.resample(rule, label=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . The object must have a datetime-like index ( DatetimeIndex , PeriodIndex , or TimedeltaIndex ) , or the caller must pass the `label` of a datetime-like series/index to the on/level keyword parameter .", "question_id": 8296},
{"snippet": "Series.resample(rule, convention='start')", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` .", "question_id": 8297},
{"snippet": "Series.resample(rule, kind=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `kind`.", "question_id": 8298},
{"snippet": "Series.resample(rule, loffset=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . To replace the use of the deprecated `loffset` argument :", "question_id": 8299},
{"snippet": "Series.resample(rule, base=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . To replace the use of the deprecated `base` argument , you can now use offset , in this example it is equivalent to have base=2 :", "question_id": 8300},
{"snippet": "Series.resample(rule, on=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . For DataFrame objects , the keyword `on` can be used to specify the column instead of the index for resampling .", "question_id": 8301},
{"snippet": "Series.resample(rule, level=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . For a DataFrame with MultiIndex , the keyword `level` can be used to specify on which level the resampling needs to take place .", "question_id": 8302},
{"snippet": "Series.resample(rule)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` .", "question_id": 8303},
{"snippet": "Series.resample(rule, axis=0)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `axis`.", "question_id": 8304},
{"snippet": "Series.resample(rule, closed=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `closed`.", "question_id": 8305},
{"snippet": "Series.resample(rule, label=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . The object must have a datetime-like index ( DatetimeIndex , PeriodIndex , or TimedeltaIndex ) , or the caller must pass the `label` of a datetime-like series/index to the on/level keyword parameter .", "question_id": 8306},
{"snippet": "Series.resample(rule, convention='start')", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` .", "question_id": 8307},
{"snippet": "Series.resample(rule, kind=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . With arguments `kind`.", "question_id": 8308},
{"snippet": "Series.resample(rule, loffset=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . To replace the use of the deprecated `loffset` argument :", "question_id": 8309},
{"snippet": "Series.resample(rule, base=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . To replace the use of the deprecated `base` argument , you can now use offset , in this example it is equivalent to have base=2 :", "question_id": 8310},
{"snippet": "Series.resample(rule, on=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . For DataFrame objects , the keyword `on` can be used to specify the column instead of the index for resampling .", "question_id": 8311},
{"snippet": "Series.resample(rule, level=None)", "intent": "Resample time-series data . For a Series with a PeriodIndex , the keyword `convention` can be used to control whether to use the start or end of `rule` . For a DataFrame with MultiIndex , the keyword `level` can be used to specify on which level the resampling needs to take place .", "question_id": 8312},
{"snippet": "Series.reset_index()", "intent": "Generate a new DataFrame or Series with the index reset .", "question_id": 8313},
{"snippet": "Series.reset_index(level=None)", "intent": "Generate a new DataFrame or Series with the index reset . The `level` parameter is interesting for Series with a multi-level index .", "question_id": 8314},
{"snippet": "Series.reset_index(drop=False)", "intent": "Generate a new DataFrame or Series with the index reset . To generate a new Series with the default set `drop` to True .", "question_id": 8315},
{"snippet": "Series.reset_index(name=None)", "intent": "Generate a new DataFrame or Series with the index reset . To specify the `name` of the new column use name .", "question_id": 8316},
{"snippet": "Series.reset_index(inplace=False)", "intent": "Generate a new DataFrame or Series with the index reset . To update the Series in place , without generating a new one set `inplace` to True .", "question_id": 8317},
{"snippet": "Series.reset_index(level=None, drop=False)", "intent": "Generate a new DataFrame or Series with the index reset . The `level` parameter is interesting for Series with a multi-level index . To generate a new Series with the default set `drop` to True .", "question_id": 8318},
{"snippet": "Series.reset_index(level=None, name=None)", "intent": "Generate a new DataFrame or Series with the index reset . The `level` parameter is interesting for Series with a multi-level index . To specify the `name` of the new column use name .", "question_id": 8319},
{"snippet": "Series.reset_index(level=None, inplace=False)", "intent": "Generate a new DataFrame or Series with the index reset . The `level` parameter is interesting for Series with a multi-level index . To update the Series in place , without generating a new one set `inplace` to True .", "question_id": 8320},
{"snippet": "Series.reset_index(drop=False, name=None)", "intent": "Generate a new DataFrame or Series with the index reset . To generate a new Series with the default set `drop` to True . To specify the `name` of the new column use name .", "question_id": 8321},
{"snippet": "Series.reset_index(drop=False, inplace=False)", "intent": "Generate a new DataFrame or Series with the index reset . To generate a new Series with the default set `drop` to True . To update the Series in place , without generating a new one set `inplace` to True .", "question_id": 8322},
{"snippet": "Series.reset_index()", "intent": "Generate a new DataFrame or Series with the index reset .", "question_id": 8323},
{"snippet": "Series.reset_index(level=None)", "intent": "Generate a new DataFrame or Series with the index reset . The `level` parameter is interesting for Series with a multi-level index .", "question_id": 8324},
{"snippet": "Series.reset_index(drop=False)", "intent": "Generate a new DataFrame or Series with the index reset . To generate a new Series with the default set `drop` to True .", "question_id": 8325},
{"snippet": "Series.reset_index(name=None)", "intent": "Generate a new DataFrame or Series with the index reset . To specify the `name` of the new column use name .", "question_id": 8326},
{"snippet": "Series.reset_index(inplace=False)", "intent": "Generate a new DataFrame or Series with the index reset . To update the Series in place , without generating a new one set `inplace` to True .", "question_id": 8327},
{"snippet": "Series.reset_index(level=None, drop=False)", "intent": "Generate a new DataFrame or Series with the index reset . The `level` parameter is interesting for Series with a multi-level index . To generate a new Series with the default set `drop` to True .", "question_id": 8328},
{"snippet": "Series.reset_index(level=None, name=None)", "intent": "Generate a new DataFrame or Series with the index reset . The `level` parameter is interesting for Series with a multi-level index . To specify the `name` of the new column use name .", "question_id": 8329},
{"snippet": "Series.reset_index(level=None, inplace=False)", "intent": "Generate a new DataFrame or Series with the index reset . The `level` parameter is interesting for Series with a multi-level index . To update the Series in place , without generating a new one set `inplace` to True .", "question_id": 8330},
{"snippet": "Series.reset_index(drop=False, name=None)", "intent": "Generate a new DataFrame or Series with the index reset . To generate a new Series with the default set `drop` to True . To specify the `name` of the new column use name .", "question_id": 8331},
{"snippet": "Series.reset_index(drop=False, inplace=False)", "intent": "Generate a new DataFrame or Series with the index reset . To generate a new Series with the default set `drop` to True . To update the Series in place , without generating a new one set `inplace` to True .", "question_id": 8332},
{"snippet": "Series.reset_index()", "intent": "Generate a new DataFrame or Series with the index reset .", "question_id": 8333},
{"snippet": "Series.reset_index(level=None)", "intent": "Generate a new DataFrame or Series with the index reset . The `level` parameter is interesting for Series with a multi-level index .", "question_id": 8334},
{"snippet": "Series.reset_index(drop=False)", "intent": "Generate a new DataFrame or Series with the index reset . To generate a new Series with the default set `drop` to True .", "question_id": 8335},
{"snippet": "Series.reset_index(name=None)", "intent": "Generate a new DataFrame or Series with the index reset . To specify the `name` of the new column use name .", "question_id": 8336},
{"snippet": "Series.reset_index(inplace=False)", "intent": "Generate a new DataFrame or Series with the index reset . To update the Series in place , without generating a new one set `inplace` to True .", "question_id": 8337},
{"snippet": "Series.reset_index(level=None, drop=False)", "intent": "Generate a new DataFrame or Series with the index reset . The `level` parameter is interesting for Series with a multi-level index . To generate a new Series with the default set `drop` to True .", "question_id": 8338},
{"snippet": "Series.reset_index(level=None, name=None)", "intent": "Generate a new DataFrame or Series with the index reset . The `level` parameter is interesting for Series with a multi-level index . To specify the `name` of the new column use name .", "question_id": 8339},
{"snippet": "Series.reset_index(level=None, inplace=False)", "intent": "Generate a new DataFrame or Series with the index reset . The `level` parameter is interesting for Series with a multi-level index . To update the Series in place , without generating a new one set `inplace` to True .", "question_id": 8340},
{"snippet": "Series.reset_index(drop=False, name=None)", "intent": "Generate a new DataFrame or Series with the index reset . To generate a new Series with the default set `drop` to True . To specify the `name` of the new column use name .", "question_id": 8341},
{"snippet": "Series.reset_index(drop=False, inplace=False)", "intent": "Generate a new DataFrame or Series with the index reset . To generate a new Series with the default set `drop` to True . To update the Series in place , without generating a new one set `inplace` to True .", "question_id": 8342},
{"snippet": "Series.rfloordiv(other)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) .", "question_id": 8343},
{"snippet": "Series.rfloordiv(other, level=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . With arguments `level`.", "question_id": 8344},
{"snippet": "Series.rfloordiv(other, fill_value=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8345},
{"snippet": "Series.rfloordiv(other, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . With arguments `axis`.", "question_id": 8346},
{"snippet": "Series.rfloordiv(other, level=None, fill_value=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8347},
{"snippet": "Series.rfloordiv(other, level=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . With arguments `level`, `axis`.", "question_id": 8348},
{"snippet": "Series.rfloordiv(other, fill_value=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8349},
{"snippet": "Series.rfloordiv(other, level=None, fill_value=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8350},
{"snippet": "Series.rfloordiv(other)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) .", "question_id": 8351},
{"snippet": "Series.rfloordiv(other, level=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . With arguments `level`.", "question_id": 8352},
{"snippet": "Series.rfloordiv(other, fill_value=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8353},
{"snippet": "Series.rfloordiv(other, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . With arguments `axis`.", "question_id": 8354},
{"snippet": "Series.rfloordiv(other, level=None, fill_value=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8355},
{"snippet": "Series.rfloordiv(other, level=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . With arguments `level`, `axis`.", "question_id": 8356},
{"snippet": "Series.rfloordiv(other, fill_value=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8357},
{"snippet": "Series.rfloordiv(other, level=None, fill_value=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8358},
{"snippet": "Series.rfloordiv(other)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) .", "question_id": 8359},
{"snippet": "Series.rfloordiv(other, level=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . With arguments `level`.", "question_id": 8360},
{"snippet": "Series.rfloordiv(other, fill_value=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8361},
{"snippet": "Series.rfloordiv(other, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . With arguments `axis`.", "question_id": 8362},
{"snippet": "Series.rfloordiv(other, level=None, fill_value=None)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8363},
{"snippet": "Series.rfloordiv(other, level=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . With arguments `level`, `axis`.", "question_id": 8364},
{"snippet": "Series.rfloordiv(other, fill_value=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8365},
{"snippet": "Series.rfloordiv(other, level=None, fill_value=None, axis=0)", "intent": "Return Integer division of series and `other` , element-wise ( binary operator rfloordiv ) . Equivalent to other // series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8366},
{"snippet": "Series.rmod(other)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) .", "question_id": 8367},
{"snippet": "Series.rmod(other, level=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . With arguments `level`.", "question_id": 8368},
{"snippet": "Series.rmod(other, fill_value=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . Equivalent to other % series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8369},
{"snippet": "Series.rmod(other, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . With arguments `axis`.", "question_id": 8370},
{"snippet": "Series.rmod(other, level=None, fill_value=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . Equivalent to other % series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8371},
{"snippet": "Series.rmod(other, level=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . With arguments `level`, `axis`.", "question_id": 8372},
{"snippet": "Series.rmod(other, fill_value=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . Equivalent to other % series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8373},
{"snippet": "Series.rmod(other, level=None, fill_value=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . Equivalent to other % series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8374},
{"snippet": "Series.rmod(other)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) .", "question_id": 8375},
{"snippet": "Series.rmod(other, level=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . With arguments `level`.", "question_id": 8376},
{"snippet": "Series.rmod(other, fill_value=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . Equivalent to other % series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8377},
{"snippet": "Series.rmod(other, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . With arguments `axis`.", "question_id": 8378},
{"snippet": "Series.rmod(other, level=None, fill_value=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . Equivalent to other % series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8379},
{"snippet": "Series.rmod(other, level=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . With arguments `level`, `axis`.", "question_id": 8380},
{"snippet": "Series.rmod(other, fill_value=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . Equivalent to other % series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8381},
{"snippet": "Series.rmod(other, level=None, fill_value=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . Equivalent to other % series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8382},
{"snippet": "Series.rmod(other)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) .", "question_id": 8383},
{"snippet": "Series.rmod(other, level=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . With arguments `level`.", "question_id": 8384},
{"snippet": "Series.rmod(other, fill_value=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . Equivalent to other % series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8385},
{"snippet": "Series.rmod(other, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . With arguments `axis`.", "question_id": 8386},
{"snippet": "Series.rmod(other, level=None, fill_value=None)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . Equivalent to other % series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8387},
{"snippet": "Series.rmod(other, level=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . With arguments `level`, `axis`.", "question_id": 8388},
{"snippet": "Series.rmod(other, fill_value=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . Equivalent to other % series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8389},
{"snippet": "Series.rmod(other, level=None, fill_value=None, axis=0)", "intent": "Return Modulo of series and `other` , element-wise ( binary operator rmod ) . Equivalent to other % series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8390},
{"snippet": "Series.rmul(other)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) .", "question_id": 8391},
{"snippet": "Series.rmul(other, level=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . With arguments `level`.", "question_id": 8392},
{"snippet": "Series.rmul(other, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . Equivalent to other * series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8393},
{"snippet": "Series.rmul(other, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . With arguments `axis`.", "question_id": 8394},
{"snippet": "Series.rmul(other, level=None, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . Equivalent to other * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8395},
{"snippet": "Series.rmul(other, level=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . With arguments `level`, `axis`.", "question_id": 8396},
{"snippet": "Series.rmul(other, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . Equivalent to other * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8397},
{"snippet": "Series.rmul(other, level=None, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . Equivalent to other * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8398},
{"snippet": "Series.rmul(other)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) .", "question_id": 8399},
{"snippet": "Series.rmul(other, level=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . With arguments `level`.", "question_id": 8400},
{"snippet": "Series.rmul(other, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . Equivalent to other * series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8401},
{"snippet": "Series.rmul(other, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . With arguments `axis`.", "question_id": 8402},
{"snippet": "Series.rmul(other, level=None, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . Equivalent to other * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8403},
{"snippet": "Series.rmul(other, level=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . With arguments `level`, `axis`.", "question_id": 8404},
{"snippet": "Series.rmul(other, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . Equivalent to other * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8405},
{"snippet": "Series.rmul(other, level=None, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . Equivalent to other * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8406},
{"snippet": "Series.rmul(other)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) .", "question_id": 8407},
{"snippet": "Series.rmul(other, level=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . With arguments `level`.", "question_id": 8408},
{"snippet": "Series.rmul(other, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . Equivalent to other * series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8409},
{"snippet": "Series.rmul(other, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . With arguments `axis`.", "question_id": 8410},
{"snippet": "Series.rmul(other, level=None, fill_value=None)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . Equivalent to other * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8411},
{"snippet": "Series.rmul(other, level=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . With arguments `level`, `axis`.", "question_id": 8412},
{"snippet": "Series.rmul(other, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . Equivalent to other * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8413},
{"snippet": "Series.rmul(other, level=None, fill_value=None, axis=0)", "intent": "Return Multiplication of series and `other` , element-wise ( binary operator rmul ) . Equivalent to other * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8414},
{"snippet": "Series.rolling(window)", "intent": "Provide rolling `window` calculations .", "question_id": 8415},
{"snippet": "Series.rolling(window, min_periods=None)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length .", "question_id": 8416},
{"snippet": "Series.rolling(window, center=False)", "intent": "Provide rolling `window` calculations . This can be changed to the `center` of the window by setting center=True .", "question_id": 8417},
{"snippet": "Series.rolling(window, win_type=None)", "intent": "Provide rolling `window` calculations . If win_type=None , all points are evenly weighted ; otherwise , `win_type` can accept a string of any scipy.signal window function .", "question_id": 8418},
{"snippet": "Series.rolling(window, on=None)", "intent": "Provide rolling `window` calculations . Please see the third example below `on` how to add the additional parameters .", "question_id": 8419},
{"snippet": "Series.rolling(window, axis=0)", "intent": "Provide rolling `window` calculations . With arguments `axis`.", "question_id": 8420},
{"snippet": "Series.rolling(window, closed=None)", "intent": "Provide rolling `window` calculations . With arguments `closed`.", "question_id": 8421},
{"snippet": "Series.rolling(window, method='single')", "intent": "Provide rolling `window` calculations . The additional parameters must match the keywords specified in the Scipy window type `method` signature .", "question_id": 8422},
{"snippet": "Series.rolling(window, min_periods=None, center=False)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length . This can be changed to the `center` of the window by setting center=True .", "question_id": 8423},
{"snippet": "Series.rolling(window, min_periods=None, win_type=None)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length . If win_type=None , all points are evenly weighted ; otherwise , `win_type` can accept a string of any scipy.signal window function .", "question_id": 8424},
{"snippet": "Series.rolling(window)", "intent": "Provide rolling `window` calculations .", "question_id": 8425},
{"snippet": "Series.rolling(window, min_periods=None)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length .", "question_id": 8426},
{"snippet": "Series.rolling(window, center=False)", "intent": "Provide rolling `window` calculations . This can be changed to the `center` of the window by setting center=True .", "question_id": 8427},
{"snippet": "Series.rolling(window, win_type=None)", "intent": "Provide rolling `window` calculations . If win_type=None , all points are evenly weighted ; otherwise , `win_type` can accept a string of any scipy.signal window function .", "question_id": 8428},
{"snippet": "Series.rolling(window, on=None)", "intent": "Provide rolling `window` calculations . Please see the third example below `on` how to add the additional parameters .", "question_id": 8429},
{"snippet": "Series.rolling(window, axis=0)", "intent": "Provide rolling `window` calculations . With arguments `axis`.", "question_id": 8430},
{"snippet": "Series.rolling(window, closed=None)", "intent": "Provide rolling `window` calculations . With arguments `closed`.", "question_id": 8431},
{"snippet": "Series.rolling(window, method='single')", "intent": "Provide rolling `window` calculations . The additional parameters must match the keywords specified in the Scipy window type `method` signature .", "question_id": 8432},
{"snippet": "Series.rolling(window, min_periods=None, center=False)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length . This can be changed to the `center` of the window by setting center=True .", "question_id": 8433},
{"snippet": "Series.rolling(window, min_periods=None, win_type=None)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length . If win_type=None , all points are evenly weighted ; otherwise , `win_type` can accept a string of any scipy.signal window function .", "question_id": 8434},
{"snippet": "Series.rolling(window)", "intent": "Provide rolling `window` calculations .", "question_id": 8435},
{"snippet": "Series.rolling(window, min_periods=None)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length .", "question_id": 8436},
{"snippet": "Series.rolling(window, center=False)", "intent": "Provide rolling `window` calculations . This can be changed to the `center` of the window by setting center=True .", "question_id": 8437},
{"snippet": "Series.rolling(window, win_type=None)", "intent": "Provide rolling `window` calculations . If win_type=None , all points are evenly weighted ; otherwise , `win_type` can accept a string of any scipy.signal window function .", "question_id": 8438},
{"snippet": "Series.rolling(window, on=None)", "intent": "Provide rolling `window` calculations . Please see the third example below `on` how to add the additional parameters .", "question_id": 8439},
{"snippet": "Series.rolling(window, axis=0)", "intent": "Provide rolling `window` calculations . With arguments `axis`.", "question_id": 8440},
{"snippet": "Series.rolling(window, closed=None)", "intent": "Provide rolling `window` calculations . With arguments `closed`.", "question_id": 8441},
{"snippet": "Series.rolling(window, method='single')", "intent": "Provide rolling `window` calculations . The additional parameters must match the keywords specified in the Scipy window type `method` signature .", "question_id": 8442},
{"snippet": "Series.rolling(window, min_periods=None, center=False)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length . This can be changed to the `center` of the window by setting center=True .", "question_id": 8443},
{"snippet": "Series.rolling(window, min_periods=None, win_type=None)", "intent": "Provide rolling `window` calculations . Rolling sum with a window length of 2 , `min_periods` defaults to the window length . If win_type=None , all points are evenly weighted ; otherwise , `win_type` can accept a string of any scipy.signal window function .", "question_id": 8444},
{"snippet": "Series.round(*args, **kwargs)", "intent": "Round each value in a Series to the given number of `decimals` . With arguments `*args`, `**kwargs`.", "question_id": 8445},
{"snippet": "Series.round(*args, **kwargs, decimals=0)", "intent": "Round each value in a Series to the given number of `decimals` . With arguments `*args`, `**kwargs`.", "question_id": 8446},
{"snippet": "Series.round(*args, **kwargs)", "intent": "Round each value in a Series to the given number of `decimals` . With arguments `*args`, `**kwargs`.", "question_id": 8447},
{"snippet": "Series.round(*args, **kwargs, decimals=0)", "intent": "Round each value in a Series to the given number of `decimals` . With arguments `*args`, `**kwargs`.", "question_id": 8448},
{"snippet": "Series.round(*args, **kwargs)", "intent": "Round each value in a Series to the given number of `decimals` . With arguments `*args`, `**kwargs`.", "question_id": 8449},
{"snippet": "Series.round(*args, **kwargs, decimals=0)", "intent": "Round each value in a Series to the given number of `decimals` . With arguments `*args`, `**kwargs`.", "question_id": 8450},
{"snippet": "Series.rpow(other)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) .", "question_id": 8451},
{"snippet": "Series.rpow(other, level=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . With arguments `level`.", "question_id": 8452},
{"snippet": "Series.rpow(other, fill_value=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8453},
{"snippet": "Series.rpow(other, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . With arguments `axis`.", "question_id": 8454},
{"snippet": "Series.rpow(other, level=None, fill_value=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8455},
{"snippet": "Series.rpow(other, level=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . With arguments `level`, `axis`.", "question_id": 8456},
{"snippet": "Series.rpow(other, fill_value=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8457},
{"snippet": "Series.rpow(other, level=None, fill_value=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8458},
{"snippet": "Series.rpow(other)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) .", "question_id": 8459},
{"snippet": "Series.rpow(other, level=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . With arguments `level`.", "question_id": 8460},
{"snippet": "Series.rpow(other, fill_value=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8461},
{"snippet": "Series.rpow(other, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . With arguments `axis`.", "question_id": 8462},
{"snippet": "Series.rpow(other, level=None, fill_value=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8463},
{"snippet": "Series.rpow(other, level=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . With arguments `level`, `axis`.", "question_id": 8464},
{"snippet": "Series.rpow(other, fill_value=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8465},
{"snippet": "Series.rpow(other, level=None, fill_value=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8466},
{"snippet": "Series.rpow(other)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) .", "question_id": 8467},
{"snippet": "Series.rpow(other, level=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . With arguments `level`.", "question_id": 8468},
{"snippet": "Series.rpow(other, fill_value=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8469},
{"snippet": "Series.rpow(other, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . With arguments `axis`.", "question_id": 8470},
{"snippet": "Series.rpow(other, level=None, fill_value=None)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8471},
{"snippet": "Series.rpow(other, level=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . With arguments `level`, `axis`.", "question_id": 8472},
{"snippet": "Series.rpow(other, fill_value=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8473},
{"snippet": "Series.rpow(other, level=None, fill_value=None, axis=0)", "intent": "Return Exponential power of series and `other` , element-wise ( binary operator rpow ) . Equivalent to other * * series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8474},
{"snippet": "Series.rsub(other)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) .", "question_id": 8475},
{"snippet": "Series.rsub(other, level=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . With arguments `level`.", "question_id": 8476},
{"snippet": "Series.rsub(other, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . Equivalent to other - series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8477},
{"snippet": "Series.rsub(other, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . With arguments `axis`.", "question_id": 8478},
{"snippet": "Series.rsub(other, level=None, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . Equivalent to other - series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8479},
{"snippet": "Series.rsub(other, level=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . With arguments `level`, `axis`.", "question_id": 8480},
{"snippet": "Series.rsub(other, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . Equivalent to other - series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8481},
{"snippet": "Series.rsub(other, level=None, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . Equivalent to other - series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8482},
{"snippet": "Series.rsub(other)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) .", "question_id": 8483},
{"snippet": "Series.rsub(other, level=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . With arguments `level`.", "question_id": 8484},
{"snippet": "Series.rsub(other, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . Equivalent to other - series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8485},
{"snippet": "Series.rsub(other, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . With arguments `axis`.", "question_id": 8486},
{"snippet": "Series.rsub(other, level=None, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . Equivalent to other - series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8487},
{"snippet": "Series.rsub(other, level=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . With arguments `level`, `axis`.", "question_id": 8488},
{"snippet": "Series.rsub(other, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . Equivalent to other - series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8489},
{"snippet": "Series.rsub(other, level=None, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . Equivalent to other - series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8490},
{"snippet": "Series.rsub(other)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) .", "question_id": 8491},
{"snippet": "Series.rsub(other, level=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . With arguments `level`.", "question_id": 8492},
{"snippet": "Series.rsub(other, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . Equivalent to other - series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8493},
{"snippet": "Series.rsub(other, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . With arguments `axis`.", "question_id": 8494},
{"snippet": "Series.rsub(other, level=None, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . Equivalent to other - series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8495},
{"snippet": "Series.rsub(other, level=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . With arguments `level`, `axis`.", "question_id": 8496},
{"snippet": "Series.rsub(other, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . Equivalent to other - series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8497},
{"snippet": "Series.rsub(other, level=None, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator rsub ) . Equivalent to other - series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8498},
{"snippet": "Series.rtruediv(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) .", "question_id": 8499},
{"snippet": "Series.rtruediv(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `level`.", "question_id": 8500},
{"snippet": "Series.rtruediv(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8501},
{"snippet": "Series.rtruediv(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `axis`.", "question_id": 8502},
{"snippet": "Series.rtruediv(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8503},
{"snippet": "Series.rtruediv(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `level`, `axis`.", "question_id": 8504},
{"snippet": "Series.rtruediv(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8505},
{"snippet": "Series.rtruediv(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8506},
{"snippet": "Series.rtruediv(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) .", "question_id": 8507},
{"snippet": "Series.rtruediv(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `level`.", "question_id": 8508},
{"snippet": "Series.rtruediv(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8509},
{"snippet": "Series.rtruediv(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `axis`.", "question_id": 8510},
{"snippet": "Series.rtruediv(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8511},
{"snippet": "Series.rtruediv(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `level`, `axis`.", "question_id": 8512},
{"snippet": "Series.rtruediv(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8513},
{"snippet": "Series.rtruediv(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8514},
{"snippet": "Series.rtruediv(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) .", "question_id": 8515},
{"snippet": "Series.rtruediv(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `level`.", "question_id": 8516},
{"snippet": "Series.rtruediv(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 8517},
{"snippet": "Series.rtruediv(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `axis`.", "question_id": 8518},
{"snippet": "Series.rtruediv(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 8519},
{"snippet": "Series.rtruediv(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . With arguments `level`, `axis`.", "question_id": 8520},
{"snippet": "Series.rtruediv(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 8521},
{"snippet": "Series.rtruediv(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator rtruediv ) . Equivalent to other / series , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 8522},
{"snippet": "Series.sample()", "intent": "Return a random sample of items from an `axis` of object .", "question_id": 8523},
{"snippet": "Series.sample(n=None)", "intent": "Return a random sample of items from an `axis` of object . With arguments `n`.", "question_id": 8524},
{"snippet": "Series.sample(frac=None)", "intent": "Return a random sample of items from an `axis` of object . If `frac` > 1 , replacement should be set to True .", "question_id": 8525},
{"snippet": "Series.sample(replace=False)", "intent": "Return a random sample of items from an `axis` of object . An upsample sample of the DataFrame with replacement : Note that `replace` parameter has to be True for frac parameter > 1 .", "question_id": 8526},
{"snippet": "Series.sample(weights=None)", "intent": "Return a random sample of items from an `axis` of object . Using a DataFrame column as `weights` .", "question_id": 8527},
{"snippet": "Series.sample(random_state=None)", "intent": "Return a random sample of items from an `axis` of object . You can use `random_state` for reproducibility .", "question_id": 8528},
{"snippet": "Series.sample(axis=None)", "intent": "Return a random sample of items from an `axis` of object .", "question_id": 8529},
{"snippet": "Series.sample(ignore_index=False)", "intent": "Return a random sample of items from an `axis` of object . With arguments `ignore_index`.", "question_id": 8530},
{"snippet": "Series.sample(n=None, frac=None)", "intent": "Return a random sample of items from an `axis` of object . If `frac` > 1 , replacement should be set to True . With arguments `n`.", "question_id": 8531},
{"snippet": "Series.sample(n=None, replace=False)", "intent": "Return a random sample of items from an `axis` of object . An upsample sample of the DataFrame with replacement : Note that `replace` parameter has to be True for frac parameter > 1 . With arguments `n`.", "question_id": 8532},
{"snippet": "Series.sample()", "intent": "Return a random sample of items from an `axis` of object .", "question_id": 8533},
{"snippet": "Series.sample(n=None)", "intent": "Return a random sample of items from an `axis` of object . With arguments `n`.", "question_id": 8534},
{"snippet": "Series.sample(frac=None)", "intent": "Return a random sample of items from an `axis` of object . If `frac` > 1 , replacement should be set to True .", "question_id": 8535},
{"snippet": "Series.sample(replace=False)", "intent": "Return a random sample of items from an `axis` of object . An upsample sample of the DataFrame with replacement : Note that `replace` parameter has to be True for frac parameter > 1 .", "question_id": 8536},
{"snippet": "Series.sample(weights=None)", "intent": "Return a random sample of items from an `axis` of object . Using a DataFrame column as `weights` .", "question_id": 8537},
{"snippet": "Series.sample(random_state=None)", "intent": "Return a random sample of items from an `axis` of object . You can use `random_state` for reproducibility .", "question_id": 8538},
{"snippet": "Series.sample(axis=None)", "intent": "Return a random sample of items from an `axis` of object .", "question_id": 8539},
{"snippet": "Series.sample(ignore_index=False)", "intent": "Return a random sample of items from an `axis` of object . With arguments `ignore_index`.", "question_id": 8540},
{"snippet": "Series.sample(n=None, frac=None)", "intent": "Return a random sample of items from an `axis` of object . If `frac` > 1 , replacement should be set to True . With arguments `n`.", "question_id": 8541},
{"snippet": "Series.sample(n=None, replace=False)", "intent": "Return a random sample of items from an `axis` of object . An upsample sample of the DataFrame with replacement : Note that `replace` parameter has to be True for frac parameter > 1 . With arguments `n`.", "question_id": 8542},
{"snippet": "Series.sample()", "intent": "Return a random sample of items from an `axis` of object .", "question_id": 8543},
{"snippet": "Series.sample(n=None)", "intent": "Return a random sample of items from an `axis` of object . With arguments `n`.", "question_id": 8544},
{"snippet": "Series.sample(frac=None)", "intent": "Return a random sample of items from an `axis` of object . If `frac` > 1 , replacement should be set to True .", "question_id": 8545},
{"snippet": "Series.sample(replace=False)", "intent": "Return a random sample of items from an `axis` of object . An upsample sample of the DataFrame with replacement : Note that `replace` parameter has to be True for frac parameter > 1 .", "question_id": 8546},
{"snippet": "Series.sample(weights=None)", "intent": "Return a random sample of items from an `axis` of object . Using a DataFrame column as `weights` .", "question_id": 8547},
{"snippet": "Series.sample(random_state=None)", "intent": "Return a random sample of items from an `axis` of object . You can use `random_state` for reproducibility .", "question_id": 8548},
{"snippet": "Series.sample(axis=None)", "intent": "Return a random sample of items from an `axis` of object .", "question_id": 8549},
{"snippet": "Series.sample(ignore_index=False)", "intent": "Return a random sample of items from an `axis` of object . With arguments `ignore_index`.", "question_id": 8550},
{"snippet": "Series.sample(n=None, frac=None)", "intent": "Return a random sample of items from an `axis` of object . If `frac` > 1 , replacement should be set to True . With arguments `n`.", "question_id": 8551},
{"snippet": "Series.sample(n=None, replace=False)", "intent": "Return a random sample of items from an `axis` of object . An upsample sample of the DataFrame with replacement : Note that `replace` parameter has to be True for frac parameter > 1 . With arguments `n`.", "question_id": 8552},
{"snippet": "Series.searchsorted(value)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Series self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved .", "question_id": 8553},
{"snippet": "Series.searchsorted(value, side='left')", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Series self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`.", "question_id": 8554},
{"snippet": "Series.searchsorted(value, sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Series self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `sorter`.", "question_id": 8555},
{"snippet": "Series.searchsorted(value, side='left', sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Series self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`, `sorter`.", "question_id": 8556},
{"snippet": "Series.searchsorted(value)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Series self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved .", "question_id": 8557},
{"snippet": "Series.searchsorted(value, side='left')", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Series self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`.", "question_id": 8558},
{"snippet": "Series.searchsorted(value, sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Series self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `sorter`.", "question_id": 8559},
{"snippet": "Series.searchsorted(value, side='left', sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Series self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`, `sorter`.", "question_id": 8560},
{"snippet": "Series.searchsorted(value)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Series self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved .", "question_id": 8561},
{"snippet": "Series.searchsorted(value, side='left')", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Series self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`.", "question_id": 8562},
{"snippet": "Series.searchsorted(value, sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Series self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `sorter`.", "question_id": 8563},
{"snippet": "Series.searchsorted(value, side='left', sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted Series self such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`, `sorter`.", "question_id": 8564},
{"snippet": "Series.sem(**kwargs)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`.", "question_id": 8565},
{"snippet": "Series.sem(**kwargs, axis=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`.", "question_id": 8566},
{"snippet": "Series.sem(**kwargs, skipna=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8567},
{"snippet": "Series.sem(**kwargs, level=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8568},
{"snippet": "Series.sem(**kwargs, ddof=1)", "intent": "Return unbiased standard error of the mean over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 8569},
{"snippet": "Series.sem(**kwargs, numeric_only=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8570},
{"snippet": "Series.sem(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8571},
{"snippet": "Series.sem(**kwargs, axis=None, level=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8572},
{"snippet": "Series.sem(**kwargs, axis=None, ddof=1)", "intent": "Return unbiased standard error of the mean over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 8573},
{"snippet": "Series.sem(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8574},
{"snippet": "Series.sem(**kwargs)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`.", "question_id": 8575},
{"snippet": "Series.sem(**kwargs, axis=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`.", "question_id": 8576},
{"snippet": "Series.sem(**kwargs, skipna=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8577},
{"snippet": "Series.sem(**kwargs, level=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8578},
{"snippet": "Series.sem(**kwargs, ddof=1)", "intent": "Return unbiased standard error of the mean over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 8579},
{"snippet": "Series.sem(**kwargs, numeric_only=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8580},
{"snippet": "Series.sem(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8581},
{"snippet": "Series.sem(**kwargs, axis=None, level=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8582},
{"snippet": "Series.sem(**kwargs, axis=None, ddof=1)", "intent": "Return unbiased standard error of the mean over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 8583},
{"snippet": "Series.sem(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8584},
{"snippet": "Series.sem(**kwargs)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`.", "question_id": 8585},
{"snippet": "Series.sem(**kwargs, axis=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`.", "question_id": 8586},
{"snippet": "Series.sem(**kwargs, skipna=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8587},
{"snippet": "Series.sem(**kwargs, level=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8588},
{"snippet": "Series.sem(**kwargs, ddof=1)", "intent": "Return unbiased standard error of the mean over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 8589},
{"snippet": "Series.sem(**kwargs, numeric_only=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8590},
{"snippet": "Series.sem(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8591},
{"snippet": "Series.sem(**kwargs, axis=None, level=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8592},
{"snippet": "Series.sem(**kwargs, axis=None, ddof=1)", "intent": "Return unbiased standard error of the mean over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 8593},
{"snippet": "Series.sem(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased standard error of the mean over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8594},
{"snippet": "Series.set_axis(labels)", "intent": "Assign desired index to given `axis` . Indexes for row `labels` can be changed by assigning a list-like or Index .", "question_id": 8595},
{"snippet": "Series.set_axis(labels, axis=0)", "intent": "Assign desired index to given `axis` . Indexes for row `labels` can be changed by assigning a list-like or Index .", "question_id": 8596},
{"snippet": "Series.set_axis(labels, inplace=False)", "intent": "Assign desired index to given `axis` . Indexes for row `labels` can be changed by assigning a list-like or Index . With arguments `inplace`.", "question_id": 8597},
{"snippet": "Series.set_axis(labels, axis=0, inplace=False)", "intent": "Assign desired index to given `axis` . Indexes for row `labels` can be changed by assigning a list-like or Index . With arguments `inplace`.", "question_id": 8598},
{"snippet": "Series.set_axis(labels)", "intent": "Assign desired index to given `axis` . Indexes for row `labels` can be changed by assigning a list-like or Index .", "question_id": 8599},
{"snippet": "Series.set_axis(labels, axis=0)", "intent": "Assign desired index to given `axis` . Indexes for row `labels` can be changed by assigning a list-like or Index .", "question_id": 8600},
{"snippet": "Series.set_axis(labels, inplace=False)", "intent": "Assign desired index to given `axis` . Indexes for row `labels` can be changed by assigning a list-like or Index . With arguments `inplace`.", "question_id": 8601},
{"snippet": "Series.set_axis(labels, axis=0, inplace=False)", "intent": "Assign desired index to given `axis` . Indexes for row `labels` can be changed by assigning a list-like or Index . With arguments `inplace`.", "question_id": 8602},
{"snippet": "Series.set_axis(labels)", "intent": "Assign desired index to given `axis` . Indexes for row `labels` can be changed by assigning a list-like or Index .", "question_id": 8603},
{"snippet": "Series.set_axis(labels, axis=0)", "intent": "Assign desired index to given `axis` . Indexes for row `labels` can be changed by assigning a list-like or Index .", "question_id": 8604},
{"snippet": "Series.set_axis(labels, inplace=False)", "intent": "Assign desired index to given `axis` . Indexes for row `labels` can be changed by assigning a list-like or Index . With arguments `inplace`.", "question_id": 8605},
{"snippet": "Series.set_axis(labels, axis=0, inplace=False)", "intent": "Assign desired index to given `axis` . Indexes for row `labels` can be changed by assigning a list-like or Index . With arguments `inplace`.", "question_id": 8606},
{"snippet": "Series.set_flags()", "intent": "Return a new object with updated flags .", "question_id": 8607},
{"snippet": "Series.set_flags(copy=False)", "intent": "Return a new object with updated flags . With arguments `copy`.", "question_id": 8608},
{"snippet": "Series.set_flags(allows_duplicate_labels=None)", "intent": "Return a new object with updated flags . With arguments `allows_duplicate_labels`.", "question_id": 8609},
{"snippet": "Series.set_flags(copy=False, allows_duplicate_labels=None)", "intent": "Return a new object with updated flags . With arguments `copy`, `allows_duplicate_labels`.", "question_id": 8610},
{"snippet": "Series.set_flags()", "intent": "Return a new object with updated flags .", "question_id": 8611},
{"snippet": "Series.set_flags(copy=False)", "intent": "Return a new object with updated flags . With arguments `copy`.", "question_id": 8612},
{"snippet": "Series.set_flags(allows_duplicate_labels=None)", "intent": "Return a new object with updated flags . With arguments `allows_duplicate_labels`.", "question_id": 8613},
{"snippet": "Series.set_flags(copy=False, allows_duplicate_labels=None)", "intent": "Return a new object with updated flags . With arguments `copy`, `allows_duplicate_labels`.", "question_id": 8614},
{"snippet": "Series.set_flags()", "intent": "Return a new object with updated flags .", "question_id": 8615},
{"snippet": "Series.set_flags(copy=False)", "intent": "Return a new object with updated flags . With arguments `copy`.", "question_id": 8616},
{"snippet": "Series.set_flags(allows_duplicate_labels=None)", "intent": "Return a new object with updated flags . With arguments `allows_duplicate_labels`.", "question_id": 8617},
{"snippet": "Series.set_flags(copy=False, allows_duplicate_labels=None)", "intent": "Return a new object with updated flags . With arguments `copy`, `allows_duplicate_labels`.", "question_id": 8618},
{"snippet": "Series.shift()", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 8619},
{"snippet": "Series.shift(periods=1)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 8620},
{"snippet": "Series.shift(freq=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 8621},
{"snippet": "Series.shift(axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 8622},
{"snippet": "Series.shift(fill_value=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 8623},
{"snippet": "Series.shift(periods=1, freq=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 8624},
{"snippet": "Series.shift(periods=1, axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 8625},
{"snippet": "Series.shift(periods=1, fill_value=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 8626},
{"snippet": "Series.shift(freq=None, axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 8627},
{"snippet": "Series.shift(freq=None, fill_value=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 8628},
{"snippet": "Series.shift()", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 8629},
{"snippet": "Series.shift(periods=1)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 8630},
{"snippet": "Series.shift(freq=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 8631},
{"snippet": "Series.shift(axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 8632},
{"snippet": "Series.shift(fill_value=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 8633},
{"snippet": "Series.shift(periods=1, freq=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 8634},
{"snippet": "Series.shift(periods=1, axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 8635},
{"snippet": "Series.shift(periods=1, fill_value=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 8636},
{"snippet": "Series.shift(freq=None, axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 8637},
{"snippet": "Series.shift(freq=None, fill_value=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 8638},
{"snippet": "Series.shift()", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 8639},
{"snippet": "Series.shift(periods=1)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 8640},
{"snippet": "Series.shift(freq=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 8641},
{"snippet": "Series.shift(axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 8642},
{"snippet": "Series.shift(fill_value=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 8643},
{"snippet": "Series.shift(periods=1, freq=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` .", "question_id": 8644},
{"snippet": "Series.shift(periods=1, axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 8645},
{"snippet": "Series.shift(periods=1, fill_value=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 8646},
{"snippet": "Series.shift(freq=None, axis=0)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `axis`.", "question_id": 8647},
{"snippet": "Series.shift(freq=None, fill_value=None)", "intent": "Shift index by desired number of `periods` with an optional time `freq` . With arguments `fill_value`.", "question_id": 8648},
{"snippet": "Series.skew(**kwargs)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`.", "question_id": 8649},
{"snippet": "Series.skew(**kwargs, axis=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`.", "question_id": 8650},
{"snippet": "Series.skew(**kwargs, skipna=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8651},
{"snippet": "Series.skew(**kwargs, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8652},
{"snippet": "Series.skew(**kwargs, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8653},
{"snippet": "Series.skew(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8654},
{"snippet": "Series.skew(**kwargs, axis=None, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8655},
{"snippet": "Series.skew(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8656},
{"snippet": "Series.skew(**kwargs, skipna=None, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 8657},
{"snippet": "Series.skew(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 8658},
{"snippet": "Series.skew(**kwargs)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`.", "question_id": 8659},
{"snippet": "Series.skew(**kwargs, axis=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`.", "question_id": 8660},
{"snippet": "Series.skew(**kwargs, skipna=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8661},
{"snippet": "Series.skew(**kwargs, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8662},
{"snippet": "Series.skew(**kwargs, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8663},
{"snippet": "Series.skew(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8664},
{"snippet": "Series.skew(**kwargs, axis=None, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8665},
{"snippet": "Series.skew(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8666},
{"snippet": "Series.skew(**kwargs, skipna=None, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 8667},
{"snippet": "Series.skew(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 8668},
{"snippet": "Series.skew(**kwargs)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`.", "question_id": 8669},
{"snippet": "Series.skew(**kwargs, axis=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`.", "question_id": 8670},
{"snippet": "Series.skew(**kwargs, skipna=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8671},
{"snippet": "Series.skew(**kwargs, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8672},
{"snippet": "Series.skew(**kwargs, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8673},
{"snippet": "Series.skew(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8674},
{"snippet": "Series.skew(**kwargs, axis=None, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8675},
{"snippet": "Series.skew(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8676},
{"snippet": "Series.skew(**kwargs, skipna=None, level=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`, `level`.", "question_id": 8677},
{"snippet": "Series.skew(**kwargs, skipna=None, numeric_only=None)", "intent": "Return unbiased skew over requested `axis` . With arguments `**kwargs`, `skipna`, `numeric_only`.", "question_id": 8678},
{"snippet": "Series.slice_shift()", "intent": "Equivalent to shift without copying data .", "question_id": 8679},
{"snippet": "Series.slice_shift(periods=1)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 8680},
{"snippet": "Series.slice_shift(axis=0)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 8681},
{"snippet": "Series.slice_shift(periods=1, axis=0)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 8682},
{"snippet": "Series.slice_shift()", "intent": "Equivalent to shift without copying data .", "question_id": 8683},
{"snippet": "Series.slice_shift(periods=1)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 8684},
{"snippet": "Series.slice_shift(axis=0)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 8685},
{"snippet": "Series.slice_shift(periods=1, axis=0)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 8686},
{"snippet": "Series.slice_shift()", "intent": "Equivalent to shift without copying data .", "question_id": 8687},
{"snippet": "Series.slice_shift(periods=1)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 8688},
{"snippet": "Series.slice_shift(axis=0)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 8689},
{"snippet": "Series.slice_shift(periods=1, axis=0)", "intent": "Equivalent to shift without copying data . The shifted data will not include the dropped `periods` and the shifted `axis` will be smaller than the original .", "question_id": 8690},
{"snippet": "Series.sort_index()", "intent": "Sort Series by index labels .", "question_id": 8691},
{"snippet": "Series.sort_index(axis=0)", "intent": "Sort Series by index labels . With arguments `axis`.", "question_id": 8692},
{"snippet": "Series.sort_index(level=None)", "intent": "Sort Series by index labels . Specify index `level` to sort", "question_id": 8693},
{"snippet": "Series.sort_index(ascending=True)", "intent": "Sort Series by index labels . With arguments `ascending`.", "question_id": 8694},
{"snippet": "Series.sort_index(inplace=False)", "intent": "Sort Series by index labels . Returns a new Series sorted by label if `inplace` argument is False , otherwise updates the original series and returns None .", "question_id": 8695},
{"snippet": "Series.sort_index(kind='quicksort')", "intent": "Sort Series by index labels . With arguments `kind`.", "question_id": 8696},
{"snippet": "Series.sort_index(na_position='last')", "intent": "Sort Series by index labels . By default NaNs are put at the end , but use `na_position` to place them at the beginning", "question_id": 8697},
{"snippet": "Series.sort_index(sort_remaining=True)", "intent": "Sort Series by index labels . With arguments `sort_remaining`.", "question_id": 8698},
{"snippet": "Series.sort_index(ignore_index=False)", "intent": "Sort Series by index labels . With arguments `ignore_index`.", "question_id": 8699},
{"snippet": "Series.sort_index(key=None)", "intent": "Sort Series by index labels . Apply a `key` function before sorting", "question_id": 8700},
{"snippet": "Series.sort_index()", "intent": "Sort Series by index labels .", "question_id": 8701},
{"snippet": "Series.sort_index(axis=0)", "intent": "Sort Series by index labels . With arguments `axis`.", "question_id": 8702},
{"snippet": "Series.sort_index(level=None)", "intent": "Sort Series by index labels . Specify index `level` to sort", "question_id": 8703},
{"snippet": "Series.sort_index(ascending=True)", "intent": "Sort Series by index labels . With arguments `ascending`.", "question_id": 8704},
{"snippet": "Series.sort_index(inplace=False)", "intent": "Sort Series by index labels . Returns a new Series sorted by label if `inplace` argument is False , otherwise updates the original series and returns None .", "question_id": 8705},
{"snippet": "Series.sort_index(kind='quicksort')", "intent": "Sort Series by index labels . With arguments `kind`.", "question_id": 8706},
{"snippet": "Series.sort_index(na_position='last')", "intent": "Sort Series by index labels . By default NaNs are put at the end , but use `na_position` to place them at the beginning", "question_id": 8707},
{"snippet": "Series.sort_index(sort_remaining=True)", "intent": "Sort Series by index labels . With arguments `sort_remaining`.", "question_id": 8708},
{"snippet": "Series.sort_index(ignore_index=False)", "intent": "Sort Series by index labels . With arguments `ignore_index`.", "question_id": 8709},
{"snippet": "Series.sort_index(key=None)", "intent": "Sort Series by index labels . Apply a `key` function before sorting", "question_id": 8710},
{"snippet": "Series.sort_index()", "intent": "Sort Series by index labels .", "question_id": 8711},
{"snippet": "Series.sort_index(axis=0)", "intent": "Sort Series by index labels . With arguments `axis`.", "question_id": 8712},
{"snippet": "Series.sort_index(level=None)", "intent": "Sort Series by index labels . Specify index `level` to sort", "question_id": 8713},
{"snippet": "Series.sort_index(ascending=True)", "intent": "Sort Series by index labels . With arguments `ascending`.", "question_id": 8714},
{"snippet": "Series.sort_index(inplace=False)", "intent": "Sort Series by index labels . Returns a new Series sorted by label if `inplace` argument is False , otherwise updates the original series and returns None .", "question_id": 8715},
{"snippet": "Series.sort_index(kind='quicksort')", "intent": "Sort Series by index labels . With arguments `kind`.", "question_id": 8716},
{"snippet": "Series.sort_index(na_position='last')", "intent": "Sort Series by index labels . By default NaNs are put at the end , but use `na_position` to place them at the beginning", "question_id": 8717},
{"snippet": "Series.sort_index(sort_remaining=True)", "intent": "Sort Series by index labels . With arguments `sort_remaining`.", "question_id": 8718},
{"snippet": "Series.sort_index(ignore_index=False)", "intent": "Sort Series by index labels . With arguments `ignore_index`.", "question_id": 8719},
{"snippet": "Series.sort_index(key=None)", "intent": "Sort Series by index labels . Apply a `key` function before sorting", "question_id": 8720},
{"snippet": "Series.sort_values()", "intent": "Sort by the values .", "question_id": 8721},
{"snippet": "Series.sort_values(axis=0)", "intent": "Sort by the values . With arguments `axis`.", "question_id": 8722},
{"snippet": "Series.sort_values(ascending=True)", "intent": "Sort by the values . Sort a Series in `ascending` or descending order by some criterion .", "question_id": 8723},
{"snippet": "Series.sort_values(inplace=False)", "intent": "Sort by the values . Sort values `inplace`", "question_id": 8724},
{"snippet": "Series.sort_values(kind='quicksort')", "intent": "Sort by the values . With arguments `kind`.", "question_id": 8725},
{"snippet": "Series.sort_values(na_position='last')", "intent": "Sort by the values . With arguments `na_position`.", "question_id": 8726},
{"snippet": "Series.sort_values(ignore_index=False)", "intent": "Sort by the values . With arguments `ignore_index`.", "question_id": 8727},
{"snippet": "Series.sort_values(key=None)", "intent": "Sort by the values . Sort using a `key` function .", "question_id": 8728},
{"snippet": "Series.sort_values(axis=0, ascending=True)", "intent": "Sort by the values . Sort a Series in `ascending` or descending order by some criterion . With arguments `axis`.", "question_id": 8729},
{"snippet": "Series.sort_values(axis=0, inplace=False)", "intent": "Sort by the values . Sort values `inplace` With arguments `axis`.", "question_id": 8730},
{"snippet": "Series.sort_values()", "intent": "Sort by the values .", "question_id": 8731},
{"snippet": "Series.sort_values(axis=0)", "intent": "Sort by the values . With arguments `axis`.", "question_id": 8732},
{"snippet": "Series.sort_values(ascending=True)", "intent": "Sort by the values . Sort a Series in `ascending` or descending order by some criterion .", "question_id": 8733},
{"snippet": "Series.sort_values(inplace=False)", "intent": "Sort by the values . Sort values `inplace`", "question_id": 8734},
{"snippet": "Series.sort_values(kind='quicksort')", "intent": "Sort by the values . With arguments `kind`.", "question_id": 8735},
{"snippet": "Series.sort_values(na_position='last')", "intent": "Sort by the values . With arguments `na_position`.", "question_id": 8736},
{"snippet": "Series.sort_values(ignore_index=False)", "intent": "Sort by the values . With arguments `ignore_index`.", "question_id": 8737},
{"snippet": "Series.sort_values(key=None)", "intent": "Sort by the values . Sort using a `key` function .", "question_id": 8738},
{"snippet": "Series.sort_values(axis=0, ascending=True)", "intent": "Sort by the values . Sort a Series in `ascending` or descending order by some criterion . With arguments `axis`.", "question_id": 8739},
{"snippet": "Series.sort_values(axis=0, inplace=False)", "intent": "Sort by the values . Sort values `inplace` With arguments `axis`.", "question_id": 8740},
{"snippet": "Series.sort_values()", "intent": "Sort by the values .", "question_id": 8741},
{"snippet": "Series.sort_values(axis=0)", "intent": "Sort by the values . With arguments `axis`.", "question_id": 8742},
{"snippet": "Series.sort_values(ascending=True)", "intent": "Sort by the values . Sort a Series in `ascending` or descending order by some criterion .", "question_id": 8743},
{"snippet": "Series.sort_values(inplace=False)", "intent": "Sort by the values . Sort values `inplace`", "question_id": 8744},
{"snippet": "Series.sort_values(kind='quicksort')", "intent": "Sort by the values . With arguments `kind`.", "question_id": 8745},
{"snippet": "Series.sort_values(na_position='last')", "intent": "Sort by the values . With arguments `na_position`.", "question_id": 8746},
{"snippet": "Series.sort_values(ignore_index=False)", "intent": "Sort by the values . With arguments `ignore_index`.", "question_id": 8747},
{"snippet": "Series.sort_values(key=None)", "intent": "Sort by the values . Sort using a `key` function .", "question_id": 8748},
{"snippet": "Series.sort_values(axis=0, ascending=True)", "intent": "Sort by the values . Sort a Series in `ascending` or descending order by some criterion . With arguments `axis`.", "question_id": 8749},
{"snippet": "Series.sort_values(axis=0, inplace=False)", "intent": "Sort by the values . Sort values `inplace` With arguments `axis`.", "question_id": 8750},
{"snippet": "Series.sparse.density", "intent": "The percent of non- fill_value points, as decimal.", "question_id": 8751},
{"snippet": "Series.sparse.density", "intent": "The percent of non- fill_value points, as decimal.", "question_id": 8752},
{"snippet": "Series.sparse.density", "intent": "The percent of non- fill_value points, as decimal.", "question_id": 8753},
{"snippet": "Series.sparse.fill_value", "intent": "Elements in data that are fill_value are not stored.", "question_id": 8754},
{"snippet": "Series.sparse.fill_value", "intent": "Elements in data that are fill_value are not stored.", "question_id": 8755},
{"snippet": "Series.sparse.fill_value", "intent": "Elements in data that are fill_value are not stored.", "question_id": 8756},
{"snippet": "Series.sparse.from_coo(A)", "intent": "Create a Series with sparse values from a scipy.sparse.coo_matrix . With arguments `A`.", "question_id": 8757},
{"snippet": "Series.sparse.from_coo(A, dense_index=False)", "intent": "Create a Series with sparse values from a scipy.sparse.coo_matrix . With arguments `A`, `dense_index`.", "question_id": 8758},
{"snippet": "Series.sparse.from_coo(A)", "intent": "Create a Series with sparse values from a scipy.sparse.coo_matrix . With arguments `A`.", "question_id": 8759},
{"snippet": "Series.sparse.from_coo(A, dense_index=False)", "intent": "Create a Series with sparse values from a scipy.sparse.coo_matrix . With arguments `A`, `dense_index`.", "question_id": 8760},
{"snippet": "Series.sparse.from_coo(A)", "intent": "Create a Series with sparse values from a scipy.sparse.coo_matrix . With arguments `A`.", "question_id": 8761},
{"snippet": "Series.sparse.from_coo(A, dense_index=False)", "intent": "Create a Series with sparse values from a scipy.sparse.coo_matrix . With arguments `A`, `dense_index`.", "question_id": 8762},
{"snippet": "Series.sparse()", "intent": "Accessor for SparseSparse from other sparse matrix data types .", "question_id": 8763},
{"snippet": "Series.sparse()", "intent": "Accessor for SparseSparse from other sparse matrix data types .", "question_id": 8764},
{"snippet": "Series.sparse()", "intent": "Accessor for SparseSparse from other sparse matrix data types .", "question_id": 8765},
{"snippet": "Series.sparse.npoints", "intent": "The number of non- fill_value points.", "question_id": 8766},
{"snippet": "Series.sparse.npoints", "intent": "The number of non- fill_value points.", "question_id": 8767},
{"snippet": "Series.sparse.npoints", "intent": "The number of non- fill_value points.", "question_id": 8768},
{"snippet": "Series.sparse.sp_values", "intent": "An ndarray containing the non- fill_value values.", "question_id": 8769},
{"snippet": "Series.sparse.sp_values", "intent": "An ndarray containing the non- fill_value values.", "question_id": 8770},
{"snippet": "Series.sparse.sp_values", "intent": "An ndarray containing the non- fill_value values.", "question_id": 8771},
{"snippet": "Series.sparse.to_coo()", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex .", "question_id": 8772},
{"snippet": "Series.sparse.to_coo(row_levels=(0,))", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively .", "question_id": 8773},
{"snippet": "Series.sparse.to_coo(column_levels=(1,))", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively .", "question_id": 8774},
{"snippet": "Series.sparse.to_coo(sort_labels=False)", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . With arguments `sort_labels`.", "question_id": 8775},
{"snippet": "Series.sparse.to_coo(row_levels=(0,), column_levels=(1,))", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively .", "question_id": 8776},
{"snippet": "Series.sparse.to_coo(row_levels=(0,), sort_labels=False)", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively . With arguments `sort_labels`.", "question_id": 8777},
{"snippet": "Series.sparse.to_coo(column_levels=(1,), sort_labels=False)", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively . With arguments `sort_labels`.", "question_id": 8778},
{"snippet": "Series.sparse.to_coo(row_levels=(0,), column_levels=(1,), sort_labels=False)", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively . With arguments `sort_labels`.", "question_id": 8779},
{"snippet": "Series.sparse.to_coo()", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex .", "question_id": 8780},
{"snippet": "Series.sparse.to_coo(row_levels=(0,))", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively .", "question_id": 8781},
{"snippet": "Series.sparse.to_coo(column_levels=(1,))", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively .", "question_id": 8782},
{"snippet": "Series.sparse.to_coo(sort_labels=False)", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . With arguments `sort_labels`.", "question_id": 8783},
{"snippet": "Series.sparse.to_coo(row_levels=(0,), column_levels=(1,))", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively .", "question_id": 8784},
{"snippet": "Series.sparse.to_coo(row_levels=(0,), sort_labels=False)", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively . With arguments `sort_labels`.", "question_id": 8785},
{"snippet": "Series.sparse.to_coo(column_levels=(1,), sort_labels=False)", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively . With arguments `sort_labels`.", "question_id": 8786},
{"snippet": "Series.sparse.to_coo(row_levels=(0,), column_levels=(1,), sort_labels=False)", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively . With arguments `sort_labels`.", "question_id": 8787},
{"snippet": "Series.sparse.to_coo()", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex .", "question_id": 8788},
{"snippet": "Series.sparse.to_coo(row_levels=(0,))", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively .", "question_id": 8789},
{"snippet": "Series.sparse.to_coo(column_levels=(1,))", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively .", "question_id": 8790},
{"snippet": "Series.sparse.to_coo(sort_labels=False)", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . With arguments `sort_labels`.", "question_id": 8791},
{"snippet": "Series.sparse.to_coo(row_levels=(0,), column_levels=(1,))", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively .", "question_id": 8792},
{"snippet": "Series.sparse.to_coo(row_levels=(0,), sort_labels=False)", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively . With arguments `sort_labels`.", "question_id": 8793},
{"snippet": "Series.sparse.to_coo(column_levels=(1,), sort_labels=False)", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively . With arguments `sort_labels`.", "question_id": 8794},
{"snippet": "Series.sparse.to_coo(row_levels=(0,), column_levels=(1,), sort_labels=False)", "intent": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex . Use `row_levels` and `column_levels` to determine the row and column coordinates respectively . With arguments `sort_labels`.", "question_id": 8795},
{"snippet": "Series.squeeze()", "intent": "Squeeze 1 dimensional `axis` objects into scalars .", "question_id": 8796},
{"snippet": "Series.squeeze(axis=None)", "intent": "Squeeze 1 dimensional `axis` objects into scalars .", "question_id": 8797},
{"snippet": "Series.squeeze()", "intent": "Squeeze 1 dimensional `axis` objects into scalars .", "question_id": 8798},
{"snippet": "Series.squeeze(axis=None)", "intent": "Squeeze 1 dimensional `axis` objects into scalars .", "question_id": 8799},
{"snippet": "Series.squeeze()", "intent": "Squeeze 1 dimensional `axis` objects into scalars .", "question_id": 8800},
{"snippet": "Series.squeeze(axis=None)", "intent": "Squeeze 1 dimensional `axis` objects into scalars .", "question_id": 8801},
{"snippet": "Series.std(**kwargs)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`.", "question_id": 8802},
{"snippet": "Series.std(**kwargs, axis=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`.", "question_id": 8803},
{"snippet": "Series.std(**kwargs, skipna=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8804},
{"snippet": "Series.std(**kwargs, level=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8805},
{"snippet": "Series.std(**kwargs, ddof=1)", "intent": "Return sample standard deviation over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 8806},
{"snippet": "Series.std(**kwargs, numeric_only=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8807},
{"snippet": "Series.std(**kwargs, axis=None, skipna=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8808},
{"snippet": "Series.std(**kwargs, axis=None, level=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8809},
{"snippet": "Series.std(**kwargs, axis=None, ddof=1)", "intent": "Return sample standard deviation over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 8810},
{"snippet": "Series.std(**kwargs, axis=None, numeric_only=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8811},
{"snippet": "Series.std(**kwargs)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`.", "question_id": 8812},
{"snippet": "Series.std(**kwargs, axis=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`.", "question_id": 8813},
{"snippet": "Series.std(**kwargs, skipna=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8814},
{"snippet": "Series.std(**kwargs, level=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8815},
{"snippet": "Series.std(**kwargs, ddof=1)", "intent": "Return sample standard deviation over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 8816},
{"snippet": "Series.std(**kwargs, numeric_only=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8817},
{"snippet": "Series.std(**kwargs, axis=None, skipna=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8818},
{"snippet": "Series.std(**kwargs, axis=None, level=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8819},
{"snippet": "Series.std(**kwargs, axis=None, ddof=1)", "intent": "Return sample standard deviation over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 8820},
{"snippet": "Series.std(**kwargs, axis=None, numeric_only=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8821},
{"snippet": "Series.std(**kwargs)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`.", "question_id": 8822},
{"snippet": "Series.std(**kwargs, axis=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`.", "question_id": 8823},
{"snippet": "Series.std(**kwargs, skipna=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8824},
{"snippet": "Series.std(**kwargs, level=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8825},
{"snippet": "Series.std(**kwargs, ddof=1)", "intent": "Return sample standard deviation over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 8826},
{"snippet": "Series.std(**kwargs, numeric_only=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8827},
{"snippet": "Series.std(**kwargs, axis=None, skipna=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 8828},
{"snippet": "Series.std(**kwargs, axis=None, level=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 8829},
{"snippet": "Series.std(**kwargs, axis=None, ddof=1)", "intent": "Return sample standard deviation over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 8830},
{"snippet": "Series.std(**kwargs, axis=None, numeric_only=None)", "intent": "Return sample standard deviation over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 8831},
{"snippet": "Series.str.capitalize()", "intent": "Convert strings in the Series/Index to be capitalized .", "question_id": 8832},
{"snippet": "Series.str.capitalize()", "intent": "Convert strings in the Series/Index to be capitalized .", "question_id": 8833},
{"snippet": "Series.str.capitalize()", "intent": "Convert strings in the Series/Index to be capitalized .", "question_id": 8834},
{"snippet": "Series.str.casefold()", "intent": "Convert strings in the Series/Index to be casefolded .", "question_id": 8835},
{"snippet": "Series.str.casefold()", "intent": "Convert strings in the Series/Index to be casefolded .", "question_id": 8836},
{"snippet": "Series.str.casefold()", "intent": "Convert strings in the Series/Index to be casefolded .", "question_id": 8837},
{"snippet": "Series.str.cat()", "intent": "Concatenate strings in the Series/Index with given separator .", "question_id": 8838},
{"snippet": "Series.str.cat(others=None)", "intent": "Concatenate strings in the Series/Index with given separator . If `others` is specified , this function concatenates the Series/Index and elements of others element-wise .", "question_id": 8839},
{"snippet": "Series.str.cat(sep=None)", "intent": "Concatenate strings in the Series/Index with given separator . If others is not passed , then all values in the Series/Index are concatenated into a single string with a given `sep` .", "question_id": 8840},
{"snippet": "Series.str.cat(na_rep=None)", "intent": "Concatenate strings in the Series/Index with given separator . Using `na_rep` , they can be given a representation :", "question_id": 8841},
{"snippet": "Series.str.cat(join='left')", "intent": "Concatenate strings in the Series/Index with given separator . With arguments `join`.", "question_id": 8842},
{"snippet": "Series.str.cat(others=None, sep=None)", "intent": "Concatenate strings in the Series/Index with given separator . If `others` is specified , this function concatenates the Series/Index and elements of others element-wise . If others is not passed , then all values in the Series/Index are concatenated into a single string with a given `sep` .", "question_id": 8843},
{"snippet": "Series.str.cat(others=None, na_rep=None)", "intent": "Concatenate strings in the Series/Index with given separator . If `others` is specified , this function concatenates the Series/Index and elements of others element-wise . Using `na_rep` , they can be given a representation :", "question_id": 8844},
{"snippet": "Series.str.cat(others=None, join='left')", "intent": "Concatenate strings in the Series/Index with given separator . If `others` is specified , this function concatenates the Series/Index and elements of others element-wise . With arguments `join`.", "question_id": 8845},
{"snippet": "Series.str.cat(sep=None, na_rep=None)", "intent": "Concatenate strings in the Series/Index with given separator . If others is not passed , then all values in the Series/Index are concatenated into a single string with a given `sep` . Using `na_rep` , they can be given a representation :", "question_id": 8846},
{"snippet": "Series.str.cat(sep=None, join='left')", "intent": "Concatenate strings in the Series/Index with given separator . If others is not passed , then all values in the Series/Index are concatenated into a single string with a given `sep` . With arguments `join`.", "question_id": 8847},
{"snippet": "Series.str.cat()", "intent": "Concatenate strings in the Series/Index with given separator .", "question_id": 8848},
{"snippet": "Series.str.cat(others=None)", "intent": "Concatenate strings in the Series/Index with given separator . If `others` is specified , this function concatenates the Series/Index and elements of others element-wise .", "question_id": 8849},
{"snippet": "Series.str.cat(sep=None)", "intent": "Concatenate strings in the Series/Index with given separator . If others is not passed , then all values in the Series/Index are concatenated into a single string with a given `sep` .", "question_id": 8850},
{"snippet": "Series.str.cat(na_rep=None)", "intent": "Concatenate strings in the Series/Index with given separator . Using `na_rep` , they can be given a representation :", "question_id": 8851},
{"snippet": "Series.str.cat(join='left')", "intent": "Concatenate strings in the Series/Index with given separator . With arguments `join`.", "question_id": 8852},
{"snippet": "Series.str.cat(others=None, sep=None)", "intent": "Concatenate strings in the Series/Index with given separator . If `others` is specified , this function concatenates the Series/Index and elements of others element-wise . If others is not passed , then all values in the Series/Index are concatenated into a single string with a given `sep` .", "question_id": 8853},
{"snippet": "Series.str.cat(others=None, na_rep=None)", "intent": "Concatenate strings in the Series/Index with given separator . If `others` is specified , this function concatenates the Series/Index and elements of others element-wise . Using `na_rep` , they can be given a representation :", "question_id": 8854},
{"snippet": "Series.str.cat(others=None, join='left')", "intent": "Concatenate strings in the Series/Index with given separator . If `others` is specified , this function concatenates the Series/Index and elements of others element-wise . With arguments `join`.", "question_id": 8855},
{"snippet": "Series.str.cat(sep=None, na_rep=None)", "intent": "Concatenate strings in the Series/Index with given separator . If others is not passed , then all values in the Series/Index are concatenated into a single string with a given `sep` . Using `na_rep` , they can be given a representation :", "question_id": 8856},
{"snippet": "Series.str.cat(sep=None, join='left')", "intent": "Concatenate strings in the Series/Index with given separator . If others is not passed , then all values in the Series/Index are concatenated into a single string with a given `sep` . With arguments `join`.", "question_id": 8857},
{"snippet": "Series.str.cat()", "intent": "Concatenate strings in the Series/Index with given separator .", "question_id": 8858},
{"snippet": "Series.str.cat(others=None)", "intent": "Concatenate strings in the Series/Index with given separator . If `others` is specified , this function concatenates the Series/Index and elements of others element-wise .", "question_id": 8859},
{"snippet": "Series.str.cat(sep=None)", "intent": "Concatenate strings in the Series/Index with given separator . If others is not passed , then all values in the Series/Index are concatenated into a single string with a given `sep` .", "question_id": 8860},
{"snippet": "Series.str.cat(na_rep=None)", "intent": "Concatenate strings in the Series/Index with given separator . Using `na_rep` , they can be given a representation :", "question_id": 8861},
{"snippet": "Series.str.cat(join='left')", "intent": "Concatenate strings in the Series/Index with given separator . With arguments `join`.", "question_id": 8862},
{"snippet": "Series.str.cat(others=None, sep=None)", "intent": "Concatenate strings in the Series/Index with given separator . If `others` is specified , this function concatenates the Series/Index and elements of others element-wise . If others is not passed , then all values in the Series/Index are concatenated into a single string with a given `sep` .", "question_id": 8863},
{"snippet": "Series.str.cat(others=None, na_rep=None)", "intent": "Concatenate strings in the Series/Index with given separator . If `others` is specified , this function concatenates the Series/Index and elements of others element-wise . Using `na_rep` , they can be given a representation :", "question_id": 8864},
{"snippet": "Series.str.cat(others=None, join='left')", "intent": "Concatenate strings in the Series/Index with given separator . If `others` is specified , this function concatenates the Series/Index and elements of others element-wise . With arguments `join`.", "question_id": 8865},
{"snippet": "Series.str.cat(sep=None, na_rep=None)", "intent": "Concatenate strings in the Series/Index with given separator . If others is not passed , then all values in the Series/Index are concatenated into a single string with a given `sep` . Using `na_rep` , they can be given a representation :", "question_id": 8866},
{"snippet": "Series.str.cat(sep=None, join='left')", "intent": "Concatenate strings in the Series/Index with given separator . If others is not passed , then all values in the Series/Index are concatenated into a single string with a given `sep` . With arguments `join`.", "question_id": 8867},
{"snippet": "Series.str.center(width)", "intent": "Pad left and right side of strings in the Series/Index . With arguments `width`.", "question_id": 8868},
{"snippet": "Series.str.center(width, fillchar=' ')", "intent": "Pad left and right side of strings in the Series/Index . With arguments `width`, `fillchar`.", "question_id": 8869},
{"snippet": "Series.str.center(width)", "intent": "Pad left and right side of strings in the Series/Index . With arguments `width`.", "question_id": 8870},
{"snippet": "Series.str.center(width, fillchar=' ')", "intent": "Pad left and right side of strings in the Series/Index . With arguments `width`, `fillchar`.", "question_id": 8871},
{"snippet": "Series.str.center(width)", "intent": "Pad left and right side of strings in the Series/Index . With arguments `width`.", "question_id": 8872},
{"snippet": "Series.str.center(width, fillchar=' ')", "intent": "Pad left and right side of strings in the Series/Index . With arguments `width`, `fillchar`.", "question_id": 8873},
{"snippet": "Series.str.contains(pat)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True .", "question_id": 8874},
{"snippet": "Series.str.contains(pat, case=True)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `case` sensitivity using case .", "question_id": 8875},
{"snippet": "Series.str.contains(pat, flags=0)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Ignoring case sensitivity using `flags` with regex .", "question_id": 8876},
{"snippet": "Series.str.contains(pat, na=None)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `na` to be False instead of NaN replaces NaN values with False .", "question_id": 8877},
{"snippet": "Series.str.contains(pat, regex=True)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True .", "question_id": 8878},
{"snippet": "Series.str.contains(pat, case=True, flags=0)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `case` sensitivity using case . Ignoring case sensitivity using `flags` with regex .", "question_id": 8879},
{"snippet": "Series.str.contains(pat, case=True, na=None)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `case` sensitivity using case . Specifying `na` to be False instead of NaN replaces NaN values with False .", "question_id": 8880},
{"snippet": "Series.str.contains(pat, case=True, regex=True)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `case` sensitivity using case .", "question_id": 8881},
{"snippet": "Series.str.contains(pat, flags=0, na=None)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Ignoring case sensitivity using `flags` with regex . Specifying `na` to be False instead of NaN replaces NaN values with False .", "question_id": 8882},
{"snippet": "Series.str.contains(pat, flags=0, regex=True)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Ignoring case sensitivity using `flags` with regex .", "question_id": 8883},
{"snippet": "Series.str.contains(pat)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True .", "question_id": 8884},
{"snippet": "Series.str.contains(pat, case=True)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `case` sensitivity using case .", "question_id": 8885},
{"snippet": "Series.str.contains(pat, flags=0)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Ignoring case sensitivity using `flags` with regex .", "question_id": 8886},
{"snippet": "Series.str.contains(pat, na=None)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `na` to be False instead of NaN replaces NaN values with False .", "question_id": 8887},
{"snippet": "Series.str.contains(pat, regex=True)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True .", "question_id": 8888},
{"snippet": "Series.str.contains(pat, case=True, flags=0)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `case` sensitivity using case . Ignoring case sensitivity using `flags` with regex .", "question_id": 8889},
{"snippet": "Series.str.contains(pat, case=True, na=None)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `case` sensitivity using case . Specifying `na` to be False instead of NaN replaces NaN values with False .", "question_id": 8890},
{"snippet": "Series.str.contains(pat, case=True, regex=True)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `case` sensitivity using case .", "question_id": 8891},
{"snippet": "Series.str.contains(pat, flags=0, na=None)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Ignoring case sensitivity using `flags` with regex . Specifying `na` to be False instead of NaN replaces NaN values with False .", "question_id": 8892},
{"snippet": "Series.str.contains(pat, flags=0, regex=True)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Ignoring case sensitivity using `flags` with regex .", "question_id": 8893},
{"snippet": "Series.str.contains(pat)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True .", "question_id": 8894},
{"snippet": "Series.str.contains(pat, case=True)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `case` sensitivity using case .", "question_id": 8895},
{"snippet": "Series.str.contains(pat, flags=0)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Ignoring case sensitivity using `flags` with regex .", "question_id": 8896},
{"snippet": "Series.str.contains(pat, na=None)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `na` to be False instead of NaN replaces NaN values with False .", "question_id": 8897},
{"snippet": "Series.str.contains(pat, regex=True)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True .", "question_id": 8898},
{"snippet": "Series.str.contains(pat, case=True, flags=0)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `case` sensitivity using case . Ignoring case sensitivity using `flags` with regex .", "question_id": 8899},
{"snippet": "Series.str.contains(pat, case=True, na=None)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `case` sensitivity using case . Specifying `na` to be False instead of NaN replaces NaN values with False .", "question_id": 8900},
{"snippet": "Series.str.contains(pat, case=True, regex=True)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Specifying `case` sensitivity using case .", "question_id": 8901},
{"snippet": "Series.str.contains(pat, flags=0, na=None)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Ignoring case sensitivity using `flags` with regex . Specifying `na` to be False instead of NaN replaces NaN values with False .", "question_id": 8902},
{"snippet": "Series.str.contains(pat, flags=0, regex=True)", "intent": "Test if pattern or `regex` is contained within a string of a Series or Index . Ensure `pat` is a not a literal pattern when regex is set to True . Ignoring case sensitivity using `flags` with regex .", "question_id": 8903},
{"snippet": "Series.str.count(pat)", "intent": "Count occurrences of pattern in each string of the Series/Index . Some characters need to be escaped when passing in `pat` .", "question_id": 8904},
{"snippet": "Series.str.count(pat, flags=0)", "intent": "Count occurrences of pattern in each string of the Series/Index . Some characters need to be escaped when passing in `pat` . With arguments `flags`.", "question_id": 8905},
{"snippet": "Series.str.count(pat)", "intent": "Count occurrences of pattern in each string of the Series/Index . Some characters need to be escaped when passing in `pat` .", "question_id": 8906},
{"snippet": "Series.str.count(pat, flags=0)", "intent": "Count occurrences of pattern in each string of the Series/Index . Some characters need to be escaped when passing in `pat` . With arguments `flags`.", "question_id": 8907},
{"snippet": "Series.str.count(pat)", "intent": "Count occurrences of pattern in each string of the Series/Index . Some characters need to be escaped when passing in `pat` .", "question_id": 8908},
{"snippet": "Series.str.count(pat, flags=0)", "intent": "Count occurrences of pattern in each string of the Series/Index . Some characters need to be escaped when passing in `pat` . With arguments `flags`.", "question_id": 8909},
{"snippet": "Series.str.decode(encoding)", "intent": "Decode character string in the Series/Index using indicated `encoding` .", "question_id": 8910},
{"snippet": "Series.str.decode(encoding, errors='strict')", "intent": "Decode character string in the Series/Index using indicated `encoding` . With arguments `errors`.", "question_id": 8911},
{"snippet": "Series.str.decode(encoding)", "intent": "Decode character string in the Series/Index using indicated `encoding` .", "question_id": 8912},
{"snippet": "Series.str.decode(encoding, errors='strict')", "intent": "Decode character string in the Series/Index using indicated `encoding` . With arguments `errors`.", "question_id": 8913},
{"snippet": "Series.str.decode(encoding)", "intent": "Decode character string in the Series/Index using indicated `encoding` .", "question_id": 8914},
{"snippet": "Series.str.decode(encoding, errors='strict')", "intent": "Decode character string in the Series/Index using indicated `encoding` . With arguments `errors`.", "question_id": 8915},
{"snippet": "Series.str.encode(encoding)", "intent": "Encode character string in the Series/Index using indicated `encoding` .", "question_id": 8916},
{"snippet": "Series.str.encode(encoding, errors='strict')", "intent": "Encode character string in the Series/Index using indicated `encoding` . With arguments `errors`.", "question_id": 8917},
{"snippet": "Series.str.encode(encoding)", "intent": "Encode character string in the Series/Index using indicated `encoding` .", "question_id": 8918},
{"snippet": "Series.str.encode(encoding, errors='strict')", "intent": "Encode character string in the Series/Index using indicated `encoding` . With arguments `errors`.", "question_id": 8919},
{"snippet": "Series.str.encode(encoding)", "intent": "Encode character string in the Series/Index using indicated `encoding` .", "question_id": 8920},
{"snippet": "Series.str.encode(encoding, errors='strict')", "intent": "Encode character string in the Series/Index using indicated `encoding` . With arguments `errors`.", "question_id": 8921},
{"snippet": "Series.str.endswith(pat)", "intent": "Test if the end of each string element matches a pattern . With arguments `pat`.", "question_id": 8922},
{"snippet": "Series.str.endswith(pat, na=None)", "intent": "Test if the end of each string element matches a pattern . Specifying `na` to be False instead of NaN . With arguments `pat`.", "question_id": 8923},
{"snippet": "Series.str.endswith(pat)", "intent": "Test if the end of each string element matches a pattern . With arguments `pat`.", "question_id": 8924},
{"snippet": "Series.str.endswith(pat, na=None)", "intent": "Test if the end of each string element matches a pattern . Specifying `na` to be False instead of NaN . With arguments `pat`.", "question_id": 8925},
{"snippet": "Series.str.endswith(pat)", "intent": "Test if the end of each string element matches a pattern . With arguments `pat`.", "question_id": 8926},
{"snippet": "Series.str.endswith(pat, na=None)", "intent": "Test if the end of each string element matches a pattern . Specifying `na` to be False instead of NaN . With arguments `pat`.", "question_id": 8927},
{"snippet": "Series.str.extract(pat)", "intent": "Extract capture groups in the regex `pat` as columns in a DataFrame .", "question_id": 8928},
{"snippet": "Series.str.extract(pat, flags=0)", "intent": "Extract capture groups in the regex `pat` as columns in a DataFrame . With arguments `flags`.", "question_id": 8929},
{"snippet": "Series.str.extract(pat, expand=True)", "intent": "Extract capture groups in the regex `pat` as columns in a DataFrame . With arguments `expand`.", "question_id": 8930},
{"snippet": "Series.str.extract(pat, flags=0, expand=True)", "intent": "Extract capture groups in the regex `pat` as columns in a DataFrame . With arguments `flags`, `expand`.", "question_id": 8931},
{"snippet": "Series.str.extract(pat)", "intent": "Extract capture groups in the regex `pat` as columns in a DataFrame .", "question_id": 8932},
{"snippet": "Series.str.extract(pat, flags=0)", "intent": "Extract capture groups in the regex `pat` as columns in a DataFrame . With arguments `flags`.", "question_id": 8933},
{"snippet": "Series.str.extract(pat, expand=True)", "intent": "Extract capture groups in the regex `pat` as columns in a DataFrame . With arguments `expand`.", "question_id": 8934},
{"snippet": "Series.str.extract(pat, flags=0, expand=True)", "intent": "Extract capture groups in the regex `pat` as columns in a DataFrame . With arguments `flags`, `expand`.", "question_id": 8935},
{"snippet": "Series.str.extract(pat)", "intent": "Extract capture groups in the regex `pat` as columns in a DataFrame .", "question_id": 8936},
{"snippet": "Series.str.extract(pat, flags=0)", "intent": "Extract capture groups in the regex `pat` as columns in a DataFrame . With arguments `flags`.", "question_id": 8937},
{"snippet": "Series.str.extract(pat, expand=True)", "intent": "Extract capture groups in the regex `pat` as columns in a DataFrame . With arguments `expand`.", "question_id": 8938},
{"snippet": "Series.str.extract(pat, flags=0, expand=True)", "intent": "Extract capture groups in the regex `pat` as columns in a DataFrame . With arguments `flags`, `expand`.", "question_id": 8939},
{"snippet": "Series.str.extractall(pat)", "intent": "Extract capture groups in the regex `pat` as columns in DataFrame .", "question_id": 8940},
{"snippet": "Series.str.extractall(pat, flags=0)", "intent": "Extract capture groups in the regex `pat` as columns in DataFrame . With arguments `flags`.", "question_id": 8941},
{"snippet": "Series.str.extractall(pat)", "intent": "Extract capture groups in the regex `pat` as columns in DataFrame .", "question_id": 8942},
{"snippet": "Series.str.extractall(pat, flags=0)", "intent": "Extract capture groups in the regex `pat` as columns in DataFrame . With arguments `flags`.", "question_id": 8943},
{"snippet": "Series.str.extractall(pat)", "intent": "Extract capture groups in the regex `pat` as columns in DataFrame .", "question_id": 8944},
{"snippet": "Series.str.extractall(pat, flags=0)", "intent": "Extract capture groups in the regex `pat` as columns in DataFrame . With arguments `flags`.", "question_id": 8945},
{"snippet": "Series.str.find(sub)", "intent": "Return lowest indexes in each strings in the Series/Index . With arguments `sub`.", "question_id": 8946},
{"snippet": "Series.str.find(sub, start=0)", "intent": "Return lowest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 8947},
{"snippet": "Series.str.find(sub, end=None)", "intent": "Return lowest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 8948},
{"snippet": "Series.str.find(sub, start=0, end=None)", "intent": "Return lowest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 8949},
{"snippet": "Series.str.find(sub)", "intent": "Return lowest indexes in each strings in the Series/Index . With arguments `sub`.", "question_id": 8950},
{"snippet": "Series.str.find(sub, start=0)", "intent": "Return lowest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 8951},
{"snippet": "Series.str.find(sub, end=None)", "intent": "Return lowest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 8952},
{"snippet": "Series.str.find(sub, start=0, end=None)", "intent": "Return lowest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 8953},
{"snippet": "Series.str.find(sub)", "intent": "Return lowest indexes in each strings in the Series/Index . With arguments `sub`.", "question_id": 8954},
{"snippet": "Series.str.find(sub, start=0)", "intent": "Return lowest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 8955},
{"snippet": "Series.str.find(sub, end=None)", "intent": "Return lowest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 8956},
{"snippet": "Series.str.find(sub, start=0, end=None)", "intent": "Return lowest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 8957},
{"snippet": "Series.str.findall(pat)", "intent": "Find all occurrences of pattern or regular expression in the Series/Index . With arguments `pat`.", "question_id": 8958},
{"snippet": "Series.str.findall(pat, flags=0)", "intent": "Find all occurrences of pattern or regular expression in the Series/Index . With arguments `pat`, `flags`.", "question_id": 8959},
{"snippet": "Series.str.findall(pat)", "intent": "Find all occurrences of pattern or regular expression in the Series/Index . With arguments `pat`.", "question_id": 8960},
{"snippet": "Series.str.findall(pat, flags=0)", "intent": "Find all occurrences of pattern or regular expression in the Series/Index . With arguments `pat`, `flags`.", "question_id": 8961},
{"snippet": "Series.str.findall(pat)", "intent": "Find all occurrences of pattern or regular expression in the Series/Index . With arguments `pat`.", "question_id": 8962},
{"snippet": "Series.str.findall(pat, flags=0)", "intent": "Find all occurrences of pattern or regular expression in the Series/Index . With arguments `pat`, `flags`.", "question_id": 8963},
{"snippet": "Series.str.fullmatch(pat)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`.", "question_id": 8964},
{"snippet": "Series.str.fullmatch(pat, case=True)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `case`.", "question_id": 8965},
{"snippet": "Series.str.fullmatch(pat, flags=0)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `flags`.", "question_id": 8966},
{"snippet": "Series.str.fullmatch(pat, na=None)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `na`.", "question_id": 8967},
{"snippet": "Series.str.fullmatch(pat, case=True, flags=0)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `case`, `flags`.", "question_id": 8968},
{"snippet": "Series.str.fullmatch(pat, case=True, na=None)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `case`, `na`.", "question_id": 8969},
{"snippet": "Series.str.fullmatch(pat, flags=0, na=None)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `flags`, `na`.", "question_id": 8970},
{"snippet": "Series.str.fullmatch(pat, case=True, flags=0, na=None)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `case`, `flags`, `na`.", "question_id": 8971},
{"snippet": "Series.str.fullmatch(pat)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`.", "question_id": 8972},
{"snippet": "Series.str.fullmatch(pat, case=True)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `case`.", "question_id": 8973},
{"snippet": "Series.str.fullmatch(pat, flags=0)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `flags`.", "question_id": 8974},
{"snippet": "Series.str.fullmatch(pat, na=None)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `na`.", "question_id": 8975},
{"snippet": "Series.str.fullmatch(pat, case=True, flags=0)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `case`, `flags`.", "question_id": 8976},
{"snippet": "Series.str.fullmatch(pat, case=True, na=None)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `case`, `na`.", "question_id": 8977},
{"snippet": "Series.str.fullmatch(pat, flags=0, na=None)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `flags`, `na`.", "question_id": 8978},
{"snippet": "Series.str.fullmatch(pat, case=True, flags=0, na=None)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `case`, `flags`, `na`.", "question_id": 8979},
{"snippet": "Series.str.fullmatch(pat)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`.", "question_id": 8980},
{"snippet": "Series.str.fullmatch(pat, case=True)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `case`.", "question_id": 8981},
{"snippet": "Series.str.fullmatch(pat, flags=0)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `flags`.", "question_id": 8982},
{"snippet": "Series.str.fullmatch(pat, na=None)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `na`.", "question_id": 8983},
{"snippet": "Series.str.fullmatch(pat, case=True, flags=0)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `case`, `flags`.", "question_id": 8984},
{"snippet": "Series.str.fullmatch(pat, case=True, na=None)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `case`, `na`.", "question_id": 8985},
{"snippet": "Series.str.fullmatch(pat, flags=0, na=None)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `flags`, `na`.", "question_id": 8986},
{"snippet": "Series.str.fullmatch(pat, case=True, flags=0, na=None)", "intent": "Determine if each string entirely matches a regular expression . With arguments `pat`, `case`, `flags`, `na`.", "question_id": 8987},
{"snippet": "Series.str.get(i)", "intent": "Extract element from each component at specified position . With arguments `i`.", "question_id": 8988},
{"snippet": "Series.str.get(i)", "intent": "Extract element from each component at specified position . With arguments `i`.", "question_id": 8989},
{"snippet": "Series.str.get(i)", "intent": "Extract element from each component at specified position . With arguments `i`.", "question_id": 8990},
{"snippet": "Series.str.get_dummies()", "intent": "Return DataFrame of dummy/indicator variables for Series .", "question_id": 8991},
{"snippet": "Series.str.get_dummies(sep='|')", "intent": "Return DataFrame of dummy/indicator variables for Series . Each string in Series is split by `sep` and returned as a DataFrame of dummy/indicator variables .", "question_id": 8992},
{"snippet": "Series.str.get_dummies()", "intent": "Return DataFrame of dummy/indicator variables for Series .", "question_id": 8993},
{"snippet": "Series.str.get_dummies(sep='|')", "intent": "Return DataFrame of dummy/indicator variables for Series . Each string in Series is split by `sep` and returned as a DataFrame of dummy/indicator variables .", "question_id": 8994},
{"snippet": "Series.str.get_dummies()", "intent": "Return DataFrame of dummy/indicator variables for Series .", "question_id": 8995},
{"snippet": "Series.str.get_dummies(sep='|')", "intent": "Return DataFrame of dummy/indicator variables for Series . Each string in Series is split by `sep` and returned as a DataFrame of dummy/indicator variables .", "question_id": 8996},
{"snippet": "Series.str()", "intent": "Vectorized string functions for Series and Index .", "question_id": 8997},
{"snippet": "Series.str()", "intent": "Vectorized string functions for Series and Index .", "question_id": 8998},
{"snippet": "Series.str()", "intent": "Vectorized string functions for Series and Index .", "question_id": 8999},
{"snippet": "Series.str.index(sub)", "intent": "Return lowest indexes in each string in Series/Index . With arguments `sub`.", "question_id": 9000},
{"snippet": "Series.str.index(sub, start=0)", "intent": "Return lowest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9001},
{"snippet": "Series.str.index(sub, end=None)", "intent": "Return lowest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9002},
{"snippet": "Series.str.index(sub, start=0, end=None)", "intent": "Return lowest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9003},
{"snippet": "Series.str.index(sub)", "intent": "Return lowest indexes in each string in Series/Index . With arguments `sub`.", "question_id": 9004},
{"snippet": "Series.str.index(sub, start=0)", "intent": "Return lowest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9005},
{"snippet": "Series.str.index(sub, end=None)", "intent": "Return lowest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9006},
{"snippet": "Series.str.index(sub, start=0, end=None)", "intent": "Return lowest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9007},
{"snippet": "Series.str.index(sub)", "intent": "Return lowest indexes in each string in Series/Index . With arguments `sub`.", "question_id": 9008},
{"snippet": "Series.str.index(sub, start=0)", "intent": "Return lowest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9009},
{"snippet": "Series.str.index(sub, end=None)", "intent": "Return lowest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9010},
{"snippet": "Series.str.index(sub, start=0, end=None)", "intent": "Return lowest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9011},
{"snippet": "Series.str.isalnum()", "intent": "Check whether all characters in each string are alphanumeric .", "question_id": 9012},
{"snippet": "Series.str.isalnum()", "intent": "Check whether all characters in each string are alphanumeric .", "question_id": 9013},
{"snippet": "Series.str.isalnum()", "intent": "Check whether all characters in each string are alphanumeric .", "question_id": 9014},
{"snippet": "Series.str.isalpha()", "intent": "Check whether all characters in each string are alphabetic .", "question_id": 9015},
{"snippet": "Series.str.isalpha()", "intent": "Check whether all characters in each string are alphabetic .", "question_id": 9016},
{"snippet": "Series.str.isalpha()", "intent": "Check whether all characters in each string are alphabetic .", "question_id": 9017},
{"snippet": "Series.str.isdecimal()", "intent": "Check whether all characters in each string are decimal .", "question_id": 9018},
{"snippet": "Series.str.isdecimal()", "intent": "Check whether all characters in each string are decimal .", "question_id": 9019},
{"snippet": "Series.str.isdecimal()", "intent": "Check whether all characters in each string are decimal .", "question_id": 9020},
{"snippet": "Series.str.isdigit()", "intent": "Check whether all characters in each string are digits .", "question_id": 9021},
{"snippet": "Series.str.isdigit()", "intent": "Check whether all characters in each string are digits .", "question_id": 9022},
{"snippet": "Series.str.isdigit()", "intent": "Check whether all characters in each string are digits .", "question_id": 9023},
{"snippet": "Series.str.islower()", "intent": "Check whether all characters in each string are lowercase .", "question_id": 9024},
{"snippet": "Series.str.islower()", "intent": "Check whether all characters in each string are lowercase .", "question_id": 9025},
{"snippet": "Series.str.islower()", "intent": "Check whether all characters in each string are lowercase .", "question_id": 9026},
{"snippet": "Series.str.isnumeric()", "intent": "Check whether all characters in each string are numeric .", "question_id": 9027},
{"snippet": "Series.str.isnumeric()", "intent": "Check whether all characters in each string are numeric .", "question_id": 9028},
{"snippet": "Series.str.isnumeric()", "intent": "Check whether all characters in each string are numeric .", "question_id": 9029},
{"snippet": "Series.str.isspace()", "intent": "Check whether all characters in each string are whitespace .", "question_id": 9030},
{"snippet": "Series.str.isspace()", "intent": "Check whether all characters in each string are whitespace .", "question_id": 9031},
{"snippet": "Series.str.isspace()", "intent": "Check whether all characters in each string are whitespace .", "question_id": 9032},
{"snippet": "Series.str.istitle()", "intent": "Check whether all characters in each string are titlecase .", "question_id": 9033},
{"snippet": "Series.str.istitle()", "intent": "Check whether all characters in each string are titlecase .", "question_id": 9034},
{"snippet": "Series.str.istitle()", "intent": "Check whether all characters in each string are titlecase .", "question_id": 9035},
{"snippet": "Series.str.isupper()", "intent": "Check whether all characters in each string are uppercase .", "question_id": 9036},
{"snippet": "Series.str.isupper()", "intent": "Check whether all characters in each string are uppercase .", "question_id": 9037},
{"snippet": "Series.str.isupper()", "intent": "Check whether all characters in each string are uppercase .", "question_id": 9038},
{"snippet": "Series.str.join(sep)", "intent": "Join lists contained as elements in the Series/Index with passed delimiter . With arguments `sep`.", "question_id": 9039},
{"snippet": "Series.str.join(sep)", "intent": "Join lists contained as elements in the Series/Index with passed delimiter . With arguments `sep`.", "question_id": 9040},
{"snippet": "Series.str.join(sep)", "intent": "Join lists contained as elements in the Series/Index with passed delimiter . With arguments `sep`.", "question_id": 9041},
{"snippet": "Series.str.len()", "intent": "Compute the length of each element in the Series/Index .", "question_id": 9042},
{"snippet": "Series.str.len()", "intent": "Compute the length of each element in the Series/Index .", "question_id": 9043},
{"snippet": "Series.str.len()", "intent": "Compute the length of each element in the Series/Index .", "question_id": 9044},
{"snippet": "Series.str.ljust(width)", "intent": "Pad right side of strings in the Series/Index . With arguments `width`.", "question_id": 9045},
{"snippet": "Series.str.ljust(width, fillchar=' ')", "intent": "Pad right side of strings in the Series/Index . With arguments `width`, `fillchar`.", "question_id": 9046},
{"snippet": "Series.str.ljust(width)", "intent": "Pad right side of strings in the Series/Index . With arguments `width`.", "question_id": 9047},
{"snippet": "Series.str.ljust(width, fillchar=' ')", "intent": "Pad right side of strings in the Series/Index . With arguments `width`, `fillchar`.", "question_id": 9048},
{"snippet": "Series.str.ljust(width)", "intent": "Pad right side of strings in the Series/Index . With arguments `width`.", "question_id": 9049},
{"snippet": "Series.str.ljust(width, fillchar=' ')", "intent": "Pad right side of strings in the Series/Index . With arguments `width`, `fillchar`.", "question_id": 9050},
{"snippet": "Series.str.lower()", "intent": "Convert strings in the Series/Index to lowercase .", "question_id": 9051},
{"snippet": "Series.str.lower()", "intent": "Convert strings in the Series/Index to lowercase .", "question_id": 9052},
{"snippet": "Series.str.lower()", "intent": "Convert strings in the Series/Index to lowercase .", "question_id": 9053},
{"snippet": "Series.str.lstrip()", "intent": "Remove leading characters .", "question_id": 9054},
{"snippet": "Series.str.lstrip(to_strip=None)", "intent": "Remove leading characters . With arguments `to_strip`.", "question_id": 9055},
{"snippet": "Series.str.lstrip()", "intent": "Remove leading characters .", "question_id": 9056},
{"snippet": "Series.str.lstrip(to_strip=None)", "intent": "Remove leading characters . With arguments `to_strip`.", "question_id": 9057},
{"snippet": "Series.str.lstrip()", "intent": "Remove leading characters .", "question_id": 9058},
{"snippet": "Series.str.lstrip(to_strip=None)", "intent": "Remove leading characters . With arguments `to_strip`.", "question_id": 9059},
{"snippet": "Series.str.match(pat)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`.", "question_id": 9060},
{"snippet": "Series.str.match(pat, case=True)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `case`.", "question_id": 9061},
{"snippet": "Series.str.match(pat, flags=0)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `flags`.", "question_id": 9062},
{"snippet": "Series.str.match(pat, na=None)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `na`.", "question_id": 9063},
{"snippet": "Series.str.match(pat, case=True, flags=0)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `case`, `flags`.", "question_id": 9064},
{"snippet": "Series.str.match(pat, case=True, na=None)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `case`, `na`.", "question_id": 9065},
{"snippet": "Series.str.match(pat, flags=0, na=None)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `flags`, `na`.", "question_id": 9066},
{"snippet": "Series.str.match(pat, case=True, flags=0, na=None)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `case`, `flags`, `na`.", "question_id": 9067},
{"snippet": "Series.str.match(pat)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`.", "question_id": 9068},
{"snippet": "Series.str.match(pat, case=True)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `case`.", "question_id": 9069},
{"snippet": "Series.str.match(pat, flags=0)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `flags`.", "question_id": 9070},
{"snippet": "Series.str.match(pat, na=None)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `na`.", "question_id": 9071},
{"snippet": "Series.str.match(pat, case=True, flags=0)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `case`, `flags`.", "question_id": 9072},
{"snippet": "Series.str.match(pat, case=True, na=None)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `case`, `na`.", "question_id": 9073},
{"snippet": "Series.str.match(pat, flags=0, na=None)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `flags`, `na`.", "question_id": 9074},
{"snippet": "Series.str.match(pat, case=True, flags=0, na=None)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `case`, `flags`, `na`.", "question_id": 9075},
{"snippet": "Series.str.match(pat)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`.", "question_id": 9076},
{"snippet": "Series.str.match(pat, case=True)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `case`.", "question_id": 9077},
{"snippet": "Series.str.match(pat, flags=0)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `flags`.", "question_id": 9078},
{"snippet": "Series.str.match(pat, na=None)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `na`.", "question_id": 9079},
{"snippet": "Series.str.match(pat, case=True, flags=0)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `case`, `flags`.", "question_id": 9080},
{"snippet": "Series.str.match(pat, case=True, na=None)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `case`, `na`.", "question_id": 9081},
{"snippet": "Series.str.match(pat, flags=0, na=None)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `flags`, `na`.", "question_id": 9082},
{"snippet": "Series.str.match(pat, case=True, flags=0, na=None)", "intent": "Determine if each string starts with a match of a regular expression . With arguments `pat`, `case`, `flags`, `na`.", "question_id": 9083},
{"snippet": "Series.str.normalize(form)", "intent": "Return the Unicode normal `form` for the strings in the Series/Index .", "question_id": 9084},
{"snippet": "Series.str.normalize(form)", "intent": "Return the Unicode normal `form` for the strings in the Series/Index .", "question_id": 9085},
{"snippet": "Series.str.normalize(form)", "intent": "Return the Unicode normal `form` for the strings in the Series/Index .", "question_id": 9086},
{"snippet": "Series.str.pad(width)", "intent": "Pad strings in the Series/Index up to `width` .", "question_id": 9087},
{"snippet": "Series.str.pad(width, side='left')", "intent": "Pad strings in the Series/Index up to `width` . With arguments `side`.", "question_id": 9088},
{"snippet": "Series.str.pad(width, fillchar=' ')", "intent": "Pad strings in the Series/Index up to `width` . With arguments `fillchar`.", "question_id": 9089},
{"snippet": "Series.str.pad(width, side='left', fillchar=' ')", "intent": "Pad strings in the Series/Index up to `width` . With arguments `side`, `fillchar`.", "question_id": 9090},
{"snippet": "Series.str.pad(width)", "intent": "Pad strings in the Series/Index up to `width` .", "question_id": 9091},
{"snippet": "Series.str.pad(width, side='left')", "intent": "Pad strings in the Series/Index up to `width` . With arguments `side`.", "question_id": 9092},
{"snippet": "Series.str.pad(width, fillchar=' ')", "intent": "Pad strings in the Series/Index up to `width` . With arguments `fillchar`.", "question_id": 9093},
{"snippet": "Series.str.pad(width, side='left', fillchar=' ')", "intent": "Pad strings in the Series/Index up to `width` . With arguments `side`, `fillchar`.", "question_id": 9094},
{"snippet": "Series.str.pad(width)", "intent": "Pad strings in the Series/Index up to `width` .", "question_id": 9095},
{"snippet": "Series.str.pad(width, side='left')", "intent": "Pad strings in the Series/Index up to `width` . With arguments `side`.", "question_id": 9096},
{"snippet": "Series.str.pad(width, fillchar=' ')", "intent": "Pad strings in the Series/Index up to `width` . With arguments `fillchar`.", "question_id": 9097},
{"snippet": "Series.str.pad(width, side='left', fillchar=' ')", "intent": "Pad strings in the Series/Index up to `width` . With arguments `side`, `fillchar`.", "question_id": 9098},
{"snippet": "Series.str.partition()", "intent": "Split the string at the first occurrence of `sep` .", "question_id": 9099},
{"snippet": "Series.str.partition(sep=' ')", "intent": "Split the string at the first occurrence of `sep` .", "question_id": 9100},
{"snippet": "Series.str.partition(expand=True)", "intent": "Split the string at the first occurrence of `sep` . With arguments `expand`.", "question_id": 9101},
{"snippet": "Series.str.partition(sep=' ', expand=True)", "intent": "Split the string at the first occurrence of `sep` . With arguments `expand`.", "question_id": 9102},
{"snippet": "Series.str.partition()", "intent": "Split the string at the first occurrence of `sep` .", "question_id": 9103},
{"snippet": "Series.str.partition(sep=' ')", "intent": "Split the string at the first occurrence of `sep` .", "question_id": 9104},
{"snippet": "Series.str.partition(expand=True)", "intent": "Split the string at the first occurrence of `sep` . With arguments `expand`.", "question_id": 9105},
{"snippet": "Series.str.partition(sep=' ', expand=True)", "intent": "Split the string at the first occurrence of `sep` . With arguments `expand`.", "question_id": 9106},
{"snippet": "Series.str.partition()", "intent": "Split the string at the first occurrence of `sep` .", "question_id": 9107},
{"snippet": "Series.str.partition(sep=' ')", "intent": "Split the string at the first occurrence of `sep` .", "question_id": 9108},
{"snippet": "Series.str.partition(expand=True)", "intent": "Split the string at the first occurrence of `sep` . With arguments `expand`.", "question_id": 9109},
{"snippet": "Series.str.partition(sep=' ', expand=True)", "intent": "Split the string at the first occurrence of `sep` . With arguments `expand`.", "question_id": 9110},
{"snippet": "Series.str.repeat(repeats)", "intent": "Duplicate each string in the Series or Index . Single int `repeats` string in Series", "question_id": 9111},
{"snippet": "Series.str.repeat(repeats)", "intent": "Duplicate each string in the Series or Index . Single int `repeats` string in Series", "question_id": 9112},
{"snippet": "Series.str.repeat(repeats)", "intent": "Duplicate each string in the Series or Index . Single int `repeats` string in Series", "question_id": 9113},
{"snippet": "Series.str.replace(pat, repl)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) .", "question_id": 9114},
{"snippet": "Series.str.replace(pat, repl, n=- 1)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . With arguments `n`.", "question_id": 9115},
{"snippet": "Series.str.replace(pat, repl, case=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Use of `case` , flags , or regex=False with a compiled regex will raise an error .", "question_id": 9116},
{"snippet": "Series.str.replace(pat, repl, flags=0)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) .", "question_id": 9117},
{"snippet": "Series.str.replace(pat, repl, regex=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Equivalent to str.replace ( ) or re.sub ( ) , depending on the `regex` value .", "question_id": 9118},
{"snippet": "Series.str.replace(pat, repl, n=- 1, case=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Use of `case` , flags , or regex=False with a compiled regex will raise an error . With arguments `n`.", "question_id": 9119},
{"snippet": "Series.str.replace(pat, repl, n=- 1, flags=0)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . With arguments `n`.", "question_id": 9120},
{"snippet": "Series.str.replace(pat, repl, n=- 1, regex=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Equivalent to str.replace ( ) or re.sub ( ) , depending on the `regex` value . With arguments `n`.", "question_id": 9121},
{"snippet": "Series.str.replace(pat, repl, case=None, flags=0)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Use of `case` , flags , or regex=False with a compiled regex will raise an error .", "question_id": 9122},
{"snippet": "Series.str.replace(pat, repl, case=None, regex=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Use of `case` , flags , or regex=False with a compiled regex will raise an error . Equivalent to str.replace ( ) or re.sub ( ) , depending on the `regex` value .", "question_id": 9123},
{"snippet": "Series.str.replace(pat, repl)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) .", "question_id": 9124},
{"snippet": "Series.str.replace(pat, repl, n=- 1)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . With arguments `n`.", "question_id": 9125},
{"snippet": "Series.str.replace(pat, repl, case=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Use of `case` , flags , or regex=False with a compiled regex will raise an error .", "question_id": 9126},
{"snippet": "Series.str.replace(pat, repl, flags=0)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) .", "question_id": 9127},
{"snippet": "Series.str.replace(pat, repl, regex=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Equivalent to str.replace ( ) or re.sub ( ) , depending on the `regex` value .", "question_id": 9128},
{"snippet": "Series.str.replace(pat, repl, n=- 1, case=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Use of `case` , flags , or regex=False with a compiled regex will raise an error . With arguments `n`.", "question_id": 9129},
{"snippet": "Series.str.replace(pat, repl, n=- 1, flags=0)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . With arguments `n`.", "question_id": 9130},
{"snippet": "Series.str.replace(pat, repl, n=- 1, regex=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Equivalent to str.replace ( ) or re.sub ( ) , depending on the `regex` value . With arguments `n`.", "question_id": 9131},
{"snippet": "Series.str.replace(pat, repl, case=None, flags=0)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Use of `case` , flags , or regex=False with a compiled regex will raise an error .", "question_id": 9132},
{"snippet": "Series.str.replace(pat, repl, case=None, regex=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Use of `case` , flags , or regex=False with a compiled regex will raise an error . Equivalent to str.replace ( ) or re.sub ( ) , depending on the `regex` value .", "question_id": 9133},
{"snippet": "Series.str.replace(pat, repl)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) .", "question_id": 9134},
{"snippet": "Series.str.replace(pat, repl, n=- 1)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . With arguments `n`.", "question_id": 9135},
{"snippet": "Series.str.replace(pat, repl, case=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Use of `case` , flags , or regex=False with a compiled regex will raise an error .", "question_id": 9136},
{"snippet": "Series.str.replace(pat, repl, flags=0)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) .", "question_id": 9137},
{"snippet": "Series.str.replace(pat, repl, regex=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Equivalent to str.replace ( ) or re.sub ( ) , depending on the `regex` value .", "question_id": 9138},
{"snippet": "Series.str.replace(pat, repl, n=- 1, case=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Use of `case` , flags , or regex=False with a compiled regex will raise an error . With arguments `n`.", "question_id": 9139},
{"snippet": "Series.str.replace(pat, repl, n=- 1, flags=0)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . With arguments `n`.", "question_id": 9140},
{"snippet": "Series.str.replace(pat, repl, n=- 1, regex=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Equivalent to str.replace ( ) or re.sub ( ) , depending on the `regex` value . With arguments `n`.", "question_id": 9141},
{"snippet": "Series.str.replace(pat, repl, case=None, flags=0)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Use of `case` , flags , or regex=False with a compiled regex will raise an error .", "question_id": 9142},
{"snippet": "Series.str.replace(pat, repl, case=None, regex=None)", "intent": "Replace each occurrence of pattern/regex in the Series/Index . When `pat` is a compiled regex , all `flags` should be included in the compiled regex . When `repl` is a string , it replaces matching regex patterns as with re.sub ( ) . Use of `case` , flags , or regex=False with a compiled regex will raise an error . Equivalent to str.replace ( ) or re.sub ( ) , depending on the `regex` value .", "question_id": 9143},
{"snippet": "Series.str.rfind(sub)", "intent": "Return highest indexes in each strings in the Series/Index . With arguments `sub`.", "question_id": 9144},
{"snippet": "Series.str.rfind(sub, start=0)", "intent": "Return highest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9145},
{"snippet": "Series.str.rfind(sub, end=None)", "intent": "Return highest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9146},
{"snippet": "Series.str.rfind(sub, start=0, end=None)", "intent": "Return highest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9147},
{"snippet": "Series.str.rfind(sub)", "intent": "Return highest indexes in each strings in the Series/Index . With arguments `sub`.", "question_id": 9148},
{"snippet": "Series.str.rfind(sub, start=0)", "intent": "Return highest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9149},
{"snippet": "Series.str.rfind(sub, end=None)", "intent": "Return highest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9150},
{"snippet": "Series.str.rfind(sub, start=0, end=None)", "intent": "Return highest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9151},
{"snippet": "Series.str.rfind(sub)", "intent": "Return highest indexes in each strings in the Series/Index . With arguments `sub`.", "question_id": 9152},
{"snippet": "Series.str.rfind(sub, start=0)", "intent": "Return highest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9153},
{"snippet": "Series.str.rfind(sub, end=None)", "intent": "Return highest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9154},
{"snippet": "Series.str.rfind(sub, start=0, end=None)", "intent": "Return highest indexes in each strings in the Series/Index . Each of returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9155},
{"snippet": "Series.str.rindex(sub)", "intent": "Return highest indexes in each string in Series/Index . With arguments `sub`.", "question_id": 9156},
{"snippet": "Series.str.rindex(sub, start=0)", "intent": "Return highest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9157},
{"snippet": "Series.str.rindex(sub, end=None)", "intent": "Return highest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9158},
{"snippet": "Series.str.rindex(sub, start=0, end=None)", "intent": "Return highest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9159},
{"snippet": "Series.str.rindex(sub)", "intent": "Return highest indexes in each string in Series/Index . With arguments `sub`.", "question_id": 9160},
{"snippet": "Series.str.rindex(sub, start=0)", "intent": "Return highest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9161},
{"snippet": "Series.str.rindex(sub, end=None)", "intent": "Return highest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9162},
{"snippet": "Series.str.rindex(sub, start=0, end=None)", "intent": "Return highest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9163},
{"snippet": "Series.str.rindex(sub)", "intent": "Return highest indexes in each string in Series/Index . With arguments `sub`.", "question_id": 9164},
{"snippet": "Series.str.rindex(sub, start=0)", "intent": "Return highest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9165},
{"snippet": "Series.str.rindex(sub, end=None)", "intent": "Return highest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9166},
{"snippet": "Series.str.rindex(sub, start=0, end=None)", "intent": "Return highest indexes in each string in Series/Index . Each of the returned indexes corresponds to the position where the substring is fully contained between [ `start` : `end` ] . With arguments `sub`.", "question_id": 9167},
{"snippet": "Series.str.rjust(width)", "intent": "Pad left side of strings in the Series/Index . With arguments `width`.", "question_id": 9168},
{"snippet": "Series.str.rjust(width, fillchar=' ')", "intent": "Pad left side of strings in the Series/Index . With arguments `width`, `fillchar`.", "question_id": 9169},
{"snippet": "Series.str.rjust(width)", "intent": "Pad left side of strings in the Series/Index . With arguments `width`.", "question_id": 9170},
{"snippet": "Series.str.rjust(width, fillchar=' ')", "intent": "Pad left side of strings in the Series/Index . With arguments `width`, `fillchar`.", "question_id": 9171},
{"snippet": "Series.str.rjust(width)", "intent": "Pad left side of strings in the Series/Index . With arguments `width`.", "question_id": 9172},
{"snippet": "Series.str.rjust(width, fillchar=' ')", "intent": "Pad left side of strings in the Series/Index . With arguments `width`, `fillchar`.", "question_id": 9173},
{"snippet": "Series.str.rpartition()", "intent": "Split the string at the last occurrence of `sep` .", "question_id": 9174},
{"snippet": "Series.str.rpartition(sep=' ')", "intent": "Split the string at the last occurrence of `sep` .", "question_id": 9175},
{"snippet": "Series.str.rpartition(expand=True)", "intent": "Split the string at the last occurrence of `sep` . With arguments `expand`.", "question_id": 9176},
{"snippet": "Series.str.rpartition(sep=' ', expand=True)", "intent": "Split the string at the last occurrence of `sep` . With arguments `expand`.", "question_id": 9177},
{"snippet": "Series.str.rpartition()", "intent": "Split the string at the last occurrence of `sep` .", "question_id": 9178},
{"snippet": "Series.str.rpartition(sep=' ')", "intent": "Split the string at the last occurrence of `sep` .", "question_id": 9179},
{"snippet": "Series.str.rpartition(expand=True)", "intent": "Split the string at the last occurrence of `sep` . With arguments `expand`.", "question_id": 9180},
{"snippet": "Series.str.rpartition(sep=' ', expand=True)", "intent": "Split the string at the last occurrence of `sep` . With arguments `expand`.", "question_id": 9181},
{"snippet": "Series.str.rpartition()", "intent": "Split the string at the last occurrence of `sep` .", "question_id": 9182},
{"snippet": "Series.str.rpartition(sep=' ')", "intent": "Split the string at the last occurrence of `sep` .", "question_id": 9183},
{"snippet": "Series.str.rpartition(expand=True)", "intent": "Split the string at the last occurrence of `sep` . With arguments `expand`.", "question_id": 9184},
{"snippet": "Series.str.rpartition(sep=' ', expand=True)", "intent": "Split the string at the last occurrence of `sep` . With arguments `expand`.", "question_id": 9185},
{"snippet": "Series.str.rsplit()", "intent": "Split strings around given separator/delimiter .", "question_id": 9186},
{"snippet": "Series.str.rsplit(pat=None)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters .", "question_id": 9187},
{"snippet": "Series.str.rsplit(n=- 1)", "intent": "Split strings around given separator/delimiter . The handling of the `n` keyword depends on the number of found splits :", "question_id": 9188},
{"snippet": "Series.str.rsplit(expand=False)", "intent": "Split strings around given separator/delimiter . When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9189},
{"snippet": "Series.str.rsplit(pat=None, n=- 1)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . The handling of the `n` keyword depends on the number of found splits :", "question_id": 9190},
{"snippet": "Series.str.rsplit(pat=None, expand=False)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9191},
{"snippet": "Series.str.rsplit(n=- 1, expand=False)", "intent": "Split strings around given separator/delimiter . The handling of the `n` keyword depends on the number of found splits : When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9192},
{"snippet": "Series.str.rsplit(pat=None, n=- 1, expand=False)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . The handling of the `n` keyword depends on the number of found splits : When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9193},
{"snippet": "Series.str.rsplit()", "intent": "Split strings around given separator/delimiter .", "question_id": 9194},
{"snippet": "Series.str.rsplit(pat=None)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters .", "question_id": 9195},
{"snippet": "Series.str.rsplit(n=- 1)", "intent": "Split strings around given separator/delimiter . The handling of the `n` keyword depends on the number of found splits :", "question_id": 9196},
{"snippet": "Series.str.rsplit(expand=False)", "intent": "Split strings around given separator/delimiter . When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9197},
{"snippet": "Series.str.rsplit(pat=None, n=- 1)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . The handling of the `n` keyword depends on the number of found splits :", "question_id": 9198},
{"snippet": "Series.str.rsplit(pat=None, expand=False)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9199},
{"snippet": "Series.str.rsplit(n=- 1, expand=False)", "intent": "Split strings around given separator/delimiter . The handling of the `n` keyword depends on the number of found splits : When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9200},
{"snippet": "Series.str.rsplit(pat=None, n=- 1, expand=False)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . The handling of the `n` keyword depends on the number of found splits : When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9201},
{"snippet": "Series.str.rsplit()", "intent": "Split strings around given separator/delimiter .", "question_id": 9202},
{"snippet": "Series.str.rsplit(pat=None)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters .", "question_id": 9203},
{"snippet": "Series.str.rsplit(n=- 1)", "intent": "Split strings around given separator/delimiter . The handling of the `n` keyword depends on the number of found splits :", "question_id": 9204},
{"snippet": "Series.str.rsplit(expand=False)", "intent": "Split strings around given separator/delimiter . When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9205},
{"snippet": "Series.str.rsplit(pat=None, n=- 1)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . The handling of the `n` keyword depends on the number of found splits :", "question_id": 9206},
{"snippet": "Series.str.rsplit(pat=None, expand=False)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9207},
{"snippet": "Series.str.rsplit(n=- 1, expand=False)", "intent": "Split strings around given separator/delimiter . The handling of the `n` keyword depends on the number of found splits : When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9208},
{"snippet": "Series.str.rsplit(pat=None, n=- 1, expand=False)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . The handling of the `n` keyword depends on the number of found splits : When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9209},
{"snippet": "Series.str.rstrip()", "intent": "Remove trailing characters .", "question_id": 9210},
{"snippet": "Series.str.rstrip(to_strip=None)", "intent": "Remove trailing characters . With arguments `to_strip`.", "question_id": 9211},
{"snippet": "Series.str.rstrip()", "intent": "Remove trailing characters .", "question_id": 9212},
{"snippet": "Series.str.rstrip(to_strip=None)", "intent": "Remove trailing characters . With arguments `to_strip`.", "question_id": 9213},
{"snippet": "Series.str.rstrip()", "intent": "Remove trailing characters .", "question_id": 9214},
{"snippet": "Series.str.rstrip(to_strip=None)", "intent": "Remove trailing characters . With arguments `to_strip`.", "question_id": 9215},
{"snippet": "Series.str.slice()", "intent": "Slice substrings from each element in the Series or Index .", "question_id": 9216},
{"snippet": "Series.str.slice(start=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `start`.", "question_id": 9217},
{"snippet": "Series.str.slice(stop=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `stop`.", "question_id": 9218},
{"snippet": "Series.str.slice(step=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `step`.", "question_id": 9219},
{"snippet": "Series.str.slice(start=None, stop=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `start`, `stop`.", "question_id": 9220},
{"snippet": "Series.str.slice(start=None, step=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `start`, `step`.", "question_id": 9221},
{"snippet": "Series.str.slice(stop=None, step=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `stop`, `step`.", "question_id": 9222},
{"snippet": "Series.str.slice(start=None, stop=None, step=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `start`, `stop`, `step`.", "question_id": 9223},
{"snippet": "Series.str.slice()", "intent": "Slice substrings from each element in the Series or Index .", "question_id": 9224},
{"snippet": "Series.str.slice(start=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `start`.", "question_id": 9225},
{"snippet": "Series.str.slice(stop=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `stop`.", "question_id": 9226},
{"snippet": "Series.str.slice(step=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `step`.", "question_id": 9227},
{"snippet": "Series.str.slice(start=None, stop=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `start`, `stop`.", "question_id": 9228},
{"snippet": "Series.str.slice(start=None, step=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `start`, `step`.", "question_id": 9229},
{"snippet": "Series.str.slice(stop=None, step=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `stop`, `step`.", "question_id": 9230},
{"snippet": "Series.str.slice(start=None, stop=None, step=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `start`, `stop`, `step`.", "question_id": 9231},
{"snippet": "Series.str.slice()", "intent": "Slice substrings from each element in the Series or Index .", "question_id": 9232},
{"snippet": "Series.str.slice(start=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `start`.", "question_id": 9233},
{"snippet": "Series.str.slice(stop=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `stop`.", "question_id": 9234},
{"snippet": "Series.str.slice(step=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `step`.", "question_id": 9235},
{"snippet": "Series.str.slice(start=None, stop=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `start`, `stop`.", "question_id": 9236},
{"snippet": "Series.str.slice(start=None, step=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `start`, `step`.", "question_id": 9237},
{"snippet": "Series.str.slice(stop=None, step=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `stop`, `step`.", "question_id": 9238},
{"snippet": "Series.str.slice(start=None, stop=None, step=None)", "intent": "Slice substrings from each element in the Series or Index . With arguments `start`, `stop`, `step`.", "question_id": 9239},
{"snippet": "Series.str.slice_replace()", "intent": "Replace a positional slice of a string with another value .", "question_id": 9240},
{"snippet": "Series.str.slice_replace(start=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` .", "question_id": 9241},
{"snippet": "Series.str.slice_replace(stop=None)", "intent": "Replace a positional slice of a string with another value . Specify just `stop` , meaning the start of the string to stop is replaced with repl , and the rest of the string is included .", "question_id": 9242},
{"snippet": "Series.str.slice_replace(repl=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` .", "question_id": 9243},
{"snippet": "Series.str.slice_replace(start=None, stop=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` . Specify just `stop` , meaning the start of the string to stop is replaced with repl , and the rest of the string is included .", "question_id": 9244},
{"snippet": "Series.str.slice_replace(start=None, repl=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` .", "question_id": 9245},
{"snippet": "Series.str.slice_replace(stop=None, repl=None)", "intent": "Replace a positional slice of a string with another value . Specify just `stop` , meaning the start of the string to stop is replaced with repl , and the rest of the string is included . Specify just `start` , meaning replace start until the end of the string with `repl` .", "question_id": 9246},
{"snippet": "Series.str.slice_replace(start=None, stop=None, repl=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` . Specify just `stop` , meaning the start of the string to stop is replaced with repl , and the rest of the string is included .", "question_id": 9247},
{"snippet": "Series.str.slice_replace()", "intent": "Replace a positional slice of a string with another value .", "question_id": 9248},
{"snippet": "Series.str.slice_replace(start=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` .", "question_id": 9249},
{"snippet": "Series.str.slice_replace(stop=None)", "intent": "Replace a positional slice of a string with another value . Specify just `stop` , meaning the start of the string to stop is replaced with repl , and the rest of the string is included .", "question_id": 9250},
{"snippet": "Series.str.slice_replace(repl=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` .", "question_id": 9251},
{"snippet": "Series.str.slice_replace(start=None, stop=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` . Specify just `stop` , meaning the start of the string to stop is replaced with repl , and the rest of the string is included .", "question_id": 9252},
{"snippet": "Series.str.slice_replace(start=None, repl=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` .", "question_id": 9253},
{"snippet": "Series.str.slice_replace(stop=None, repl=None)", "intent": "Replace a positional slice of a string with another value . Specify just `stop` , meaning the start of the string to stop is replaced with repl , and the rest of the string is included . Specify just `start` , meaning replace start until the end of the string with `repl` .", "question_id": 9254},
{"snippet": "Series.str.slice_replace(start=None, stop=None, repl=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` . Specify just `stop` , meaning the start of the string to stop is replaced with repl , and the rest of the string is included .", "question_id": 9255},
{"snippet": "Series.str.slice_replace()", "intent": "Replace a positional slice of a string with another value .", "question_id": 9256},
{"snippet": "Series.str.slice_replace(start=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` .", "question_id": 9257},
{"snippet": "Series.str.slice_replace(stop=None)", "intent": "Replace a positional slice of a string with another value . Specify just `stop` , meaning the start of the string to stop is replaced with repl , and the rest of the string is included .", "question_id": 9258},
{"snippet": "Series.str.slice_replace(repl=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` .", "question_id": 9259},
{"snippet": "Series.str.slice_replace(start=None, stop=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` . Specify just `stop` , meaning the start of the string to stop is replaced with repl , and the rest of the string is included .", "question_id": 9260},
{"snippet": "Series.str.slice_replace(start=None, repl=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` .", "question_id": 9261},
{"snippet": "Series.str.slice_replace(stop=None, repl=None)", "intent": "Replace a positional slice of a string with another value . Specify just `stop` , meaning the start of the string to stop is replaced with repl , and the rest of the string is included . Specify just `start` , meaning replace start until the end of the string with `repl` .", "question_id": 9262},
{"snippet": "Series.str.slice_replace(start=None, stop=None, repl=None)", "intent": "Replace a positional slice of a string with another value . Specify just `start` , meaning replace start until the end of the string with `repl` . Specify just `stop` , meaning the start of the string to stop is replaced with repl , and the rest of the string is included .", "question_id": 9263},
{"snippet": "Series.str.split()", "intent": "Split strings around given separator/delimiter .", "question_id": 9264},
{"snippet": "Series.str.split(pat=None)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters .", "question_id": 9265},
{"snippet": "Series.str.split(n=- 1)", "intent": "Split strings around given separator/delimiter . The handling of the `n` keyword depends on the number of found splits :", "question_id": 9266},
{"snippet": "Series.str.split(expand=False)", "intent": "Split strings around given separator/delimiter . When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9267},
{"snippet": "Series.str.split(pat=None, n=- 1)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . The handling of the `n` keyword depends on the number of found splits :", "question_id": 9268},
{"snippet": "Series.str.split(pat=None, expand=False)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9269},
{"snippet": "Series.str.split(n=- 1, expand=False)", "intent": "Split strings around given separator/delimiter . The handling of the `n` keyword depends on the number of found splits : When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9270},
{"snippet": "Series.str.split(pat=None, n=- 1, expand=False)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . The handling of the `n` keyword depends on the number of found splits : When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9271},
{"snippet": "Series.str.split()", "intent": "Split strings around given separator/delimiter .", "question_id": 9272},
{"snippet": "Series.str.split(pat=None)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters .", "question_id": 9273},
{"snippet": "Series.str.split(n=- 1)", "intent": "Split strings around given separator/delimiter . The handling of the `n` keyword depends on the number of found splits :", "question_id": 9274},
{"snippet": "Series.str.split(expand=False)", "intent": "Split strings around given separator/delimiter . When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9275},
{"snippet": "Series.str.split(pat=None, n=- 1)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . The handling of the `n` keyword depends on the number of found splits :", "question_id": 9276},
{"snippet": "Series.str.split(pat=None, expand=False)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9277},
{"snippet": "Series.str.split(n=- 1, expand=False)", "intent": "Split strings around given separator/delimiter . The handling of the `n` keyword depends on the number of found splits : When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9278},
{"snippet": "Series.str.split(pat=None, n=- 1, expand=False)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . The handling of the `n` keyword depends on the number of found splits : When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9279},
{"snippet": "Series.str.split()", "intent": "Split strings around given separator/delimiter .", "question_id": 9280},
{"snippet": "Series.str.split(pat=None)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters .", "question_id": 9281},
{"snippet": "Series.str.split(n=- 1)", "intent": "Split strings around given separator/delimiter . The handling of the `n` keyword depends on the number of found splits :", "question_id": 9282},
{"snippet": "Series.str.split(expand=False)", "intent": "Split strings around given separator/delimiter . When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9283},
{"snippet": "Series.str.split(pat=None, n=- 1)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . The handling of the `n` keyword depends on the number of found splits :", "question_id": 9284},
{"snippet": "Series.str.split(pat=None, expand=False)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9285},
{"snippet": "Series.str.split(n=- 1, expand=False)", "intent": "Split strings around given separator/delimiter . The handling of the `n` keyword depends on the number of found splits : When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9286},
{"snippet": "Series.str.split(pat=None, n=- 1, expand=False)", "intent": "Split strings around given separator/delimiter . The `pat` parameter can be used to split by other characters . The handling of the `n` keyword depends on the number of found splits : When using expand=True , the split elements will `expand` out into separate columns .", "question_id": 9287},
{"snippet": "Series.str.startswith(pat)", "intent": "Test if the start of each string element matches a pattern . With arguments `pat`.", "question_id": 9288},
{"snippet": "Series.str.startswith(pat, na=None)", "intent": "Test if the start of each string element matches a pattern . Specifying `na` to be False instead of NaN . With arguments `pat`.", "question_id": 9289},
{"snippet": "Series.str.startswith(pat)", "intent": "Test if the start of each string element matches a pattern . With arguments `pat`.", "question_id": 9290},
{"snippet": "Series.str.startswith(pat, na=None)", "intent": "Test if the start of each string element matches a pattern . Specifying `na` to be False instead of NaN . With arguments `pat`.", "question_id": 9291},
{"snippet": "Series.str.startswith(pat)", "intent": "Test if the start of each string element matches a pattern . With arguments `pat`.", "question_id": 9292},
{"snippet": "Series.str.startswith(pat, na=None)", "intent": "Test if the start of each string element matches a pattern . Specifying `na` to be False instead of NaN . With arguments `pat`.", "question_id": 9293},
{"snippet": "Series.str.strip()", "intent": "Remove leading and trailing characters .", "question_id": 9294},
{"snippet": "Series.str.strip(to_strip=None)", "intent": "Remove leading and trailing characters . With arguments `to_strip`.", "question_id": 9295},
{"snippet": "Series.str.strip()", "intent": "Remove leading and trailing characters .", "question_id": 9296},
{"snippet": "Series.str.strip(to_strip=None)", "intent": "Remove leading and trailing characters . With arguments `to_strip`.", "question_id": 9297},
{"snippet": "Series.str.strip()", "intent": "Remove leading and trailing characters .", "question_id": 9298},
{"snippet": "Series.str.strip(to_strip=None)", "intent": "Remove leading and trailing characters . With arguments `to_strip`.", "question_id": 9299},
{"snippet": "Series.str.swapcase()", "intent": "Convert strings in the Series/Index to be swapcased .", "question_id": 9300},
{"snippet": "Series.str.swapcase()", "intent": "Convert strings in the Series/Index to be swapcased .", "question_id": 9301},
{"snippet": "Series.str.swapcase()", "intent": "Convert strings in the Series/Index to be swapcased .", "question_id": 9302},
{"snippet": "Series.str.title()", "intent": "Convert strings in the Series/Index to titlecase .", "question_id": 9303},
{"snippet": "Series.str.title()", "intent": "Convert strings in the Series/Index to titlecase .", "question_id": 9304},
{"snippet": "Series.str.title()", "intent": "Convert strings in the Series/Index to titlecase .", "question_id": 9305},
{"snippet": "Series.str.translate(table)", "intent": "Map all characters in the string through the given mapping `table` .", "question_id": 9306},
{"snippet": "Series.str.translate(table)", "intent": "Map all characters in the string through the given mapping `table` .", "question_id": 9307},
{"snippet": "Series.str.translate(table)", "intent": "Map all characters in the string through the given mapping `table` .", "question_id": 9308},
{"snippet": "Series.str.upper()", "intent": "Convert strings in the Series/Index to uppercase .", "question_id": 9309},
{"snippet": "Series.str.upper()", "intent": "Convert strings in the Series/Index to uppercase .", "question_id": 9310},
{"snippet": "Series.str.upper()", "intent": "Convert strings in the Series/Index to uppercase .", "question_id": 9311},
{"snippet": "Series.str.wrap(width, **kwargs)", "intent": "Wrap strings in Series/Index at specified line `width` . With arguments `**kwargs`.", "question_id": 9312},
{"snippet": "Series.str.wrap(width, **kwargs)", "intent": "Wrap strings in Series/Index at specified line `width` . With arguments `**kwargs`.", "question_id": 9313},
{"snippet": "Series.str.wrap(width, **kwargs)", "intent": "Wrap strings in Series/Index at specified line `width` . With arguments `**kwargs`.", "question_id": 9314},
{"snippet": "Series.str.zfill(width)", "intent": "Pad strings in the Series/Index by prepending \u2018 0 \u2019 characters . Strings in the Series/Index are padded with \u2018 0 \u2019 characters on the left of the string to reach a total string length `width` .", "question_id": 9315},
{"snippet": "Series.str.zfill(width)", "intent": "Pad strings in the Series/Index by prepending \u2018 0 \u2019 characters . Strings in the Series/Index are padded with \u2018 0 \u2019 characters on the left of the string to reach a total string length `width` .", "question_id": 9316},
{"snippet": "Series.str.zfill(width)", "intent": "Pad strings in the Series/Index by prepending \u2018 0 \u2019 characters . Strings in the Series/Index are padded with \u2018 0 \u2019 characters on the left of the string to reach a total string length `width` .", "question_id": 9317},
{"snippet": "Series.sub(other)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) .", "question_id": 9318},
{"snippet": "Series.sub(other, level=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `level`.", "question_id": 9319},
{"snippet": "Series.sub(other, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 9320},
{"snippet": "Series.sub(other, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `axis`.", "question_id": 9321},
{"snippet": "Series.sub(other, level=None, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 9322},
{"snippet": "Series.sub(other, level=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `level`, `axis`.", "question_id": 9323},
{"snippet": "Series.sub(other, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 9324},
{"snippet": "Series.sub(other, level=None, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 9325},
{"snippet": "Series.sub(other)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) .", "question_id": 9326},
{"snippet": "Series.sub(other, level=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `level`.", "question_id": 9327},
{"snippet": "Series.sub(other, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 9328},
{"snippet": "Series.sub(other, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `axis`.", "question_id": 9329},
{"snippet": "Series.sub(other, level=None, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 9330},
{"snippet": "Series.sub(other, level=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `level`, `axis`.", "question_id": 9331},
{"snippet": "Series.sub(other, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 9332},
{"snippet": "Series.sub(other, level=None, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 9333},
{"snippet": "Series.sub(other)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) .", "question_id": 9334},
{"snippet": "Series.sub(other, level=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `level`.", "question_id": 9335},
{"snippet": "Series.sub(other, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 9336},
{"snippet": "Series.sub(other, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `axis`.", "question_id": 9337},
{"snippet": "Series.sub(other, level=None, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 9338},
{"snippet": "Series.sub(other, level=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `level`, `axis`.", "question_id": 9339},
{"snippet": "Series.sub(other, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 9340},
{"snippet": "Series.sub(other, level=None, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 9341},
{"snippet": "Series.subtract(other)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) .", "question_id": 9342},
{"snippet": "Series.subtract(other, level=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `level`.", "question_id": 9343},
{"snippet": "Series.subtract(other, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 9344},
{"snippet": "Series.subtract(other, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `axis`.", "question_id": 9345},
{"snippet": "Series.subtract(other, level=None, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 9346},
{"snippet": "Series.subtract(other, level=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `level`, `axis`.", "question_id": 9347},
{"snippet": "Series.subtract(other, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 9348},
{"snippet": "Series.subtract(other, level=None, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 9349},
{"snippet": "Series.subtract(other)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) .", "question_id": 9350},
{"snippet": "Series.subtract(other, level=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `level`.", "question_id": 9351},
{"snippet": "Series.subtract(other, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 9352},
{"snippet": "Series.subtract(other, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `axis`.", "question_id": 9353},
{"snippet": "Series.subtract(other, level=None, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 9354},
{"snippet": "Series.subtract(other, level=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `level`, `axis`.", "question_id": 9355},
{"snippet": "Series.subtract(other, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 9356},
{"snippet": "Series.subtract(other, level=None, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 9357},
{"snippet": "Series.subtract(other)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) .", "question_id": 9358},
{"snippet": "Series.subtract(other, level=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `level`.", "question_id": 9359},
{"snippet": "Series.subtract(other, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 9360},
{"snippet": "Series.subtract(other, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `axis`.", "question_id": 9361},
{"snippet": "Series.subtract(other, level=None, fill_value=None)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 9362},
{"snippet": "Series.subtract(other, level=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . With arguments `level`, `axis`.", "question_id": 9363},
{"snippet": "Series.subtract(other, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 9364},
{"snippet": "Series.subtract(other, level=None, fill_value=None, axis=0)", "intent": "Return Subtraction of series and `other` , element-wise ( binary operator sub ) . Equivalent to series - other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 9365},
{"snippet": "Series.sum(**kwargs)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 9366},
{"snippet": "Series.sum(**kwargs, axis=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 9367},
{"snippet": "Series.sum(**kwargs, skipna=None)", "intent": "Return the sum of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 9368},
{"snippet": "Series.sum(**kwargs, level=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 9369},
{"snippet": "Series.sum(**kwargs, numeric_only=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 9370},
{"snippet": "Series.sum(**kwargs, min_count=0)", "intent": "Return the sum of the values over the requested `axis` . This can be controlled with the `min_count` parameter . With arguments `**kwargs`.", "question_id": 9371},
{"snippet": "Series.sum(**kwargs, axis=None, skipna=None)", "intent": "Return the sum of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 9372},
{"snippet": "Series.sum(**kwargs, axis=None, level=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 9373},
{"snippet": "Series.sum(**kwargs, axis=None, numeric_only=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 9374},
{"snippet": "Series.sum(**kwargs, axis=None, min_count=0)", "intent": "Return the sum of the values over the requested `axis` . This can be controlled with the `min_count` parameter . With arguments `**kwargs`.", "question_id": 9375},
{"snippet": "Series.sum(**kwargs)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 9376},
{"snippet": "Series.sum(**kwargs, axis=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 9377},
{"snippet": "Series.sum(**kwargs, skipna=None)", "intent": "Return the sum of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 9378},
{"snippet": "Series.sum(**kwargs, level=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 9379},
{"snippet": "Series.sum(**kwargs, numeric_only=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 9380},
{"snippet": "Series.sum(**kwargs, min_count=0)", "intent": "Return the sum of the values over the requested `axis` . This can be controlled with the `min_count` parameter . With arguments `**kwargs`.", "question_id": 9381},
{"snippet": "Series.sum(**kwargs, axis=None, skipna=None)", "intent": "Return the sum of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 9382},
{"snippet": "Series.sum(**kwargs, axis=None, level=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 9383},
{"snippet": "Series.sum(**kwargs, axis=None, numeric_only=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 9384},
{"snippet": "Series.sum(**kwargs, axis=None, min_count=0)", "intent": "Return the sum of the values over the requested `axis` . This can be controlled with the `min_count` parameter . With arguments `**kwargs`.", "question_id": 9385},
{"snippet": "Series.sum(**kwargs)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 9386},
{"snippet": "Series.sum(**kwargs, axis=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`.", "question_id": 9387},
{"snippet": "Series.sum(**kwargs, skipna=None)", "intent": "Return the sum of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 9388},
{"snippet": "Series.sum(**kwargs, level=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 9389},
{"snippet": "Series.sum(**kwargs, numeric_only=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 9390},
{"snippet": "Series.sum(**kwargs, min_count=0)", "intent": "Return the sum of the values over the requested `axis` . This can be controlled with the `min_count` parameter . With arguments `**kwargs`.", "question_id": 9391},
{"snippet": "Series.sum(**kwargs, axis=None, skipna=None)", "intent": "Return the sum of the values over the requested `axis` . Thanks to the `skipna` parameter , min_count handles all-NA and empty series identically . With arguments `**kwargs`.", "question_id": 9392},
{"snippet": "Series.sum(**kwargs, axis=None, level=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 9393},
{"snippet": "Series.sum(**kwargs, axis=None, numeric_only=None)", "intent": "Return the sum of the values over the requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 9394},
{"snippet": "Series.sum(**kwargs, axis=None, min_count=0)", "intent": "Return the sum of the values over the requested `axis` . This can be controlled with the `min_count` parameter . With arguments `**kwargs`.", "question_id": 9395},
{"snippet": "Series.swapaxes(axis1, axis2)", "intent": "Interchange axes and swap values axes appropriately . With arguments `axis1`, `axis2`.", "question_id": 9396},
{"snippet": "Series.swapaxes(axis1, axis2, copy=True)", "intent": "Interchange axes and swap values axes appropriately . With arguments `axis1`, `axis2`, `copy`.", "question_id": 9397},
{"snippet": "Series.swapaxes(axis1, axis2)", "intent": "Interchange axes and swap values axes appropriately . With arguments `axis1`, `axis2`.", "question_id": 9398},
{"snippet": "Series.swapaxes(axis1, axis2, copy=True)", "intent": "Interchange axes and swap values axes appropriately . With arguments `axis1`, `axis2`, `copy`.", "question_id": 9399},
{"snippet": "Series.swapaxes(axis1, axis2)", "intent": "Interchange axes and swap values axes appropriately . With arguments `axis1`, `axis2`.", "question_id": 9400},
{"snippet": "Series.swapaxes(axis1, axis2, copy=True)", "intent": "Interchange axes and swap values axes appropriately . With arguments `axis1`, `axis2`, `copy`.", "question_id": 9401},
{"snippet": "Series.swaplevel()", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 9402},
{"snippet": "Series.swaplevel(i=- 2)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 9403},
{"snippet": "Series.swaplevel(j=- 1)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 9404},
{"snippet": "Series.swaplevel(copy=True)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `copy`.", "question_id": 9405},
{"snippet": "Series.swaplevel(i=- 2, j=- 1)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 9406},
{"snippet": "Series.swaplevel(i=- 2, copy=True)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `copy`.", "question_id": 9407},
{"snippet": "Series.swaplevel(j=- 1, copy=True)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `copy`.", "question_id": 9408},
{"snippet": "Series.swaplevel(i=- 2, j=- 1, copy=True)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `copy`.", "question_id": 9409},
{"snippet": "Series.swaplevel()", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 9410},
{"snippet": "Series.swaplevel(i=- 2)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 9411},
{"snippet": "Series.swaplevel(j=- 1)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 9412},
{"snippet": "Series.swaplevel(copy=True)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `copy`.", "question_id": 9413},
{"snippet": "Series.swaplevel(i=- 2, j=- 1)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 9414},
{"snippet": "Series.swaplevel(i=- 2, copy=True)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `copy`.", "question_id": 9415},
{"snippet": "Series.swaplevel(j=- 1, copy=True)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `copy`.", "question_id": 9416},
{"snippet": "Series.swaplevel(i=- 2, j=- 1, copy=True)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `copy`.", "question_id": 9417},
{"snippet": "Series.swaplevel()", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 9418},
{"snippet": "Series.swaplevel(i=- 2)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 9419},
{"snippet": "Series.swaplevel(j=- 1)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 9420},
{"snippet": "Series.swaplevel(copy=True)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `copy`.", "question_id": 9421},
{"snippet": "Series.swaplevel(i=- 2, j=- 1)", "intent": "Swap levels `i` and `j` in a MultiIndex .", "question_id": 9422},
{"snippet": "Series.swaplevel(i=- 2, copy=True)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `copy`.", "question_id": 9423},
{"snippet": "Series.swaplevel(j=- 1, copy=True)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `copy`.", "question_id": 9424},
{"snippet": "Series.swaplevel(i=- 2, j=- 1, copy=True)", "intent": "Swap levels `i` and `j` in a MultiIndex . With arguments `copy`.", "question_id": 9425},
{"snippet": "Series.tail()", "intent": "Return the last `n` rows .", "question_id": 9426},
{"snippet": "Series.tail(n=5)", "intent": "Return the last `n` rows .", "question_id": 9427},
{"snippet": "Series.tail()", "intent": "Return the last `n` rows .", "question_id": 9428},
{"snippet": "Series.tail(n=5)", "intent": "Return the last `n` rows .", "question_id": 9429},
{"snippet": "Series.tail()", "intent": "Return the last `n` rows .", "question_id": 9430},
{"snippet": "Series.tail(n=5)", "intent": "Return the last `n` rows .", "question_id": 9431},
{"snippet": "Series.take(indices, **kwargs)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`.", "question_id": 9432},
{"snippet": "Series.take(indices, **kwargs, axis=0)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`.", "question_id": 9433},
{"snippet": "Series.take(indices, **kwargs, is_copy=None)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`, `is_copy`.", "question_id": 9434},
{"snippet": "Series.take(indices, **kwargs, axis=0, is_copy=None)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`, `is_copy`.", "question_id": 9435},
{"snippet": "Series.take(indices, **kwargs)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`.", "question_id": 9436},
{"snippet": "Series.take(indices, **kwargs, axis=0)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`.", "question_id": 9437},
{"snippet": "Series.take(indices, **kwargs, is_copy=None)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`, `is_copy`.", "question_id": 9438},
{"snippet": "Series.take(indices, **kwargs, axis=0, is_copy=None)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`, `is_copy`.", "question_id": 9439},
{"snippet": "Series.take(indices, **kwargs)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`.", "question_id": 9440},
{"snippet": "Series.take(indices, **kwargs, axis=0)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`.", "question_id": 9441},
{"snippet": "Series.take(indices, **kwargs, is_copy=None)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`, `is_copy`.", "question_id": 9442},
{"snippet": "Series.take(indices, **kwargs, axis=0, is_copy=None)", "intent": "Return the elements in the given positional `indices` along an `axis` . With arguments `**kwargs`, `is_copy`.", "question_id": 9443},
{"snippet": "Series.to_clipboard(**kwargs)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`.", "question_id": 9444},
{"snippet": "Series.to_clipboard(**kwargs, excel=True)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `excel`.", "question_id": 9445},
{"snippet": "Series.to_clipboard(**kwargs, sep=None)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `sep`.", "question_id": 9446},
{"snippet": "Series.to_clipboard(**kwargs, excel=True, sep=None)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `excel`, `sep`.", "question_id": 9447},
{"snippet": "Series.to_clipboard(**kwargs)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`.", "question_id": 9448},
{"snippet": "Series.to_clipboard(**kwargs, excel=True)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `excel`.", "question_id": 9449},
{"snippet": "Series.to_clipboard(**kwargs, sep=None)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `sep`.", "question_id": 9450},
{"snippet": "Series.to_clipboard(**kwargs, excel=True, sep=None)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `excel`, `sep`.", "question_id": 9451},
{"snippet": "Series.to_clipboard(**kwargs)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`.", "question_id": 9452},
{"snippet": "Series.to_clipboard(**kwargs, excel=True)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `excel`.", "question_id": 9453},
{"snippet": "Series.to_clipboard(**kwargs, sep=None)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `sep`.", "question_id": 9454},
{"snippet": "Series.to_clipboard(**kwargs, excel=True, sep=None)", "intent": "Copy object to the system clipboard . With arguments `**kwargs`, `excel`, `sep`.", "question_id": 9455},
{"snippet": "Series.to_csv()", "intent": "Write object to a comma-separated values ( csv ) file .", "question_id": 9456},
{"snippet": "Series.to_csv(path_or_buf=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `path_or_buf`.", "question_id": 9457},
{"snippet": "Series.to_csv(sep=',')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `sep`.", "question_id": 9458},
{"snippet": "Series.to_csv(na_rep='')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `na_rep`.", "question_id": 9459},
{"snippet": "Series.to_csv(float_format=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `float_format`.", "question_id": 9460},
{"snippet": "Series.to_csv(columns=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `columns`.", "question_id": 9461},
{"snippet": "Series.to_csv(header=True)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `header`.", "question_id": 9462},
{"snippet": "Series.to_csv(index=True)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `index`.", "question_id": 9463},
{"snippet": "Series.to_csv(index_label=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `index_label`.", "question_id": 9464},
{"snippet": "Series.to_csv(mode='w')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `mode`.", "question_id": 9465},
{"snippet": "Series.to_csv()", "intent": "Write object to a comma-separated values ( csv ) file .", "question_id": 9466},
{"snippet": "Series.to_csv(path_or_buf=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `path_or_buf`.", "question_id": 9467},
{"snippet": "Series.to_csv(sep=',')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `sep`.", "question_id": 9468},
{"snippet": "Series.to_csv(na_rep='')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `na_rep`.", "question_id": 9469},
{"snippet": "Series.to_csv(float_format=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `float_format`.", "question_id": 9470},
{"snippet": "Series.to_csv(columns=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `columns`.", "question_id": 9471},
{"snippet": "Series.to_csv(header=True)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `header`.", "question_id": 9472},
{"snippet": "Series.to_csv(index=True)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `index`.", "question_id": 9473},
{"snippet": "Series.to_csv(index_label=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `index_label`.", "question_id": 9474},
{"snippet": "Series.to_csv(mode='w')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `mode`.", "question_id": 9475},
{"snippet": "Series.to_csv()", "intent": "Write object to a comma-separated values ( csv ) file .", "question_id": 9476},
{"snippet": "Series.to_csv(path_or_buf=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `path_or_buf`.", "question_id": 9477},
{"snippet": "Series.to_csv(sep=',')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `sep`.", "question_id": 9478},
{"snippet": "Series.to_csv(na_rep='')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `na_rep`.", "question_id": 9479},
{"snippet": "Series.to_csv(float_format=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `float_format`.", "question_id": 9480},
{"snippet": "Series.to_csv(columns=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `columns`.", "question_id": 9481},
{"snippet": "Series.to_csv(header=True)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `header`.", "question_id": 9482},
{"snippet": "Series.to_csv(index=True)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `index`.", "question_id": 9483},
{"snippet": "Series.to_csv(index_label=None)", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `index_label`.", "question_id": 9484},
{"snippet": "Series.to_csv(mode='w')", "intent": "Write object to a comma-separated values ( csv ) file . With arguments `mode`.", "question_id": 9485},
{"snippet": "Series.to_dict()", "intent": "Convert Series to { label - > value } dict or dict-like object .", "question_id": 9486},
{"snippet": "Series.to_dict(into=<class 'dict'>)", "intent": "Convert Series to { label - > value } dict or dict-like object . With arguments `into`.", "question_id": 9487},
{"snippet": "Series.to_dict()", "intent": "Convert Series to { label - > value } dict or dict-like object .", "question_id": 9488},
{"snippet": "Series.to_dict(into=<class 'dict'>)", "intent": "Convert Series to { label - > value } dict or dict-like object . With arguments `into`.", "question_id": 9489},
{"snippet": "Series.to_dict()", "intent": "Convert Series to { label - > value } dict or dict-like object .", "question_id": 9490},
{"snippet": "Series.to_dict(into=<class 'dict'>)", "intent": "Convert Series to { label - > value } dict or dict-like object . With arguments `into`.", "question_id": 9491},
{"snippet": "Series.to_excel(excel_writer)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`.", "question_id": 9492},
{"snippet": "Series.to_excel(excel_writer, sheet_name='Sheet1')", "intent": "Write object to an Excel sheet . Multiple sheets may be written to by specifying unique `sheet_name` . With arguments `excel_writer`.", "question_id": 9493},
{"snippet": "Series.to_excel(excel_writer, na_rep='')", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `na_rep`.", "question_id": 9494},
{"snippet": "Series.to_excel(excel_writer, float_format=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `float_format`.", "question_id": 9495},
{"snippet": "Series.to_excel(excel_writer, columns=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `columns`.", "question_id": 9496},
{"snippet": "Series.to_excel(excel_writer, header=True)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `header`.", "question_id": 9497},
{"snippet": "Series.to_excel(excel_writer, index=True)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `index`.", "question_id": 9498},
{"snippet": "Series.to_excel(excel_writer, index_label=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `index_label`.", "question_id": 9499},
{"snippet": "Series.to_excel(excel_writer, startrow=0)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `startrow`.", "question_id": 9500},
{"snippet": "Series.to_excel(excel_writer, startcol=0)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `startcol`.", "question_id": 9501},
{"snippet": "Series.to_excel(excel_writer)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`.", "question_id": 9502},
{"snippet": "Series.to_excel(excel_writer, sheet_name='Sheet1')", "intent": "Write object to an Excel sheet . Multiple sheets may be written to by specifying unique `sheet_name` . With arguments `excel_writer`.", "question_id": 9503},
{"snippet": "Series.to_excel(excel_writer, na_rep='')", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `na_rep`.", "question_id": 9504},
{"snippet": "Series.to_excel(excel_writer, float_format=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `float_format`.", "question_id": 9505},
{"snippet": "Series.to_excel(excel_writer, columns=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `columns`.", "question_id": 9506},
{"snippet": "Series.to_excel(excel_writer, header=True)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `header`.", "question_id": 9507},
{"snippet": "Series.to_excel(excel_writer, index=True)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `index`.", "question_id": 9508},
{"snippet": "Series.to_excel(excel_writer, index_label=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `index_label`.", "question_id": 9509},
{"snippet": "Series.to_excel(excel_writer, startrow=0)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `startrow`.", "question_id": 9510},
{"snippet": "Series.to_excel(excel_writer, startcol=0)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `startcol`.", "question_id": 9511},
{"snippet": "Series.to_excel(excel_writer)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`.", "question_id": 9512},
{"snippet": "Series.to_excel(excel_writer, sheet_name='Sheet1')", "intent": "Write object to an Excel sheet . Multiple sheets may be written to by specifying unique `sheet_name` . With arguments `excel_writer`.", "question_id": 9513},
{"snippet": "Series.to_excel(excel_writer, na_rep='')", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `na_rep`.", "question_id": 9514},
{"snippet": "Series.to_excel(excel_writer, float_format=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `float_format`.", "question_id": 9515},
{"snippet": "Series.to_excel(excel_writer, columns=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `columns`.", "question_id": 9516},
{"snippet": "Series.to_excel(excel_writer, header=True)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `header`.", "question_id": 9517},
{"snippet": "Series.to_excel(excel_writer, index=True)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `index`.", "question_id": 9518},
{"snippet": "Series.to_excel(excel_writer, index_label=None)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `index_label`.", "question_id": 9519},
{"snippet": "Series.to_excel(excel_writer, startrow=0)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `startrow`.", "question_id": 9520},
{"snippet": "Series.to_excel(excel_writer, startcol=0)", "intent": "Write object to an Excel sheet . With arguments `excel_writer`, `startcol`.", "question_id": 9521},
{"snippet": "Series.to_frame()", "intent": "Convert Series to DataFrame .", "question_id": 9522},
{"snippet": "Series.to_frame(name=None)", "intent": "Convert Series to DataFrame . With arguments `name`.", "question_id": 9523},
{"snippet": "Series.to_frame()", "intent": "Convert Series to DataFrame .", "question_id": 9524},
{"snippet": "Series.to_frame(name=None)", "intent": "Convert Series to DataFrame . With arguments `name`.", "question_id": 9525},
{"snippet": "Series.to_frame()", "intent": "Convert Series to DataFrame .", "question_id": 9526},
{"snippet": "Series.to_frame(name=None)", "intent": "Convert Series to DataFrame . With arguments `name`.", "question_id": 9527},
{"snippet": "Series.to_hdf(path_or_buf, key)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 9528},
{"snippet": "Series.to_hdf(path_or_buf, key, mode='a')", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 9529},
{"snippet": "Series.to_hdf(path_or_buf, key, complevel=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `complevel`.", "question_id": 9530},
{"snippet": "Series.to_hdf(path_or_buf, key, complib=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `complib`.", "question_id": 9531},
{"snippet": "Series.to_hdf(path_or_buf, key, append=False)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 9532},
{"snippet": "Series.to_hdf(path_or_buf, key, format=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `format`.", "question_id": 9533},
{"snippet": "Series.to_hdf(path_or_buf, key, index=True)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `index`.", "question_id": 9534},
{"snippet": "Series.to_hdf(path_or_buf, key, min_itemsize=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `min_itemsize`.", "question_id": 9535},
{"snippet": "Series.to_hdf(path_or_buf, key, nan_rep=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `nan_rep`.", "question_id": 9536},
{"snippet": "Series.to_hdf(path_or_buf, key, dropna=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `dropna`.", "question_id": 9537},
{"snippet": "Series.to_hdf(path_or_buf, key)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 9538},
{"snippet": "Series.to_hdf(path_or_buf, key, mode='a')", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 9539},
{"snippet": "Series.to_hdf(path_or_buf, key, complevel=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `complevel`.", "question_id": 9540},
{"snippet": "Series.to_hdf(path_or_buf, key, complib=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `complib`.", "question_id": 9541},
{"snippet": "Series.to_hdf(path_or_buf, key, append=False)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 9542},
{"snippet": "Series.to_hdf(path_or_buf, key, format=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `format`.", "question_id": 9543},
{"snippet": "Series.to_hdf(path_or_buf, key, index=True)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `index`.", "question_id": 9544},
{"snippet": "Series.to_hdf(path_or_buf, key, min_itemsize=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `min_itemsize`.", "question_id": 9545},
{"snippet": "Series.to_hdf(path_or_buf, key, nan_rep=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `nan_rep`.", "question_id": 9546},
{"snippet": "Series.to_hdf(path_or_buf, key, dropna=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `dropna`.", "question_id": 9547},
{"snippet": "Series.to_hdf(path_or_buf, key)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 9548},
{"snippet": "Series.to_hdf(path_or_buf, key, mode='a')", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 9549},
{"snippet": "Series.to_hdf(path_or_buf, key, complevel=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `complevel`.", "question_id": 9550},
{"snippet": "Series.to_hdf(path_or_buf, key, complib=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `complib`.", "question_id": 9551},
{"snippet": "Series.to_hdf(path_or_buf, key, append=False)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`.", "question_id": 9552},
{"snippet": "Series.to_hdf(path_or_buf, key, format=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `format`.", "question_id": 9553},
{"snippet": "Series.to_hdf(path_or_buf, key, index=True)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `index`.", "question_id": 9554},
{"snippet": "Series.to_hdf(path_or_buf, key, min_itemsize=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `min_itemsize`.", "question_id": 9555},
{"snippet": "Series.to_hdf(path_or_buf, key, nan_rep=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `nan_rep`.", "question_id": 9556},
{"snippet": "Series.to_hdf(path_or_buf, key, dropna=None)", "intent": "Write the contained data to an HDF5 file using HDFStore . In order to add another DataFrame or Series to an existing HDF file please use `append` `mode` and a different a `key` . With arguments `path_or_buf`, `dropna`.", "question_id": 9557},
{"snippet": "Series.to_json()", "intent": "Convert the object to a JSON string .", "question_id": 9558},
{"snippet": "Series.to_json(path_or_buf=None)", "intent": "Convert the object to a JSON string . With arguments `path_or_buf`.", "question_id": 9559},
{"snippet": "Series.to_json(orient=None)", "intent": "Convert the object to a JSON string . With arguments `orient`.", "question_id": 9560},
{"snippet": "Series.to_json(date_format=None)", "intent": "Convert the object to a JSON string . With arguments `date_format`.", "question_id": 9561},
{"snippet": "Series.to_json(double_precision=10)", "intent": "Convert the object to a JSON string . With arguments `double_precision`.", "question_id": 9562},
{"snippet": "Series.to_json(force_ascii=True)", "intent": "Convert the object to a JSON string . With arguments `force_ascii`.", "question_id": 9563},
{"snippet": "Series.to_json(date_unit='ms')", "intent": "Convert the object to a JSON string . With arguments `date_unit`.", "question_id": 9564},
{"snippet": "Series.to_json(default_handler=None)", "intent": "Convert the object to a JSON string . With arguments `default_handler`.", "question_id": 9565},
{"snippet": "Series.to_json(lines=False)", "intent": "Convert the object to a JSON string . With arguments `lines`.", "question_id": 9566},
{"snippet": "Series.to_json(compression='infer')", "intent": "Convert the object to a JSON string . With arguments `compression`.", "question_id": 9567},
{"snippet": "Series.to_json()", "intent": "Convert the object to a JSON string .", "question_id": 9568},
{"snippet": "Series.to_json(path_or_buf=None)", "intent": "Convert the object to a JSON string . With arguments `path_or_buf`.", "question_id": 9569},
{"snippet": "Series.to_json(orient=None)", "intent": "Convert the object to a JSON string . With arguments `orient`.", "question_id": 9570},
{"snippet": "Series.to_json(date_format=None)", "intent": "Convert the object to a JSON string . With arguments `date_format`.", "question_id": 9571},
{"snippet": "Series.to_json(double_precision=10)", "intent": "Convert the object to a JSON string . With arguments `double_precision`.", "question_id": 9572},
{"snippet": "Series.to_json(force_ascii=True)", "intent": "Convert the object to a JSON string . With arguments `force_ascii`.", "question_id": 9573},
{"snippet": "Series.to_json(date_unit='ms')", "intent": "Convert the object to a JSON string . With arguments `date_unit`.", "question_id": 9574},
{"snippet": "Series.to_json(default_handler=None)", "intent": "Convert the object to a JSON string . With arguments `default_handler`.", "question_id": 9575},
{"snippet": "Series.to_json(lines=False)", "intent": "Convert the object to a JSON string . With arguments `lines`.", "question_id": 9576},
{"snippet": "Series.to_json(compression='infer')", "intent": "Convert the object to a JSON string . With arguments `compression`.", "question_id": 9577},
{"snippet": "Series.to_json()", "intent": "Convert the object to a JSON string .", "question_id": 9578},
{"snippet": "Series.to_json(path_or_buf=None)", "intent": "Convert the object to a JSON string . With arguments `path_or_buf`.", "question_id": 9579},
{"snippet": "Series.to_json(orient=None)", "intent": "Convert the object to a JSON string . With arguments `orient`.", "question_id": 9580},
{"snippet": "Series.to_json(date_format=None)", "intent": "Convert the object to a JSON string . With arguments `date_format`.", "question_id": 9581},
{"snippet": "Series.to_json(double_precision=10)", "intent": "Convert the object to a JSON string . With arguments `double_precision`.", "question_id": 9582},
{"snippet": "Series.to_json(force_ascii=True)", "intent": "Convert the object to a JSON string . With arguments `force_ascii`.", "question_id": 9583},
{"snippet": "Series.to_json(date_unit='ms')", "intent": "Convert the object to a JSON string . With arguments `date_unit`.", "question_id": 9584},
{"snippet": "Series.to_json(default_handler=None)", "intent": "Convert the object to a JSON string . With arguments `default_handler`.", "question_id": 9585},
{"snippet": "Series.to_json(lines=False)", "intent": "Convert the object to a JSON string . With arguments `lines`.", "question_id": 9586},
{"snippet": "Series.to_json(compression='infer')", "intent": "Convert the object to a JSON string . With arguments `compression`.", "question_id": 9587},
{"snippet": "Series.to_latex()", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular .", "question_id": 9588},
{"snippet": "Series.to_latex(buf=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `buf`.", "question_id": 9589},
{"snippet": "Series.to_latex(columns=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `columns`.", "question_id": 9590},
{"snippet": "Series.to_latex(col_space=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `col_space`.", "question_id": 9591},
{"snippet": "Series.to_latex(header=True)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `header`.", "question_id": 9592},
{"snippet": "Series.to_latex(index=True)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `index`.", "question_id": 9593},
{"snippet": "Series.to_latex(na_rep='NaN')", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `na_rep`.", "question_id": 9594},
{"snippet": "Series.to_latex(formatters=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `formatters`.", "question_id": 9595},
{"snippet": "Series.to_latex(float_format=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `float_format`.", "question_id": 9596},
{"snippet": "Series.to_latex(sparsify=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `sparsify`.", "question_id": 9597},
{"snippet": "Series.to_latex()", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular .", "question_id": 9598},
{"snippet": "Series.to_latex(buf=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `buf`.", "question_id": 9599},
{"snippet": "Series.to_latex(columns=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `columns`.", "question_id": 9600},
{"snippet": "Series.to_latex(col_space=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `col_space`.", "question_id": 9601},
{"snippet": "Series.to_latex(header=True)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `header`.", "question_id": 9602},
{"snippet": "Series.to_latex(index=True)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `index`.", "question_id": 9603},
{"snippet": "Series.to_latex(na_rep='NaN')", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `na_rep`.", "question_id": 9604},
{"snippet": "Series.to_latex(formatters=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `formatters`.", "question_id": 9605},
{"snippet": "Series.to_latex(float_format=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `float_format`.", "question_id": 9606},
{"snippet": "Series.to_latex(sparsify=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `sparsify`.", "question_id": 9607},
{"snippet": "Series.to_latex()", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular .", "question_id": 9608},
{"snippet": "Series.to_latex(buf=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `buf`.", "question_id": 9609},
{"snippet": "Series.to_latex(columns=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `columns`.", "question_id": 9610},
{"snippet": "Series.to_latex(col_space=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `col_space`.", "question_id": 9611},
{"snippet": "Series.to_latex(header=True)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `header`.", "question_id": 9612},
{"snippet": "Series.to_latex(index=True)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `index`.", "question_id": 9613},
{"snippet": "Series.to_latex(na_rep='NaN')", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `na_rep`.", "question_id": 9614},
{"snippet": "Series.to_latex(formatters=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `formatters`.", "question_id": 9615},
{"snippet": "Series.to_latex(float_format=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `float_format`.", "question_id": 9616},
{"snippet": "Series.to_latex(sparsify=None)", "intent": "Render object to a LaTeX tabular , `longtable` , or nested table/tabular . With arguments `sparsify`.", "question_id": 9617},
{"snippet": "Series.to_list()", "intent": "Return a list of the values .", "question_id": 9618},
{"snippet": "Series.to_list()", "intent": "Return a list of the values .", "question_id": 9619},
{"snippet": "Series.to_list()", "intent": "Return a list of the values .", "question_id": 9620},
{"snippet": "Series.to_markdown(**kwargs)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`.", "question_id": 9621},
{"snippet": "Series.to_markdown(**kwargs, buf=None)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `buf`.", "question_id": 9622},
{"snippet": "Series.to_markdown(**kwargs, mode='wt')", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `mode`.", "question_id": 9623},
{"snippet": "Series.to_markdown(**kwargs, index=True)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `index`.", "question_id": 9624},
{"snippet": "Series.to_markdown(**kwargs, storage_options=None)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `storage_options`.", "question_id": 9625},
{"snippet": "Series.to_markdown(**kwargs, buf=None, mode='wt')", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `buf`, `mode`.", "question_id": 9626},
{"snippet": "Series.to_markdown(**kwargs, buf=None, index=True)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `buf`, `index`.", "question_id": 9627},
{"snippet": "Series.to_markdown(**kwargs, buf=None, storage_options=None)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `buf`, `storage_options`.", "question_id": 9628},
{"snippet": "Series.to_markdown(**kwargs, mode='wt', index=True)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `mode`, `index`.", "question_id": 9629},
{"snippet": "Series.to_markdown(**kwargs, mode='wt', storage_options=None)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `mode`, `storage_options`.", "question_id": 9630},
{"snippet": "Series.to_markdown(**kwargs)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`.", "question_id": 9631},
{"snippet": "Series.to_markdown(**kwargs, buf=None)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `buf`.", "question_id": 9632},
{"snippet": "Series.to_markdown(**kwargs, mode='wt')", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `mode`.", "question_id": 9633},
{"snippet": "Series.to_markdown(**kwargs, index=True)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `index`.", "question_id": 9634},
{"snippet": "Series.to_markdown(**kwargs, storage_options=None)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `storage_options`.", "question_id": 9635},
{"snippet": "Series.to_markdown(**kwargs, buf=None, mode='wt')", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `buf`, `mode`.", "question_id": 9636},
{"snippet": "Series.to_markdown(**kwargs, buf=None, index=True)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `buf`, `index`.", "question_id": 9637},
{"snippet": "Series.to_markdown(**kwargs, buf=None, storage_options=None)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `buf`, `storage_options`.", "question_id": 9638},
{"snippet": "Series.to_markdown(**kwargs, mode='wt', index=True)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `mode`, `index`.", "question_id": 9639},
{"snippet": "Series.to_markdown(**kwargs, mode='wt', storage_options=None)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `mode`, `storage_options`.", "question_id": 9640},
{"snippet": "Series.to_markdown(**kwargs)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`.", "question_id": 9641},
{"snippet": "Series.to_markdown(**kwargs, buf=None)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `buf`.", "question_id": 9642},
{"snippet": "Series.to_markdown(**kwargs, mode='wt')", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `mode`.", "question_id": 9643},
{"snippet": "Series.to_markdown(**kwargs, index=True)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `index`.", "question_id": 9644},
{"snippet": "Series.to_markdown(**kwargs, storage_options=None)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `storage_options`.", "question_id": 9645},
{"snippet": "Series.to_markdown(**kwargs, buf=None, mode='wt')", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `buf`, `mode`.", "question_id": 9646},
{"snippet": "Series.to_markdown(**kwargs, buf=None, index=True)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `buf`, `index`.", "question_id": 9647},
{"snippet": "Series.to_markdown(**kwargs, buf=None, storage_options=None)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `buf`, `storage_options`.", "question_id": 9648},
{"snippet": "Series.to_markdown(**kwargs, mode='wt', index=True)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `mode`, `index`.", "question_id": 9649},
{"snippet": "Series.to_markdown(**kwargs, mode='wt', storage_options=None)", "intent": "Print Series in Markdown-friendly format . With arguments `**kwargs`, `mode`, `storage_options`.", "question_id": 9650},
{"snippet": "Series.to_numpy(**kwargs)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`.", "question_id": 9651},
{"snippet": "Series.to_numpy(**kwargs, dtype=None)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`.", "question_id": 9652},
{"snippet": "Series.to_numpy(**kwargs, copy=False)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `copy`.", "question_id": 9653},
{"snippet": "Series.to_numpy(**kwargs, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `na_value`.", "question_id": 9654},
{"snippet": "Series.to_numpy(**kwargs, dtype=None, copy=False)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `copy`.", "question_id": 9655},
{"snippet": "Series.to_numpy(**kwargs, dtype=None, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `na_value`.", "question_id": 9656},
{"snippet": "Series.to_numpy(**kwargs, copy=False, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `copy`, `na_value`.", "question_id": 9657},
{"snippet": "Series.to_numpy(**kwargs, dtype=None, copy=False, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `copy`, `na_value`.", "question_id": 9658},
{"snippet": "Series.to_numpy(**kwargs)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`.", "question_id": 9659},
{"snippet": "Series.to_numpy(**kwargs, dtype=None)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`.", "question_id": 9660},
{"snippet": "Series.to_numpy(**kwargs, copy=False)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `copy`.", "question_id": 9661},
{"snippet": "Series.to_numpy(**kwargs, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `na_value`.", "question_id": 9662},
{"snippet": "Series.to_numpy(**kwargs, dtype=None, copy=False)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `copy`.", "question_id": 9663},
{"snippet": "Series.to_numpy(**kwargs, dtype=None, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `na_value`.", "question_id": 9664},
{"snippet": "Series.to_numpy(**kwargs, copy=False, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `copy`, `na_value`.", "question_id": 9665},
{"snippet": "Series.to_numpy(**kwargs, dtype=None, copy=False, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `copy`, `na_value`.", "question_id": 9666},
{"snippet": "Series.to_numpy(**kwargs)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`.", "question_id": 9667},
{"snippet": "Series.to_numpy(**kwargs, dtype=None)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`.", "question_id": 9668},
{"snippet": "Series.to_numpy(**kwargs, copy=False)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `copy`.", "question_id": 9669},
{"snippet": "Series.to_numpy(**kwargs, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `na_value`.", "question_id": 9670},
{"snippet": "Series.to_numpy(**kwargs, dtype=None, copy=False)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `copy`.", "question_id": 9671},
{"snippet": "Series.to_numpy(**kwargs, dtype=None, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `na_value`.", "question_id": 9672},
{"snippet": "Series.to_numpy(**kwargs, copy=False, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . With arguments `**kwargs`, `copy`, `na_value`.", "question_id": 9673},
{"snippet": "Series.to_numpy(**kwargs, dtype=None, copy=False, na_value=NoDefault.no_default)", "intent": "A NumPy ndarray representing the values in this Series or Index . When self contains an ExtensionArray , the `dtype` may be different . With arguments `**kwargs`, `copy`, `na_value`.", "question_id": 9674},
{"snippet": "Series.to_period()", "intent": "Convert Series from DatetimeIndex to PeriodIndex .", "question_id": 9675},
{"snippet": "Series.to_period(freq=None)", "intent": "Convert Series from DatetimeIndex to PeriodIndex . With arguments `freq`.", "question_id": 9676},
{"snippet": "Series.to_period(copy=True)", "intent": "Convert Series from DatetimeIndex to PeriodIndex . With arguments `copy`.", "question_id": 9677},
{"snippet": "Series.to_period(freq=None, copy=True)", "intent": "Convert Series from DatetimeIndex to PeriodIndex . With arguments `freq`, `copy`.", "question_id": 9678},
{"snippet": "Series.to_period()", "intent": "Convert Series from DatetimeIndex to PeriodIndex .", "question_id": 9679},
{"snippet": "Series.to_period(freq=None)", "intent": "Convert Series from DatetimeIndex to PeriodIndex . With arguments `freq`.", "question_id": 9680},
{"snippet": "Series.to_period(copy=True)", "intent": "Convert Series from DatetimeIndex to PeriodIndex . With arguments `copy`.", "question_id": 9681},
{"snippet": "Series.to_period(freq=None, copy=True)", "intent": "Convert Series from DatetimeIndex to PeriodIndex . With arguments `freq`, `copy`.", "question_id": 9682},
{"snippet": "Series.to_period()", "intent": "Convert Series from DatetimeIndex to PeriodIndex .", "question_id": 9683},
{"snippet": "Series.to_period(freq=None)", "intent": "Convert Series from DatetimeIndex to PeriodIndex . With arguments `freq`.", "question_id": 9684},
{"snippet": "Series.to_period(copy=True)", "intent": "Convert Series from DatetimeIndex to PeriodIndex . With arguments `copy`.", "question_id": 9685},
{"snippet": "Series.to_period(freq=None, copy=True)", "intent": "Convert Series from DatetimeIndex to PeriodIndex . With arguments `freq`, `copy`.", "question_id": 9686},
{"snippet": "Series.to_pickle(path)", "intent": "Pickle ( serialize ) object to file . With arguments `path`.", "question_id": 9687},
{"snippet": "Series.to_pickle(path, compression='infer')", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`.", "question_id": 9688},
{"snippet": "Series.to_pickle(path, protocol=5)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `protocol`.", "question_id": 9689},
{"snippet": "Series.to_pickle(path, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `storage_options`.", "question_id": 9690},
{"snippet": "Series.to_pickle(path, compression='infer', protocol=5)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `protocol`.", "question_id": 9691},
{"snippet": "Series.to_pickle(path, compression='infer', storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `storage_options`.", "question_id": 9692},
{"snippet": "Series.to_pickle(path, protocol=5, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `protocol`, `storage_options`.", "question_id": 9693},
{"snippet": "Series.to_pickle(path, compression='infer', protocol=5, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `protocol`, `storage_options`.", "question_id": 9694},
{"snippet": "Series.to_pickle(path)", "intent": "Pickle ( serialize ) object to file . With arguments `path`.", "question_id": 9695},
{"snippet": "Series.to_pickle(path, compression='infer')", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`.", "question_id": 9696},
{"snippet": "Series.to_pickle(path, protocol=5)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `protocol`.", "question_id": 9697},
{"snippet": "Series.to_pickle(path, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `storage_options`.", "question_id": 9698},
{"snippet": "Series.to_pickle(path, compression='infer', protocol=5)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `protocol`.", "question_id": 9699},
{"snippet": "Series.to_pickle(path, compression='infer', storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `storage_options`.", "question_id": 9700},
{"snippet": "Series.to_pickle(path, protocol=5, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `protocol`, `storage_options`.", "question_id": 9701},
{"snippet": "Series.to_pickle(path, compression='infer', protocol=5, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `protocol`, `storage_options`.", "question_id": 9702},
{"snippet": "Series.to_pickle(path)", "intent": "Pickle ( serialize ) object to file . With arguments `path`.", "question_id": 9703},
{"snippet": "Series.to_pickle(path, compression='infer')", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`.", "question_id": 9704},
{"snippet": "Series.to_pickle(path, protocol=5)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `protocol`.", "question_id": 9705},
{"snippet": "Series.to_pickle(path, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `storage_options`.", "question_id": 9706},
{"snippet": "Series.to_pickle(path, compression='infer', protocol=5)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `protocol`.", "question_id": 9707},
{"snippet": "Series.to_pickle(path, compression='infer', storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `storage_options`.", "question_id": 9708},
{"snippet": "Series.to_pickle(path, protocol=5, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `protocol`, `storage_options`.", "question_id": 9709},
{"snippet": "Series.to_pickle(path, compression='infer', protocol=5, storage_options=None)", "intent": "Pickle ( serialize ) object to file . With arguments `path`, `compression`, `protocol`, `storage_options`.", "question_id": 9710},
{"snippet": "Series.to_sql(name, con)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`.", "question_id": 9711},
{"snippet": "Series.to_sql(name, con, schema=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`.", "question_id": 9712},
{"snippet": "Series.to_sql(name, con, if_exists='fail')", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `if_exists`.", "question_id": 9713},
{"snippet": "Series.to_sql(name, con, index=True)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `index`.", "question_id": 9714},
{"snippet": "Series.to_sql(name, con, index_label=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `index_label`.", "question_id": 9715},
{"snippet": "Series.to_sql(name, con, chunksize=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `chunksize`.", "question_id": 9716},
{"snippet": "Series.to_sql(name, con, dtype=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : Specify the `dtype` ( especially useful for integers with missing values ) . With arguments `name`.", "question_id": 9717},
{"snippet": "Series.to_sql(name, con, method=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `method`.", "question_id": 9718},
{"snippet": "Series.to_sql(name, con, schema=None, if_exists='fail')", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`, `if_exists`.", "question_id": 9719},
{"snippet": "Series.to_sql(name, con, schema=None, index=True)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`, `index`.", "question_id": 9720},
{"snippet": "Series.to_sql(name, con)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`.", "question_id": 9721},
{"snippet": "Series.to_sql(name, con, schema=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`.", "question_id": 9722},
{"snippet": "Series.to_sql(name, con, if_exists='fail')", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `if_exists`.", "question_id": 9723},
{"snippet": "Series.to_sql(name, con, index=True)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `index`.", "question_id": 9724},
{"snippet": "Series.to_sql(name, con, index_label=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `index_label`.", "question_id": 9725},
{"snippet": "Series.to_sql(name, con, chunksize=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `chunksize`.", "question_id": 9726},
{"snippet": "Series.to_sql(name, con, dtype=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : Specify the `dtype` ( especially useful for integers with missing values ) . With arguments `name`.", "question_id": 9727},
{"snippet": "Series.to_sql(name, con, method=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `method`.", "question_id": 9728},
{"snippet": "Series.to_sql(name, con, schema=None, if_exists='fail')", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`, `if_exists`.", "question_id": 9729},
{"snippet": "Series.to_sql(name, con, schema=None, index=True)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`, `index`.", "question_id": 9730},
{"snippet": "Series.to_sql(name, con)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`.", "question_id": 9731},
{"snippet": "Series.to_sql(name, con, schema=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`.", "question_id": 9732},
{"snippet": "Series.to_sql(name, con, if_exists='fail')", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `if_exists`.", "question_id": 9733},
{"snippet": "Series.to_sql(name, con, index=True)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `index`.", "question_id": 9734},
{"snippet": "Series.to_sql(name, con, index_label=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `index_label`.", "question_id": 9735},
{"snippet": "Series.to_sql(name, con, chunksize=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `chunksize`.", "question_id": 9736},
{"snippet": "Series.to_sql(name, con, dtype=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : Specify the `dtype` ( especially useful for integers with missing values ) . With arguments `name`.", "question_id": 9737},
{"snippet": "Series.to_sql(name, con, method=None)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `method`.", "question_id": 9738},
{"snippet": "Series.to_sql(name, con, schema=None, if_exists='fail')", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`, `if_exists`.", "question_id": 9739},
{"snippet": "Series.to_sql(name, con, schema=None, index=True)", "intent": "Write records stored in a DataFrame to a SQL database . An sqlalchemy.engine.Connection can also be passed to `con` : With arguments `name`, `schema`, `index`.", "question_id": 9740},
{"snippet": "Series.to_string()", "intent": "Render a string representation of the Series .", "question_id": 9741},
{"snippet": "Series.to_string(buf=None)", "intent": "Render a string representation of the Series . With arguments `buf`.", "question_id": 9742},
{"snippet": "Series.to_string(na_rep='NaN')", "intent": "Render a string representation of the Series . With arguments `na_rep`.", "question_id": 9743},
{"snippet": "Series.to_string(float_format=None)", "intent": "Render a string representation of the Series . With arguments `float_format`.", "question_id": 9744},
{"snippet": "Series.to_string(header=True)", "intent": "Render a string representation of the Series . With arguments `header`.", "question_id": 9745},
{"snippet": "Series.to_string(index=True)", "intent": "Render a string representation of the Series . With arguments `index`.", "question_id": 9746},
{"snippet": "Series.to_string(length=False)", "intent": "Render a string representation of the Series . With arguments `length`.", "question_id": 9747},
{"snippet": "Series.to_string(dtype=False)", "intent": "Render a string representation of the Series . With arguments `dtype`.", "question_id": 9748},
{"snippet": "Series.to_string(name=False)", "intent": "Render a string representation of the Series . With arguments `name`.", "question_id": 9749},
{"snippet": "Series.to_string(max_rows=None)", "intent": "Render a string representation of the Series . With arguments `max_rows`.", "question_id": 9750},
{"snippet": "Series.to_string()", "intent": "Render a string representation of the Series .", "question_id": 9751},
{"snippet": "Series.to_string(buf=None)", "intent": "Render a string representation of the Series . With arguments `buf`.", "question_id": 9752},
{"snippet": "Series.to_string(na_rep='NaN')", "intent": "Render a string representation of the Series . With arguments `na_rep`.", "question_id": 9753},
{"snippet": "Series.to_string(float_format=None)", "intent": "Render a string representation of the Series . With arguments `float_format`.", "question_id": 9754},
{"snippet": "Series.to_string(header=True)", "intent": "Render a string representation of the Series . With arguments `header`.", "question_id": 9755},
{"snippet": "Series.to_string(index=True)", "intent": "Render a string representation of the Series . With arguments `index`.", "question_id": 9756},
{"snippet": "Series.to_string(length=False)", "intent": "Render a string representation of the Series . With arguments `length`.", "question_id": 9757},
{"snippet": "Series.to_string(dtype=False)", "intent": "Render a string representation of the Series . With arguments `dtype`.", "question_id": 9758},
{"snippet": "Series.to_string(name=False)", "intent": "Render a string representation of the Series . With arguments `name`.", "question_id": 9759},
{"snippet": "Series.to_string(max_rows=None)", "intent": "Render a string representation of the Series . With arguments `max_rows`.", "question_id": 9760},
{"snippet": "Series.to_string()", "intent": "Render a string representation of the Series .", "question_id": 9761},
{"snippet": "Series.to_string(buf=None)", "intent": "Render a string representation of the Series . With arguments `buf`.", "question_id": 9762},
{"snippet": "Series.to_string(na_rep='NaN')", "intent": "Render a string representation of the Series . With arguments `na_rep`.", "question_id": 9763},
{"snippet": "Series.to_string(float_format=None)", "intent": "Render a string representation of the Series . With arguments `float_format`.", "question_id": 9764},
{"snippet": "Series.to_string(header=True)", "intent": "Render a string representation of the Series . With arguments `header`.", "question_id": 9765},
{"snippet": "Series.to_string(index=True)", "intent": "Render a string representation of the Series . With arguments `index`.", "question_id": 9766},
{"snippet": "Series.to_string(length=False)", "intent": "Render a string representation of the Series . With arguments `length`.", "question_id": 9767},
{"snippet": "Series.to_string(dtype=False)", "intent": "Render a string representation of the Series . With arguments `dtype`.", "question_id": 9768},
{"snippet": "Series.to_string(name=False)", "intent": "Render a string representation of the Series . With arguments `name`.", "question_id": 9769},
{"snippet": "Series.to_string(max_rows=None)", "intent": "Render a string representation of the Series . With arguments `max_rows`.", "question_id": 9770},
{"snippet": "Series.to_timestamp()", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period .", "question_id": 9771},
{"snippet": "Series.to_timestamp(freq=None)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `freq`.", "question_id": 9772},
{"snippet": "Series.to_timestamp(how='start')", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `how`.", "question_id": 9773},
{"snippet": "Series.to_timestamp(copy=True)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `copy`.", "question_id": 9774},
{"snippet": "Series.to_timestamp(freq=None, how='start')", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `freq`, `how`.", "question_id": 9775},
{"snippet": "Series.to_timestamp(freq=None, copy=True)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `freq`, `copy`.", "question_id": 9776},
{"snippet": "Series.to_timestamp(how='start', copy=True)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `how`, `copy`.", "question_id": 9777},
{"snippet": "Series.to_timestamp(freq=None, how='start', copy=True)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `freq`, `how`, `copy`.", "question_id": 9778},
{"snippet": "Series.to_timestamp()", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period .", "question_id": 9779},
{"snippet": "Series.to_timestamp(freq=None)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `freq`.", "question_id": 9780},
{"snippet": "Series.to_timestamp(how='start')", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `how`.", "question_id": 9781},
{"snippet": "Series.to_timestamp(copy=True)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `copy`.", "question_id": 9782},
{"snippet": "Series.to_timestamp(freq=None, how='start')", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `freq`, `how`.", "question_id": 9783},
{"snippet": "Series.to_timestamp(freq=None, copy=True)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `freq`, `copy`.", "question_id": 9784},
{"snippet": "Series.to_timestamp(how='start', copy=True)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `how`, `copy`.", "question_id": 9785},
{"snippet": "Series.to_timestamp(freq=None, how='start', copy=True)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `freq`, `how`, `copy`.", "question_id": 9786},
{"snippet": "Series.to_timestamp()", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period .", "question_id": 9787},
{"snippet": "Series.to_timestamp(freq=None)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `freq`.", "question_id": 9788},
{"snippet": "Series.to_timestamp(how='start')", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `how`.", "question_id": 9789},
{"snippet": "Series.to_timestamp(copy=True)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `copy`.", "question_id": 9790},
{"snippet": "Series.to_timestamp(freq=None, how='start')", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `freq`, `how`.", "question_id": 9791},
{"snippet": "Series.to_timestamp(freq=None, copy=True)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `freq`, `copy`.", "question_id": 9792},
{"snippet": "Series.to_timestamp(how='start', copy=True)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `how`, `copy`.", "question_id": 9793},
{"snippet": "Series.to_timestamp(freq=None, how='start', copy=True)", "intent": "Cast to DatetimeIndex of Timestamps , at beginning of period . With arguments `freq`, `how`, `copy`.", "question_id": 9794},
{"snippet": "Series.to_xarray()", "intent": "Return an xarray object from the pandas object .", "question_id": 9795},
{"snippet": "Series.to_xarray()", "intent": "Return an xarray object from the pandas object .", "question_id": 9796},
{"snippet": "Series.to_xarray()", "intent": "Return an xarray object from the pandas object .", "question_id": 9797},
{"snippet": "Series.tolist()", "intent": "Return a list of the values .", "question_id": 9798},
{"snippet": "Series.tolist()", "intent": "Return a list of the values .", "question_id": 9799},
{"snippet": "Series.tolist()", "intent": "Return a list of the values .", "question_id": 9800},
{"snippet": "Series.transform(func, *args, **kwargs)", "intent": "Call `func` on self producing a Series with transformed values . With arguments `*args`, `**kwargs`.", "question_id": 9801},
{"snippet": "Series.transform(func, *args, **kwargs, axis=0)", "intent": "Call `func` on self producing a Series with transformed values . Produced Series will have same `axis` length as self . With arguments `*args`, `**kwargs`.", "question_id": 9802},
{"snippet": "Series.transform(func, *args, **kwargs)", "intent": "Call `func` on self producing a Series with transformed values . With arguments `*args`, `**kwargs`.", "question_id": 9803},
{"snippet": "Series.transform(func, *args, **kwargs, axis=0)", "intent": "Call `func` on self producing a Series with transformed values . Produced Series will have same `axis` length as self . With arguments `*args`, `**kwargs`.", "question_id": 9804},
{"snippet": "Series.transform(func, *args, **kwargs)", "intent": "Call `func` on self producing a Series with transformed values . With arguments `*args`, `**kwargs`.", "question_id": 9805},
{"snippet": "Series.transform(func, *args, **kwargs, axis=0)", "intent": "Call `func` on self producing a Series with transformed values . Produced Series will have same `axis` length as self . With arguments `*args`, `**kwargs`.", "question_id": 9806},
{"snippet": "Series.transpose(*args, **kwargs)", "intent": "Return the transpose , which is by definition self . With arguments `*args`, `**kwargs`.", "question_id": 9807},
{"snippet": "Series.transpose(*args, **kwargs)", "intent": "Return the transpose , which is by definition self . With arguments `*args`, `**kwargs`.", "question_id": 9808},
{"snippet": "Series.transpose(*args, **kwargs)", "intent": "Return the transpose , which is by definition self . With arguments `*args`, `**kwargs`.", "question_id": 9809},
{"snippet": "Series.truediv(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) .", "question_id": 9810},
{"snippet": "Series.truediv(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`.", "question_id": 9811},
{"snippet": "Series.truediv(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 9812},
{"snippet": "Series.truediv(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `axis`.", "question_id": 9813},
{"snippet": "Series.truediv(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 9814},
{"snippet": "Series.truediv(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`, `axis`.", "question_id": 9815},
{"snippet": "Series.truediv(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 9816},
{"snippet": "Series.truediv(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 9817},
{"snippet": "Series.truediv(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) .", "question_id": 9818},
{"snippet": "Series.truediv(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`.", "question_id": 9819},
{"snippet": "Series.truediv(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 9820},
{"snippet": "Series.truediv(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `axis`.", "question_id": 9821},
{"snippet": "Series.truediv(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 9822},
{"snippet": "Series.truediv(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`, `axis`.", "question_id": 9823},
{"snippet": "Series.truediv(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 9824},
{"snippet": "Series.truediv(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 9825},
{"snippet": "Series.truediv(other)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) .", "question_id": 9826},
{"snippet": "Series.truediv(other, level=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`.", "question_id": 9827},
{"snippet": "Series.truediv(other, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs .", "question_id": 9828},
{"snippet": "Series.truediv(other, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `axis`.", "question_id": 9829},
{"snippet": "Series.truediv(other, level=None, fill_value=None)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`.", "question_id": 9830},
{"snippet": "Series.truediv(other, level=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . With arguments `level`, `axis`.", "question_id": 9831},
{"snippet": "Series.truediv(other, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `axis`.", "question_id": 9832},
{"snippet": "Series.truediv(other, level=None, fill_value=None, axis=0)", "intent": "Return Floating division of series and `other` , element-wise ( binary operator truediv ) . Equivalent to series / other , but with support to substitute a `fill_value` for missing data in either one of the inputs . With arguments `level`, `axis`.", "question_id": 9833},
{"snippet": "Series.truncate()", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 9834},
{"snippet": "Series.truncate(before=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 9835},
{"snippet": "Series.truncate(after=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 9836},
{"snippet": "Series.truncate(axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 9837},
{"snippet": "Series.truncate(copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 9838},
{"snippet": "Series.truncate(before=None, after=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 9839},
{"snippet": "Series.truncate(before=None, axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 9840},
{"snippet": "Series.truncate(before=None, copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 9841},
{"snippet": "Series.truncate(after=None, axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 9842},
{"snippet": "Series.truncate(after=None, copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 9843},
{"snippet": "Series.truncate()", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 9844},
{"snippet": "Series.truncate(before=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 9845},
{"snippet": "Series.truncate(after=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 9846},
{"snippet": "Series.truncate(axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 9847},
{"snippet": "Series.truncate(copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 9848},
{"snippet": "Series.truncate(before=None, after=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 9849},
{"snippet": "Series.truncate(before=None, axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 9850},
{"snippet": "Series.truncate(before=None, copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 9851},
{"snippet": "Series.truncate(after=None, axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 9852},
{"snippet": "Series.truncate(after=None, copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 9853},
{"snippet": "Series.truncate()", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 9854},
{"snippet": "Series.truncate(before=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 9855},
{"snippet": "Series.truncate(after=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 9856},
{"snippet": "Series.truncate(axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 9857},
{"snippet": "Series.truncate(copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 9858},
{"snippet": "Series.truncate(before=None, after=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value .", "question_id": 9859},
{"snippet": "Series.truncate(before=None, axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 9860},
{"snippet": "Series.truncate(before=None, copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 9861},
{"snippet": "Series.truncate(after=None, axis=None)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `axis`.", "question_id": 9862},
{"snippet": "Series.truncate(after=None, copy=True)", "intent": "Truncate a Series or DataFrame `before` and `after` some index value . With arguments `copy`.", "question_id": 9863},
{"snippet": "Series.tshift()", "intent": "Shift the time index , using the index \u2019 s frequency if available .", "question_id": 9864},
{"snippet": "Series.tshift(periods=1)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `periods`.", "question_id": 9865},
{"snippet": "Series.tshift(freq=None)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index .", "question_id": 9866},
{"snippet": "Series.tshift(axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `axis`.", "question_id": 9867},
{"snippet": "Series.tshift(periods=1, freq=None)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `periods`.", "question_id": 9868},
{"snippet": "Series.tshift(periods=1, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `periods`, `axis`.", "question_id": 9869},
{"snippet": "Series.tshift(freq=None, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `axis`.", "question_id": 9870},
{"snippet": "Series.tshift(periods=1, freq=None, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `periods`, `axis`.", "question_id": 9871},
{"snippet": "Series.tshift()", "intent": "Shift the time index , using the index \u2019 s frequency if available .", "question_id": 9872},
{"snippet": "Series.tshift(periods=1)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `periods`.", "question_id": 9873},
{"snippet": "Series.tshift(freq=None)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index .", "question_id": 9874},
{"snippet": "Series.tshift(axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `axis`.", "question_id": 9875},
{"snippet": "Series.tshift(periods=1, freq=None)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `periods`.", "question_id": 9876},
{"snippet": "Series.tshift(periods=1, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `periods`, `axis`.", "question_id": 9877},
{"snippet": "Series.tshift(freq=None, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `axis`.", "question_id": 9878},
{"snippet": "Series.tshift(periods=1, freq=None, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `periods`, `axis`.", "question_id": 9879},
{"snippet": "Series.tshift()", "intent": "Shift the time index , using the index \u2019 s frequency if available .", "question_id": 9880},
{"snippet": "Series.tshift(periods=1)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `periods`.", "question_id": 9881},
{"snippet": "Series.tshift(freq=None)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index .", "question_id": 9882},
{"snippet": "Series.tshift(axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `axis`.", "question_id": 9883},
{"snippet": "Series.tshift(periods=1, freq=None)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `periods`.", "question_id": 9884},
{"snippet": "Series.tshift(periods=1, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . With arguments `periods`, `axis`.", "question_id": 9885},
{"snippet": "Series.tshift(freq=None, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `axis`.", "question_id": 9886},
{"snippet": "Series.tshift(periods=1, freq=None, axis=0)", "intent": "Shift the time index , using the index \u2019 s frequency if available . If `freq` is not specified then tries to use the freq or inferred_freq attributes of the index . With arguments `periods`, `axis`.", "question_id": 9887},
{"snippet": "Series.tz_convert(tz)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`.", "question_id": 9888},
{"snippet": "Series.tz_convert(tz, axis=0)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`.", "question_id": 9889},
{"snippet": "Series.tz_convert(tz, level=None)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`.", "question_id": 9890},
{"snippet": "Series.tz_convert(tz, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `copy`.", "question_id": 9891},
{"snippet": "Series.tz_convert(tz, axis=0, level=None)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`.", "question_id": 9892},
{"snippet": "Series.tz_convert(tz, axis=0, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `copy`.", "question_id": 9893},
{"snippet": "Series.tz_convert(tz, level=None, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`, `copy`.", "question_id": 9894},
{"snippet": "Series.tz_convert(tz, axis=0, level=None, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`, `copy`.", "question_id": 9895},
{"snippet": "Series.tz_convert(tz)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`.", "question_id": 9896},
{"snippet": "Series.tz_convert(tz, axis=0)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`.", "question_id": 9897},
{"snippet": "Series.tz_convert(tz, level=None)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`.", "question_id": 9898},
{"snippet": "Series.tz_convert(tz, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `copy`.", "question_id": 9899},
{"snippet": "Series.tz_convert(tz, axis=0, level=None)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`.", "question_id": 9900},
{"snippet": "Series.tz_convert(tz, axis=0, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `copy`.", "question_id": 9901},
{"snippet": "Series.tz_convert(tz, level=None, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`, `copy`.", "question_id": 9902},
{"snippet": "Series.tz_convert(tz, axis=0, level=None, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`, `copy`.", "question_id": 9903},
{"snippet": "Series.tz_convert(tz)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`.", "question_id": 9904},
{"snippet": "Series.tz_convert(tz, axis=0)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`.", "question_id": 9905},
{"snippet": "Series.tz_convert(tz, level=None)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`.", "question_id": 9906},
{"snippet": "Series.tz_convert(tz, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `copy`.", "question_id": 9907},
{"snippet": "Series.tz_convert(tz, axis=0, level=None)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`.", "question_id": 9908},
{"snippet": "Series.tz_convert(tz, axis=0, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `copy`.", "question_id": 9909},
{"snippet": "Series.tz_convert(tz, level=None, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`, `copy`.", "question_id": 9910},
{"snippet": "Series.tz_convert(tz, axis=0, level=None, copy=True)", "intent": "Convert tz-aware `axis` to target time zone . With arguments `tz`, `level`, `copy`.", "question_id": 9911},
{"snippet": "Series.tz_localize(tz)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`.", "question_id": 9912},
{"snippet": "Series.tz_localize(tz, axis=0)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`.", "question_id": 9913},
{"snippet": "Series.tz_localize(tz, level=None)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `level`.", "question_id": 9914},
{"snippet": "Series.tz_localize(tz, copy=True)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `copy`.", "question_id": 9915},
{"snippet": "Series.tz_localize(tz, ambiguous='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly With arguments `tz`.", "question_id": 9916},
{"snippet": "Series.tz_localize(tz, nonexistent='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . If the DST transition causes `nonexistent` times , you can shift these dates forward or backward with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backward \u2019 . With arguments `tz`.", "question_id": 9917},
{"snippet": "Series.tz_localize(tz, axis=0, level=None)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`, `level`.", "question_id": 9918},
{"snippet": "Series.tz_localize(tz, axis=0, copy=True)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`, `copy`.", "question_id": 9919},
{"snippet": "Series.tz_localize(tz, axis=0, ambiguous='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly With arguments `tz`, `axis`.", "question_id": 9920},
{"snippet": "Series.tz_localize(tz, axis=0, nonexistent='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . If the DST transition causes `nonexistent` times , you can shift these dates forward or backward with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backward \u2019 . With arguments `tz`, `axis`.", "question_id": 9921},
{"snippet": "Series.tz_localize(tz)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`.", "question_id": 9922},
{"snippet": "Series.tz_localize(tz, axis=0)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`.", "question_id": 9923},
{"snippet": "Series.tz_localize(tz, level=None)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `level`.", "question_id": 9924},
{"snippet": "Series.tz_localize(tz, copy=True)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `copy`.", "question_id": 9925},
{"snippet": "Series.tz_localize(tz, ambiguous='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly With arguments `tz`.", "question_id": 9926},
{"snippet": "Series.tz_localize(tz, nonexistent='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . If the DST transition causes `nonexistent` times , you can shift these dates forward or backward with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backward \u2019 . With arguments `tz`.", "question_id": 9927},
{"snippet": "Series.tz_localize(tz, axis=0, level=None)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`, `level`.", "question_id": 9928},
{"snippet": "Series.tz_localize(tz, axis=0, copy=True)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`, `copy`.", "question_id": 9929},
{"snippet": "Series.tz_localize(tz, axis=0, ambiguous='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly With arguments `tz`, `axis`.", "question_id": 9930},
{"snippet": "Series.tz_localize(tz, axis=0, nonexistent='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . If the DST transition causes `nonexistent` times , you can shift these dates forward or backward with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backward \u2019 . With arguments `tz`, `axis`.", "question_id": 9931},
{"snippet": "Series.tz_localize(tz)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`.", "question_id": 9932},
{"snippet": "Series.tz_localize(tz, axis=0)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`.", "question_id": 9933},
{"snippet": "Series.tz_localize(tz, level=None)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `level`.", "question_id": 9934},
{"snippet": "Series.tz_localize(tz, copy=True)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `copy`.", "question_id": 9935},
{"snippet": "Series.tz_localize(tz, ambiguous='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly With arguments `tz`.", "question_id": 9936},
{"snippet": "Series.tz_localize(tz, nonexistent='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . If the DST transition causes `nonexistent` times , you can shift these dates forward or backward with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backward \u2019 . With arguments `tz`.", "question_id": 9937},
{"snippet": "Series.tz_localize(tz, axis=0, level=None)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`, `level`.", "question_id": 9938},
{"snippet": "Series.tz_localize(tz, axis=0, copy=True)", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . With arguments `tz`, `axis`, `copy`.", "question_id": 9939},
{"snippet": "Series.tz_localize(tz, axis=0, ambiguous='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . In such cases , you can pass an ndarray to the `ambiguous` parameter to set the DST explicitly With arguments `tz`, `axis`.", "question_id": 9940},
{"snippet": "Series.tz_localize(tz, axis=0, nonexistent='raise')", "intent": "Localize tz-naive index of a Series or DataFrame to target time zone . If the DST transition causes `nonexistent` times , you can shift these dates forward or backward with a timedelta object or \u2018 shift_forward \u2019 or \u2018 shift_backward \u2019 . With arguments `tz`, `axis`.", "question_id": 9941},
{"snippet": "Series.unique()", "intent": "Return unique values of Series object .", "question_id": 9942},
{"snippet": "Series.unique()", "intent": "Return unique values of Series object .", "question_id": 9943},
{"snippet": "Series.unique()", "intent": "Return unique values of Series object .", "question_id": 9944},
{"snippet": "Series.unstack()", "intent": "Unstack , also known as pivot , Series with MultiIndex to produce DataFrame .", "question_id": 9945},
{"snippet": "Series.unstack(level=- 1)", "intent": "Unstack , also known as pivot , Series with MultiIndex to produce DataFrame . With arguments `level`.", "question_id": 9946},
{"snippet": "Series.unstack(fill_value=None)", "intent": "Unstack , also known as pivot , Series with MultiIndex to produce DataFrame . With arguments `fill_value`.", "question_id": 9947},
{"snippet": "Series.unstack(level=- 1, fill_value=None)", "intent": "Unstack , also known as pivot , Series with MultiIndex to produce DataFrame . With arguments `level`, `fill_value`.", "question_id": 9948},
{"snippet": "Series.unstack()", "intent": "Unstack , also known as pivot , Series with MultiIndex to produce DataFrame .", "question_id": 9949},
{"snippet": "Series.unstack(level=- 1)", "intent": "Unstack , also known as pivot , Series with MultiIndex to produce DataFrame . With arguments `level`.", "question_id": 9950},
{"snippet": "Series.unstack(fill_value=None)", "intent": "Unstack , also known as pivot , Series with MultiIndex to produce DataFrame . With arguments `fill_value`.", "question_id": 9951},
{"snippet": "Series.unstack(level=- 1, fill_value=None)", "intent": "Unstack , also known as pivot , Series with MultiIndex to produce DataFrame . With arguments `level`, `fill_value`.", "question_id": 9952},
{"snippet": "Series.unstack()", "intent": "Unstack , also known as pivot , Series with MultiIndex to produce DataFrame .", "question_id": 9953},
{"snippet": "Series.unstack(level=- 1)", "intent": "Unstack , also known as pivot , Series with MultiIndex to produce DataFrame . With arguments `level`.", "question_id": 9954},
{"snippet": "Series.unstack(fill_value=None)", "intent": "Unstack , also known as pivot , Series with MultiIndex to produce DataFrame . With arguments `fill_value`.", "question_id": 9955},
{"snippet": "Series.unstack(level=- 1, fill_value=None)", "intent": "Unstack , also known as pivot , Series with MultiIndex to produce DataFrame . With arguments `level`, `fill_value`.", "question_id": 9956},
{"snippet": "Series.update(other)", "intent": "Modify Series in place using values from passed Series . If `other` contains NaNs the corresponding values are not updated in the original Series .", "question_id": 9957},
{"snippet": "Series.update(other)", "intent": "Modify Series in place using values from passed Series . If `other` contains NaNs the corresponding values are not updated in the original Series .", "question_id": 9958},
{"snippet": "Series.update(other)", "intent": "Modify Series in place using values from passed Series . If `other` contains NaNs the corresponding values are not updated in the original Series .", "question_id": 9959},
{"snippet": "Series.value_counts()", "intent": "Return a Series containing counts of unique values .", "question_id": 9960},
{"snippet": "Series.value_counts(normalize=False)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values .", "question_id": 9961},
{"snippet": "Series.value_counts(sort=True)", "intent": "Return a Series containing counts of unique values . With arguments `sort`.", "question_id": 9962},
{"snippet": "Series.value_counts(ascending=False)", "intent": "Return a Series containing counts of unique values . With arguments `ascending`.", "question_id": 9963},
{"snippet": "Series.value_counts(bins=None)", "intent": "Return a Series containing counts of unique values . `bins`", "question_id": 9964},
{"snippet": "Series.value_counts(dropna=True)", "intent": "Return a Series containing counts of unique values . `dropna`", "question_id": 9965},
{"snippet": "Series.value_counts(normalize=False, sort=True)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . With arguments `sort`.", "question_id": 9966},
{"snippet": "Series.value_counts(normalize=False, ascending=False)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . With arguments `ascending`.", "question_id": 9967},
{"snippet": "Series.value_counts(normalize=False, bins=None)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . `bins`", "question_id": 9968},
{"snippet": "Series.value_counts(normalize=False, dropna=True)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . `dropna`", "question_id": 9969},
{"snippet": "Series.value_counts()", "intent": "Return a Series containing counts of unique values .", "question_id": 9970},
{"snippet": "Series.value_counts(normalize=False)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values .", "question_id": 9971},
{"snippet": "Series.value_counts(sort=True)", "intent": "Return a Series containing counts of unique values . With arguments `sort`.", "question_id": 9972},
{"snippet": "Series.value_counts(ascending=False)", "intent": "Return a Series containing counts of unique values . With arguments `ascending`.", "question_id": 9973},
{"snippet": "Series.value_counts(bins=None)", "intent": "Return a Series containing counts of unique values . `bins`", "question_id": 9974},
{"snippet": "Series.value_counts(dropna=True)", "intent": "Return a Series containing counts of unique values . `dropna`", "question_id": 9975},
{"snippet": "Series.value_counts(normalize=False, sort=True)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . With arguments `sort`.", "question_id": 9976},
{"snippet": "Series.value_counts(normalize=False, ascending=False)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . With arguments `ascending`.", "question_id": 9977},
{"snippet": "Series.value_counts(normalize=False, bins=None)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . `bins`", "question_id": 9978},
{"snippet": "Series.value_counts(normalize=False, dropna=True)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . `dropna`", "question_id": 9979},
{"snippet": "Series.value_counts()", "intent": "Return a Series containing counts of unique values .", "question_id": 9980},
{"snippet": "Series.value_counts(normalize=False)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values .", "question_id": 9981},
{"snippet": "Series.value_counts(sort=True)", "intent": "Return a Series containing counts of unique values . With arguments `sort`.", "question_id": 9982},
{"snippet": "Series.value_counts(ascending=False)", "intent": "Return a Series containing counts of unique values . With arguments `ascending`.", "question_id": 9983},
{"snippet": "Series.value_counts(bins=None)", "intent": "Return a Series containing counts of unique values . `bins`", "question_id": 9984},
{"snippet": "Series.value_counts(dropna=True)", "intent": "Return a Series containing counts of unique values . `dropna`", "question_id": 9985},
{"snippet": "Series.value_counts(normalize=False, sort=True)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . With arguments `sort`.", "question_id": 9986},
{"snippet": "Series.value_counts(normalize=False, ascending=False)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . With arguments `ascending`.", "question_id": 9987},
{"snippet": "Series.value_counts(normalize=False, bins=None)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . `bins`", "question_id": 9988},
{"snippet": "Series.value_counts(normalize=False, dropna=True)", "intent": "Return a Series containing counts of unique values . With `normalize` set to True , returns the relative frequency by dividing all values by the sum of values . `dropna`", "question_id": 9989},
{"snippet": "Series.var(**kwargs)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`.", "question_id": 9990},
{"snippet": "Series.var(**kwargs, axis=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`.", "question_id": 9991},
{"snippet": "Series.var(**kwargs, skipna=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 9992},
{"snippet": "Series.var(**kwargs, level=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 9993},
{"snippet": "Series.var(**kwargs, ddof=1)", "intent": "Return unbiased variance over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 9994},
{"snippet": "Series.var(**kwargs, numeric_only=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 9995},
{"snippet": "Series.var(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 9996},
{"snippet": "Series.var(**kwargs, axis=None, level=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 9997},
{"snippet": "Series.var(**kwargs, axis=None, ddof=1)", "intent": "Return unbiased variance over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 9998},
{"snippet": "Series.var(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 9999},
{"snippet": "Series.var(**kwargs)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`.", "question_id": 10000},
{"snippet": "Series.var(**kwargs, axis=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`.", "question_id": 10001},
{"snippet": "Series.var(**kwargs, skipna=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 10002},
{"snippet": "Series.var(**kwargs, level=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 10003},
{"snippet": "Series.var(**kwargs, ddof=1)", "intent": "Return unbiased variance over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 10004},
{"snippet": "Series.var(**kwargs, numeric_only=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 10005},
{"snippet": "Series.var(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 10006},
{"snippet": "Series.var(**kwargs, axis=None, level=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 10007},
{"snippet": "Series.var(**kwargs, axis=None, ddof=1)", "intent": "Return unbiased variance over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 10008},
{"snippet": "Series.var(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 10009},
{"snippet": "Series.var(**kwargs)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`.", "question_id": 10010},
{"snippet": "Series.var(**kwargs, axis=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`.", "question_id": 10011},
{"snippet": "Series.var(**kwargs, skipna=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 10012},
{"snippet": "Series.var(**kwargs, level=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 10013},
{"snippet": "Series.var(**kwargs, ddof=1)", "intent": "Return unbiased variance over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 10014},
{"snippet": "Series.var(**kwargs, numeric_only=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 10015},
{"snippet": "Series.var(**kwargs, axis=None, skipna=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `skipna`.", "question_id": 10016},
{"snippet": "Series.var(**kwargs, axis=None, level=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `level`.", "question_id": 10017},
{"snippet": "Series.var(**kwargs, axis=None, ddof=1)", "intent": "Return unbiased variance over requested `axis` . This can be changed using the `ddof` argument With arguments `**kwargs`.", "question_id": 10018},
{"snippet": "Series.var(**kwargs, axis=None, numeric_only=None)", "intent": "Return unbiased variance over requested `axis` . With arguments `**kwargs`, `numeric_only`.", "question_id": 10019},
{"snippet": "Series.view()", "intent": "Create a new view of the Series .", "question_id": 10020},
{"snippet": "Series.view(dtype=None)", "intent": "Create a new view of the Series . While numpy.ndarray.view ( ) will return a view with the same data type as the original array , Series.view ( ) ( without specified `dtype` ) will try using float64 and may fail if the original data type size in bytes is not the same .", "question_id": 10021},
{"snippet": "Series.view()", "intent": "Create a new view of the Series .", "question_id": 10022},
{"snippet": "Series.view(dtype=None)", "intent": "Create a new view of the Series . While numpy.ndarray.view ( ) will return a view with the same data type as the original array , Series.view ( ) ( without specified `dtype` ) will try using float64 and may fail if the original data type size in bytes is not the same .", "question_id": 10023},
{"snippet": "Series.view()", "intent": "Create a new view of the Series .", "question_id": 10024},
{"snippet": "Series.view(dtype=None)", "intent": "Create a new view of the Series . While numpy.ndarray.view ( ) will return a view with the same data type as the original array , Series.view ( ) ( without specified `dtype` ) will try using float64 and may fail if the original data type size in bytes is not the same .", "question_id": 10025},
{"snippet": "Series.where(cond)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 10026},
{"snippet": "Series.where(cond, other=nan)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 10027},
{"snippet": "Series.where(cond, inplace=False)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 10028},
{"snippet": "Series.where(cond, axis=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 10029},
{"snippet": "Series.where(cond, level=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 10030},
{"snippet": "Series.where(cond, errors='raise')", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `errors`.", "question_id": 10031},
{"snippet": "Series.where(cond, try_cast=NoDefault.no_default)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `try_cast`.", "question_id": 10032},
{"snippet": "Series.where(cond, other=nan, inplace=False)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 10033},
{"snippet": "Series.where(cond, other=nan, axis=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 10034},
{"snippet": "Series.where(cond, other=nan, level=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 10035},
{"snippet": "Series.where(cond)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 10036},
{"snippet": "Series.where(cond, other=nan)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 10037},
{"snippet": "Series.where(cond, inplace=False)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 10038},
{"snippet": "Series.where(cond, axis=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 10039},
{"snippet": "Series.where(cond, level=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 10040},
{"snippet": "Series.where(cond, errors='raise')", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `errors`.", "question_id": 10041},
{"snippet": "Series.where(cond, try_cast=NoDefault.no_default)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `try_cast`.", "question_id": 10042},
{"snippet": "Series.where(cond, other=nan, inplace=False)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 10043},
{"snippet": "Series.where(cond, other=nan, axis=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 10044},
{"snippet": "Series.where(cond, other=nan, level=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 10045},
{"snippet": "Series.where(cond)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 10046},
{"snippet": "Series.where(cond, other=nan)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used .", "question_id": 10047},
{"snippet": "Series.where(cond, inplace=False)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 10048},
{"snippet": "Series.where(cond, axis=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 10049},
{"snippet": "Series.where(cond, level=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 10050},
{"snippet": "Series.where(cond, errors='raise')", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `errors`.", "question_id": 10051},
{"snippet": "Series.where(cond, try_cast=NoDefault.no_default)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `try_cast`.", "question_id": 10052},
{"snippet": "Series.where(cond, other=nan, inplace=False)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `inplace`.", "question_id": 10053},
{"snippet": "Series.where(cond, other=nan, axis=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `axis`.", "question_id": 10054},
{"snippet": "Series.where(cond, other=nan, level=None)", "intent": "Replace values where the condition is False . For each element in the calling DataFrame , if `cond` is True the element is used ; otherwise the corresponding element from the DataFrame `other` is used . With arguments `level`.", "question_id": 10055},
{"snippet": "Series.xs(key)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex .", "question_id": 10056},
{"snippet": "Series.xs(key, axis=0)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis`", "question_id": 10057},
{"snippet": "Series.xs(key, level=None)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex .", "question_id": 10058},
{"snippet": "Series.xs(key, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . With arguments `drop_level`.", "question_id": 10059},
{"snippet": "Series.xs(key, axis=0, level=None)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis`", "question_id": 10060},
{"snippet": "Series.xs(key, axis=0, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis` With arguments `drop_level`.", "question_id": 10061},
{"snippet": "Series.xs(key, level=None, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . With arguments `drop_level`.", "question_id": 10062},
{"snippet": "Series.xs(key, axis=0, level=None, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis` With arguments `drop_level`.", "question_id": 10063},
{"snippet": "Series.xs(key)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex .", "question_id": 10064},
{"snippet": "Series.xs(key, axis=0)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis`", "question_id": 10065},
{"snippet": "Series.xs(key, level=None)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex .", "question_id": 10066},
{"snippet": "Series.xs(key, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . With arguments `drop_level`.", "question_id": 10067},
{"snippet": "Series.xs(key, axis=0, level=None)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis`", "question_id": 10068},
{"snippet": "Series.xs(key, axis=0, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis` With arguments `drop_level`.", "question_id": 10069},
{"snippet": "Series.xs(key, level=None, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . With arguments `drop_level`.", "question_id": 10070},
{"snippet": "Series.xs(key, axis=0, level=None, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis` With arguments `drop_level`.", "question_id": 10071},
{"snippet": "Series.xs(key)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex .", "question_id": 10072},
{"snippet": "Series.xs(key, axis=0)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis`", "question_id": 10073},
{"snippet": "Series.xs(key, level=None)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex .", "question_id": 10074},
{"snippet": "Series.xs(key, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . With arguments `drop_level`.", "question_id": 10075},
{"snippet": "Series.xs(key, axis=0, level=None)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis`", "question_id": 10076},
{"snippet": "Series.xs(key, axis=0, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis` With arguments `drop_level`.", "question_id": 10077},
{"snippet": "Series.xs(key, level=None, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . With arguments `drop_level`.", "question_id": 10078},
{"snippet": "Series.xs(key, axis=0, level=None, drop_level=True)", "intent": "Return cross-section from the Series/DataFrame . This method takes a `key` argument to select data at a particular `level` of a MultiIndex . Get values at specified column and `axis` With arguments `drop_level`.", "question_id": 10079},
{"snippet": "pandas.SparseDtype()", "intent": "Dtype for data stored in SparseArray .", "question_id": 10080},
{"snippet": "pandas.SparseDtype(dtype=<class 'numpy.float64'>)", "intent": "Dtype for data stored in SparseArray . This `dtype` implements the pandas ExtensionDtype interface .", "question_id": 10081},
{"snippet": "pandas.SparseDtype(fill_value=None)", "intent": "Dtype for data stored in SparseArray . With arguments `fill_value`.", "question_id": 10082},
{"snippet": "pandas.SparseDtype(dtype=<class 'numpy.float64'>, fill_value=None)", "intent": "Dtype for data stored in SparseArray . This `dtype` implements the pandas ExtensionDtype interface . With arguments `fill_value`.", "question_id": 10083},
{"snippet": "pandas.SparseDtype()", "intent": "Dtype for data stored in SparseArray .", "question_id": 10084},
{"snippet": "pandas.SparseDtype(dtype=<class 'numpy.float64'>)", "intent": "Dtype for data stored in SparseArray . This `dtype` implements the pandas ExtensionDtype interface .", "question_id": 10085},
{"snippet": "pandas.SparseDtype(fill_value=None)", "intent": "Dtype for data stored in SparseArray . With arguments `fill_value`.", "question_id": 10086},
{"snippet": "pandas.SparseDtype(dtype=<class 'numpy.float64'>, fill_value=None)", "intent": "Dtype for data stored in SparseArray . This `dtype` implements the pandas ExtensionDtype interface . With arguments `fill_value`.", "question_id": 10087},
{"snippet": "pandas.SparseDtype()", "intent": "Dtype for data stored in SparseArray .", "question_id": 10088},
{"snippet": "pandas.SparseDtype(dtype=<class 'numpy.float64'>)", "intent": "Dtype for data stored in SparseArray . This `dtype` implements the pandas ExtensionDtype interface .", "question_id": 10089},
{"snippet": "pandas.SparseDtype(fill_value=None)", "intent": "Dtype for data stored in SparseArray . With arguments `fill_value`.", "question_id": 10090},
{"snippet": "pandas.SparseDtype(dtype=<class 'numpy.float64'>, fill_value=None)", "intent": "Dtype for data stored in SparseArray . This `dtype` implements the pandas ExtensionDtype interface . With arguments `fill_value`.", "question_id": 10091},
{"snippet": "pandas.StringDtype()", "intent": "Extension dtype for string data .", "question_id": 10092},
{"snippet": "pandas.StringDtype(storage=None)", "intent": "Extension dtype for string data . With arguments `storage`.", "question_id": 10093},
{"snippet": "pandas.StringDtype()", "intent": "Extension dtype for string data .", "question_id": 10094},
{"snippet": "pandas.StringDtype(storage=None)", "intent": "Extension dtype for string data . With arguments `storage`.", "question_id": 10095},
{"snippet": "pandas.StringDtype()", "intent": "Extension dtype for string data .", "question_id": 10096},
{"snippet": "pandas.StringDtype(storage=None)", "intent": "Extension dtype for string data . With arguments `storage`.", "question_id": 10097},
{"snippet": "Timedelta.asm8", "intent": "Return a numpy timedelta64 array scalar view.", "question_id": 10098},
{"snippet": "Timedelta.asm8", "intent": "Return a numpy timedelta64 array scalar view.", "question_id": 10099},
{"snippet": "Timedelta.asm8", "intent": "Return a numpy timedelta64 array scalar view.", "question_id": 10100},
{"snippet": "Timedelta.ceil(freq)", "intent": "Return a new Timedelta ceiled to this resolution . With arguments `freq`.", "question_id": 10101},
{"snippet": "Timedelta.ceil(freq)", "intent": "Return a new Timedelta ceiled to this resolution . With arguments `freq`.", "question_id": 10102},
{"snippet": "Timedelta.ceil(freq)", "intent": "Return a new Timedelta ceiled to this resolution . With arguments `freq`.", "question_id": 10103},
{"snippet": "Timedelta.components", "intent": "Return a components namedtuple-like.", "question_id": 10104},
{"snippet": "Timedelta.components", "intent": "Return a components namedtuple-like.", "question_id": 10105},
{"snippet": "Timedelta.components", "intent": "Return a components namedtuple-like.", "question_id": 10106},
{"snippet": "Timedelta.days", "intent": "Number of days.", "question_id": 10107},
{"snippet": "Timedelta.days", "intent": "Number of days.", "question_id": 10108},
{"snippet": "Timedelta.days", "intent": "Number of days.", "question_id": 10109},
{"snippet": "Timedelta.delta", "intent": "Return the timedelta in nanoseconds (ns), for internal compatibility.", "question_id": 10110},
{"snippet": "Timedelta.delta", "intent": "Return the timedelta in nanoseconds (ns), for internal compatibility.", "question_id": 10111},
{"snippet": "Timedelta.delta", "intent": "Return the timedelta in nanoseconds (ns), for internal compatibility.", "question_id": 10112},
{"snippet": "Timedelta.floor(freq)", "intent": "Return a new Timedelta floored to this resolution . With arguments `freq`.", "question_id": 10113},
{"snippet": "Timedelta.floor(freq)", "intent": "Return a new Timedelta floored to this resolution . With arguments `freq`.", "question_id": 10114},
{"snippet": "Timedelta.floor(freq)", "intent": "Return a new Timedelta floored to this resolution . With arguments `freq`.", "question_id": 10115},
{"snippet": "pandas.Timedelta(**kwargs)", "intent": "Represents a duration , the difference between two dates or times . With arguments `**kwargs`.", "question_id": 10116},
{"snippet": "pandas.Timedelta(**kwargs, value=<object object>)", "intent": "Represents a duration , the difference between two dates or times . With arguments `**kwargs`, `value`.", "question_id": 10117},
{"snippet": "pandas.Timedelta(**kwargs, unit=None)", "intent": "Represents a duration , the difference between two dates or times . With arguments `**kwargs`, `unit`.", "question_id": 10118},
{"snippet": "pandas.Timedelta(**kwargs, value=<object object>, unit=None)", "intent": "Represents a duration , the difference between two dates or times . With arguments `**kwargs`, `value`, `unit`.", "question_id": 10119},
{"snippet": "pandas.Timedelta(**kwargs)", "intent": "Represents a duration , the difference between two dates or times . With arguments `**kwargs`.", "question_id": 10120},
{"snippet": "pandas.Timedelta(**kwargs, value=<object object>)", "intent": "Represents a duration , the difference between two dates or times . With arguments `**kwargs`, `value`.", "question_id": 10121},
{"snippet": "pandas.Timedelta(**kwargs, unit=None)", "intent": "Represents a duration , the difference between two dates or times . With arguments `**kwargs`, `unit`.", "question_id": 10122},
{"snippet": "pandas.Timedelta(**kwargs, value=<object object>, unit=None)", "intent": "Represents a duration , the difference between two dates or times . With arguments `**kwargs`, `value`, `unit`.", "question_id": 10123},
{"snippet": "pandas.Timedelta(**kwargs)", "intent": "Represents a duration , the difference between two dates or times . With arguments `**kwargs`.", "question_id": 10124},
{"snippet": "pandas.Timedelta(**kwargs, value=<object object>)", "intent": "Represents a duration , the difference between two dates or times . With arguments `**kwargs`, `value`.", "question_id": 10125},
{"snippet": "pandas.Timedelta(**kwargs, unit=None)", "intent": "Represents a duration , the difference between two dates or times . With arguments `**kwargs`, `unit`.", "question_id": 10126},
{"snippet": "pandas.Timedelta(**kwargs, value=<object object>, unit=None)", "intent": "Represents a duration , the difference between two dates or times . With arguments `**kwargs`, `value`, `unit`.", "question_id": 10127},
{"snippet": "Timedelta.isoformat()", "intent": "Format Timedelta as ISO 8601 Duration like P [ n ] Y [ n ] M [ n ] DT [ n ] H [ n ] M [ n ] S , where the [ n ] s are replaced by the values .", "question_id": 10128},
{"snippet": "Timedelta.isoformat()", "intent": "Format Timedelta as ISO 8601 Duration like P [ n ] Y [ n ] M [ n ] DT [ n ] H [ n ] M [ n ] S , where the [ n ] s are replaced by the values .", "question_id": 10129},
{"snippet": "Timedelta.isoformat()", "intent": "Format Timedelta as ISO 8601 Duration like P [ n ] Y [ n ] M [ n ] DT [ n ] H [ n ] M [ n ] S , where the [ n ] s are replaced by the values .", "question_id": 10130},
{"snippet": "Timedelta.microseconds", "intent": "Number of microseconds (>= 0 and less than 1 second).", "question_id": 10131},
{"snippet": "Timedelta.microseconds", "intent": "Number of microseconds (>= 0 and less than 1 second).", "question_id": 10132},
{"snippet": "Timedelta.microseconds", "intent": "Number of microseconds (>= 0 and less than 1 second).", "question_id": 10133},
{"snippet": "Timedelta.nanoseconds", "intent": "Return the number of nanoseconds (n), where 0 <= n < 1 microsecond.", "question_id": 10134},
{"snippet": "Timedelta.nanoseconds", "intent": "Return the number of nanoseconds (n), where 0 <= n < 1 microsecond.", "question_id": 10135},
{"snippet": "Timedelta.nanoseconds", "intent": "Return the number of nanoseconds (n), where 0 <= n < 1 microsecond.", "question_id": 10136},
{"snippet": "Timedelta.resolution_string", "intent": "Return a string representing the lowest timedelta resolution.", "question_id": 10137},
{"snippet": "Timedelta.resolution_string", "intent": "Return a string representing the lowest timedelta resolution.", "question_id": 10138},
{"snippet": "Timedelta.resolution_string", "intent": "Return a string representing the lowest timedelta resolution.", "question_id": 10139},
{"snippet": "Timedelta.round(freq)", "intent": "Round the Timedelta to the specified resolution . With arguments `freq`.", "question_id": 10140},
{"snippet": "Timedelta.round(freq)", "intent": "Round the Timedelta to the specified resolution . With arguments `freq`.", "question_id": 10141},
{"snippet": "Timedelta.round(freq)", "intent": "Round the Timedelta to the specified resolution . With arguments `freq`.", "question_id": 10142},
{"snippet": "Timedelta.seconds", "intent": "Number of seconds (>= 0 and less than 1 day).", "question_id": 10143},
{"snippet": "Timedelta.seconds", "intent": "Number of seconds (>= 0 and less than 1 day).", "question_id": 10144},
{"snippet": "Timedelta.seconds", "intent": "Number of seconds (>= 0 and less than 1 day).", "question_id": 10145},
{"snippet": "Timedelta.to_numpy()", "intent": "Convert the Timedelta to a NumPy timedelta64 .", "question_id": 10146},
{"snippet": "Timedelta.to_numpy()", "intent": "Convert the Timedelta to a NumPy timedelta64 .", "question_id": 10147},
{"snippet": "Timedelta.to_numpy()", "intent": "Convert the Timedelta to a NumPy timedelta64 .", "question_id": 10148},
{"snippet": "Timedelta.to_pytimedelta()", "intent": "Convert a pandas Timedelta object into a python timedelta object .", "question_id": 10149},
{"snippet": "Timedelta.to_pytimedelta()", "intent": "Convert a pandas Timedelta object into a python timedelta object .", "question_id": 10150},
{"snippet": "Timedelta.to_pytimedelta()", "intent": "Convert a pandas Timedelta object into a python timedelta object .", "question_id": 10151},
{"snippet": "Timedelta.to_timedelta64()", "intent": "Return a numpy.timedelta64 object with \u2018 ns \u2019 precision .", "question_id": 10152},
{"snippet": "Timedelta.to_timedelta64()", "intent": "Return a numpy.timedelta64 object with \u2018 ns \u2019 precision .", "question_id": 10153},
{"snippet": "Timedelta.to_timedelta64()", "intent": "Return a numpy.timedelta64 object with \u2018 ns \u2019 precision .", "question_id": 10154},
{"snippet": "Timedelta.total_seconds()", "intent": "Total seconds in the duration .", "question_id": 10155},
{"snippet": "Timedelta.total_seconds()", "intent": "Total seconds in the duration .", "question_id": 10156},
{"snippet": "Timedelta.total_seconds()", "intent": "Total seconds in the duration .", "question_id": 10157},
{"snippet": "Timedelta.view()", "intent": "Array view compatibility .", "question_id": 10158},
{"snippet": "Timedelta.view()", "intent": "Array view compatibility .", "question_id": 10159},
{"snippet": "Timedelta.view()", "intent": "Array view compatibility .", "question_id": 10160},
{"snippet": "TimedeltaIndex.ceil(*args, **kwargs)", "intent": "Perform ceil operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 10161},
{"snippet": "TimedeltaIndex.ceil(*args, **kwargs)", "intent": "Perform ceil operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 10162},
{"snippet": "TimedeltaIndex.ceil(*args, **kwargs)", "intent": "Perform ceil operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 10163},
{"snippet": "TimedeltaIndex.floor(*args, **kwargs)", "intent": "Perform floor operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 10164},
{"snippet": "TimedeltaIndex.floor(*args, **kwargs)", "intent": "Perform floor operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 10165},
{"snippet": "TimedeltaIndex.floor(*args, **kwargs)", "intent": "Perform floor operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 10166},
{"snippet": "pandas.TimedeltaIndex()", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects .", "question_id": 10167},
{"snippet": "pandas.TimedeltaIndex(data=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects .", "question_id": 10168},
{"snippet": "pandas.TimedeltaIndex(unit=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `unit`.", "question_id": 10169},
{"snippet": "pandas.TimedeltaIndex(freq=NoDefault.no_default)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `freq`.", "question_id": 10170},
{"snippet": "pandas.TimedeltaIndex(closed=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `closed`.", "question_id": 10171},
{"snippet": "pandas.TimedeltaIndex(dtype=dtype('<m8ns'))", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `dtype`.", "question_id": 10172},
{"snippet": "pandas.TimedeltaIndex(copy=False)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `copy`.", "question_id": 10173},
{"snippet": "pandas.TimedeltaIndex(name=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `name`.", "question_id": 10174},
{"snippet": "pandas.TimedeltaIndex(data=None, unit=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `unit`.", "question_id": 10175},
{"snippet": "pandas.TimedeltaIndex(data=None, freq=NoDefault.no_default)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `freq`.", "question_id": 10176},
{"snippet": "pandas.TimedeltaIndex()", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects .", "question_id": 10177},
{"snippet": "pandas.TimedeltaIndex(data=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects .", "question_id": 10178},
{"snippet": "pandas.TimedeltaIndex(unit=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `unit`.", "question_id": 10179},
{"snippet": "pandas.TimedeltaIndex(freq=NoDefault.no_default)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `freq`.", "question_id": 10180},
{"snippet": "pandas.TimedeltaIndex(closed=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `closed`.", "question_id": 10181},
{"snippet": "pandas.TimedeltaIndex(dtype=dtype('<m8ns'))", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `dtype`.", "question_id": 10182},
{"snippet": "pandas.TimedeltaIndex(copy=False)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `copy`.", "question_id": 10183},
{"snippet": "pandas.TimedeltaIndex(name=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `name`.", "question_id": 10184},
{"snippet": "pandas.TimedeltaIndex(data=None, unit=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `unit`.", "question_id": 10185},
{"snippet": "pandas.TimedeltaIndex(data=None, freq=NoDefault.no_default)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `freq`.", "question_id": 10186},
{"snippet": "pandas.TimedeltaIndex()", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects .", "question_id": 10187},
{"snippet": "pandas.TimedeltaIndex(data=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects .", "question_id": 10188},
{"snippet": "pandas.TimedeltaIndex(unit=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `unit`.", "question_id": 10189},
{"snippet": "pandas.TimedeltaIndex(freq=NoDefault.no_default)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `freq`.", "question_id": 10190},
{"snippet": "pandas.TimedeltaIndex(closed=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `closed`.", "question_id": 10191},
{"snippet": "pandas.TimedeltaIndex(dtype=dtype('<m8ns'))", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `dtype`.", "question_id": 10192},
{"snippet": "pandas.TimedeltaIndex(copy=False)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `copy`.", "question_id": 10193},
{"snippet": "pandas.TimedeltaIndex(name=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `name`.", "question_id": 10194},
{"snippet": "pandas.TimedeltaIndex(data=None, unit=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `unit`.", "question_id": 10195},
{"snippet": "pandas.TimedeltaIndex(data=None, freq=NoDefault.no_default)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `freq`.", "question_id": 10196},
{"snippet": "pandas.TimedeltaIndex()", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects .", "question_id": 10197},
{"snippet": "pandas.TimedeltaIndex(data=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects .", "question_id": 10198},
{"snippet": "pandas.TimedeltaIndex(unit=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `unit`.", "question_id": 10199},
{"snippet": "pandas.TimedeltaIndex(freq=NoDefault.no_default)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `freq`.", "question_id": 10200},
{"snippet": "pandas.TimedeltaIndex(closed=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `closed`.", "question_id": 10201},
{"snippet": "pandas.TimedeltaIndex(dtype=dtype('<m8ns'))", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `dtype`.", "question_id": 10202},
{"snippet": "pandas.TimedeltaIndex(copy=False)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `copy`.", "question_id": 10203},
{"snippet": "pandas.TimedeltaIndex(name=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `name`.", "question_id": 10204},
{"snippet": "pandas.TimedeltaIndex(data=None, unit=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `unit`.", "question_id": 10205},
{"snippet": "pandas.TimedeltaIndex(data=None, freq=NoDefault.no_default)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `freq`.", "question_id": 10206},
{"snippet": "pandas.TimedeltaIndex()", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects .", "question_id": 10207},
{"snippet": "pandas.TimedeltaIndex(data=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects .", "question_id": 10208},
{"snippet": "pandas.TimedeltaIndex(unit=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `unit`.", "question_id": 10209},
{"snippet": "pandas.TimedeltaIndex(freq=NoDefault.no_default)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `freq`.", "question_id": 10210},
{"snippet": "pandas.TimedeltaIndex(closed=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `closed`.", "question_id": 10211},
{"snippet": "pandas.TimedeltaIndex(dtype=dtype('<m8ns'))", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `dtype`.", "question_id": 10212},
{"snippet": "pandas.TimedeltaIndex(copy=False)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `copy`.", "question_id": 10213},
{"snippet": "pandas.TimedeltaIndex(name=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `name`.", "question_id": 10214},
{"snippet": "pandas.TimedeltaIndex(data=None, unit=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `unit`.", "question_id": 10215},
{"snippet": "pandas.TimedeltaIndex(data=None, freq=NoDefault.no_default)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `freq`.", "question_id": 10216},
{"snippet": "pandas.TimedeltaIndex()", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects .", "question_id": 10217},
{"snippet": "pandas.TimedeltaIndex(data=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects .", "question_id": 10218},
{"snippet": "pandas.TimedeltaIndex(unit=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `unit`.", "question_id": 10219},
{"snippet": "pandas.TimedeltaIndex(freq=NoDefault.no_default)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `freq`.", "question_id": 10220},
{"snippet": "pandas.TimedeltaIndex(closed=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `closed`.", "question_id": 10221},
{"snippet": "pandas.TimedeltaIndex(dtype=dtype('<m8ns'))", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `dtype`.", "question_id": 10222},
{"snippet": "pandas.TimedeltaIndex(copy=False)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `copy`.", "question_id": 10223},
{"snippet": "pandas.TimedeltaIndex(name=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `name`.", "question_id": 10224},
{"snippet": "pandas.TimedeltaIndex(data=None, unit=None)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `unit`.", "question_id": 10225},
{"snippet": "pandas.TimedeltaIndex(data=None, freq=NoDefault.no_default)", "intent": "Immutable ndarray of timedelta64 `data` , represented internally as int64 , and which can be boxed to timedelta objects . With arguments `freq`.", "question_id": 10226},
{"snippet": "TimedeltaIndex.inferred_freq", "intent": "Tries to return a string representing a frequency guess, generated by infer_freq.", "question_id": 10227},
{"snippet": "TimedeltaIndex.inferred_freq", "intent": "Tries to return a string representing a frequency guess, generated by infer_freq.", "question_id": 10228},
{"snippet": "TimedeltaIndex.inferred_freq", "intent": "Tries to return a string representing a frequency guess, generated by infer_freq.", "question_id": 10229},
{"snippet": "TimedeltaIndex.mean(*args, **kwargs)", "intent": "Return the mean value of the Array . With arguments `*args`, `**kwargs`.", "question_id": 10230},
{"snippet": "TimedeltaIndex.mean(*args, **kwargs)", "intent": "Return the mean value of the Array . With arguments `*args`, `**kwargs`.", "question_id": 10231},
{"snippet": "TimedeltaIndex.mean(*args, **kwargs)", "intent": "Return the mean value of the Array . With arguments `*args`, `**kwargs`.", "question_id": 10232},
{"snippet": "TimedeltaIndex.round(*args, **kwargs)", "intent": "Perform round operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 10233},
{"snippet": "TimedeltaIndex.round(*args, **kwargs)", "intent": "Perform round operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 10234},
{"snippet": "TimedeltaIndex.round(*args, **kwargs)", "intent": "Perform round operation on the data to the specified freq . With arguments `*args`, `**kwargs`.", "question_id": 10235},
{"snippet": "TimedeltaIndex.to_frame()", "intent": "Create a DataFrame with a column containing the Index .", "question_id": 10236},
{"snippet": "TimedeltaIndex.to_frame(index=True)", "intent": "Create a DataFrame with a column containing the Index . With arguments `index`.", "question_id": 10237},
{"snippet": "TimedeltaIndex.to_frame(name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name :", "question_id": 10238},
{"snippet": "TimedeltaIndex.to_frame(index=True, name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name : With arguments `index`.", "question_id": 10239},
{"snippet": "TimedeltaIndex.to_frame()", "intent": "Create a DataFrame with a column containing the Index .", "question_id": 10240},
{"snippet": "TimedeltaIndex.to_frame(index=True)", "intent": "Create a DataFrame with a column containing the Index . With arguments `index`.", "question_id": 10241},
{"snippet": "TimedeltaIndex.to_frame(name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name :", "question_id": 10242},
{"snippet": "TimedeltaIndex.to_frame(index=True, name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name : With arguments `index`.", "question_id": 10243},
{"snippet": "TimedeltaIndex.to_frame()", "intent": "Create a DataFrame with a column containing the Index .", "question_id": 10244},
{"snippet": "TimedeltaIndex.to_frame(index=True)", "intent": "Create a DataFrame with a column containing the Index . With arguments `index`.", "question_id": 10245},
{"snippet": "TimedeltaIndex.to_frame(name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name :", "question_id": 10246},
{"snippet": "TimedeltaIndex.to_frame(index=True, name=None)", "intent": "Create a DataFrame with a column containing the Index . To override the `name` of the resulting column , specify name : With arguments `index`.", "question_id": 10247},
{"snippet": "TimedeltaIndex.to_pytimedelta(*args, **kwargs)", "intent": "Return Timedelta Array/Index as object ndarray of datetime.timedelta objects . With arguments `*args`, `**kwargs`.", "question_id": 10248},
{"snippet": "TimedeltaIndex.to_pytimedelta(*args, **kwargs)", "intent": "Return Timedelta Array/Index as object ndarray of datetime.timedelta objects . With arguments `*args`, `**kwargs`.", "question_id": 10249},
{"snippet": "TimedeltaIndex.to_pytimedelta(*args, **kwargs)", "intent": "Return Timedelta Array/Index as object ndarray of datetime.timedelta objects . With arguments `*args`, `**kwargs`.", "question_id": 10250},
{"snippet": "TimedeltaIndex.to_series()", "intent": "Create a Series with both `index` and values equal to the index keys .", "question_id": 10251},
{"snippet": "TimedeltaIndex.to_series(index=None)", "intent": "Create a Series with both `index` and values equal to the index keys .", "question_id": 10252},
{"snippet": "TimedeltaIndex.to_series(name=None)", "intent": "Create a Series with both `index` and values equal to the index keys . By default , the original Index and original `name` is reused .", "question_id": 10253},
{"snippet": "TimedeltaIndex.to_series(index=None, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys . By default , the original Index and original `name` is reused .", "question_id": 10254},
{"snippet": "TimedeltaIndex.to_series()", "intent": "Create a Series with both `index` and values equal to the index keys .", "question_id": 10255},
{"snippet": "TimedeltaIndex.to_series(index=None)", "intent": "Create a Series with both `index` and values equal to the index keys .", "question_id": 10256},
{"snippet": "TimedeltaIndex.to_series(name=None)", "intent": "Create a Series with both `index` and values equal to the index keys . By default , the original Index and original `name` is reused .", "question_id": 10257},
{"snippet": "TimedeltaIndex.to_series(index=None, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys . By default , the original Index and original `name` is reused .", "question_id": 10258},
{"snippet": "TimedeltaIndex.to_series()", "intent": "Create a Series with both `index` and values equal to the index keys .", "question_id": 10259},
{"snippet": "TimedeltaIndex.to_series(index=None)", "intent": "Create a Series with both `index` and values equal to the index keys .", "question_id": 10260},
{"snippet": "TimedeltaIndex.to_series(name=None)", "intent": "Create a Series with both `index` and values equal to the index keys . By default , the original Index and original `name` is reused .", "question_id": 10261},
{"snippet": "TimedeltaIndex.to_series(index=None, name=None)", "intent": "Create a Series with both `index` and values equal to the index keys . By default , the original Index and original `name` is reused .", "question_id": 10262},
{"snippet": "Timestamp.asm8", "intent": "Return numpy datetime64 format in nanoseconds.", "question_id": 10263},
{"snippet": "Timestamp.asm8", "intent": "Return numpy datetime64 format in nanoseconds.", "question_id": 10264},
{"snippet": "Timestamp.asm8", "intent": "Return numpy datetime64 format in nanoseconds.", "question_id": 10265},
{"snippet": "Timestamp.astimezone(tz)", "intent": "Convert tz-aware Timestamp to another time zone . With arguments `tz`.", "question_id": 10266},
{"snippet": "Timestamp.astimezone(tz)", "intent": "Convert tz-aware Timestamp to another time zone . With arguments `tz`.", "question_id": 10267},
{"snippet": "Timestamp.astimezone(tz)", "intent": "Convert tz-aware Timestamp to another time zone . With arguments `tz`.", "question_id": 10268},
{"snippet": "Timestamp.ceil(freq)", "intent": "Return a new Timestamp ceiled to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e .", "question_id": 10269},
{"snippet": "Timestamp.ceil(freq, ambiguous='raise')", "intent": "Return a new Timestamp ceiled to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`.", "question_id": 10270},
{"snippet": "Timestamp.ceil(freq, nonexistent='raise')", "intent": "Return a new Timestamp ceiled to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `nonexistent`.", "question_id": 10271},
{"snippet": "Timestamp.ceil(freq, ambiguous='raise', nonexistent='raise')", "intent": "Return a new Timestamp ceiled to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`, `nonexistent`.", "question_id": 10272},
{"snippet": "Timestamp.ceil(freq)", "intent": "Return a new Timestamp ceiled to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e .", "question_id": 10273},
{"snippet": "Timestamp.ceil(freq, ambiguous='raise')", "intent": "Return a new Timestamp ceiled to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`.", "question_id": 10274},
{"snippet": "Timestamp.ceil(freq, nonexistent='raise')", "intent": "Return a new Timestamp ceiled to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `nonexistent`.", "question_id": 10275},
{"snippet": "Timestamp.ceil(freq, ambiguous='raise', nonexistent='raise')", "intent": "Return a new Timestamp ceiled to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`, `nonexistent`.", "question_id": 10276},
{"snippet": "Timestamp.ceil(freq)", "intent": "Return a new Timestamp ceiled to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e .", "question_id": 10277},
{"snippet": "Timestamp.ceil(freq, ambiguous='raise')", "intent": "Return a new Timestamp ceiled to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`.", "question_id": 10278},
{"snippet": "Timestamp.ceil(freq, nonexistent='raise')", "intent": "Return a new Timestamp ceiled to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `nonexistent`.", "question_id": 10279},
{"snippet": "Timestamp.ceil(freq, ambiguous='raise', nonexistent='raise')", "intent": "Return a new Timestamp ceiled to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`, `nonexistent`.", "question_id": 10280},
{"snippet": "Timestamp.combine(date, time)", "intent": "Combine `date` , `time` into datetime with same date and time fields .", "question_id": 10281},
{"snippet": "Timestamp.combine(date, time)", "intent": "Combine `date` , `time` into datetime with same date and time fields .", "question_id": 10282},
{"snippet": "Timestamp.combine(date, time)", "intent": "Combine `date` , `time` into datetime with same date and time fields .", "question_id": 10283},
{"snippet": "Timestamp.ctime()", "intent": "Return ctime ( ) style string .", "question_id": 10284},
{"snippet": "Timestamp.ctime()", "intent": "Return ctime ( ) style string .", "question_id": 10285},
{"snippet": "Timestamp.ctime()", "intent": "Return ctime ( ) style string .", "question_id": 10286},
{"snippet": "Timestamp.date()", "intent": "Return date object with same year , month and day .", "question_id": 10287},
{"snippet": "Timestamp.date()", "intent": "Return date object with same year , month and day .", "question_id": 10288},
{"snippet": "Timestamp.date()", "intent": "Return date object with same year , month and day .", "question_id": 10289},
{"snippet": "Timestamp.day_name()", "intent": "Return the day name of the Timestamp with specified locale .", "question_id": 10290},
{"snippet": "Timestamp.day_name()", "intent": "Return the day name of the Timestamp with specified locale .", "question_id": 10291},
{"snippet": "Timestamp.day_name()", "intent": "Return the day name of the Timestamp with specified locale .", "question_id": 10292},
{"snippet": "Timestamp.day_of_week", "intent": "Return day of the week.", "question_id": 10293},
{"snippet": "Timestamp.day_of_week", "intent": "Return day of the week.", "question_id": 10294},
{"snippet": "Timestamp.day_of_week", "intent": "Return day of the week.", "question_id": 10295},
{"snippet": "Timestamp.day_of_year", "intent": "Return the day of the year.", "question_id": 10296},
{"snippet": "Timestamp.day_of_year", "intent": "Return the day of the year.", "question_id": 10297},
{"snippet": "Timestamp.day_of_year", "intent": "Return the day of the year.", "question_id": 10298},
{"snippet": "Timestamp.dayofweek", "intent": "Return day of the week.", "question_id": 10299},
{"snippet": "Timestamp.dayofweek", "intent": "Return day of the week.", "question_id": 10300},
{"snippet": "Timestamp.dayofweek", "intent": "Return day of the week.", "question_id": 10301},
{"snippet": "Timestamp.dayofyear", "intent": "Return the day of the year.", "question_id": 10302},
{"snippet": "Timestamp.dayofyear", "intent": "Return the day of the year.", "question_id": 10303},
{"snippet": "Timestamp.dayofyear", "intent": "Return the day of the year.", "question_id": 10304},
{"snippet": "Timestamp.days_in_month", "intent": "Return the number of days in the month.", "question_id": 10305},
{"snippet": "Timestamp.days_in_month", "intent": "Return the number of days in the month.", "question_id": 10306},
{"snippet": "Timestamp.days_in_month", "intent": "Return the number of days in the month.", "question_id": 10307},
{"snippet": "Timestamp.daysinmonth", "intent": "Return the number of days in the month.", "question_id": 10308},
{"snippet": "Timestamp.daysinmonth", "intent": "Return the number of days in the month.", "question_id": 10309},
{"snippet": "Timestamp.daysinmonth", "intent": "Return the number of days in the month.", "question_id": 10310},
{"snippet": "Timestamp.dst()", "intent": "Return self.tzinfo.dst ( self ) .", "question_id": 10311},
{"snippet": "Timestamp.dst()", "intent": "Return self.tzinfo.dst ( self ) .", "question_id": 10312},
{"snippet": "Timestamp.dst()", "intent": "Return self.tzinfo.dst ( self ) .", "question_id": 10313},
{"snippet": "Timestamp.floor(freq)", "intent": "Return a new Timestamp floored to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e .", "question_id": 10314},
{"snippet": "Timestamp.floor(freq, ambiguous='raise')", "intent": "Return a new Timestamp floored to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`.", "question_id": 10315},
{"snippet": "Timestamp.floor(freq, nonexistent='raise')", "intent": "Return a new Timestamp floored to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `nonexistent`.", "question_id": 10316},
{"snippet": "Timestamp.floor(freq, ambiguous='raise', nonexistent='raise')", "intent": "Return a new Timestamp floored to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`, `nonexistent`.", "question_id": 10317},
{"snippet": "Timestamp.floor(freq)", "intent": "Return a new Timestamp floored to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e .", "question_id": 10318},
{"snippet": "Timestamp.floor(freq, ambiguous='raise')", "intent": "Return a new Timestamp floored to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`.", "question_id": 10319},
{"snippet": "Timestamp.floor(freq, nonexistent='raise')", "intent": "Return a new Timestamp floored to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `nonexistent`.", "question_id": 10320},
{"snippet": "Timestamp.floor(freq, ambiguous='raise', nonexistent='raise')", "intent": "Return a new Timestamp floored to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`, `nonexistent`.", "question_id": 10321},
{"snippet": "Timestamp.floor(freq)", "intent": "Return a new Timestamp floored to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e .", "question_id": 10322},
{"snippet": "Timestamp.floor(freq, ambiguous='raise')", "intent": "Return a new Timestamp floored to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`.", "question_id": 10323},
{"snippet": "Timestamp.floor(freq, nonexistent='raise')", "intent": "Return a new Timestamp floored to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `nonexistent`.", "question_id": 10324},
{"snippet": "Timestamp.floor(freq, ambiguous='raise', nonexistent='raise')", "intent": "Return a new Timestamp floored to this resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`, `nonexistent`.", "question_id": 10325},
{"snippet": "Timestamp.fromisocalendar()", "intent": "int , int , int - > Construct a date from the ISO year , week number and weekday .", "question_id": 10326},
{"snippet": "Timestamp.fromisocalendar()", "intent": "int , int , int - > Construct a date from the ISO year , week number and weekday .", "question_id": 10327},
{"snippet": "Timestamp.fromisocalendar()", "intent": "int , int , int - > Construct a date from the ISO year , week number and weekday .", "question_id": 10328},
{"snippet": "Timestamp.fromisoformat()", "intent": "string - > datetime from datetime.isoformat ( ) output", "question_id": 10329},
{"snippet": "Timestamp.fromisoformat()", "intent": "string - > datetime from datetime.isoformat ( ) output", "question_id": 10330},
{"snippet": "Timestamp.fromisoformat()", "intent": "string - > datetime from datetime.isoformat ( ) output", "question_id": 10331},
{"snippet": "Timestamp.fromordinal(ordinal)", "intent": "Passed an `ordinal` , translate and convert to a ts .", "question_id": 10332},
{"snippet": "Timestamp.fromordinal(ordinal, freq=None)", "intent": "Passed an `ordinal` , translate and convert to a ts . With arguments `freq`.", "question_id": 10333},
{"snippet": "Timestamp.fromordinal(ordinal, tz=None)", "intent": "Passed an `ordinal` , translate and convert to a ts . Note : by definition there can not be any `tz` info on the ordinal itself .", "question_id": 10334},
{"snippet": "Timestamp.fromordinal(ordinal, freq=None, tz=None)", "intent": "Passed an `ordinal` , translate and convert to a ts . Note : by definition there can not be any `tz` info on the ordinal itself . With arguments `freq`.", "question_id": 10335},
{"snippet": "Timestamp.fromordinal(ordinal)", "intent": "Passed an `ordinal` , translate and convert to a ts .", "question_id": 10336},
{"snippet": "Timestamp.fromordinal(ordinal, freq=None)", "intent": "Passed an `ordinal` , translate and convert to a ts . With arguments `freq`.", "question_id": 10337},
{"snippet": "Timestamp.fromordinal(ordinal, tz=None)", "intent": "Passed an `ordinal` , translate and convert to a ts . Note : by definition there can not be any `tz` info on the ordinal itself .", "question_id": 10338},
{"snippet": "Timestamp.fromordinal(ordinal, freq=None, tz=None)", "intent": "Passed an `ordinal` , translate and convert to a ts . Note : by definition there can not be any `tz` info on the ordinal itself . With arguments `freq`.", "question_id": 10339},
{"snippet": "Timestamp.fromordinal(ordinal)", "intent": "Passed an `ordinal` , translate and convert to a ts .", "question_id": 10340},
{"snippet": "Timestamp.fromordinal(ordinal, freq=None)", "intent": "Passed an `ordinal` , translate and convert to a ts . With arguments `freq`.", "question_id": 10341},
{"snippet": "Timestamp.fromordinal(ordinal, tz=None)", "intent": "Passed an `ordinal` , translate and convert to a ts . Note : by definition there can not be any `tz` info on the ordinal itself .", "question_id": 10342},
{"snippet": "Timestamp.fromordinal(ordinal, freq=None, tz=None)", "intent": "Passed an `ordinal` , translate and convert to a ts . Note : by definition there can not be any `tz` info on the ordinal itself . With arguments `freq`.", "question_id": 10343},
{"snippet": "Timestamp.fromtimestamp(ts)", "intent": "Transform timestamp [ , tz ] to tz \u2019 s local time from POSIX timestamp . With arguments `ts`.", "question_id": 10344},
{"snippet": "Timestamp.fromtimestamp(ts)", "intent": "Transform timestamp [ , tz ] to tz \u2019 s local time from POSIX timestamp . With arguments `ts`.", "question_id": 10345},
{"snippet": "Timestamp.fromtimestamp(ts)", "intent": "Transform timestamp [ , tz ] to tz \u2019 s local time from POSIX timestamp . With arguments `ts`.", "question_id": 10346},
{"snippet": "pandas.Timestamp()", "intent": "Pandas replacement for python datetime.datetime object .", "question_id": 10347},
{"snippet": "pandas.Timestamp(ts_input=<object object>)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `ts_input`.", "question_id": 10348},
{"snippet": "pandas.Timestamp(freq=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `freq`.", "question_id": 10349},
{"snippet": "pandas.Timestamp(tz=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `tz`.", "question_id": 10350},
{"snippet": "pandas.Timestamp(unit=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `unit`.", "question_id": 10351},
{"snippet": "pandas.Timestamp(year=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `year`.", "question_id": 10352},
{"snippet": "pandas.Timestamp(month=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `month`.", "question_id": 10353},
{"snippet": "pandas.Timestamp(day=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `day`.", "question_id": 10354},
{"snippet": "pandas.Timestamp(hour=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `hour`.", "question_id": 10355},
{"snippet": "pandas.Timestamp(minute=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `minute`.", "question_id": 10356},
{"snippet": "pandas.Timestamp()", "intent": "Pandas replacement for python datetime.datetime object .", "question_id": 10357},
{"snippet": "pandas.Timestamp(ts_input=<object object>)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `ts_input`.", "question_id": 10358},
{"snippet": "pandas.Timestamp(freq=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `freq`.", "question_id": 10359},
{"snippet": "pandas.Timestamp(tz=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `tz`.", "question_id": 10360},
{"snippet": "pandas.Timestamp(unit=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `unit`.", "question_id": 10361},
{"snippet": "pandas.Timestamp(year=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `year`.", "question_id": 10362},
{"snippet": "pandas.Timestamp(month=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `month`.", "question_id": 10363},
{"snippet": "pandas.Timestamp(day=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `day`.", "question_id": 10364},
{"snippet": "pandas.Timestamp(hour=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `hour`.", "question_id": 10365},
{"snippet": "pandas.Timestamp(minute=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `minute`.", "question_id": 10366},
{"snippet": "pandas.Timestamp()", "intent": "Pandas replacement for python datetime.datetime object .", "question_id": 10367},
{"snippet": "pandas.Timestamp(ts_input=<object object>)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `ts_input`.", "question_id": 10368},
{"snippet": "pandas.Timestamp(freq=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `freq`.", "question_id": 10369},
{"snippet": "pandas.Timestamp(tz=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `tz`.", "question_id": 10370},
{"snippet": "pandas.Timestamp(unit=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `unit`.", "question_id": 10371},
{"snippet": "pandas.Timestamp(year=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `year`.", "question_id": 10372},
{"snippet": "pandas.Timestamp(month=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `month`.", "question_id": 10373},
{"snippet": "pandas.Timestamp(day=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `day`.", "question_id": 10374},
{"snippet": "pandas.Timestamp(hour=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `hour`.", "question_id": 10375},
{"snippet": "pandas.Timestamp(minute=None)", "intent": "Pandas replacement for python datetime.datetime object . With arguments `minute`.", "question_id": 10376},
{"snippet": "Timestamp.is_leap_year", "intent": "Return True if year is a leap year.", "question_id": 10377},
{"snippet": "Timestamp.is_leap_year", "intent": "Return True if year is a leap year.", "question_id": 10378},
{"snippet": "Timestamp.is_leap_year", "intent": "Return True if year is a leap year.", "question_id": 10379},
{"snippet": "Timestamp.is_month_end", "intent": "Return True if date is last day of month.", "question_id": 10380},
{"snippet": "Timestamp.is_month_end", "intent": "Return True if date is last day of month.", "question_id": 10381},
{"snippet": "Timestamp.is_month_end", "intent": "Return True if date is last day of month.", "question_id": 10382},
{"snippet": "Timestamp.is_month_start", "intent": "Return True if date is first day of month.", "question_id": 10383},
{"snippet": "Timestamp.is_month_start", "intent": "Return True if date is first day of month.", "question_id": 10384},
{"snippet": "Timestamp.is_month_start", "intent": "Return True if date is first day of month.", "question_id": 10385},
{"snippet": "Timestamp.is_quarter_end", "intent": "Return True if date is last day of the quarter.", "question_id": 10386},
{"snippet": "Timestamp.is_quarter_end", "intent": "Return True if date is last day of the quarter.", "question_id": 10387},
{"snippet": "Timestamp.is_quarter_end", "intent": "Return True if date is last day of the quarter.", "question_id": 10388},
{"snippet": "Timestamp.is_quarter_start", "intent": "Return True if date is first day of the quarter.", "question_id": 10389},
{"snippet": "Timestamp.is_quarter_start", "intent": "Return True if date is first day of the quarter.", "question_id": 10390},
{"snippet": "Timestamp.is_quarter_start", "intent": "Return True if date is first day of the quarter.", "question_id": 10391},
{"snippet": "Timestamp.is_year_end", "intent": "Return True if date is last day of the year.", "question_id": 10392},
{"snippet": "Timestamp.is_year_end", "intent": "Return True if date is last day of the year.", "question_id": 10393},
{"snippet": "Timestamp.is_year_end", "intent": "Return True if date is last day of the year.", "question_id": 10394},
{"snippet": "Timestamp.is_year_start", "intent": "Return True if date is first day of the year.", "question_id": 10395},
{"snippet": "Timestamp.is_year_start", "intent": "Return True if date is first day of the year.", "question_id": 10396},
{"snippet": "Timestamp.is_year_start", "intent": "Return True if date is first day of the year.", "question_id": 10397},
{"snippet": "Timestamp.isocalendar()", "intent": "Return a 3-tuple containing ISO year , week number , and weekday .", "question_id": 10398},
{"snippet": "Timestamp.isocalendar()", "intent": "Return a 3-tuple containing ISO year , week number , and weekday .", "question_id": 10399},
{"snippet": "Timestamp.isocalendar()", "intent": "Return a 3-tuple containing ISO year , week number , and weekday .", "question_id": 10400},
{"snippet": "Timestamp.isoformat()", "intent": "[ sep ] - > string in ISO 8601 format , YYYY-MM-DDT [ HH [ : MM [ : SS [ .mmm [ uuu ] ] ] ] ] [ +HH : MM ] .", "question_id": 10401},
{"snippet": "Timestamp.isoformat()", "intent": "[ sep ] - > string in ISO 8601 format , YYYY-MM-DDT [ HH [ : MM [ : SS [ .mmm [ uuu ] ] ] ] ] [ +HH : MM ] .", "question_id": 10402},
{"snippet": "Timestamp.isoformat()", "intent": "[ sep ] - > string in ISO 8601 format , YYYY-MM-DDT [ HH [ : MM [ : SS [ .mmm [ uuu ] ] ] ] ] [ +HH : MM ] .", "question_id": 10403},
{"snippet": "Timestamp.isoweekday()", "intent": "Return the day of the week represented by the date .", "question_id": 10404},
{"snippet": "Timestamp.isoweekday()", "intent": "Return the day of the week represented by the date .", "question_id": 10405},
{"snippet": "Timestamp.isoweekday()", "intent": "Return the day of the week represented by the date .", "question_id": 10406},
{"snippet": "Timestamp.month_name()", "intent": "Return the month name of the Timestamp with specified locale .", "question_id": 10407},
{"snippet": "Timestamp.month_name()", "intent": "Return the month name of the Timestamp with specified locale .", "question_id": 10408},
{"snippet": "Timestamp.month_name()", "intent": "Return the month name of the Timestamp with specified locale .", "question_id": 10409},
{"snippet": "Timestamp.normalize()", "intent": "Normalize Timestamp to midnight , preserving tz information .", "question_id": 10410},
{"snippet": "Timestamp.normalize()", "intent": "Normalize Timestamp to midnight , preserving tz information .", "question_id": 10411},
{"snippet": "Timestamp.normalize()", "intent": "Normalize Timestamp to midnight , preserving tz information .", "question_id": 10412},
{"snippet": "Timestamp.now()", "intent": "Return new Timestamp object representing current time local to `tz` .", "question_id": 10413},
{"snippet": "Timestamp.now(tz=None)", "intent": "Return new Timestamp object representing current time local to `tz` .", "question_id": 10414},
{"snippet": "Timestamp.now()", "intent": "Return new Timestamp object representing current time local to `tz` .", "question_id": 10415},
{"snippet": "Timestamp.now(tz=None)", "intent": "Return new Timestamp object representing current time local to `tz` .", "question_id": 10416},
{"snippet": "Timestamp.now()", "intent": "Return new Timestamp object representing current time local to `tz` .", "question_id": 10417},
{"snippet": "Timestamp.now(tz=None)", "intent": "Return new Timestamp object representing current time local to `tz` .", "question_id": 10418},
{"snippet": "Timestamp.quarter", "intent": "Return the quarter of the year.", "question_id": 10419},
{"snippet": "Timestamp.quarter", "intent": "Return the quarter of the year.", "question_id": 10420},
{"snippet": "Timestamp.quarter", "intent": "Return the quarter of the year.", "question_id": 10421},
{"snippet": "Timestamp.replace()", "intent": "Implements datetime.replace , handles nanoseconds .", "question_id": 10422},
{"snippet": "Timestamp.replace(year=None)", "intent": "Implements datetime.replace , handles nanoseconds . Replace `year` and the `hour` :", "question_id": 10423},
{"snippet": "Timestamp.replace(month=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `month`.", "question_id": 10424},
{"snippet": "Timestamp.replace(day=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `day`.", "question_id": 10425},
{"snippet": "Timestamp.replace(hour=None)", "intent": "Implements datetime.replace , handles nanoseconds . Replace `year` and the `hour` :", "question_id": 10426},
{"snippet": "Timestamp.replace(minute=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `minute`.", "question_id": 10427},
{"snippet": "Timestamp.replace(second=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `second`.", "question_id": 10428},
{"snippet": "Timestamp.replace(microsecond=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `microsecond`.", "question_id": 10429},
{"snippet": "Timestamp.replace(nanosecond=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `nanosecond`.", "question_id": 10430},
{"snippet": "Timestamp.replace(tzinfo=<class 'object'>)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `tzinfo`.", "question_id": 10431},
{"snippet": "Timestamp.replace()", "intent": "Implements datetime.replace , handles nanoseconds .", "question_id": 10432},
{"snippet": "Timestamp.replace(year=None)", "intent": "Implements datetime.replace , handles nanoseconds . Replace `year` and the `hour` :", "question_id": 10433},
{"snippet": "Timestamp.replace(month=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `month`.", "question_id": 10434},
{"snippet": "Timestamp.replace(day=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `day`.", "question_id": 10435},
{"snippet": "Timestamp.replace(hour=None)", "intent": "Implements datetime.replace , handles nanoseconds . Replace `year` and the `hour` :", "question_id": 10436},
{"snippet": "Timestamp.replace(minute=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `minute`.", "question_id": 10437},
{"snippet": "Timestamp.replace(second=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `second`.", "question_id": 10438},
{"snippet": "Timestamp.replace(microsecond=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `microsecond`.", "question_id": 10439},
{"snippet": "Timestamp.replace(nanosecond=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `nanosecond`.", "question_id": 10440},
{"snippet": "Timestamp.replace(tzinfo=<class 'object'>)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `tzinfo`.", "question_id": 10441},
{"snippet": "Timestamp.replace()", "intent": "Implements datetime.replace , handles nanoseconds .", "question_id": 10442},
{"snippet": "Timestamp.replace(year=None)", "intent": "Implements datetime.replace , handles nanoseconds . Replace `year` and the `hour` :", "question_id": 10443},
{"snippet": "Timestamp.replace(month=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `month`.", "question_id": 10444},
{"snippet": "Timestamp.replace(day=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `day`.", "question_id": 10445},
{"snippet": "Timestamp.replace(hour=None)", "intent": "Implements datetime.replace , handles nanoseconds . Replace `year` and the `hour` :", "question_id": 10446},
{"snippet": "Timestamp.replace(minute=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `minute`.", "question_id": 10447},
{"snippet": "Timestamp.replace(second=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `second`.", "question_id": 10448},
{"snippet": "Timestamp.replace(microsecond=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `microsecond`.", "question_id": 10449},
{"snippet": "Timestamp.replace(nanosecond=None)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `nanosecond`.", "question_id": 10450},
{"snippet": "Timestamp.replace(tzinfo=<class 'object'>)", "intent": "Implements datetime.replace , handles nanoseconds . With arguments `tzinfo`.", "question_id": 10451},
{"snippet": "Timestamp.round(freq)", "intent": "Round the Timestamp to the specified resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e .", "question_id": 10452},
{"snippet": "Timestamp.round(freq, ambiguous='raise')", "intent": "Round the Timestamp to the specified resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`.", "question_id": 10453},
{"snippet": "Timestamp.round(freq, nonexistent='raise')", "intent": "Round the Timestamp to the specified resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `nonexistent`.", "question_id": 10454},
{"snippet": "Timestamp.round(freq, ambiguous='raise', nonexistent='raise')", "intent": "Round the Timestamp to the specified resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`, `nonexistent`.", "question_id": 10455},
{"snippet": "Timestamp.round(freq)", "intent": "Round the Timestamp to the specified resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e .", "question_id": 10456},
{"snippet": "Timestamp.round(freq, ambiguous='raise')", "intent": "Round the Timestamp to the specified resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`.", "question_id": 10457},
{"snippet": "Timestamp.round(freq, nonexistent='raise')", "intent": "Round the Timestamp to the specified resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `nonexistent`.", "question_id": 10458},
{"snippet": "Timestamp.round(freq, ambiguous='raise', nonexistent='raise')", "intent": "Round the Timestamp to the specified resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`, `nonexistent`.", "question_id": 10459},
{"snippet": "Timestamp.round(freq)", "intent": "Round the Timestamp to the specified resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e .", "question_id": 10460},
{"snippet": "Timestamp.round(freq, ambiguous='raise')", "intent": "Round the Timestamp to the specified resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`.", "question_id": 10461},
{"snippet": "Timestamp.round(freq, nonexistent='raise')", "intent": "Round the Timestamp to the specified resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `nonexistent`.", "question_id": 10462},
{"snippet": "Timestamp.round(freq, ambiguous='raise', nonexistent='raise')", "intent": "Round the Timestamp to the specified resolution . `freq` can also be a multiple of a single unit , like \u2018 5T \u2019 ( i.e . With arguments `ambiguous`, `nonexistent`.", "question_id": 10463},
{"snippet": "Timestamp.strftime(format)", "intent": "Return a string representing the given POSIX timestamp controlled by an explicit `format` string .", "question_id": 10464},
{"snippet": "Timestamp.strftime(format)", "intent": "Return a string representing the given POSIX timestamp controlled by an explicit `format` string .", "question_id": 10465},
{"snippet": "Timestamp.strftime(format)", "intent": "Return a string representing the given POSIX timestamp controlled by an explicit `format` string .", "question_id": 10466},
{"snippet": "Timestamp.strptime(string, format)", "intent": "Function is not implemented . With arguments `string`, `format`.", "question_id": 10467},
{"snippet": "Timestamp.strptime(string, format)", "intent": "Function is not implemented . With arguments `string`, `format`.", "question_id": 10468},
{"snippet": "Timestamp.strptime(string, format)", "intent": "Function is not implemented . With arguments `string`, `format`.", "question_id": 10469},
{"snippet": "Timestamp.time()", "intent": "Return time object with same time but with tzinfo=None .", "question_id": 10470},
{"snippet": "Timestamp.time()", "intent": "Return time object with same time but with tzinfo=None .", "question_id": 10471},
{"snippet": "Timestamp.time()", "intent": "Return time object with same time but with tzinfo=None .", "question_id": 10472},
{"snippet": "Timestamp.timestamp()", "intent": "Return POSIX timestamp as float .", "question_id": 10473},
{"snippet": "Timestamp.timestamp()", "intent": "Return POSIX timestamp as float .", "question_id": 10474},
{"snippet": "Timestamp.timestamp()", "intent": "Return POSIX timestamp as float .", "question_id": 10475},
{"snippet": "Timestamp.timetuple()", "intent": "Return time tuple , compatible with time.localtime ( ) .", "question_id": 10476},
{"snippet": "Timestamp.timetuple()", "intent": "Return time tuple , compatible with time.localtime ( ) .", "question_id": 10477},
{"snippet": "Timestamp.timetuple()", "intent": "Return time tuple , compatible with time.localtime ( ) .", "question_id": 10478},
{"snippet": "Timestamp.timetz()", "intent": "Return time object with same time and tzinfo .", "question_id": 10479},
{"snippet": "Timestamp.timetz()", "intent": "Return time object with same time and tzinfo .", "question_id": 10480},
{"snippet": "Timestamp.timetz()", "intent": "Return time object with same time and tzinfo .", "question_id": 10481},
{"snippet": "Timestamp.to_datetime64()", "intent": "Return a numpy.datetime64 object with \u2018 ns \u2019 precision .", "question_id": 10482},
{"snippet": "Timestamp.to_datetime64()", "intent": "Return a numpy.datetime64 object with \u2018 ns \u2019 precision .", "question_id": 10483},
{"snippet": "Timestamp.to_datetime64()", "intent": "Return a numpy.datetime64 object with \u2018 ns \u2019 precision .", "question_id": 10484},
{"snippet": "Timestamp.to_julian_date()", "intent": "Convert TimeStamp to a Julian Date .", "question_id": 10485},
{"snippet": "Timestamp.to_julian_date()", "intent": "Convert TimeStamp to a Julian Date .", "question_id": 10486},
{"snippet": "Timestamp.to_julian_date()", "intent": "Convert TimeStamp to a Julian Date .", "question_id": 10487},
{"snippet": "Timestamp.to_numpy()", "intent": "Convert the Timestamp to a NumPy datetime64 .", "question_id": 10488},
{"snippet": "Timestamp.to_numpy()", "intent": "Convert the Timestamp to a NumPy datetime64 .", "question_id": 10489},
{"snippet": "Timestamp.to_numpy()", "intent": "Convert the Timestamp to a NumPy datetime64 .", "question_id": 10490},
{"snippet": "Timestamp.to_period()", "intent": "Return an period of which this timestamp is an observation .", "question_id": 10491},
{"snippet": "Timestamp.to_period()", "intent": "Return an period of which this timestamp is an observation .", "question_id": 10492},
{"snippet": "Timestamp.to_period()", "intent": "Return an period of which this timestamp is an observation .", "question_id": 10493},
{"snippet": "Timestamp.to_pydatetime()", "intent": "Convert a Timestamp object to a native Python datetime object .", "question_id": 10494},
{"snippet": "Timestamp.to_pydatetime()", "intent": "Convert a Timestamp object to a native Python datetime object .", "question_id": 10495},
{"snippet": "Timestamp.to_pydatetime()", "intent": "Convert a Timestamp object to a native Python datetime object .", "question_id": 10496},
{"snippet": "Timestamp.today(cls)", "intent": "Return the current time in the local timezone . With arguments `cls`.", "question_id": 10497},
{"snippet": "Timestamp.today(cls, tz=None)", "intent": "Return the current time in the local timezone . With arguments `cls`, `tz`.", "question_id": 10498},
{"snippet": "Timestamp.today(cls)", "intent": "Return the current time in the local timezone . With arguments `cls`.", "question_id": 10499},
{"snippet": "Timestamp.today(cls, tz=None)", "intent": "Return the current time in the local timezone . With arguments `cls`, `tz`.", "question_id": 10500},
{"snippet": "Timestamp.today(cls)", "intent": "Return the current time in the local timezone . With arguments `cls`.", "question_id": 10501},
{"snippet": "Timestamp.today(cls, tz=None)", "intent": "Return the current time in the local timezone . With arguments `cls`, `tz`.", "question_id": 10502},
{"snippet": "Timestamp.toordinal()", "intent": "Return proleptic Gregorian ordinal .", "question_id": 10503},
{"snippet": "Timestamp.toordinal()", "intent": "Return proleptic Gregorian ordinal .", "question_id": 10504},
{"snippet": "Timestamp.toordinal()", "intent": "Return proleptic Gregorian ordinal .", "question_id": 10505},
{"snippet": "Timestamp.tz_convert(tz)", "intent": "Convert tz-aware Timestamp to another time zone . With arguments `tz`.", "question_id": 10506},
{"snippet": "Timestamp.tz_convert(tz)", "intent": "Convert tz-aware Timestamp to another time zone . With arguments `tz`.", "question_id": 10507},
{"snippet": "Timestamp.tz_convert(tz)", "intent": "Convert tz-aware Timestamp to another time zone . With arguments `tz`.", "question_id": 10508},
{"snippet": "Timestamp.tz_localize(tz)", "intent": "Convert naive Timestamp to local time zone , or remove timezone from tz-aware Timestamp . With arguments `tz`.", "question_id": 10509},
{"snippet": "Timestamp.tz_localize(tz, ambiguous='raise')", "intent": "Convert naive Timestamp to local time zone , or remove timezone from tz-aware Timestamp . With arguments `tz`, `ambiguous`.", "question_id": 10510},
{"snippet": "Timestamp.tz_localize(tz, nonexistent='raise')", "intent": "Convert naive Timestamp to local time zone , or remove timezone from tz-aware Timestamp . With arguments `tz`, `nonexistent`.", "question_id": 10511},
{"snippet": "Timestamp.tz_localize(tz, ambiguous='raise', nonexistent='raise')", "intent": "Convert naive Timestamp to local time zone , or remove timezone from tz-aware Timestamp . With arguments `tz`, `ambiguous`, `nonexistent`.", "question_id": 10512},
{"snippet": "Timestamp.tz_localize(tz)", "intent": "Convert naive Timestamp to local time zone , or remove timezone from tz-aware Timestamp . With arguments `tz`.", "question_id": 10513},
{"snippet": "Timestamp.tz_localize(tz, ambiguous='raise')", "intent": "Convert naive Timestamp to local time zone , or remove timezone from tz-aware Timestamp . With arguments `tz`, `ambiguous`.", "question_id": 10514},
{"snippet": "Timestamp.tz_localize(tz, nonexistent='raise')", "intent": "Convert naive Timestamp to local time zone , or remove timezone from tz-aware Timestamp . With arguments `tz`, `nonexistent`.", "question_id": 10515},
{"snippet": "Timestamp.tz_localize(tz, ambiguous='raise', nonexistent='raise')", "intent": "Convert naive Timestamp to local time zone , or remove timezone from tz-aware Timestamp . With arguments `tz`, `ambiguous`, `nonexistent`.", "question_id": 10516},
{"snippet": "Timestamp.tz_localize(tz)", "intent": "Convert naive Timestamp to local time zone , or remove timezone from tz-aware Timestamp . With arguments `tz`.", "question_id": 10517},
{"snippet": "Timestamp.tz_localize(tz, ambiguous='raise')", "intent": "Convert naive Timestamp to local time zone , or remove timezone from tz-aware Timestamp . With arguments `tz`, `ambiguous`.", "question_id": 10518},
{"snippet": "Timestamp.tz_localize(tz, nonexistent='raise')", "intent": "Convert naive Timestamp to local time zone , or remove timezone from tz-aware Timestamp . With arguments `tz`, `nonexistent`.", "question_id": 10519},
{"snippet": "Timestamp.tz_localize(tz, ambiguous='raise', nonexistent='raise')", "intent": "Convert naive Timestamp to local time zone , or remove timezone from tz-aware Timestamp . With arguments `tz`, `ambiguous`, `nonexistent`.", "question_id": 10520},
{"snippet": "Timestamp.tzname()", "intent": "Return self.tzinfo.tzname ( self ) .", "question_id": 10521},
{"snippet": "Timestamp.tzname()", "intent": "Return self.tzinfo.tzname ( self ) .", "question_id": 10522},
{"snippet": "Timestamp.tzname()", "intent": "Return self.tzinfo.tzname ( self ) .", "question_id": 10523},
{"snippet": "Timestamp.utcfromtimestamp(ts)", "intent": "Construct a naive UTC datetime from a POSIX timestamp . With arguments `ts`.", "question_id": 10524},
{"snippet": "Timestamp.utcfromtimestamp(ts)", "intent": "Construct a naive UTC datetime from a POSIX timestamp . With arguments `ts`.", "question_id": 10525},
{"snippet": "Timestamp.utcfromtimestamp(ts)", "intent": "Construct a naive UTC datetime from a POSIX timestamp . With arguments `ts`.", "question_id": 10526},
{"snippet": "Timestamp.utcnow()", "intent": "Return a new Timestamp representing UTC day and time .", "question_id": 10527},
{"snippet": "Timestamp.utcnow()", "intent": "Return a new Timestamp representing UTC day and time .", "question_id": 10528},
{"snippet": "Timestamp.utcnow()", "intent": "Return a new Timestamp representing UTC day and time .", "question_id": 10529},
{"snippet": "Timestamp.utcoffset()", "intent": "Return self.tzinfo.utcoffset ( self ) .", "question_id": 10530},
{"snippet": "Timestamp.utcoffset()", "intent": "Return self.tzinfo.utcoffset ( self ) .", "question_id": 10531},
{"snippet": "Timestamp.utcoffset()", "intent": "Return self.tzinfo.utcoffset ( self ) .", "question_id": 10532},
{"snippet": "Timestamp.utctimetuple()", "intent": "Return UTC time tuple , compatible with time.localtime ( ) .", "question_id": 10533},
{"snippet": "Timestamp.utctimetuple()", "intent": "Return UTC time tuple , compatible with time.localtime ( ) .", "question_id": 10534},
{"snippet": "Timestamp.utctimetuple()", "intent": "Return UTC time tuple , compatible with time.localtime ( ) .", "question_id": 10535},
{"snippet": "Timestamp.week", "intent": "Return the week number of the year.", "question_id": 10536},
{"snippet": "Timestamp.week", "intent": "Return the week number of the year.", "question_id": 10537},
{"snippet": "Timestamp.week", "intent": "Return the week number of the year.", "question_id": 10538},
{"snippet": "Timestamp.weekday()", "intent": "Return the day of the week represented by the date .", "question_id": 10539},
{"snippet": "Timestamp.weekday()", "intent": "Return the day of the week represented by the date .", "question_id": 10540},
{"snippet": "Timestamp.weekday()", "intent": "Return the day of the week represented by the date .", "question_id": 10541},
{"snippet": "Timestamp.weekofyear", "intent": "Return the week number of the year.", "question_id": 10542},
{"snippet": "Timestamp.weekofyear", "intent": "Return the week number of the year.", "question_id": 10543},
{"snippet": "Timestamp.weekofyear", "intent": "Return the week number of the year.", "question_id": 10544},
{"snippet": "pandas.UInt16Dtype", "intent": "An ExtensionDtype for uint16 integer data.", "question_id": 10545},
{"snippet": "pandas.UInt16Dtype", "intent": "An ExtensionDtype for uint16 integer data.", "question_id": 10546},
{"snippet": "pandas.UInt16Dtype", "intent": "An ExtensionDtype for uint16 integer data.", "question_id": 10547},
{"snippet": "pandas.UInt32Dtype", "intent": "An ExtensionDtype for uint32 integer data.", "question_id": 10548},
{"snippet": "pandas.UInt32Dtype", "intent": "An ExtensionDtype for uint32 integer data.", "question_id": 10549},
{"snippet": "pandas.UInt32Dtype", "intent": "An ExtensionDtype for uint32 integer data.", "question_id": 10550},
{"snippet": "pandas.UInt64Dtype", "intent": "An ExtensionDtype for uint64 integer data.", "question_id": 10551},
{"snippet": "pandas.UInt64Dtype", "intent": "An ExtensionDtype for uint64 integer data.", "question_id": 10552},
{"snippet": "pandas.UInt64Dtype", "intent": "An ExtensionDtype for uint64 integer data.", "question_id": 10553},
{"snippet": "pandas.UInt64Index()", "intent": "Immutable sequence used for indexing and alignment .", "question_id": 10554},
{"snippet": "pandas.UInt64Index(data=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`.", "question_id": 10555},
{"snippet": "pandas.UInt64Index(dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`.", "question_id": 10556},
{"snippet": "pandas.UInt64Index(copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `copy`.", "question_id": 10557},
{"snippet": "pandas.UInt64Index(name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `name`.", "question_id": 10558},
{"snippet": "pandas.UInt64Index(data=None, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `dtype`.", "question_id": 10559},
{"snippet": "pandas.UInt64Index(data=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `copy`.", "question_id": 10560},
{"snippet": "pandas.UInt64Index(data=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `name`.", "question_id": 10561},
{"snippet": "pandas.UInt64Index(dtype=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `copy`.", "question_id": 10562},
{"snippet": "pandas.UInt64Index(dtype=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `name`.", "question_id": 10563},
{"snippet": "pandas.UInt64Index()", "intent": "Immutable sequence used for indexing and alignment .", "question_id": 10564},
{"snippet": "pandas.UInt64Index(data=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`.", "question_id": 10565},
{"snippet": "pandas.UInt64Index(dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`.", "question_id": 10566},
{"snippet": "pandas.UInt64Index(copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `copy`.", "question_id": 10567},
{"snippet": "pandas.UInt64Index(name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `name`.", "question_id": 10568},
{"snippet": "pandas.UInt64Index(data=None, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `dtype`.", "question_id": 10569},
{"snippet": "pandas.UInt64Index(data=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `copy`.", "question_id": 10570},
{"snippet": "pandas.UInt64Index(data=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `name`.", "question_id": 10571},
{"snippet": "pandas.UInt64Index(dtype=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `copy`.", "question_id": 10572},
{"snippet": "pandas.UInt64Index(dtype=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `name`.", "question_id": 10573},
{"snippet": "pandas.UInt64Index()", "intent": "Immutable sequence used for indexing and alignment .", "question_id": 10574},
{"snippet": "pandas.UInt64Index(data=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`.", "question_id": 10575},
{"snippet": "pandas.UInt64Index(dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`.", "question_id": 10576},
{"snippet": "pandas.UInt64Index(copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `copy`.", "question_id": 10577},
{"snippet": "pandas.UInt64Index(name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `name`.", "question_id": 10578},
{"snippet": "pandas.UInt64Index(data=None, dtype=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `dtype`.", "question_id": 10579},
{"snippet": "pandas.UInt64Index(data=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `copy`.", "question_id": 10580},
{"snippet": "pandas.UInt64Index(data=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `data`, `name`.", "question_id": 10581},
{"snippet": "pandas.UInt64Index(dtype=None, copy=False)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `copy`.", "question_id": 10582},
{"snippet": "pandas.UInt64Index(dtype=None, name=None)", "intent": "Immutable sequence used for indexing and alignment . With arguments `dtype`, `name`.", "question_id": 10583},
{"snippet": "pandas.UInt8Dtype", "intent": "An ExtensionDtype for uint8 integer data.", "question_id": 10584},
{"snippet": "pandas.UInt8Dtype", "intent": "An ExtensionDtype for uint8 integer data.", "question_id": 10585},
{"snippet": "pandas.UInt8Dtype", "intent": "An ExtensionDtype for uint8 integer data.", "question_id": 10586},
{"snippet": "ExtensionArray._concat_same_type(to_concat)", "intent": "Concatenate multiple array of this dtype . With arguments `to_concat`.", "question_id": 10587},
{"snippet": "ExtensionArray._concat_same_type(to_concat)", "intent": "Concatenate multiple array of this dtype . With arguments `to_concat`.", "question_id": 10588},
{"snippet": "ExtensionArray._concat_same_type(to_concat)", "intent": "Concatenate multiple array of this dtype . With arguments `to_concat`.", "question_id": 10589},
{"snippet": "ExtensionArray._formatter()", "intent": "Formatting function for scalar values .", "question_id": 10590},
{"snippet": "ExtensionArray._formatter(boxed=False)", "intent": "Formatting function for scalar values . With arguments `boxed`.", "question_id": 10591},
{"snippet": "ExtensionArray._formatter()", "intent": "Formatting function for scalar values .", "question_id": 10592},
{"snippet": "ExtensionArray._formatter(boxed=False)", "intent": "Formatting function for scalar values . With arguments `boxed`.", "question_id": 10593},
{"snippet": "ExtensionArray._formatter()", "intent": "Formatting function for scalar values .", "question_id": 10594},
{"snippet": "ExtensionArray._formatter(boxed=False)", "intent": "Formatting function for scalar values . With arguments `boxed`.", "question_id": 10595},
{"snippet": "ExtensionArray._from_factorized(values, original)", "intent": "Reconstruct an ExtensionArray after factorization . With arguments `values`, `original`.", "question_id": 10596},
{"snippet": "ExtensionArray._from_factorized(values, original)", "intent": "Reconstruct an ExtensionArray after factorization . With arguments `values`, `original`.", "question_id": 10597},
{"snippet": "ExtensionArray._from_factorized(values, original)", "intent": "Reconstruct an ExtensionArray after factorization . With arguments `values`, `original`.", "question_id": 10598},
{"snippet": "ExtensionArray._from_sequence(scalars)", "intent": "Construct a new ExtensionArray from a sequence of `scalars` .", "question_id": 10599},
{"snippet": "ExtensionArray._from_sequence(scalars, dtype=None)", "intent": "Construct a new ExtensionArray from a sequence of `scalars` . With arguments `dtype`.", "question_id": 10600},
{"snippet": "ExtensionArray._from_sequence(scalars, copy=False)", "intent": "Construct a new ExtensionArray from a sequence of `scalars` . With arguments `copy`.", "question_id": 10601},
{"snippet": "ExtensionArray._from_sequence(scalars, dtype=None, copy=False)", "intent": "Construct a new ExtensionArray from a sequence of `scalars` . With arguments `dtype`, `copy`.", "question_id": 10602},
{"snippet": "ExtensionArray._from_sequence(scalars)", "intent": "Construct a new ExtensionArray from a sequence of `scalars` .", "question_id": 10603},
{"snippet": "ExtensionArray._from_sequence(scalars, dtype=None)", "intent": "Construct a new ExtensionArray from a sequence of `scalars` . With arguments `dtype`.", "question_id": 10604},
{"snippet": "ExtensionArray._from_sequence(scalars, copy=False)", "intent": "Construct a new ExtensionArray from a sequence of `scalars` . With arguments `copy`.", "question_id": 10605},
{"snippet": "ExtensionArray._from_sequence(scalars, dtype=None, copy=False)", "intent": "Construct a new ExtensionArray from a sequence of `scalars` . With arguments `dtype`, `copy`.", "question_id": 10606},
{"snippet": "ExtensionArray._from_sequence(scalars)", "intent": "Construct a new ExtensionArray from a sequence of `scalars` .", "question_id": 10607},
{"snippet": "ExtensionArray._from_sequence(scalars, dtype=None)", "intent": "Construct a new ExtensionArray from a sequence of `scalars` . With arguments `dtype`.", "question_id": 10608},
{"snippet": "ExtensionArray._from_sequence(scalars, copy=False)", "intent": "Construct a new ExtensionArray from a sequence of `scalars` . With arguments `copy`.", "question_id": 10609},
{"snippet": "ExtensionArray._from_sequence(scalars, dtype=None, copy=False)", "intent": "Construct a new ExtensionArray from a sequence of `scalars` . With arguments `dtype`, `copy`.", "question_id": 10610},
{"snippet": "ExtensionArray._from_sequence_of_strings(strings)", "intent": "Construct a new ExtensionArray from a sequence of `strings` .", "question_id": 10611},
{"snippet": "ExtensionArray._from_sequence_of_strings(strings, dtype=None)", "intent": "Construct a new ExtensionArray from a sequence of `strings` . With arguments `dtype`.", "question_id": 10612},
{"snippet": "ExtensionArray._from_sequence_of_strings(strings, copy=False)", "intent": "Construct a new ExtensionArray from a sequence of `strings` . With arguments `copy`.", "question_id": 10613},
{"snippet": "ExtensionArray._from_sequence_of_strings(strings, dtype=None, copy=False)", "intent": "Construct a new ExtensionArray from a sequence of `strings` . With arguments `dtype`, `copy`.", "question_id": 10614},
{"snippet": "ExtensionArray._from_sequence_of_strings(strings)", "intent": "Construct a new ExtensionArray from a sequence of `strings` .", "question_id": 10615},
{"snippet": "ExtensionArray._from_sequence_of_strings(strings, dtype=None)", "intent": "Construct a new ExtensionArray from a sequence of `strings` . With arguments `dtype`.", "question_id": 10616},
{"snippet": "ExtensionArray._from_sequence_of_strings(strings, copy=False)", "intent": "Construct a new ExtensionArray from a sequence of `strings` . With arguments `copy`.", "question_id": 10617},
{"snippet": "ExtensionArray._from_sequence_of_strings(strings, dtype=None, copy=False)", "intent": "Construct a new ExtensionArray from a sequence of `strings` . With arguments `dtype`, `copy`.", "question_id": 10618},
{"snippet": "ExtensionArray._from_sequence_of_strings(strings)", "intent": "Construct a new ExtensionArray from a sequence of `strings` .", "question_id": 10619},
{"snippet": "ExtensionArray._from_sequence_of_strings(strings, dtype=None)", "intent": "Construct a new ExtensionArray from a sequence of `strings` . With arguments `dtype`.", "question_id": 10620},
{"snippet": "ExtensionArray._from_sequence_of_strings(strings, copy=False)", "intent": "Construct a new ExtensionArray from a sequence of `strings` . With arguments `copy`.", "question_id": 10621},
{"snippet": "ExtensionArray._from_sequence_of_strings(strings, dtype=None, copy=False)", "intent": "Construct a new ExtensionArray from a sequence of `strings` . With arguments `dtype`, `copy`.", "question_id": 10622},
{"snippet": "ExtensionArray._reduce(name, **kwargs)", "intent": "Return a scalar result of performing the reduction operation . With arguments `name`, `**kwargs`.", "question_id": 10623},
{"snippet": "ExtensionArray._reduce(name, **kwargs, skipna=True)", "intent": "Return a scalar result of performing the reduction operation . With arguments `name`, `**kwargs`, `skipna`.", "question_id": 10624},
{"snippet": "ExtensionArray._reduce(name, **kwargs)", "intent": "Return a scalar result of performing the reduction operation . With arguments `name`, `**kwargs`.", "question_id": 10625},
{"snippet": "ExtensionArray._reduce(name, **kwargs, skipna=True)", "intent": "Return a scalar result of performing the reduction operation . With arguments `name`, `**kwargs`, `skipna`.", "question_id": 10626},
{"snippet": "ExtensionArray._reduce(name, **kwargs)", "intent": "Return a scalar result of performing the reduction operation . With arguments `name`, `**kwargs`.", "question_id": 10627},
{"snippet": "ExtensionArray._reduce(name, **kwargs, skipna=True)", "intent": "Return a scalar result of performing the reduction operation . With arguments `name`, `**kwargs`, `skipna`.", "question_id": 10628},
{"snippet": "ExtensionArray._values_for_argsort()", "intent": "Return values for sorting .", "question_id": 10629},
{"snippet": "ExtensionArray._values_for_argsort()", "intent": "Return values for sorting .", "question_id": 10630},
{"snippet": "ExtensionArray._values_for_argsort()", "intent": "Return values for sorting .", "question_id": 10631},
{"snippet": "ExtensionArray._values_for_factorize()", "intent": "Return an array and missing value suitable for factorization .", "question_id": 10632},
{"snippet": "ExtensionArray._values_for_factorize()", "intent": "Return an array and missing value suitable for factorization .", "question_id": 10633},
{"snippet": "ExtensionArray._values_for_factorize()", "intent": "Return an array and missing value suitable for factorization .", "question_id": 10634},
{"snippet": "ExtensionArray.argsort(*args, **kwargs)", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`.", "question_id": 10635},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, ascending=True)", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `ascending`.", "question_id": 10636},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, kind='quicksort')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `kind`.", "question_id": 10637},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, na_position='last')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `na_position`.", "question_id": 10638},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, ascending=True, kind='quicksort')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `ascending`, `kind`.", "question_id": 10639},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, ascending=True, na_position='last')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `ascending`, `na_position`.", "question_id": 10640},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, kind='quicksort', na_position='last')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `kind`, `na_position`.", "question_id": 10641},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, ascending=True, kind='quicksort', na_position='last')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `ascending`, `kind`, `na_position`.", "question_id": 10642},
{"snippet": "ExtensionArray.argsort(*args, **kwargs)", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`.", "question_id": 10643},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, ascending=True)", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `ascending`.", "question_id": 10644},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, kind='quicksort')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `kind`.", "question_id": 10645},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, na_position='last')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `na_position`.", "question_id": 10646},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, ascending=True, kind='quicksort')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `ascending`, `kind`.", "question_id": 10647},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, ascending=True, na_position='last')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `ascending`, `na_position`.", "question_id": 10648},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, kind='quicksort', na_position='last')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `kind`, `na_position`.", "question_id": 10649},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, ascending=True, kind='quicksort', na_position='last')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `ascending`, `kind`, `na_position`.", "question_id": 10650},
{"snippet": "ExtensionArray.argsort(*args, **kwargs)", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`.", "question_id": 10651},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, ascending=True)", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `ascending`.", "question_id": 10652},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, kind='quicksort')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `kind`.", "question_id": 10653},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, na_position='last')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `na_position`.", "question_id": 10654},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, ascending=True, kind='quicksort')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `ascending`, `kind`.", "question_id": 10655},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, ascending=True, na_position='last')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `ascending`, `na_position`.", "question_id": 10656},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, kind='quicksort', na_position='last')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `kind`, `na_position`.", "question_id": 10657},
{"snippet": "ExtensionArray.argsort(*args, **kwargs, ascending=True, kind='quicksort', na_position='last')", "intent": "Return the indices that would sort this array . With arguments `*args`, `**kwargs`, `ascending`, `kind`, `na_position`.", "question_id": 10658},
{"snippet": "ExtensionArray.astype(dtype)", "intent": "Cast to a NumPy array with \u2018 `dtype` \u2019 .", "question_id": 10659},
{"snippet": "ExtensionArray.astype(dtype, copy=True)", "intent": "Cast to a NumPy array with \u2018 `dtype` \u2019 . With arguments `copy`.", "question_id": 10660},
{"snippet": "ExtensionArray.astype(dtype)", "intent": "Cast to a NumPy array with \u2018 `dtype` \u2019 .", "question_id": 10661},
{"snippet": "ExtensionArray.astype(dtype, copy=True)", "intent": "Cast to a NumPy array with \u2018 `dtype` \u2019 . With arguments `copy`.", "question_id": 10662},
{"snippet": "ExtensionArray.astype(dtype)", "intent": "Cast to a NumPy array with \u2018 `dtype` \u2019 .", "question_id": 10663},
{"snippet": "ExtensionArray.astype(dtype, copy=True)", "intent": "Cast to a NumPy array with \u2018 `dtype` \u2019 . With arguments `copy`.", "question_id": 10664},
{"snippet": "ExtensionArray.copy()", "intent": "Return a copy of the array .", "question_id": 10665},
{"snippet": "ExtensionArray.copy()", "intent": "Return a copy of the array .", "question_id": 10666},
{"snippet": "ExtensionArray.copy()", "intent": "Return a copy of the array .", "question_id": 10667},
{"snippet": "ExtensionArray.dropna()", "intent": "Return ExtensionArray without NA values .", "question_id": 10668},
{"snippet": "ExtensionArray.dropna()", "intent": "Return ExtensionArray without NA values .", "question_id": 10669},
{"snippet": "ExtensionArray.dropna()", "intent": "Return ExtensionArray without NA values .", "question_id": 10670},
{"snippet": "ExtensionArray.equals(other)", "intent": "Return if another array is equivalent to this array . With arguments `other`.", "question_id": 10671},
{"snippet": "ExtensionArray.equals(other)", "intent": "Return if another array is equivalent to this array . With arguments `other`.", "question_id": 10672},
{"snippet": "ExtensionArray.equals(other)", "intent": "Return if another array is equivalent to this array . With arguments `other`.", "question_id": 10673},
{"snippet": "ExtensionArray.factorize()", "intent": "Encode the extension array as an enumerated type .", "question_id": 10674},
{"snippet": "ExtensionArray.factorize(na_sentinel=- 1)", "intent": "Encode the extension array as an enumerated type . With arguments `na_sentinel`.", "question_id": 10675},
{"snippet": "ExtensionArray.factorize()", "intent": "Encode the extension array as an enumerated type .", "question_id": 10676},
{"snippet": "ExtensionArray.factorize(na_sentinel=- 1)", "intent": "Encode the extension array as an enumerated type . With arguments `na_sentinel`.", "question_id": 10677},
{"snippet": "ExtensionArray.factorize()", "intent": "Encode the extension array as an enumerated type .", "question_id": 10678},
{"snippet": "ExtensionArray.factorize(na_sentinel=- 1)", "intent": "Encode the extension array as an enumerated type . With arguments `na_sentinel`.", "question_id": 10679},
{"snippet": "ExtensionArray.fillna()", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 10680},
{"snippet": "ExtensionArray.fillna(value=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 10681},
{"snippet": "ExtensionArray.fillna(method=None)", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 10682},
{"snippet": "ExtensionArray.fillna(limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `limit`.", "question_id": 10683},
{"snippet": "ExtensionArray.fillna(value=None, method=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 10684},
{"snippet": "ExtensionArray.fillna(value=None, limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `limit`.", "question_id": 10685},
{"snippet": "ExtensionArray.fillna(method=None, limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `limit`.", "question_id": 10686},
{"snippet": "ExtensionArray.fillna(value=None, method=None, limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `limit`.", "question_id": 10687},
{"snippet": "ExtensionArray.fillna()", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 10688},
{"snippet": "ExtensionArray.fillna(value=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 10689},
{"snippet": "ExtensionArray.fillna(method=None)", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 10690},
{"snippet": "ExtensionArray.fillna(limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `limit`.", "question_id": 10691},
{"snippet": "ExtensionArray.fillna(value=None, method=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 10692},
{"snippet": "ExtensionArray.fillna(value=None, limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `limit`.", "question_id": 10693},
{"snippet": "ExtensionArray.fillna(method=None, limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `limit`.", "question_id": 10694},
{"snippet": "ExtensionArray.fillna(value=None, method=None, limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `limit`.", "question_id": 10695},
{"snippet": "ExtensionArray.fillna()", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 10696},
{"snippet": "ExtensionArray.fillna(value=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 10697},
{"snippet": "ExtensionArray.fillna(method=None)", "intent": "Fill NA/NaN values using the specified `method` .", "question_id": 10698},
{"snippet": "ExtensionArray.fillna(limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `limit`.", "question_id": 10699},
{"snippet": "ExtensionArray.fillna(value=None, method=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`.", "question_id": 10700},
{"snippet": "ExtensionArray.fillna(value=None, limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `limit`.", "question_id": 10701},
{"snippet": "ExtensionArray.fillna(method=None, limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `limit`.", "question_id": 10702},
{"snippet": "ExtensionArray.fillna(value=None, method=None, limit=None)", "intent": "Fill NA/NaN values using the specified `method` . With arguments `value`, `limit`.", "question_id": 10703},
{"snippet": "pandas.api.extensions.ExtensionArray", "intent": "Abstract base class for custom 1-D array types.", "question_id": 10704},
{"snippet": "pandas.api.extensions.ExtensionArray", "intent": "Abstract base class for custom 1-D array types.", "question_id": 10705},
{"snippet": "pandas.api.extensions.ExtensionArray", "intent": "Abstract base class for custom 1-D array types.", "question_id": 10706},
{"snippet": "ExtensionArray.isin(values)", "intent": "Pointwise comparison for set containment in the given `values` .", "question_id": 10707},
{"snippet": "ExtensionArray.isin(values)", "intent": "Pointwise comparison for set containment in the given `values` .", "question_id": 10708},
{"snippet": "ExtensionArray.isin(values)", "intent": "Pointwise comparison for set containment in the given `values` .", "question_id": 10709},
{"snippet": "ExtensionArray.isna()", "intent": "A 1-D array indicating if each value is missing .", "question_id": 10710},
{"snippet": "ExtensionArray.isna()", "intent": "A 1-D array indicating if each value is missing .", "question_id": 10711},
{"snippet": "ExtensionArray.isna()", "intent": "A 1-D array indicating if each value is missing .", "question_id": 10712},
{"snippet": "ExtensionArray.ravel()", "intent": "Return a flattened view on this array .", "question_id": 10713},
{"snippet": "ExtensionArray.ravel(order='C')", "intent": "Return a flattened view on this array . With arguments `order`.", "question_id": 10714},
{"snippet": "ExtensionArray.ravel()", "intent": "Return a flattened view on this array .", "question_id": 10715},
{"snippet": "ExtensionArray.ravel(order='C')", "intent": "Return a flattened view on this array . With arguments `order`.", "question_id": 10716},
{"snippet": "ExtensionArray.ravel()", "intent": "Return a flattened view on this array .", "question_id": 10717},
{"snippet": "ExtensionArray.ravel(order='C')", "intent": "Return a flattened view on this array . With arguments `order`.", "question_id": 10718},
{"snippet": "ExtensionArray.repeat(repeats)", "intent": "Repeat elements of a ExtensionArray . With arguments `repeats`.", "question_id": 10719},
{"snippet": "ExtensionArray.repeat(repeats, axis=None)", "intent": "Repeat elements of a ExtensionArray . With arguments `repeats`, `axis`.", "question_id": 10720},
{"snippet": "ExtensionArray.repeat(repeats)", "intent": "Repeat elements of a ExtensionArray . With arguments `repeats`.", "question_id": 10721},
{"snippet": "ExtensionArray.repeat(repeats, axis=None)", "intent": "Repeat elements of a ExtensionArray . With arguments `repeats`, `axis`.", "question_id": 10722},
{"snippet": "ExtensionArray.repeat(repeats)", "intent": "Repeat elements of a ExtensionArray . With arguments `repeats`.", "question_id": 10723},
{"snippet": "ExtensionArray.repeat(repeats, axis=None)", "intent": "Repeat elements of a ExtensionArray . With arguments `repeats`, `axis`.", "question_id": 10724},
{"snippet": "ExtensionArray.searchsorted(value)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted array self ( a ) such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved .", "question_id": 10725},
{"snippet": "ExtensionArray.searchsorted(value, side='left')", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted array self ( a ) such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`.", "question_id": 10726},
{"snippet": "ExtensionArray.searchsorted(value, sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted array self ( a ) such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `sorter`.", "question_id": 10727},
{"snippet": "ExtensionArray.searchsorted(value, side='left', sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted array self ( a ) such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`, `sorter`.", "question_id": 10728},
{"snippet": "ExtensionArray.searchsorted(value)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted array self ( a ) such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved .", "question_id": 10729},
{"snippet": "ExtensionArray.searchsorted(value, side='left')", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted array self ( a ) such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`.", "question_id": 10730},
{"snippet": "ExtensionArray.searchsorted(value, sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted array self ( a ) such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `sorter`.", "question_id": 10731},
{"snippet": "ExtensionArray.searchsorted(value, side='left', sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted array self ( a ) such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`, `sorter`.", "question_id": 10732},
{"snippet": "ExtensionArray.searchsorted(value)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted array self ( a ) such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved .", "question_id": 10733},
{"snippet": "ExtensionArray.searchsorted(value, side='left')", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted array self ( a ) such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`.", "question_id": 10734},
{"snippet": "ExtensionArray.searchsorted(value, sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted array self ( a ) such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `sorter`.", "question_id": 10735},
{"snippet": "ExtensionArray.searchsorted(value, side='left', sorter=None)", "intent": "Find indices where elements should be inserted to maintain order . Find the indices into a sorted array self ( a ) such that , if the corresponding elements in `value` were inserted before the indices , the order of self would be preserved . With arguments `side`, `sorter`.", "question_id": 10736},
{"snippet": "ExtensionArray.shift()", "intent": "Shift values by desired number .", "question_id": 10737},
{"snippet": "ExtensionArray.shift(periods=1)", "intent": "Shift values by desired number . If self is empty or `periods` is 0 , a copy of self is returned .", "question_id": 10738},
{"snippet": "ExtensionArray.shift(fill_value=None)", "intent": "Shift values by desired number . With arguments `fill_value`.", "question_id": 10739},
{"snippet": "ExtensionArray.shift(periods=1, fill_value=None)", "intent": "Shift values by desired number . If self is empty or `periods` is 0 , a copy of self is returned . With arguments `fill_value`.", "question_id": 10740},
{"snippet": "ExtensionArray.shift()", "intent": "Shift values by desired number .", "question_id": 10741},
{"snippet": "ExtensionArray.shift(periods=1)", "intent": "Shift values by desired number . If self is empty or `periods` is 0 , a copy of self is returned .", "question_id": 10742},
{"snippet": "ExtensionArray.shift(fill_value=None)", "intent": "Shift values by desired number . With arguments `fill_value`.", "question_id": 10743},
{"snippet": "ExtensionArray.shift(periods=1, fill_value=None)", "intent": "Shift values by desired number . If self is empty or `periods` is 0 , a copy of self is returned . With arguments `fill_value`.", "question_id": 10744},
{"snippet": "ExtensionArray.shift()", "intent": "Shift values by desired number .", "question_id": 10745},
{"snippet": "ExtensionArray.shift(periods=1)", "intent": "Shift values by desired number . If self is empty or `periods` is 0 , a copy of self is returned .", "question_id": 10746},
{"snippet": "ExtensionArray.shift(fill_value=None)", "intent": "Shift values by desired number . With arguments `fill_value`.", "question_id": 10747},
{"snippet": "ExtensionArray.shift(periods=1, fill_value=None)", "intent": "Shift values by desired number . If self is empty or `periods` is 0 , a copy of self is returned . With arguments `fill_value`.", "question_id": 10748},
{"snippet": "ExtensionArray.take(indices)", "intent": "Take elements from an array . ExtensionArray.take is called by Series.__getitem__ , .loc , iloc , when `indices` is a sequence of values .", "question_id": 10749},
{"snippet": "ExtensionArray.take(indices, allow_fill=False)", "intent": "Take elements from an array . ExtensionArray.take is called by Series.__getitem__ , .loc , iloc , when `indices` is a sequence of values . With arguments `allow_fill`.", "question_id": 10750},
{"snippet": "ExtensionArray.take(indices, fill_value=None)", "intent": "Take elements from an array . ExtensionArray.take is called by Series.__getitem__ , .loc , iloc , when `indices` is a sequence of values . Additionally , it \u2019 s called by Series.reindex ( ) , or any other method that causes realignment , with a `fill_value` .", "question_id": 10751},
{"snippet": "ExtensionArray.take(indices, allow_fill=False, fill_value=None)", "intent": "Take elements from an array . ExtensionArray.take is called by Series.__getitem__ , .loc , iloc , when `indices` is a sequence of values . Additionally , it \u2019 s called by Series.reindex ( ) , or any other method that causes realignment , with a `fill_value` . With arguments `allow_fill`.", "question_id": 10752},
{"snippet": "ExtensionArray.take(indices)", "intent": "Take elements from an array . ExtensionArray.take is called by Series.__getitem__ , .loc , iloc , when `indices` is a sequence of values .", "question_id": 10753},
{"snippet": "ExtensionArray.take(indices, allow_fill=False)", "intent": "Take elements from an array . ExtensionArray.take is called by Series.__getitem__ , .loc , iloc , when `indices` is a sequence of values . With arguments `allow_fill`.", "question_id": 10754},
{"snippet": "ExtensionArray.take(indices, fill_value=None)", "intent": "Take elements from an array . ExtensionArray.take is called by Series.__getitem__ , .loc , iloc , when `indices` is a sequence of values . Additionally , it \u2019 s called by Series.reindex ( ) , or any other method that causes realignment , with a `fill_value` .", "question_id": 10755},
{"snippet": "ExtensionArray.take(indices, allow_fill=False, fill_value=None)", "intent": "Take elements from an array . ExtensionArray.take is called by Series.__getitem__ , .loc , iloc , when `indices` is a sequence of values . Additionally , it \u2019 s called by Series.reindex ( ) , or any other method that causes realignment , with a `fill_value` . With arguments `allow_fill`.", "question_id": 10756},
{"snippet": "ExtensionArray.take(indices)", "intent": "Take elements from an array . ExtensionArray.take is called by Series.__getitem__ , .loc , iloc , when `indices` is a sequence of values .", "question_id": 10757},
{"snippet": "ExtensionArray.take(indices, allow_fill=False)", "intent": "Take elements from an array . ExtensionArray.take is called by Series.__getitem__ , .loc , iloc , when `indices` is a sequence of values . With arguments `allow_fill`.", "question_id": 10758},
{"snippet": "ExtensionArray.take(indices, fill_value=None)", "intent": "Take elements from an array . ExtensionArray.take is called by Series.__getitem__ , .loc , iloc , when `indices` is a sequence of values . Additionally , it \u2019 s called by Series.reindex ( ) , or any other method that causes realignment , with a `fill_value` .", "question_id": 10759},
{"snippet": "ExtensionArray.take(indices, allow_fill=False, fill_value=None)", "intent": "Take elements from an array . ExtensionArray.take is called by Series.__getitem__ , .loc , iloc , when `indices` is a sequence of values . Additionally , it \u2019 s called by Series.reindex ( ) , or any other method that causes realignment , with a `fill_value` . With arguments `allow_fill`.", "question_id": 10760},
{"snippet": "ExtensionArray.unique()", "intent": "Compute the ExtensionArray of unique values .", "question_id": 10761},
{"snippet": "ExtensionArray.unique()", "intent": "Compute the ExtensionArray of unique values .", "question_id": 10762},
{"snippet": "ExtensionArray.unique()", "intent": "Compute the ExtensionArray of unique values .", "question_id": 10763},
{"snippet": "ExtensionArray.view()", "intent": "Return a view on the array .", "question_id": 10764},
{"snippet": "ExtensionArray.view(dtype=None)", "intent": "Return a view on the array . With arguments `dtype`.", "question_id": 10765},
{"snippet": "ExtensionArray.view()", "intent": "Return a view on the array .", "question_id": 10766},
{"snippet": "ExtensionArray.view(dtype=None)", "intent": "Return a view on the array . With arguments `dtype`.", "question_id": 10767},
{"snippet": "ExtensionArray.view()", "intent": "Return a view on the array .", "question_id": 10768},
{"snippet": "ExtensionArray.view(dtype=None)", "intent": "Return a view on the array . With arguments `dtype`.", "question_id": 10769},
{"snippet": "ExtensionDtype.construct_array_type()", "intent": "Return the array type associated with this dtype .", "question_id": 10770},
{"snippet": "ExtensionDtype.construct_array_type()", "intent": "Return the array type associated with this dtype .", "question_id": 10771},
{"snippet": "ExtensionDtype.construct_array_type()", "intent": "Return the array type associated with this dtype .", "question_id": 10772},
{"snippet": "ExtensionDtype.construct_from_string(string)", "intent": "Construct this type from a `string` .", "question_id": 10773},
{"snippet": "ExtensionDtype.construct_from_string(string)", "intent": "Construct this type from a `string` .", "question_id": 10774},
{"snippet": "ExtensionDtype.construct_from_string(string)", "intent": "Construct this type from a `string` .", "question_id": 10775},
{"snippet": "pandas.api.extensions.ExtensionDtype", "intent": "A custom data type, to be paired with an ExtensionArray.", "question_id": 10776},
{"snippet": "pandas.api.extensions.ExtensionDtype", "intent": "A custom data type, to be paired with an ExtensionArray.", "question_id": 10777},
{"snippet": "pandas.api.extensions.ExtensionDtype", "intent": "A custom data type, to be paired with an ExtensionArray.", "question_id": 10778},
{"snippet": "ExtensionDtype.is_dtype(dtype)", "intent": "Check if we match \u2018 `dtype` \u2019 .", "question_id": 10779},
{"snippet": "ExtensionDtype.is_dtype(dtype)", "intent": "Check if we match \u2018 `dtype` \u2019 .", "question_id": 10780},
{"snippet": "ExtensionDtype.is_dtype(dtype)", "intent": "Check if we match \u2018 `dtype` \u2019 .", "question_id": 10781},
{"snippet": "pandas.api.extensions.register_dataframe_accessor(name)", "intent": "Register a custom accessor on DataFrame objects . With arguments `name`.", "question_id": 10782},
{"snippet": "pandas.api.extensions.register_dataframe_accessor(name)", "intent": "Register a custom accessor on DataFrame objects . With arguments `name`.", "question_id": 10783},
{"snippet": "pandas.api.extensions.register_dataframe_accessor(name)", "intent": "Register a custom accessor on DataFrame objects . With arguments `name`.", "question_id": 10784},
{"snippet": "pandas.api.extensions.register_extension_dtype(cls)", "intent": "Register an ExtensionType with pandas as class decorator . With arguments `cls`.", "question_id": 10785},
{"snippet": "pandas.api.extensions.register_extension_dtype(cls)", "intent": "Register an ExtensionType with pandas as class decorator . With arguments `cls`.", "question_id": 10786},
{"snippet": "pandas.api.extensions.register_extension_dtype(cls)", "intent": "Register an ExtensionType with pandas as class decorator . With arguments `cls`.", "question_id": 10787},
{"snippet": "pandas.api.extensions.register_index_accessor(name)", "intent": "Register a custom accessor on Index objects . With arguments `name`.", "question_id": 10788},
{"snippet": "pandas.api.extensions.register_index_accessor(name)", "intent": "Register a custom accessor on Index objects . With arguments `name`.", "question_id": 10789},
{"snippet": "pandas.api.extensions.register_index_accessor(name)", "intent": "Register a custom accessor on Index objects . With arguments `name`.", "question_id": 10790},
{"snippet": "pandas.api.extensions.register_series_accessor(name)", "intent": "Register a custom accessor on Series objects . With arguments `name`.", "question_id": 10791},
{"snippet": "pandas.api.extensions.register_series_accessor(name)", "intent": "Register a custom accessor on Series objects . With arguments `name`.", "question_id": 10792},
{"snippet": "pandas.api.extensions.register_series_accessor(name)", "intent": "Register a custom accessor on Series objects . With arguments `name`.", "question_id": 10793},
{"snippet": "BaseIndexer.get_window_bounds()", "intent": "Computes the bounds of a window .", "question_id": 10794},
{"snippet": "BaseIndexer.get_window_bounds(num_values=0)", "intent": "Computes the bounds of a window . With arguments `num_values`.", "question_id": 10795},
{"snippet": "BaseIndexer.get_window_bounds(min_periods=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`.", "question_id": 10796},
{"snippet": "BaseIndexer.get_window_bounds(center=None)", "intent": "Computes the bounds of a window . With arguments `center`.", "question_id": 10797},
{"snippet": "BaseIndexer.get_window_bounds(closed=None)", "intent": "Computes the bounds of a window . With arguments `closed`.", "question_id": 10798},
{"snippet": "BaseIndexer.get_window_bounds(num_values=0, min_periods=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `min_periods`.", "question_id": 10799},
{"snippet": "BaseIndexer.get_window_bounds(num_values=0, center=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `center`.", "question_id": 10800},
{"snippet": "BaseIndexer.get_window_bounds(num_values=0, closed=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `closed`.", "question_id": 10801},
{"snippet": "BaseIndexer.get_window_bounds(min_periods=None, center=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `center`.", "question_id": 10802},
{"snippet": "BaseIndexer.get_window_bounds(min_periods=None, closed=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `closed`.", "question_id": 10803},
{"snippet": "BaseIndexer.get_window_bounds()", "intent": "Computes the bounds of a window .", "question_id": 10804},
{"snippet": "BaseIndexer.get_window_bounds(num_values=0)", "intent": "Computes the bounds of a window . With arguments `num_values`.", "question_id": 10805},
{"snippet": "BaseIndexer.get_window_bounds(min_periods=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`.", "question_id": 10806},
{"snippet": "BaseIndexer.get_window_bounds(center=None)", "intent": "Computes the bounds of a window . With arguments `center`.", "question_id": 10807},
{"snippet": "BaseIndexer.get_window_bounds(closed=None)", "intent": "Computes the bounds of a window . With arguments `closed`.", "question_id": 10808},
{"snippet": "BaseIndexer.get_window_bounds(num_values=0, min_periods=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `min_periods`.", "question_id": 10809},
{"snippet": "BaseIndexer.get_window_bounds(num_values=0, center=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `center`.", "question_id": 10810},
{"snippet": "BaseIndexer.get_window_bounds(num_values=0, closed=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `closed`.", "question_id": 10811},
{"snippet": "BaseIndexer.get_window_bounds(min_periods=None, center=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `center`.", "question_id": 10812},
{"snippet": "BaseIndexer.get_window_bounds(min_periods=None, closed=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `closed`.", "question_id": 10813},
{"snippet": "BaseIndexer.get_window_bounds()", "intent": "Computes the bounds of a window .", "question_id": 10814},
{"snippet": "BaseIndexer.get_window_bounds(num_values=0)", "intent": "Computes the bounds of a window . With arguments `num_values`.", "question_id": 10815},
{"snippet": "BaseIndexer.get_window_bounds(min_periods=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`.", "question_id": 10816},
{"snippet": "BaseIndexer.get_window_bounds(center=None)", "intent": "Computes the bounds of a window . With arguments `center`.", "question_id": 10817},
{"snippet": "BaseIndexer.get_window_bounds(closed=None)", "intent": "Computes the bounds of a window . With arguments `closed`.", "question_id": 10818},
{"snippet": "BaseIndexer.get_window_bounds(num_values=0, min_periods=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `min_periods`.", "question_id": 10819},
{"snippet": "BaseIndexer.get_window_bounds(num_values=0, center=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `center`.", "question_id": 10820},
{"snippet": "BaseIndexer.get_window_bounds(num_values=0, closed=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `closed`.", "question_id": 10821},
{"snippet": "BaseIndexer.get_window_bounds(min_periods=None, center=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `center`.", "question_id": 10822},
{"snippet": "BaseIndexer.get_window_bounds(min_periods=None, closed=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `closed`.", "question_id": 10823},
{"snippet": "pandas.api.indexers.BaseIndexer(**kwargs)", "intent": "Base class for window bounds calculations . With arguments `**kwargs`.", "question_id": 10824},
{"snippet": "pandas.api.indexers.BaseIndexer(**kwargs, index_array=None)", "intent": "Base class for window bounds calculations . With arguments `**kwargs`, `index_array`.", "question_id": 10825},
{"snippet": "pandas.api.indexers.BaseIndexer(**kwargs, window_size=0)", "intent": "Base class for window bounds calculations . With arguments `**kwargs`, `window_size`.", "question_id": 10826},
{"snippet": "pandas.api.indexers.BaseIndexer(**kwargs, index_array=None, window_size=0)", "intent": "Base class for window bounds calculations . With arguments `**kwargs`, `index_array`, `window_size`.", "question_id": 10827},
{"snippet": "pandas.api.indexers.BaseIndexer(**kwargs)", "intent": "Base class for window bounds calculations . With arguments `**kwargs`.", "question_id": 10828},
{"snippet": "pandas.api.indexers.BaseIndexer(**kwargs, index_array=None)", "intent": "Base class for window bounds calculations . With arguments `**kwargs`, `index_array`.", "question_id": 10829},
{"snippet": "pandas.api.indexers.BaseIndexer(**kwargs, window_size=0)", "intent": "Base class for window bounds calculations . With arguments `**kwargs`, `window_size`.", "question_id": 10830},
{"snippet": "pandas.api.indexers.BaseIndexer(**kwargs, index_array=None, window_size=0)", "intent": "Base class for window bounds calculations . With arguments `**kwargs`, `index_array`, `window_size`.", "question_id": 10831},
{"snippet": "pandas.api.indexers.BaseIndexer(**kwargs)", "intent": "Base class for window bounds calculations . With arguments `**kwargs`.", "question_id": 10832},
{"snippet": "pandas.api.indexers.BaseIndexer(**kwargs, index_array=None)", "intent": "Base class for window bounds calculations . With arguments `**kwargs`, `index_array`.", "question_id": 10833},
{"snippet": "pandas.api.indexers.BaseIndexer(**kwargs, window_size=0)", "intent": "Base class for window bounds calculations . With arguments `**kwargs`, `window_size`.", "question_id": 10834},
{"snippet": "pandas.api.indexers.BaseIndexer(**kwargs, index_array=None, window_size=0)", "intent": "Base class for window bounds calculations . With arguments `**kwargs`, `index_array`, `window_size`.", "question_id": 10835},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds()", "intent": "Computes the bounds of a window .", "question_id": 10836},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(num_values=0)", "intent": "Computes the bounds of a window . With arguments `num_values`.", "question_id": 10837},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(min_periods=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`.", "question_id": 10838},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(center=None)", "intent": "Computes the bounds of a window . With arguments `center`.", "question_id": 10839},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(closed=None)", "intent": "Computes the bounds of a window . With arguments `closed`.", "question_id": 10840},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(num_values=0, min_periods=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `min_periods`.", "question_id": 10841},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(num_values=0, center=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `center`.", "question_id": 10842},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(num_values=0, closed=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `closed`.", "question_id": 10843},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(min_periods=None, center=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `center`.", "question_id": 10844},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(min_periods=None, closed=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `closed`.", "question_id": 10845},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds()", "intent": "Computes the bounds of a window .", "question_id": 10846},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(num_values=0)", "intent": "Computes the bounds of a window . With arguments `num_values`.", "question_id": 10847},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(min_periods=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`.", "question_id": 10848},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(center=None)", "intent": "Computes the bounds of a window . With arguments `center`.", "question_id": 10849},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(closed=None)", "intent": "Computes the bounds of a window . With arguments `closed`.", "question_id": 10850},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(num_values=0, min_periods=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `min_periods`.", "question_id": 10851},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(num_values=0, center=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `center`.", "question_id": 10852},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(num_values=0, closed=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `closed`.", "question_id": 10853},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(min_periods=None, center=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `center`.", "question_id": 10854},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(min_periods=None, closed=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `closed`.", "question_id": 10855},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds()", "intent": "Computes the bounds of a window .", "question_id": 10856},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(num_values=0)", "intent": "Computes the bounds of a window . With arguments `num_values`.", "question_id": 10857},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(min_periods=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`.", "question_id": 10858},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(center=None)", "intent": "Computes the bounds of a window . With arguments `center`.", "question_id": 10859},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(closed=None)", "intent": "Computes the bounds of a window . With arguments `closed`.", "question_id": 10860},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(num_values=0, min_periods=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `min_periods`.", "question_id": 10861},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(num_values=0, center=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `center`.", "question_id": 10862},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(num_values=0, closed=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `closed`.", "question_id": 10863},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(min_periods=None, center=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `center`.", "question_id": 10864},
{"snippet": "FixedForwardWindowIndexer.get_window_bounds(min_periods=None, closed=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `closed`.", "question_id": 10865},
{"snippet": "pandas.api.indexers.FixedForwardWindowIndexer(**kwargs)", "intent": "Creates window boundaries for fixed-length windows that include the current row . With arguments `**kwargs`.", "question_id": 10866},
{"snippet": "pandas.api.indexers.FixedForwardWindowIndexer(**kwargs, index_array=None)", "intent": "Creates window boundaries for fixed-length windows that include the current row . With arguments `**kwargs`, `index_array`.", "question_id": 10867},
{"snippet": "pandas.api.indexers.FixedForwardWindowIndexer(**kwargs, window_size=0)", "intent": "Creates window boundaries for fixed-length windows that include the current row . With arguments `**kwargs`, `window_size`.", "question_id": 10868},
{"snippet": "pandas.api.indexers.FixedForwardWindowIndexer(**kwargs, index_array=None, window_size=0)", "intent": "Creates window boundaries for fixed-length windows that include the current row . With arguments `**kwargs`, `index_array`, `window_size`.", "question_id": 10869},
{"snippet": "pandas.api.indexers.FixedForwardWindowIndexer(**kwargs)", "intent": "Creates window boundaries for fixed-length windows that include the current row . With arguments `**kwargs`.", "question_id": 10870},
{"snippet": "pandas.api.indexers.FixedForwardWindowIndexer(**kwargs, index_array=None)", "intent": "Creates window boundaries for fixed-length windows that include the current row . With arguments `**kwargs`, `index_array`.", "question_id": 10871},
{"snippet": "pandas.api.indexers.FixedForwardWindowIndexer(**kwargs, window_size=0)", "intent": "Creates window boundaries for fixed-length windows that include the current row . With arguments `**kwargs`, `window_size`.", "question_id": 10872},
{"snippet": "pandas.api.indexers.FixedForwardWindowIndexer(**kwargs, index_array=None, window_size=0)", "intent": "Creates window boundaries for fixed-length windows that include the current row . With arguments `**kwargs`, `index_array`, `window_size`.", "question_id": 10873},
{"snippet": "pandas.api.indexers.FixedForwardWindowIndexer(**kwargs)", "intent": "Creates window boundaries for fixed-length windows that include the current row . With arguments `**kwargs`.", "question_id": 10874},
{"snippet": "pandas.api.indexers.FixedForwardWindowIndexer(**kwargs, index_array=None)", "intent": "Creates window boundaries for fixed-length windows that include the current row . With arguments `**kwargs`, `index_array`.", "question_id": 10875},
{"snippet": "pandas.api.indexers.FixedForwardWindowIndexer(**kwargs, window_size=0)", "intent": "Creates window boundaries for fixed-length windows that include the current row . With arguments `**kwargs`, `window_size`.", "question_id": 10876},
{"snippet": "pandas.api.indexers.FixedForwardWindowIndexer(**kwargs, index_array=None, window_size=0)", "intent": "Creates window boundaries for fixed-length windows that include the current row . With arguments `**kwargs`, `index_array`, `window_size`.", "question_id": 10877},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds()", "intent": "Computes the bounds of a window .", "question_id": 10878},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(num_values=0)", "intent": "Computes the bounds of a window . With arguments `num_values`.", "question_id": 10879},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(min_periods=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`.", "question_id": 10880},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(center=None)", "intent": "Computes the bounds of a window . With arguments `center`.", "question_id": 10881},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(closed=None)", "intent": "Computes the bounds of a window . With arguments `closed`.", "question_id": 10882},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(num_values=0, min_periods=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `min_periods`.", "question_id": 10883},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(num_values=0, center=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `center`.", "question_id": 10884},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(num_values=0, closed=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `closed`.", "question_id": 10885},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(min_periods=None, center=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `center`.", "question_id": 10886},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(min_periods=None, closed=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `closed`.", "question_id": 10887},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds()", "intent": "Computes the bounds of a window .", "question_id": 10888},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(num_values=0)", "intent": "Computes the bounds of a window . With arguments `num_values`.", "question_id": 10889},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(min_periods=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`.", "question_id": 10890},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(center=None)", "intent": "Computes the bounds of a window . With arguments `center`.", "question_id": 10891},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(closed=None)", "intent": "Computes the bounds of a window . With arguments `closed`.", "question_id": 10892},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(num_values=0, min_periods=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `min_periods`.", "question_id": 10893},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(num_values=0, center=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `center`.", "question_id": 10894},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(num_values=0, closed=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `closed`.", "question_id": 10895},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(min_periods=None, center=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `center`.", "question_id": 10896},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(min_periods=None, closed=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `closed`.", "question_id": 10897},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds()", "intent": "Computes the bounds of a window .", "question_id": 10898},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(num_values=0)", "intent": "Computes the bounds of a window . With arguments `num_values`.", "question_id": 10899},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(min_periods=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`.", "question_id": 10900},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(center=None)", "intent": "Computes the bounds of a window . With arguments `center`.", "question_id": 10901},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(closed=None)", "intent": "Computes the bounds of a window . With arguments `closed`.", "question_id": 10902},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(num_values=0, min_periods=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `min_periods`.", "question_id": 10903},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(num_values=0, center=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `center`.", "question_id": 10904},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(num_values=0, closed=None)", "intent": "Computes the bounds of a window . With arguments `num_values`, `closed`.", "question_id": 10905},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(min_periods=None, center=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `center`.", "question_id": 10906},
{"snippet": "VariableOffsetWindowIndexer.get_window_bounds(min_periods=None, closed=None)", "intent": "Computes the bounds of a window . With arguments `min_periods`, `closed`.", "question_id": 10907},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`.", "question_id": 10908},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index_array=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index_array`.", "question_id": 10909},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, window_size=0)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `window_size`.", "question_id": 10910},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index`.", "question_id": 10911},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, offset=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`.", "question_id": 10912},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index_array=None, window_size=0)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index_array`, `window_size`.", "question_id": 10913},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index_array=None, index=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index_array`, `index`.", "question_id": 10914},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index_array=None, offset=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index_array`.", "question_id": 10915},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, window_size=0, index=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `window_size`, `index`.", "question_id": 10916},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, window_size=0, offset=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `window_size`.", "question_id": 10917},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`.", "question_id": 10918},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index_array=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index_array`.", "question_id": 10919},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, window_size=0)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `window_size`.", "question_id": 10920},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index`.", "question_id": 10921},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, offset=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`.", "question_id": 10922},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index_array=None, window_size=0)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index_array`, `window_size`.", "question_id": 10923},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index_array=None, index=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index_array`, `index`.", "question_id": 10924},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index_array=None, offset=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index_array`.", "question_id": 10925},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, window_size=0, index=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `window_size`, `index`.", "question_id": 10926},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, window_size=0, offset=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `window_size`.", "question_id": 10927},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`.", "question_id": 10928},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index_array=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index_array`.", "question_id": 10929},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, window_size=0)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `window_size`.", "question_id": 10930},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index`.", "question_id": 10931},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, offset=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`.", "question_id": 10932},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index_array=None, window_size=0)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index_array`, `window_size`.", "question_id": 10933},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index_array=None, index=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index_array`, `index`.", "question_id": 10934},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, index_array=None, offset=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `index_array`.", "question_id": 10935},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, window_size=0, index=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `window_size`, `index`.", "question_id": 10936},
{"snippet": "pandas.api.indexers.VariableOffsetWindowIndexer(**kwargs, window_size=0, offset=None)", "intent": "Calculate window boundaries based on a non-fixed `offset` such as a BusinessDay With arguments `**kwargs`, `window_size`.", "question_id": 10937},
{"snippet": "pandas.api.indexers.check_array_indexer(array, indexer)", "intent": "Check if `indexer` is a valid `array` indexer for array .", "question_id": 10938},
{"snippet": "pandas.api.indexers.check_array_indexer(array, indexer)", "intent": "Check if `indexer` is a valid `array` indexer for array .", "question_id": 10939},
{"snippet": "pandas.api.indexers.check_array_indexer(array, indexer)", "intent": "Check if `indexer` is a valid `array` indexer for array .", "question_id": 10940},
{"snippet": "pandas.api.types.infer_dtype()", "intent": "Efficiently infer the type of a passed val , or list-like array of values .", "question_id": 10941},
{"snippet": "pandas.api.types.infer_dtype()", "intent": "Efficiently infer the type of a passed val , or list-like array of values .", "question_id": 10942},
{"snippet": "pandas.api.types.infer_dtype()", "intent": "Efficiently infer the type of a passed val , or list-like array of values .", "question_id": 10943},
{"snippet": "pandas.api.types.is_bool()", "intent": "Return True if given object is boolean .", "question_id": 10944},
{"snippet": "pandas.api.types.is_bool()", "intent": "Return True if given object is boolean .", "question_id": 10945},
{"snippet": "pandas.api.types.is_bool()", "intent": "Return True if given object is boolean .", "question_id": 10946},
{"snippet": "pandas.api.types.is_bool_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a boolean dtype . With arguments `arr_or_dtype`.", "question_id": 10947},
{"snippet": "pandas.api.types.is_bool_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a boolean dtype . With arguments `arr_or_dtype`.", "question_id": 10948},
{"snippet": "pandas.api.types.is_bool_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a boolean dtype . With arguments `arr_or_dtype`.", "question_id": 10949},
{"snippet": "pandas.api.types.is_categorical(arr)", "intent": "Check whether an array-like is a Categorical instance . With arguments `arr`.", "question_id": 10950},
{"snippet": "pandas.api.types.is_categorical(arr)", "intent": "Check whether an array-like is a Categorical instance . With arguments `arr`.", "question_id": 10951},
{"snippet": "pandas.api.types.is_categorical(arr)", "intent": "Check whether an array-like is a Categorical instance . With arguments `arr`.", "question_id": 10952},
{"snippet": "pandas.api.types.is_categorical_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the Categorical dtype . With arguments `arr_or_dtype`.", "question_id": 10953},
{"snippet": "pandas.api.types.is_categorical_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the Categorical dtype . With arguments `arr_or_dtype`.", "question_id": 10954},
{"snippet": "pandas.api.types.is_categorical_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the Categorical dtype . With arguments `arr_or_dtype`.", "question_id": 10955},
{"snippet": "pandas.api.types.is_complex()", "intent": "Return True if given object is complex .", "question_id": 10956},
{"snippet": "pandas.api.types.is_complex()", "intent": "Return True if given object is complex .", "question_id": 10957},
{"snippet": "pandas.api.types.is_complex()", "intent": "Return True if given object is complex .", "question_id": 10958},
{"snippet": "pandas.api.types.is_complex_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a complex dtype . With arguments `arr_or_dtype`.", "question_id": 10959},
{"snippet": "pandas.api.types.is_complex_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a complex dtype . With arguments `arr_or_dtype`.", "question_id": 10960},
{"snippet": "pandas.api.types.is_complex_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a complex dtype . With arguments `arr_or_dtype`.", "question_id": 10961},
{"snippet": "pandas.api.types.is_datetime64_any_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the datetime64 dtype . With arguments `arr_or_dtype`.", "question_id": 10962},
{"snippet": "pandas.api.types.is_datetime64_any_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the datetime64 dtype . With arguments `arr_or_dtype`.", "question_id": 10963},
{"snippet": "pandas.api.types.is_datetime64_any_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the datetime64 dtype . With arguments `arr_or_dtype`.", "question_id": 10964},
{"snippet": "pandas.api.types.is_datetime64_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the datetime64 dtype . With arguments `arr_or_dtype`.", "question_id": 10965},
{"snippet": "pandas.api.types.is_datetime64_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the datetime64 dtype . With arguments `arr_or_dtype`.", "question_id": 10966},
{"snippet": "pandas.api.types.is_datetime64_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the datetime64 dtype . With arguments `arr_or_dtype`.", "question_id": 10967},
{"snippet": "pandas.api.types.is_datetime64_ns_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the datetime64 [ ns ] dtype . With arguments `arr_or_dtype`.", "question_id": 10968},
{"snippet": "pandas.api.types.is_datetime64_ns_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the datetime64 [ ns ] dtype . With arguments `arr_or_dtype`.", "question_id": 10969},
{"snippet": "pandas.api.types.is_datetime64_ns_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the datetime64 [ ns ] dtype . With arguments `arr_or_dtype`.", "question_id": 10970},
{"snippet": "pandas.api.types.is_datetime64tz_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of a DatetimeTZDtype dtype . With arguments `arr_or_dtype`.", "question_id": 10971},
{"snippet": "pandas.api.types.is_datetime64tz_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of a DatetimeTZDtype dtype . With arguments `arr_or_dtype`.", "question_id": 10972},
{"snippet": "pandas.api.types.is_datetime64tz_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of a DatetimeTZDtype dtype . With arguments `arr_or_dtype`.", "question_id": 10973},
{"snippet": "pandas.api.types.is_dict_like(obj)", "intent": "Check if the object is dict-like . With arguments `obj`.", "question_id": 10974},
{"snippet": "pandas.api.types.is_dict_like(obj)", "intent": "Check if the object is dict-like . With arguments `obj`.", "question_id": 10975},
{"snippet": "pandas.api.types.is_dict_like(obj)", "intent": "Check if the object is dict-like . With arguments `obj`.", "question_id": 10976},
{"snippet": "pandas.api.types.is_extension_array_dtype(arr_or_dtype)", "intent": "Check if an object is a pandas extension array type . With arguments `arr_or_dtype`.", "question_id": 10977},
{"snippet": "pandas.api.types.is_extension_array_dtype(arr_or_dtype)", "intent": "Check if an object is a pandas extension array type . With arguments `arr_or_dtype`.", "question_id": 10978},
{"snippet": "pandas.api.types.is_extension_array_dtype(arr_or_dtype)", "intent": "Check if an object is a pandas extension array type . With arguments `arr_or_dtype`.", "question_id": 10979},
{"snippet": "pandas.api.types.is_extension_type(arr)", "intent": "Check whether an array-like is of a pandas extension class instance . With arguments `arr`.", "question_id": 10980},
{"snippet": "pandas.api.types.is_extension_type(arr)", "intent": "Check whether an array-like is of a pandas extension class instance . With arguments `arr`.", "question_id": 10981},
{"snippet": "pandas.api.types.is_extension_type(arr)", "intent": "Check whether an array-like is of a pandas extension class instance . With arguments `arr`.", "question_id": 10982},
{"snippet": "pandas.api.types.is_file_like(obj)", "intent": "Check if the object is a file-like object . With arguments `obj`.", "question_id": 10983},
{"snippet": "pandas.api.types.is_file_like(obj)", "intent": "Check if the object is a file-like object . With arguments `obj`.", "question_id": 10984},
{"snippet": "pandas.api.types.is_file_like(obj)", "intent": "Check if the object is a file-like object . With arguments `obj`.", "question_id": 10985},
{"snippet": "pandas.api.types.is_float()", "intent": "Return True if given object is float .", "question_id": 10986},
{"snippet": "pandas.api.types.is_float()", "intent": "Return True if given object is float .", "question_id": 10987},
{"snippet": "pandas.api.types.is_float()", "intent": "Return True if given object is float .", "question_id": 10988},
{"snippet": "pandas.api.types.is_float_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a float dtype . With arguments `arr_or_dtype`.", "question_id": 10989},
{"snippet": "pandas.api.types.is_float_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a float dtype . With arguments `arr_or_dtype`.", "question_id": 10990},
{"snippet": "pandas.api.types.is_float_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a float dtype . With arguments `arr_or_dtype`.", "question_id": 10991},
{"snippet": "pandas.api.types.is_hashable(obj)", "intent": "Return True if hash ( `obj` ) will succeed , False otherwise .", "question_id": 10992},
{"snippet": "pandas.api.types.is_hashable(obj)", "intent": "Return True if hash ( `obj` ) will succeed , False otherwise .", "question_id": 10993},
{"snippet": "pandas.api.types.is_hashable(obj)", "intent": "Return True if hash ( `obj` ) will succeed , False otherwise .", "question_id": 10994},
{"snippet": "pandas.api.types.is_int64_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the int64 dtype . With arguments `arr_or_dtype`.", "question_id": 10995},
{"snippet": "pandas.api.types.is_int64_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the int64 dtype . With arguments `arr_or_dtype`.", "question_id": 10996},
{"snippet": "pandas.api.types.is_int64_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the int64 dtype . With arguments `arr_or_dtype`.", "question_id": 10997},
{"snippet": "pandas.api.types.is_integer()", "intent": "Return True if given object is integer .", "question_id": 10998},
{"snippet": "pandas.api.types.is_integer()", "intent": "Return True if given object is integer .", "question_id": 10999},
{"snippet": "pandas.api.types.is_integer()", "intent": "Return True if given object is integer .", "question_id": 11000},
{"snippet": "pandas.api.types.is_integer_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of an integer dtype . With arguments `arr_or_dtype`.", "question_id": 11001},
{"snippet": "pandas.api.types.is_integer_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of an integer dtype . With arguments `arr_or_dtype`.", "question_id": 11002},
{"snippet": "pandas.api.types.is_integer_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of an integer dtype . With arguments `arr_or_dtype`.", "question_id": 11003},
{"snippet": "pandas.api.types.is_interval_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the Interval dtype . With arguments `arr_or_dtype`.", "question_id": 11004},
{"snippet": "pandas.api.types.is_interval_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the Interval dtype . With arguments `arr_or_dtype`.", "question_id": 11005},
{"snippet": "pandas.api.types.is_interval_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the Interval dtype . With arguments `arr_or_dtype`.", "question_id": 11006},
{"snippet": "pandas.api.types.is_iterator()", "intent": "Check if the object is an iterator .", "question_id": 11007},
{"snippet": "pandas.api.types.is_iterator()", "intent": "Check if the object is an iterator .", "question_id": 11008},
{"snippet": "pandas.api.types.is_iterator()", "intent": "Check if the object is an iterator .", "question_id": 11009},
{"snippet": "pandas.api.types.is_list_like()", "intent": "Check if the object is list-like .", "question_id": 11010},
{"snippet": "pandas.api.types.is_list_like()", "intent": "Check if the object is list-like .", "question_id": 11011},
{"snippet": "pandas.api.types.is_list_like()", "intent": "Check if the object is list-like .", "question_id": 11012},
{"snippet": "pandas.api.types.is_named_tuple(obj)", "intent": "Check if the object is a named tuple . With arguments `obj`.", "question_id": 11013},
{"snippet": "pandas.api.types.is_named_tuple(obj)", "intent": "Check if the object is a named tuple . With arguments `obj`.", "question_id": 11014},
{"snippet": "pandas.api.types.is_named_tuple(obj)", "intent": "Check if the object is a named tuple . With arguments `obj`.", "question_id": 11015},
{"snippet": "pandas.api.types.is_number(obj)", "intent": "Check if the object is a number . With arguments `obj`.", "question_id": 11016},
{"snippet": "pandas.api.types.is_number(obj)", "intent": "Check if the object is a number . With arguments `obj`.", "question_id": 11017},
{"snippet": "pandas.api.types.is_number(obj)", "intent": "Check if the object is a number . With arguments `obj`.", "question_id": 11018},
{"snippet": "pandas.api.types.is_numeric_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a numeric dtype . With arguments `arr_or_dtype`.", "question_id": 11019},
{"snippet": "pandas.api.types.is_numeric_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a numeric dtype . With arguments `arr_or_dtype`.", "question_id": 11020},
{"snippet": "pandas.api.types.is_numeric_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a numeric dtype . With arguments `arr_or_dtype`.", "question_id": 11021},
{"snippet": "pandas.api.types.is_object_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the object dtype . With arguments `arr_or_dtype`.", "question_id": 11022},
{"snippet": "pandas.api.types.is_object_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the object dtype . With arguments `arr_or_dtype`.", "question_id": 11023},
{"snippet": "pandas.api.types.is_object_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the object dtype . With arguments `arr_or_dtype`.", "question_id": 11024},
{"snippet": "pandas.api.types.is_period_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the Period dtype . With arguments `arr_or_dtype`.", "question_id": 11025},
{"snippet": "pandas.api.types.is_period_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the Period dtype . With arguments `arr_or_dtype`.", "question_id": 11026},
{"snippet": "pandas.api.types.is_period_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the Period dtype . With arguments `arr_or_dtype`.", "question_id": 11027},
{"snippet": "pandas.api.types.is_re(obj)", "intent": "Check if the object is a regex pattern instance . With arguments `obj`.", "question_id": 11028},
{"snippet": "pandas.api.types.is_re(obj)", "intent": "Check if the object is a regex pattern instance . With arguments `obj`.", "question_id": 11029},
{"snippet": "pandas.api.types.is_re(obj)", "intent": "Check if the object is a regex pattern instance . With arguments `obj`.", "question_id": 11030},
{"snippet": "pandas.api.types.is_re_compilable(obj)", "intent": "Check if the object can be compiled into a regex pattern instance . With arguments `obj`.", "question_id": 11031},
{"snippet": "pandas.api.types.is_re_compilable(obj)", "intent": "Check if the object can be compiled into a regex pattern instance . With arguments `obj`.", "question_id": 11032},
{"snippet": "pandas.api.types.is_re_compilable(obj)", "intent": "Check if the object can be compiled into a regex pattern instance . With arguments `obj`.", "question_id": 11033},
{"snippet": "pandas.api.types.is_scalar()", "intent": "Return True if given object is scalar .", "question_id": 11034},
{"snippet": "pandas.api.types.is_scalar()", "intent": "Return True if given object is scalar .", "question_id": 11035},
{"snippet": "pandas.api.types.is_scalar()", "intent": "Return True if given object is scalar .", "question_id": 11036},
{"snippet": "pandas.api.types.is_signed_integer_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a signed integer dtype . With arguments `arr_or_dtype`.", "question_id": 11037},
{"snippet": "pandas.api.types.is_signed_integer_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a signed integer dtype . With arguments `arr_or_dtype`.", "question_id": 11038},
{"snippet": "pandas.api.types.is_signed_integer_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of a signed integer dtype . With arguments `arr_or_dtype`.", "question_id": 11039},
{"snippet": "pandas.api.types.is_sparse(arr)", "intent": "Check whether an array-like is a 1-D pandas sparse array . With arguments `arr`.", "question_id": 11040},
{"snippet": "pandas.api.types.is_sparse(arr)", "intent": "Check whether an array-like is a 1-D pandas sparse array . With arguments `arr`.", "question_id": 11041},
{"snippet": "pandas.api.types.is_sparse(arr)", "intent": "Check whether an array-like is a 1-D pandas sparse array . With arguments `arr`.", "question_id": 11042},
{"snippet": "pandas.api.types.is_string_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the string dtype . With arguments `arr_or_dtype`.", "question_id": 11043},
{"snippet": "pandas.api.types.is_string_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the string dtype . With arguments `arr_or_dtype`.", "question_id": 11044},
{"snippet": "pandas.api.types.is_string_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the string dtype . With arguments `arr_or_dtype`.", "question_id": 11045},
{"snippet": "pandas.api.types.is_timedelta64_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the timedelta64 dtype . With arguments `arr_or_dtype`.", "question_id": 11046},
{"snippet": "pandas.api.types.is_timedelta64_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the timedelta64 dtype . With arguments `arr_or_dtype`.", "question_id": 11047},
{"snippet": "pandas.api.types.is_timedelta64_dtype(arr_or_dtype)", "intent": "Check whether an array-like or dtype is of the timedelta64 dtype . With arguments `arr_or_dtype`.", "question_id": 11048},
{"snippet": "pandas.api.types.is_timedelta64_ns_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the timedelta64 [ ns ] dtype . With arguments `arr_or_dtype`.", "question_id": 11049},
{"snippet": "pandas.api.types.is_timedelta64_ns_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the timedelta64 [ ns ] dtype . With arguments `arr_or_dtype`.", "question_id": 11050},
{"snippet": "pandas.api.types.is_timedelta64_ns_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of the timedelta64 [ ns ] dtype . With arguments `arr_or_dtype`.", "question_id": 11051},
{"snippet": "pandas.api.types.is_unsigned_integer_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of an unsigned integer dtype . With arguments `arr_or_dtype`.", "question_id": 11052},
{"snippet": "pandas.api.types.is_unsigned_integer_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of an unsigned integer dtype . With arguments `arr_or_dtype`.", "question_id": 11053},
{"snippet": "pandas.api.types.is_unsigned_integer_dtype(arr_or_dtype)", "intent": "Check whether the provided array or dtype is of an unsigned integer dtype . With arguments `arr_or_dtype`.", "question_id": 11054},
{"snippet": "pandas.api.types.pandas_dtype(dtype)", "intent": "Convert input into a pandas only `dtype` object or a numpy dtype object .", "question_id": 11055},
{"snippet": "pandas.api.types.pandas_dtype(dtype)", "intent": "Convert input into a pandas only `dtype` object or a numpy dtype object .", "question_id": 11056},
{"snippet": "pandas.api.types.pandas_dtype(dtype)", "intent": "Convert input into a pandas only `dtype` object or a numpy dtype object .", "question_id": 11057},
{"snippet": "pandas.api.types.union_categoricals(to_union)", "intent": "Combine list-like of Categorical-like , unioning categories . With arguments `to_union`.", "question_id": 11058},
{"snippet": "pandas.api.types.union_categoricals(to_union, sort_categories=False)", "intent": "Combine list-like of Categorical-like , unioning categories . With arguments `to_union`, `sort_categories`.", "question_id": 11059},
{"snippet": "pandas.api.types.union_categoricals(to_union, ignore_order=False)", "intent": "Combine list-like of Categorical-like , unioning categories . With arguments `to_union`, `ignore_order`.", "question_id": 11060},
{"snippet": "pandas.api.types.union_categoricals(to_union, sort_categories=False, ignore_order=False)", "intent": "Combine list-like of Categorical-like , unioning categories . With arguments `to_union`, `sort_categories`, `ignore_order`.", "question_id": 11061},
{"snippet": "pandas.api.types.union_categoricals(to_union)", "intent": "Combine list-like of Categorical-like , unioning categories . With arguments `to_union`.", "question_id": 11062},
{"snippet": "pandas.api.types.union_categoricals(to_union, sort_categories=False)", "intent": "Combine list-like of Categorical-like , unioning categories . With arguments `to_union`, `sort_categories`.", "question_id": 11063},
{"snippet": "pandas.api.types.union_categoricals(to_union, ignore_order=False)", "intent": "Combine list-like of Categorical-like , unioning categories . With arguments `to_union`, `ignore_order`.", "question_id": 11064},
{"snippet": "pandas.api.types.union_categoricals(to_union, sort_categories=False, ignore_order=False)", "intent": "Combine list-like of Categorical-like , unioning categories . With arguments `to_union`, `sort_categories`, `ignore_order`.", "question_id": 11065},
{"snippet": "pandas.api.types.union_categoricals(to_union)", "intent": "Combine list-like of Categorical-like , unioning categories . With arguments `to_union`.", "question_id": 11066},
{"snippet": "pandas.api.types.union_categoricals(to_union, sort_categories=False)", "intent": "Combine list-like of Categorical-like , unioning categories . With arguments `to_union`, `sort_categories`.", "question_id": 11067},
{"snippet": "pandas.api.types.union_categoricals(to_union, ignore_order=False)", "intent": "Combine list-like of Categorical-like , unioning categories . With arguments `to_union`, `ignore_order`.", "question_id": 11068},
{"snippet": "pandas.api.types.union_categoricals(to_union, sort_categories=False, ignore_order=False)", "intent": "Combine list-like of Categorical-like , unioning categories . With arguments `to_union`, `sort_categories`, `ignore_order`.", "question_id": 11069},
{"snippet": "pandas.array(data)", "intent": "Create an array . Omitting the `dtype` argument means pandas will attempt to infer the best array type from the values in the `data` .", "question_id": 11070},
{"snippet": "pandas.array(data, dtype=None)", "intent": "Create an array . Omitting the `dtype` argument means pandas will attempt to infer the best array type from the values in the `data` .", "question_id": 11071},
{"snippet": "pandas.array(data, copy=True)", "intent": "Create an array . Omitting the `dtype` argument means pandas will attempt to infer the best array type from the values in the `data` . With arguments `copy`.", "question_id": 11072},
{"snippet": "pandas.array(data, dtype=None, copy=True)", "intent": "Create an array . Omitting the `dtype` argument means pandas will attempt to infer the best array type from the values in the `data` . With arguments `copy`.", "question_id": 11073},
{"snippet": "pandas.array(data)", "intent": "Create an array . Omitting the `dtype` argument means pandas will attempt to infer the best array type from the values in the `data` .", "question_id": 11074},
{"snippet": "pandas.array(data, dtype=None)", "intent": "Create an array . Omitting the `dtype` argument means pandas will attempt to infer the best array type from the values in the `data` .", "question_id": 11075},
{"snippet": "pandas.array(data, copy=True)", "intent": "Create an array . Omitting the `dtype` argument means pandas will attempt to infer the best array type from the values in the `data` . With arguments `copy`.", "question_id": 11076},
{"snippet": "pandas.array(data, dtype=None, copy=True)", "intent": "Create an array . Omitting the `dtype` argument means pandas will attempt to infer the best array type from the values in the `data` . With arguments `copy`.", "question_id": 11077},
{"snippet": "pandas.array(data)", "intent": "Create an array . Omitting the `dtype` argument means pandas will attempt to infer the best array type from the values in the `data` .", "question_id": 11078},
{"snippet": "pandas.array(data, dtype=None)", "intent": "Create an array . Omitting the `dtype` argument means pandas will attempt to infer the best array type from the values in the `data` .", "question_id": 11079},
{"snippet": "pandas.array(data, copy=True)", "intent": "Create an array . Omitting the `dtype` argument means pandas will attempt to infer the best array type from the values in the `data` . With arguments `copy`.", "question_id": 11080},
{"snippet": "pandas.array(data, dtype=None, copy=True)", "intent": "Create an array . Omitting the `dtype` argument means pandas will attempt to infer the best array type from the values in the `data` . With arguments `copy`.", "question_id": 11081},
{"snippet": "pandas.arrays.ArrowStringArray(values)", "intent": "Extension array for string data in a pyarrow.ChunkedArray . With arguments `values`.", "question_id": 11082},
{"snippet": "pandas.arrays.ArrowStringArray(values)", "intent": "Extension array for string data in a pyarrow.ChunkedArray . With arguments `values`.", "question_id": 11083},
{"snippet": "pandas.arrays.ArrowStringArray(values)", "intent": "Extension array for string data in a pyarrow.ChunkedArray . With arguments `values`.", "question_id": 11084},
{"snippet": "pandas.arrays.BooleanArray(values, mask)", "intent": "Array of boolean ( True/False ) data with missing `values` . This is a pandas Extension array for boolean data , under the hood represented by 2 numpy arrays : a boolean array with the data and a boolean array with the `mask` ( True indicating missing ) .", "question_id": 11085},
{"snippet": "pandas.arrays.BooleanArray(values, mask, copy=False)", "intent": "Array of boolean ( True/False ) data with missing `values` . This is a pandas Extension array for boolean data , under the hood represented by 2 numpy arrays : a boolean array with the data and a boolean array with the `mask` ( True indicating missing ) . With arguments `copy`.", "question_id": 11086},
{"snippet": "pandas.arrays.BooleanArray(values, mask)", "intent": "Array of boolean ( True/False ) data with missing `values` . This is a pandas Extension array for boolean data , under the hood represented by 2 numpy arrays : a boolean array with the data and a boolean array with the `mask` ( True indicating missing ) .", "question_id": 11087},
{"snippet": "pandas.arrays.BooleanArray(values, mask, copy=False)", "intent": "Array of boolean ( True/False ) data with missing `values` . This is a pandas Extension array for boolean data , under the hood represented by 2 numpy arrays : a boolean array with the data and a boolean array with the `mask` ( True indicating missing ) . With arguments `copy`.", "question_id": 11088},
{"snippet": "pandas.arrays.BooleanArray(values, mask)", "intent": "Array of boolean ( True/False ) data with missing `values` . This is a pandas Extension array for boolean data , under the hood represented by 2 numpy arrays : a boolean array with the data and a boolean array with the `mask` ( True indicating missing ) .", "question_id": 11089},
{"snippet": "pandas.arrays.BooleanArray(values, mask, copy=False)", "intent": "Array of boolean ( True/False ) data with missing `values` . This is a pandas Extension array for boolean data , under the hood represented by 2 numpy arrays : a boolean array with the data and a boolean array with the `mask` ( True indicating missing ) . With arguments `copy`.", "question_id": 11090},
{"snippet": "pandas.arrays.DatetimeArray(values)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`.", "question_id": 11091},
{"snippet": "pandas.arrays.DatetimeArray(values, dtype=dtype('<M8ns'))", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `dtype`.", "question_id": 11092},
{"snippet": "pandas.arrays.DatetimeArray(values, freq=None)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `freq`.", "question_id": 11093},
{"snippet": "pandas.arrays.DatetimeArray(values, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `copy`.", "question_id": 11094},
{"snippet": "pandas.arrays.DatetimeArray(values, dtype=dtype('<M8ns'), freq=None)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `dtype`, `freq`.", "question_id": 11095},
{"snippet": "pandas.arrays.DatetimeArray(values, dtype=dtype('<M8ns'), copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `dtype`, `copy`.", "question_id": 11096},
{"snippet": "pandas.arrays.DatetimeArray(values, freq=None, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `freq`, `copy`.", "question_id": 11097},
{"snippet": "pandas.arrays.DatetimeArray(values, dtype=dtype('<M8ns'), freq=None, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `dtype`, `freq`, `copy`.", "question_id": 11098},
{"snippet": "pandas.arrays.DatetimeArray()", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data .", "question_id": 11099},
{"snippet": "pandas.arrays.DatetimeArray(dtype=dtype('<M8ns'))", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `dtype`.", "question_id": 11100},
{"snippet": "pandas.arrays.DatetimeArray(freq=None)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `freq`.", "question_id": 11101},
{"snippet": "pandas.arrays.DatetimeArray(copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `copy`.", "question_id": 11102},
{"snippet": "pandas.arrays.DatetimeArray(dtype=dtype('<M8ns'), freq=None)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `dtype`, `freq`.", "question_id": 11103},
{"snippet": "pandas.arrays.DatetimeArray(dtype=dtype('<M8ns'), copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `dtype`, `copy`.", "question_id": 11104},
{"snippet": "pandas.arrays.DatetimeArray(freq=None, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `freq`, `copy`.", "question_id": 11105},
{"snippet": "pandas.arrays.DatetimeArray(dtype=dtype('<M8ns'), freq=None, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `dtype`, `freq`, `copy`.", "question_id": 11106},
{"snippet": "pandas.arrays.DatetimeArray(values)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`.", "question_id": 11107},
{"snippet": "pandas.arrays.DatetimeArray(values, dtype=dtype('<M8ns'))", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `dtype`.", "question_id": 11108},
{"snippet": "pandas.arrays.DatetimeArray(values, freq=None)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `freq`.", "question_id": 11109},
{"snippet": "pandas.arrays.DatetimeArray(values, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `copy`.", "question_id": 11110},
{"snippet": "pandas.arrays.DatetimeArray(values, dtype=dtype('<M8ns'), freq=None)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `dtype`, `freq`.", "question_id": 11111},
{"snippet": "pandas.arrays.DatetimeArray(values, dtype=dtype('<M8ns'), copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `dtype`, `copy`.", "question_id": 11112},
{"snippet": "pandas.arrays.DatetimeArray(values, freq=None, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `freq`, `copy`.", "question_id": 11113},
{"snippet": "pandas.arrays.DatetimeArray(values, dtype=dtype('<M8ns'), freq=None, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `dtype`, `freq`, `copy`.", "question_id": 11114},
{"snippet": "pandas.arrays.DatetimeArray()", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data .", "question_id": 11115},
{"snippet": "pandas.arrays.DatetimeArray(dtype=dtype('<M8ns'))", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `dtype`.", "question_id": 11116},
{"snippet": "pandas.arrays.DatetimeArray(freq=None)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `freq`.", "question_id": 11117},
{"snippet": "pandas.arrays.DatetimeArray(copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `copy`.", "question_id": 11118},
{"snippet": "pandas.arrays.DatetimeArray(dtype=dtype('<M8ns'), freq=None)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `dtype`, `freq`.", "question_id": 11119},
{"snippet": "pandas.arrays.DatetimeArray(dtype=dtype('<M8ns'), copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `dtype`, `copy`.", "question_id": 11120},
{"snippet": "pandas.arrays.DatetimeArray(freq=None, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `freq`, `copy`.", "question_id": 11121},
{"snippet": "pandas.arrays.DatetimeArray(dtype=dtype('<M8ns'), freq=None, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `dtype`, `freq`, `copy`.", "question_id": 11122},
{"snippet": "pandas.arrays.DatetimeArray(values)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`.", "question_id": 11123},
{"snippet": "pandas.arrays.DatetimeArray(values, dtype=dtype('<M8ns'))", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `dtype`.", "question_id": 11124},
{"snippet": "pandas.arrays.DatetimeArray(values, freq=None)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `freq`.", "question_id": 11125},
{"snippet": "pandas.arrays.DatetimeArray(values, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `copy`.", "question_id": 11126},
{"snippet": "pandas.arrays.DatetimeArray(values, dtype=dtype('<M8ns'), freq=None)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `dtype`, `freq`.", "question_id": 11127},
{"snippet": "pandas.arrays.DatetimeArray(values, dtype=dtype('<M8ns'), copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `dtype`, `copy`.", "question_id": 11128},
{"snippet": "pandas.arrays.DatetimeArray(values, freq=None, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `freq`, `copy`.", "question_id": 11129},
{"snippet": "pandas.arrays.DatetimeArray(values, dtype=dtype('<M8ns'), freq=None, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `values`, `dtype`, `freq`, `copy`.", "question_id": 11130},
{"snippet": "pandas.arrays.DatetimeArray()", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data .", "question_id": 11131},
{"snippet": "pandas.arrays.DatetimeArray(dtype=dtype('<M8ns'))", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `dtype`.", "question_id": 11132},
{"snippet": "pandas.arrays.DatetimeArray(freq=None)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `freq`.", "question_id": 11133},
{"snippet": "pandas.arrays.DatetimeArray(copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `copy`.", "question_id": 11134},
{"snippet": "pandas.arrays.DatetimeArray(dtype=dtype('<M8ns'), freq=None)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `dtype`, `freq`.", "question_id": 11135},
{"snippet": "pandas.arrays.DatetimeArray(dtype=dtype('<M8ns'), copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `dtype`, `copy`.", "question_id": 11136},
{"snippet": "pandas.arrays.DatetimeArray(freq=None, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `freq`, `copy`.", "question_id": 11137},
{"snippet": "pandas.arrays.DatetimeArray(dtype=dtype('<M8ns'), freq=None, copy=False)", "intent": "Pandas ExtensionArray for tz-naive or tz-aware datetime data . With arguments `dtype`, `freq`, `copy`.", "question_id": 11138},
{"snippet": "pandas.arrays.IntegerArray(values, mask)", "intent": "Array of integer ( optional missing ) `values` . With arguments `mask`.", "question_id": 11139},
{"snippet": "pandas.arrays.IntegerArray(values, mask, copy=False)", "intent": "Array of integer ( optional missing ) `values` . With arguments `mask`, `copy`.", "question_id": 11140},
{"snippet": "pandas.arrays.IntegerArray(values, mask)", "intent": "Array of integer ( optional missing ) `values` . With arguments `mask`.", "question_id": 11141},
{"snippet": "pandas.arrays.IntegerArray(values, mask, copy=False)", "intent": "Array of integer ( optional missing ) `values` . With arguments `mask`, `copy`.", "question_id": 11142},
{"snippet": "pandas.arrays.IntegerArray(values, mask)", "intent": "Array of integer ( optional missing ) `values` . With arguments `mask`.", "question_id": 11143},
{"snippet": "pandas.arrays.IntegerArray(values, mask, copy=False)", "intent": "Array of integer ( optional missing ) `values` . With arguments `mask`, `copy`.", "question_id": 11144},
{"snippet": "IntervalArray.contains(other)", "intent": "Check elementwise if the Intervals contain the value . With arguments `other`.", "question_id": 11145},
{"snippet": "IntervalArray.contains(other)", "intent": "Check elementwise if the Intervals contain the value . With arguments `other`.", "question_id": 11146},
{"snippet": "IntervalArray.contains(other)", "intent": "Check elementwise if the Intervals contain the value . With arguments `other`.", "question_id": 11147},
{"snippet": "IntervalArray.from_arrays(left, right)", "intent": "Construct from two arrays defining the `left` and `right` bounds .", "question_id": 11148},
{"snippet": "IntervalArray.from_arrays(left, right, closed='right')", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`.", "question_id": 11149},
{"snippet": "IntervalArray.from_arrays(left, right, copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `copy`.", "question_id": 11150},
{"snippet": "IntervalArray.from_arrays(left, right, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `dtype`.", "question_id": 11151},
{"snippet": "IntervalArray.from_arrays(left, right, closed='right', copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `copy`.", "question_id": 11152},
{"snippet": "IntervalArray.from_arrays(left, right, closed='right', dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `dtype`.", "question_id": 11153},
{"snippet": "IntervalArray.from_arrays(left, right, copy=False, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `copy`, `dtype`.", "question_id": 11154},
{"snippet": "IntervalArray.from_arrays(left, right, closed='right', copy=False, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `copy`, `dtype`.", "question_id": 11155},
{"snippet": "IntervalArray.from_arrays(left, right)", "intent": "Construct from two arrays defining the `left` and `right` bounds .", "question_id": 11156},
{"snippet": "IntervalArray.from_arrays(left, right, closed='right')", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`.", "question_id": 11157},
{"snippet": "IntervalArray.from_arrays(left, right, copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `copy`.", "question_id": 11158},
{"snippet": "IntervalArray.from_arrays(left, right, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `dtype`.", "question_id": 11159},
{"snippet": "IntervalArray.from_arrays(left, right, closed='right', copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `copy`.", "question_id": 11160},
{"snippet": "IntervalArray.from_arrays(left, right, closed='right', dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `dtype`.", "question_id": 11161},
{"snippet": "IntervalArray.from_arrays(left, right, copy=False, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `copy`, `dtype`.", "question_id": 11162},
{"snippet": "IntervalArray.from_arrays(left, right, closed='right', copy=False, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `copy`, `dtype`.", "question_id": 11163},
{"snippet": "IntervalArray.from_arrays(left, right)", "intent": "Construct from two arrays defining the `left` and `right` bounds .", "question_id": 11164},
{"snippet": "IntervalArray.from_arrays(left, right, closed='right')", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`.", "question_id": 11165},
{"snippet": "IntervalArray.from_arrays(left, right, copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `copy`.", "question_id": 11166},
{"snippet": "IntervalArray.from_arrays(left, right, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `dtype`.", "question_id": 11167},
{"snippet": "IntervalArray.from_arrays(left, right, closed='right', copy=False)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `copy`.", "question_id": 11168},
{"snippet": "IntervalArray.from_arrays(left, right, closed='right', dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `dtype`.", "question_id": 11169},
{"snippet": "IntervalArray.from_arrays(left, right, copy=False, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `copy`, `dtype`.", "question_id": 11170},
{"snippet": "IntervalArray.from_arrays(left, right, closed='right', copy=False, dtype=None)", "intent": "Construct from two arrays defining the `left` and `right` bounds . With arguments `closed`, `copy`, `dtype`.", "question_id": 11171},
{"snippet": "IntervalArray.from_breaks(breaks)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`.", "question_id": 11172},
{"snippet": "IntervalArray.from_breaks(breaks, closed='right')", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `closed`.", "question_id": 11173},
{"snippet": "IntervalArray.from_breaks(breaks, copy=False)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `copy`.", "question_id": 11174},
{"snippet": "IntervalArray.from_breaks(breaks, dtype=None)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `dtype`.", "question_id": 11175},
{"snippet": "IntervalArray.from_breaks(breaks, closed='right', copy=False)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `closed`, `copy`.", "question_id": 11176},
{"snippet": "IntervalArray.from_breaks(breaks, closed='right', dtype=None)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `closed`, `dtype`.", "question_id": 11177},
{"snippet": "IntervalArray.from_breaks(breaks, copy=False, dtype=None)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `copy`, `dtype`.", "question_id": 11178},
{"snippet": "IntervalArray.from_breaks(breaks, closed='right', copy=False, dtype=None)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `closed`, `copy`, `dtype`.", "question_id": 11179},
{"snippet": "IntervalArray.from_breaks(breaks)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`.", "question_id": 11180},
{"snippet": "IntervalArray.from_breaks(breaks, closed='right')", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `closed`.", "question_id": 11181},
{"snippet": "IntervalArray.from_breaks(breaks, copy=False)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `copy`.", "question_id": 11182},
{"snippet": "IntervalArray.from_breaks(breaks, dtype=None)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `dtype`.", "question_id": 11183},
{"snippet": "IntervalArray.from_breaks(breaks, closed='right', copy=False)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `closed`, `copy`.", "question_id": 11184},
{"snippet": "IntervalArray.from_breaks(breaks, closed='right', dtype=None)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `closed`, `dtype`.", "question_id": 11185},
{"snippet": "IntervalArray.from_breaks(breaks, copy=False, dtype=None)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `copy`, `dtype`.", "question_id": 11186},
{"snippet": "IntervalArray.from_breaks(breaks, closed='right', copy=False, dtype=None)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `closed`, `copy`, `dtype`.", "question_id": 11187},
{"snippet": "IntervalArray.from_breaks(breaks)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`.", "question_id": 11188},
{"snippet": "IntervalArray.from_breaks(breaks, closed='right')", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `closed`.", "question_id": 11189},
{"snippet": "IntervalArray.from_breaks(breaks, copy=False)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `copy`.", "question_id": 11190},
{"snippet": "IntervalArray.from_breaks(breaks, dtype=None)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `dtype`.", "question_id": 11191},
{"snippet": "IntervalArray.from_breaks(breaks, closed='right', copy=False)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `closed`, `copy`.", "question_id": 11192},
{"snippet": "IntervalArray.from_breaks(breaks, closed='right', dtype=None)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `closed`, `dtype`.", "question_id": 11193},
{"snippet": "IntervalArray.from_breaks(breaks, copy=False, dtype=None)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `copy`, `dtype`.", "question_id": 11194},
{"snippet": "IntervalArray.from_breaks(breaks, closed='right', copy=False, dtype=None)", "intent": "Construct an IntervalArray from an array of splits . With arguments `breaks`, `closed`, `copy`, `dtype`.", "question_id": 11195},
{"snippet": "IntervalArray.from_tuples(data)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`.", "question_id": 11196},
{"snippet": "IntervalArray.from_tuples(data, closed='right')", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `closed`.", "question_id": 11197},
{"snippet": "IntervalArray.from_tuples(data, copy=False)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `copy`.", "question_id": 11198},
{"snippet": "IntervalArray.from_tuples(data, dtype=None)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `dtype`.", "question_id": 11199},
{"snippet": "IntervalArray.from_tuples(data, closed='right', copy=False)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `closed`, `copy`.", "question_id": 11200},
{"snippet": "IntervalArray.from_tuples(data, closed='right', dtype=None)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `closed`, `dtype`.", "question_id": 11201},
{"snippet": "IntervalArray.from_tuples(data, copy=False, dtype=None)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `copy`, `dtype`.", "question_id": 11202},
{"snippet": "IntervalArray.from_tuples(data, closed='right', copy=False, dtype=None)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `closed`, `copy`, `dtype`.", "question_id": 11203},
{"snippet": "IntervalArray.from_tuples(data)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`.", "question_id": 11204},
{"snippet": "IntervalArray.from_tuples(data, closed='right')", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `closed`.", "question_id": 11205},
{"snippet": "IntervalArray.from_tuples(data, copy=False)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `copy`.", "question_id": 11206},
{"snippet": "IntervalArray.from_tuples(data, dtype=None)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `dtype`.", "question_id": 11207},
{"snippet": "IntervalArray.from_tuples(data, closed='right', copy=False)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `closed`, `copy`.", "question_id": 11208},
{"snippet": "IntervalArray.from_tuples(data, closed='right', dtype=None)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `closed`, `dtype`.", "question_id": 11209},
{"snippet": "IntervalArray.from_tuples(data, copy=False, dtype=None)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `copy`, `dtype`.", "question_id": 11210},
{"snippet": "IntervalArray.from_tuples(data, closed='right', copy=False, dtype=None)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `closed`, `copy`, `dtype`.", "question_id": 11211},
{"snippet": "IntervalArray.from_tuples(data)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`.", "question_id": 11212},
{"snippet": "IntervalArray.from_tuples(data, closed='right')", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `closed`.", "question_id": 11213},
{"snippet": "IntervalArray.from_tuples(data, copy=False)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `copy`.", "question_id": 11214},
{"snippet": "IntervalArray.from_tuples(data, dtype=None)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `dtype`.", "question_id": 11215},
{"snippet": "IntervalArray.from_tuples(data, closed='right', copy=False)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `closed`, `copy`.", "question_id": 11216},
{"snippet": "IntervalArray.from_tuples(data, closed='right', dtype=None)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `closed`, `dtype`.", "question_id": 11217},
{"snippet": "IntervalArray.from_tuples(data, copy=False, dtype=None)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `copy`, `dtype`.", "question_id": 11218},
{"snippet": "IntervalArray.from_tuples(data, closed='right', copy=False, dtype=None)", "intent": "Construct an IntervalArray from an array-like of tuples . With arguments `data`, `closed`, `copy`, `dtype`.", "question_id": 11219},
{"snippet": "pandas.arrays.IntervalArray(data)", "intent": "Pandas array for interval `data` that are `closed` on the same side .", "question_id": 11220},
{"snippet": "pandas.arrays.IntervalArray(data, closed=None)", "intent": "Pandas array for interval `data` that are `closed` on the same side .", "question_id": 11221},
{"snippet": "pandas.arrays.IntervalArray(data, dtype=None)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `dtype`.", "question_id": 11222},
{"snippet": "pandas.arrays.IntervalArray(data, copy=False)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `copy`.", "question_id": 11223},
{"snippet": "pandas.arrays.IntervalArray(data, verify_integrity=True)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `verify_integrity`.", "question_id": 11224},
{"snippet": "pandas.arrays.IntervalArray(data, closed=None, dtype=None)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `dtype`.", "question_id": 11225},
{"snippet": "pandas.arrays.IntervalArray(data, closed=None, copy=False)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `copy`.", "question_id": 11226},
{"snippet": "pandas.arrays.IntervalArray(data, closed=None, verify_integrity=True)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `verify_integrity`.", "question_id": 11227},
{"snippet": "pandas.arrays.IntervalArray(data, dtype=None, copy=False)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `dtype`, `copy`.", "question_id": 11228},
{"snippet": "pandas.arrays.IntervalArray(data, dtype=None, verify_integrity=True)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `dtype`, `verify_integrity`.", "question_id": 11229},
{"snippet": "pandas.arrays.IntervalArray(data)", "intent": "Pandas array for interval `data` that are `closed` on the same side .", "question_id": 11230},
{"snippet": "pandas.arrays.IntervalArray(data, closed=None)", "intent": "Pandas array for interval `data` that are `closed` on the same side .", "question_id": 11231},
{"snippet": "pandas.arrays.IntervalArray(data, dtype=None)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `dtype`.", "question_id": 11232},
{"snippet": "pandas.arrays.IntervalArray(data, copy=False)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `copy`.", "question_id": 11233},
{"snippet": "pandas.arrays.IntervalArray(data, verify_integrity=True)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `verify_integrity`.", "question_id": 11234},
{"snippet": "pandas.arrays.IntervalArray(data, closed=None, dtype=None)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `dtype`.", "question_id": 11235},
{"snippet": "pandas.arrays.IntervalArray(data, closed=None, copy=False)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `copy`.", "question_id": 11236},
{"snippet": "pandas.arrays.IntervalArray(data, closed=None, verify_integrity=True)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `verify_integrity`.", "question_id": 11237},
{"snippet": "pandas.arrays.IntervalArray(data, dtype=None, copy=False)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `dtype`, `copy`.", "question_id": 11238},
{"snippet": "pandas.arrays.IntervalArray(data, dtype=None, verify_integrity=True)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `dtype`, `verify_integrity`.", "question_id": 11239},
{"snippet": "pandas.arrays.IntervalArray(data)", "intent": "Pandas array for interval `data` that are `closed` on the same side .", "question_id": 11240},
{"snippet": "pandas.arrays.IntervalArray(data, closed=None)", "intent": "Pandas array for interval `data` that are `closed` on the same side .", "question_id": 11241},
{"snippet": "pandas.arrays.IntervalArray(data, dtype=None)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `dtype`.", "question_id": 11242},
{"snippet": "pandas.arrays.IntervalArray(data, copy=False)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `copy`.", "question_id": 11243},
{"snippet": "pandas.arrays.IntervalArray(data, verify_integrity=True)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `verify_integrity`.", "question_id": 11244},
{"snippet": "pandas.arrays.IntervalArray(data, closed=None, dtype=None)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `dtype`.", "question_id": 11245},
{"snippet": "pandas.arrays.IntervalArray(data, closed=None, copy=False)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `copy`.", "question_id": 11246},
{"snippet": "pandas.arrays.IntervalArray(data, closed=None, verify_integrity=True)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `verify_integrity`.", "question_id": 11247},
{"snippet": "pandas.arrays.IntervalArray(data, dtype=None, copy=False)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `dtype`, `copy`.", "question_id": 11248},
{"snippet": "pandas.arrays.IntervalArray(data, dtype=None, verify_integrity=True)", "intent": "Pandas array for interval `data` that are `closed` on the same side . With arguments `dtype`, `verify_integrity`.", "question_id": 11249},
{"snippet": "IntervalArray.is_empty", "intent": "Indicates if an interval is empty, meaning it contains no points.", "question_id": 11250},
{"snippet": "IntervalArray.is_empty", "intent": "Indicates if an interval is empty, meaning it contains no points.", "question_id": 11251},
{"snippet": "IntervalArray.is_empty", "intent": "Indicates if an interval is empty, meaning it contains no points.", "question_id": 11252},
{"snippet": "IntervalArray.overlaps(other)", "intent": "Check elementwise if an Interval overlaps the values in the IntervalArray . With arguments `other`.", "question_id": 11253},
{"snippet": "IntervalArray.overlaps(other)", "intent": "Check elementwise if an Interval overlaps the values in the IntervalArray . With arguments `other`.", "question_id": 11254},
{"snippet": "IntervalArray.overlaps(other)", "intent": "Check elementwise if an Interval overlaps the values in the IntervalArray . With arguments `other`.", "question_id": 11255},
{"snippet": "IntervalArray.set_closed(closed)", "intent": "Return an IntervalArray identical to the current one , but `closed` on the specified side .", "question_id": 11256},
{"snippet": "IntervalArray.set_closed(closed)", "intent": "Return an IntervalArray identical to the current one , but `closed` on the specified side .", "question_id": 11257},
{"snippet": "IntervalArray.set_closed(closed)", "intent": "Return an IntervalArray identical to the current one , but `closed` on the specified side .", "question_id": 11258},
{"snippet": "IntervalArray.to_tuples()", "intent": "Return an ndarray of tuples of the form ( left , right ) .", "question_id": 11259},
{"snippet": "IntervalArray.to_tuples(na_tuple=True)", "intent": "Return an ndarray of tuples of the form ( left , right ) . With arguments `na_tuple`.", "question_id": 11260},
{"snippet": "IntervalArray.to_tuples()", "intent": "Return an ndarray of tuples of the form ( left , right ) .", "question_id": 11261},
{"snippet": "IntervalArray.to_tuples(na_tuple=True)", "intent": "Return an ndarray of tuples of the form ( left , right ) . With arguments `na_tuple`.", "question_id": 11262},
{"snippet": "IntervalArray.to_tuples()", "intent": "Return an ndarray of tuples of the form ( left , right ) .", "question_id": 11263},
{"snippet": "IntervalArray.to_tuples(na_tuple=True)", "intent": "Return an ndarray of tuples of the form ( left , right ) . With arguments `na_tuple`.", "question_id": 11264},
{"snippet": "pandas.arrays.PandasArray(values)", "intent": "A pandas ExtensionArray for NumPy data . With arguments `values`.", "question_id": 11265},
{"snippet": "pandas.arrays.PandasArray(values, copy=False)", "intent": "A pandas ExtensionArray for NumPy data . With arguments `values`, `copy`.", "question_id": 11266},
{"snippet": "pandas.arrays.PandasArray(values)", "intent": "A pandas ExtensionArray for NumPy data . With arguments `values`.", "question_id": 11267},
{"snippet": "pandas.arrays.PandasArray(values, copy=False)", "intent": "A pandas ExtensionArray for NumPy data . With arguments `values`, `copy`.", "question_id": 11268},
{"snippet": "pandas.arrays.PandasArray(values)", "intent": "A pandas ExtensionArray for NumPy data . With arguments `values`.", "question_id": 11269},
{"snippet": "pandas.arrays.PandasArray(values, copy=False)", "intent": "A pandas ExtensionArray for NumPy data . With arguments `values`, `copy`.", "question_id": 11270},
{"snippet": "pandas.arrays.PeriodArray(values)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers .", "question_id": 11271},
{"snippet": "pandas.arrays.PeriodArray(values, dtype=None)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . With arguments `dtype`.", "question_id": 11272},
{"snippet": "pandas.arrays.PeriodArray(values, freq=None)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . The `freq` indicates the span covered by each element of the array .", "question_id": 11273},
{"snippet": "pandas.arrays.PeriodArray(values, copy=False)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . With arguments `copy`.", "question_id": 11274},
{"snippet": "pandas.arrays.PeriodArray(values, dtype=None, freq=None)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . The `freq` indicates the span covered by each element of the array . With arguments `dtype`.", "question_id": 11275},
{"snippet": "pandas.arrays.PeriodArray(values, dtype=None, copy=False)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . With arguments `dtype`, `copy`.", "question_id": 11276},
{"snippet": "pandas.arrays.PeriodArray(values, freq=None, copy=False)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . The `freq` indicates the span covered by each element of the array . With arguments `copy`.", "question_id": 11277},
{"snippet": "pandas.arrays.PeriodArray(values, dtype=None, freq=None, copy=False)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . The `freq` indicates the span covered by each element of the array . With arguments `dtype`, `copy`.", "question_id": 11278},
{"snippet": "pandas.arrays.PeriodArray(values)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers .", "question_id": 11279},
{"snippet": "pandas.arrays.PeriodArray(values, dtype=None)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . With arguments `dtype`.", "question_id": 11280},
{"snippet": "pandas.arrays.PeriodArray(values, freq=None)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . The `freq` indicates the span covered by each element of the array .", "question_id": 11281},
{"snippet": "pandas.arrays.PeriodArray(values, copy=False)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . With arguments `copy`.", "question_id": 11282},
{"snippet": "pandas.arrays.PeriodArray(values, dtype=None, freq=None)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . The `freq` indicates the span covered by each element of the array . With arguments `dtype`.", "question_id": 11283},
{"snippet": "pandas.arrays.PeriodArray(values, dtype=None, copy=False)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . With arguments `dtype`, `copy`.", "question_id": 11284},
{"snippet": "pandas.arrays.PeriodArray(values, freq=None, copy=False)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . The `freq` indicates the span covered by each element of the array . With arguments `copy`.", "question_id": 11285},
{"snippet": "pandas.arrays.PeriodArray(values, dtype=None, freq=None, copy=False)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . The `freq` indicates the span covered by each element of the array . With arguments `dtype`, `copy`.", "question_id": 11286},
{"snippet": "pandas.arrays.PeriodArray(values)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers .", "question_id": 11287},
{"snippet": "pandas.arrays.PeriodArray(values, dtype=None)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . With arguments `dtype`.", "question_id": 11288},
{"snippet": "pandas.arrays.PeriodArray(values, freq=None)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . The `freq` indicates the span covered by each element of the array .", "question_id": 11289},
{"snippet": "pandas.arrays.PeriodArray(values, copy=False)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . With arguments `copy`.", "question_id": 11290},
{"snippet": "pandas.arrays.PeriodArray(values, dtype=None, freq=None)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . The `freq` indicates the span covered by each element of the array . With arguments `dtype`.", "question_id": 11291},
{"snippet": "pandas.arrays.PeriodArray(values, dtype=None, copy=False)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . With arguments `dtype`, `copy`.", "question_id": 11292},
{"snippet": "pandas.arrays.PeriodArray(values, freq=None, copy=False)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . The `freq` indicates the span covered by each element of the array . With arguments `copy`.", "question_id": 11293},
{"snippet": "pandas.arrays.PeriodArray(values, dtype=None, freq=None, copy=False)", "intent": "Pandas ExtensionArray for storing Period data . The `values` are physically stored as a 1-D ndarray of integers . The `freq` indicates the span covered by each element of the array . With arguments `dtype`, `copy`.", "question_id": 11294},
{"snippet": "pandas.arrays.SparseArray(data)", "intent": "An ExtensionArray for storing sparse `data` .", "question_id": 11295},
{"snippet": "pandas.arrays.SparseArray(data, sparse_index=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `sparse_index`.", "question_id": 11296},
{"snippet": "pandas.arrays.SparseArray(data, index=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `index`.", "question_id": 11297},
{"snippet": "pandas.arrays.SparseArray(data, fill_value=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `fill_value`.", "question_id": 11298},
{"snippet": "pandas.arrays.SparseArray(data, kind='integer')", "intent": "An ExtensionArray for storing sparse `data` . With arguments `kind`.", "question_id": 11299},
{"snippet": "pandas.arrays.SparseArray(data, dtype=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `dtype`.", "question_id": 11300},
{"snippet": "pandas.arrays.SparseArray(data, copy=False)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `copy`.", "question_id": 11301},
{"snippet": "pandas.arrays.SparseArray(data, sparse_index=None, index=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `sparse_index`, `index`.", "question_id": 11302},
{"snippet": "pandas.arrays.SparseArray(data, sparse_index=None, fill_value=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `sparse_index`, `fill_value`.", "question_id": 11303},
{"snippet": "pandas.arrays.SparseArray(data, sparse_index=None, kind='integer')", "intent": "An ExtensionArray for storing sparse `data` . With arguments `sparse_index`, `kind`.", "question_id": 11304},
{"snippet": "pandas.arrays.SparseArray(data)", "intent": "An ExtensionArray for storing sparse `data` .", "question_id": 11305},
{"snippet": "pandas.arrays.SparseArray(data, sparse_index=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `sparse_index`.", "question_id": 11306},
{"snippet": "pandas.arrays.SparseArray(data, index=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `index`.", "question_id": 11307},
{"snippet": "pandas.arrays.SparseArray(data, fill_value=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `fill_value`.", "question_id": 11308},
{"snippet": "pandas.arrays.SparseArray(data, kind='integer')", "intent": "An ExtensionArray for storing sparse `data` . With arguments `kind`.", "question_id": 11309},
{"snippet": "pandas.arrays.SparseArray(data, dtype=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `dtype`.", "question_id": 11310},
{"snippet": "pandas.arrays.SparseArray(data, copy=False)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `copy`.", "question_id": 11311},
{"snippet": "pandas.arrays.SparseArray(data, sparse_index=None, index=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `sparse_index`, `index`.", "question_id": 11312},
{"snippet": "pandas.arrays.SparseArray(data, sparse_index=None, fill_value=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `sparse_index`, `fill_value`.", "question_id": 11313},
{"snippet": "pandas.arrays.SparseArray(data, sparse_index=None, kind='integer')", "intent": "An ExtensionArray for storing sparse `data` . With arguments `sparse_index`, `kind`.", "question_id": 11314},
{"snippet": "pandas.arrays.SparseArray(data)", "intent": "An ExtensionArray for storing sparse `data` .", "question_id": 11315},
{"snippet": "pandas.arrays.SparseArray(data, sparse_index=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `sparse_index`.", "question_id": 11316},
{"snippet": "pandas.arrays.SparseArray(data, index=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `index`.", "question_id": 11317},
{"snippet": "pandas.arrays.SparseArray(data, fill_value=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `fill_value`.", "question_id": 11318},
{"snippet": "pandas.arrays.SparseArray(data, kind='integer')", "intent": "An ExtensionArray for storing sparse `data` . With arguments `kind`.", "question_id": 11319},
{"snippet": "pandas.arrays.SparseArray(data, dtype=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `dtype`.", "question_id": 11320},
{"snippet": "pandas.arrays.SparseArray(data, copy=False)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `copy`.", "question_id": 11321},
{"snippet": "pandas.arrays.SparseArray(data, sparse_index=None, index=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `sparse_index`, `index`.", "question_id": 11322},
{"snippet": "pandas.arrays.SparseArray(data, sparse_index=None, fill_value=None)", "intent": "An ExtensionArray for storing sparse `data` . With arguments `sparse_index`, `fill_value`.", "question_id": 11323},
{"snippet": "pandas.arrays.SparseArray(data, sparse_index=None, kind='integer')", "intent": "An ExtensionArray for storing sparse `data` . With arguments `sparse_index`, `kind`.", "question_id": 11324},
{"snippet": "pandas.arrays.StringArray(values)", "intent": "Extension array for string data . Unlike arrays instantiated with dtype= '' object '' , StringArray will convert the `values` to strings .", "question_id": 11325},
{"snippet": "pandas.arrays.StringArray(values, copy=False)", "intent": "Extension array for string data . Unlike arrays instantiated with dtype= '' object '' , StringArray will convert the `values` to strings . With arguments `copy`.", "question_id": 11326},
{"snippet": "pandas.arrays.StringArray(values)", "intent": "Extension array for string data . Unlike arrays instantiated with dtype= '' object '' , StringArray will convert the `values` to strings .", "question_id": 11327},
{"snippet": "pandas.arrays.StringArray(values, copy=False)", "intent": "Extension array for string data . Unlike arrays instantiated with dtype= '' object '' , StringArray will convert the `values` to strings . With arguments `copy`.", "question_id": 11328},
{"snippet": "pandas.arrays.StringArray(values)", "intent": "Extension array for string data . Unlike arrays instantiated with dtype= '' object '' , StringArray will convert the `values` to strings .", "question_id": 11329},
{"snippet": "pandas.arrays.StringArray(values, copy=False)", "intent": "Extension array for string data . Unlike arrays instantiated with dtype= '' object '' , StringArray will convert the `values` to strings . With arguments `copy`.", "question_id": 11330},
{"snippet": "pandas.arrays.TimedeltaArray(values)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`.", "question_id": 11331},
{"snippet": "pandas.arrays.TimedeltaArray(values, dtype=dtype('<m8ns'))", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `dtype`.", "question_id": 11332},
{"snippet": "pandas.arrays.TimedeltaArray(values, freq=NoDefault.no_default)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `freq`.", "question_id": 11333},
{"snippet": "pandas.arrays.TimedeltaArray(values, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `copy`.", "question_id": 11334},
{"snippet": "pandas.arrays.TimedeltaArray(values, dtype=dtype('<m8ns'), freq=NoDefault.no_default)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `dtype`, `freq`.", "question_id": 11335},
{"snippet": "pandas.arrays.TimedeltaArray(values, dtype=dtype('<m8ns'), copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `dtype`, `copy`.", "question_id": 11336},
{"snippet": "pandas.arrays.TimedeltaArray(values, freq=NoDefault.no_default, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `freq`, `copy`.", "question_id": 11337},
{"snippet": "pandas.arrays.TimedeltaArray(values, dtype=dtype('<m8ns'), freq=NoDefault.no_default, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `dtype`, `freq`, `copy`.", "question_id": 11338},
{"snippet": "pandas.arrays.TimedeltaArray()", "intent": "Pandas ExtensionArray for timedelta data .", "question_id": 11339},
{"snippet": "pandas.arrays.TimedeltaArray(dtype=dtype('<m8ns'))", "intent": "Pandas ExtensionArray for timedelta data . With arguments `dtype`.", "question_id": 11340},
{"snippet": "pandas.arrays.TimedeltaArray(freq=NoDefault.no_default)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `freq`.", "question_id": 11341},
{"snippet": "pandas.arrays.TimedeltaArray(copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `copy`.", "question_id": 11342},
{"snippet": "pandas.arrays.TimedeltaArray(dtype=dtype('<m8ns'), freq=NoDefault.no_default)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `dtype`, `freq`.", "question_id": 11343},
{"snippet": "pandas.arrays.TimedeltaArray(dtype=dtype('<m8ns'), copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `dtype`, `copy`.", "question_id": 11344},
{"snippet": "pandas.arrays.TimedeltaArray(freq=NoDefault.no_default, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `freq`, `copy`.", "question_id": 11345},
{"snippet": "pandas.arrays.TimedeltaArray(dtype=dtype('<m8ns'), freq=NoDefault.no_default, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `dtype`, `freq`, `copy`.", "question_id": 11346},
{"snippet": "pandas.arrays.TimedeltaArray(values)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`.", "question_id": 11347},
{"snippet": "pandas.arrays.TimedeltaArray(values, dtype=dtype('<m8ns'))", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `dtype`.", "question_id": 11348},
{"snippet": "pandas.arrays.TimedeltaArray(values, freq=NoDefault.no_default)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `freq`.", "question_id": 11349},
{"snippet": "pandas.arrays.TimedeltaArray(values, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `copy`.", "question_id": 11350},
{"snippet": "pandas.arrays.TimedeltaArray(values, dtype=dtype('<m8ns'), freq=NoDefault.no_default)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `dtype`, `freq`.", "question_id": 11351},
{"snippet": "pandas.arrays.TimedeltaArray(values, dtype=dtype('<m8ns'), copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `dtype`, `copy`.", "question_id": 11352},
{"snippet": "pandas.arrays.TimedeltaArray(values, freq=NoDefault.no_default, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `freq`, `copy`.", "question_id": 11353},
{"snippet": "pandas.arrays.TimedeltaArray(values, dtype=dtype('<m8ns'), freq=NoDefault.no_default, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `dtype`, `freq`, `copy`.", "question_id": 11354},
{"snippet": "pandas.arrays.TimedeltaArray()", "intent": "Pandas ExtensionArray for timedelta data .", "question_id": 11355},
{"snippet": "pandas.arrays.TimedeltaArray(dtype=dtype('<m8ns'))", "intent": "Pandas ExtensionArray for timedelta data . With arguments `dtype`.", "question_id": 11356},
{"snippet": "pandas.arrays.TimedeltaArray(freq=NoDefault.no_default)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `freq`.", "question_id": 11357},
{"snippet": "pandas.arrays.TimedeltaArray(copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `copy`.", "question_id": 11358},
{"snippet": "pandas.arrays.TimedeltaArray(dtype=dtype('<m8ns'), freq=NoDefault.no_default)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `dtype`, `freq`.", "question_id": 11359},
{"snippet": "pandas.arrays.TimedeltaArray(dtype=dtype('<m8ns'), copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `dtype`, `copy`.", "question_id": 11360},
{"snippet": "pandas.arrays.TimedeltaArray(freq=NoDefault.no_default, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `freq`, `copy`.", "question_id": 11361},
{"snippet": "pandas.arrays.TimedeltaArray(dtype=dtype('<m8ns'), freq=NoDefault.no_default, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `dtype`, `freq`, `copy`.", "question_id": 11362},
{"snippet": "pandas.arrays.TimedeltaArray(values)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`.", "question_id": 11363},
{"snippet": "pandas.arrays.TimedeltaArray(values, dtype=dtype('<m8ns'))", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `dtype`.", "question_id": 11364},
{"snippet": "pandas.arrays.TimedeltaArray(values, freq=NoDefault.no_default)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `freq`.", "question_id": 11365},
{"snippet": "pandas.arrays.TimedeltaArray(values, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `copy`.", "question_id": 11366},
{"snippet": "pandas.arrays.TimedeltaArray(values, dtype=dtype('<m8ns'), freq=NoDefault.no_default)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `dtype`, `freq`.", "question_id": 11367},
{"snippet": "pandas.arrays.TimedeltaArray(values, dtype=dtype('<m8ns'), copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `dtype`, `copy`.", "question_id": 11368},
{"snippet": "pandas.arrays.TimedeltaArray(values, freq=NoDefault.no_default, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `freq`, `copy`.", "question_id": 11369},
{"snippet": "pandas.arrays.TimedeltaArray(values, dtype=dtype('<m8ns'), freq=NoDefault.no_default, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `values`, `dtype`, `freq`, `copy`.", "question_id": 11370},
{"snippet": "pandas.arrays.TimedeltaArray()", "intent": "Pandas ExtensionArray for timedelta data .", "question_id": 11371},
{"snippet": "pandas.arrays.TimedeltaArray(dtype=dtype('<m8ns'))", "intent": "Pandas ExtensionArray for timedelta data . With arguments `dtype`.", "question_id": 11372},
{"snippet": "pandas.arrays.TimedeltaArray(freq=NoDefault.no_default)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `freq`.", "question_id": 11373},
{"snippet": "pandas.arrays.TimedeltaArray(copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `copy`.", "question_id": 11374},
{"snippet": "pandas.arrays.TimedeltaArray(dtype=dtype('<m8ns'), freq=NoDefault.no_default)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `dtype`, `freq`.", "question_id": 11375},
{"snippet": "pandas.arrays.TimedeltaArray(dtype=dtype('<m8ns'), copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `dtype`, `copy`.", "question_id": 11376},
{"snippet": "pandas.arrays.TimedeltaArray(freq=NoDefault.no_default, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `freq`, `copy`.", "question_id": 11377},
{"snippet": "pandas.arrays.TimedeltaArray(dtype=dtype('<m8ns'), freq=NoDefault.no_default, copy=False)", "intent": "Pandas ExtensionArray for timedelta data . With arguments `dtype`, `freq`, `copy`.", "question_id": 11378},
{"snippet": "pandas.bdate_range(**kwargs)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`.", "question_id": 11379},
{"snippet": "pandas.bdate_range(**kwargs, start=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . Of the four parameters : `start` , `end` , `periods` , and `freq` , exactly three must be specified . With arguments `**kwargs`.", "question_id": 11380},
{"snippet": "pandas.bdate_range(**kwargs, end=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . Of the four parameters : `start` , `end` , `periods` , and `freq` , exactly three must be specified . With arguments `**kwargs`.", "question_id": 11381},
{"snippet": "pandas.bdate_range(**kwargs, periods=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . Of the four parameters : `start` , `end` , `periods` , and `freq` , exactly three must be specified . With arguments `**kwargs`.", "question_id": 11382},
{"snippet": "pandas.bdate_range(**kwargs, freq='B')", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . Of the four parameters : `start` , `end` , `periods` , and `freq` , exactly three must be specified . With arguments `**kwargs`.", "question_id": 11383},
{"snippet": "pandas.bdate_range(**kwargs, tz=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `tz`.", "question_id": 11384},
{"snippet": "pandas.bdate_range(**kwargs, normalize=True)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `normalize`.", "question_id": 11385},
{"snippet": "pandas.bdate_range(**kwargs, name=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `name`.", "question_id": 11386},
{"snippet": "pandas.bdate_range(**kwargs, weekmask=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `weekmask`.", "question_id": 11387},
{"snippet": "pandas.bdate_range(**kwargs, holidays=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `holidays`.", "question_id": 11388},
{"snippet": "pandas.bdate_range(**kwargs)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`.", "question_id": 11389},
{"snippet": "pandas.bdate_range(**kwargs, start=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . Of the four parameters : `start` , `end` , `periods` , and `freq` , exactly three must be specified . With arguments `**kwargs`.", "question_id": 11390},
{"snippet": "pandas.bdate_range(**kwargs, end=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . Of the four parameters : `start` , `end` , `periods` , and `freq` , exactly three must be specified . With arguments `**kwargs`.", "question_id": 11391},
{"snippet": "pandas.bdate_range(**kwargs, periods=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . Of the four parameters : `start` , `end` , `periods` , and `freq` , exactly three must be specified . With arguments `**kwargs`.", "question_id": 11392},
{"snippet": "pandas.bdate_range(**kwargs, freq='B')", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . Of the four parameters : `start` , `end` , `periods` , and `freq` , exactly three must be specified . With arguments `**kwargs`.", "question_id": 11393},
{"snippet": "pandas.bdate_range(**kwargs, tz=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `tz`.", "question_id": 11394},
{"snippet": "pandas.bdate_range(**kwargs, normalize=True)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `normalize`.", "question_id": 11395},
{"snippet": "pandas.bdate_range(**kwargs, name=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `name`.", "question_id": 11396},
{"snippet": "pandas.bdate_range(**kwargs, weekmask=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `weekmask`.", "question_id": 11397},
{"snippet": "pandas.bdate_range(**kwargs, holidays=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `holidays`.", "question_id": 11398},
{"snippet": "pandas.bdate_range(**kwargs)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`.", "question_id": 11399},
{"snippet": "pandas.bdate_range(**kwargs, start=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . Of the four parameters : `start` , `end` , `periods` , and `freq` , exactly three must be specified . With arguments `**kwargs`.", "question_id": 11400},
{"snippet": "pandas.bdate_range(**kwargs, end=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . Of the four parameters : `start` , `end` , `periods` , and `freq` , exactly three must be specified . With arguments `**kwargs`.", "question_id": 11401},
{"snippet": "pandas.bdate_range(**kwargs, periods=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . Of the four parameters : `start` , `end` , `periods` , and `freq` , exactly three must be specified . With arguments `**kwargs`.", "question_id": 11402},
{"snippet": "pandas.bdate_range(**kwargs, freq='B')", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . Of the four parameters : `start` , `end` , `periods` , and `freq` , exactly three must be specified . With arguments `**kwargs`.", "question_id": 11403},
{"snippet": "pandas.bdate_range(**kwargs, tz=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `tz`.", "question_id": 11404},
{"snippet": "pandas.bdate_range(**kwargs, normalize=True)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `normalize`.", "question_id": 11405},
{"snippet": "pandas.bdate_range(**kwargs, name=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `name`.", "question_id": 11406},
{"snippet": "pandas.bdate_range(**kwargs, weekmask=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `weekmask`.", "question_id": 11407},
{"snippet": "pandas.bdate_range(**kwargs, holidays=None)", "intent": "Return a fixed frequency DatetimeIndex , with business day as the default frequency . With arguments `**kwargs`, `holidays`.", "question_id": 11408},
{"snippet": "pandas.concat(objs)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . With arguments `objs`.", "question_id": 11409},
{"snippet": "pandas.concat(objs, axis=0)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . With arguments `objs`.", "question_id": 11410},
{"snippet": "pandas.concat(objs, join='outer')", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . Combine DataFrame objects with overlapping columns and return only those that are shared by passing inner to the `join` keyword argument . With arguments `objs`.", "question_id": 11411},
{"snippet": "pandas.concat(objs, ignore_index=False)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . Clear the existing index and reset it in the result by setting the `ignore_index` option to True . With arguments `objs`.", "question_id": 11412},
{"snippet": "pandas.concat(objs, keys=None)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . The `keys` , `levels` , and `names` arguments are all optional . With arguments `objs`.", "question_id": 11413},
{"snippet": "pandas.concat(objs, levels=None)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . The `keys` , `levels` , and `names` arguments are all optional . With arguments `objs`.", "question_id": 11414},
{"snippet": "pandas.concat(objs, names=None)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . The `keys` , `levels` , and `names` arguments are all optional . With arguments `objs`.", "question_id": 11415},
{"snippet": "pandas.concat(objs, verify_integrity=False)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . Prevent the result from including duplicate index values with the `verify_integrity` option . With arguments `objs`.", "question_id": 11416},
{"snippet": "pandas.concat(objs, sort=False)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . With arguments `objs`, `sort`.", "question_id": 11417},
{"snippet": "pandas.concat(objs, copy=True)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . With arguments `objs`, `copy`.", "question_id": 11418},
{"snippet": "pandas.concat(objs)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . With arguments `objs`.", "question_id": 11419},
{"snippet": "pandas.concat(objs, axis=0)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . With arguments `objs`.", "question_id": 11420},
{"snippet": "pandas.concat(objs, join='outer')", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . Combine DataFrame objects with overlapping columns and return only those that are shared by passing inner to the `join` keyword argument . With arguments `objs`.", "question_id": 11421},
{"snippet": "pandas.concat(objs, ignore_index=False)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . Clear the existing index and reset it in the result by setting the `ignore_index` option to True . With arguments `objs`.", "question_id": 11422},
{"snippet": "pandas.concat(objs, keys=None)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . The `keys` , `levels` , and `names` arguments are all optional . With arguments `objs`.", "question_id": 11423},
{"snippet": "pandas.concat(objs, levels=None)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . The `keys` , `levels` , and `names` arguments are all optional . With arguments `objs`.", "question_id": 11424},
{"snippet": "pandas.concat(objs, names=None)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . The `keys` , `levels` , and `names` arguments are all optional . With arguments `objs`.", "question_id": 11425},
{"snippet": "pandas.concat(objs, verify_integrity=False)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . Prevent the result from including duplicate index values with the `verify_integrity` option . With arguments `objs`.", "question_id": 11426},
{"snippet": "pandas.concat(objs, sort=False)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . With arguments `objs`, `sort`.", "question_id": 11427},
{"snippet": "pandas.concat(objs, copy=True)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . With arguments `objs`, `copy`.", "question_id": 11428},
{"snippet": "pandas.concat(objs)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . With arguments `objs`.", "question_id": 11429},
{"snippet": "pandas.concat(objs, axis=0)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . With arguments `objs`.", "question_id": 11430},
{"snippet": "pandas.concat(objs, join='outer')", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . Combine DataFrame objects with overlapping columns and return only those that are shared by passing inner to the `join` keyword argument . With arguments `objs`.", "question_id": 11431},
{"snippet": "pandas.concat(objs, ignore_index=False)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . Clear the existing index and reset it in the result by setting the `ignore_index` option to True . With arguments `objs`.", "question_id": 11432},
{"snippet": "pandas.concat(objs, keys=None)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . The `keys` , `levels` , and `names` arguments are all optional . With arguments `objs`.", "question_id": 11433},
{"snippet": "pandas.concat(objs, levels=None)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . The `keys` , `levels` , and `names` arguments are all optional . With arguments `objs`.", "question_id": 11434},
{"snippet": "pandas.concat(objs, names=None)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . The `keys` , `levels` , and `names` arguments are all optional . With arguments `objs`.", "question_id": 11435},
{"snippet": "pandas.concat(objs, verify_integrity=False)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . Prevent the result from including duplicate index values with the `verify_integrity` option . With arguments `objs`.", "question_id": 11436},
{"snippet": "pandas.concat(objs, sort=False)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . With arguments `objs`, `sort`.", "question_id": 11437},
{"snippet": "pandas.concat(objs, copy=True)", "intent": "Concatenate pandas objects along a particular `axis` with optional set logic along the other axes . With arguments `objs`, `copy`.", "question_id": 11438},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`.", "question_id": 11439},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`.", "question_id": 11440},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, engine=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine`.", "question_id": 11441},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 11442},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, func=None, engine=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine`.", "question_id": 11443},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, func=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine_kwargs`.", "question_id": 11444},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine`, `engine_kwargs`.", "question_id": 11445},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, func=None, engine=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine`, `engine_kwargs`.", "question_id": 11446},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`.", "question_id": 11447},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`.", "question_id": 11448},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, engine=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine`.", "question_id": 11449},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 11450},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, func=None, engine=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine`.", "question_id": 11451},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, func=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine_kwargs`.", "question_id": 11452},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine`, `engine_kwargs`.", "question_id": 11453},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, func=None, engine=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine`, `engine_kwargs`.", "question_id": 11454},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`.", "question_id": 11455},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`.", "question_id": 11456},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, engine=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine`.", "question_id": 11457},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 11458},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, func=None, engine=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine`.", "question_id": 11459},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, func=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine_kwargs`.", "question_id": 11460},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine`, `engine_kwargs`.", "question_id": 11461},
{"snippet": "DataFrameGroupBy.aggregate(*args, **kwargs, func=None, engine=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine`, `engine_kwargs`.", "question_id": 11462},
{"snippet": "DataFrameGroupBy.all()", "intent": "Return True if all values in the group are truthful , else False .", "question_id": 11463},
{"snippet": "DataFrameGroupBy.all(skipna=True)", "intent": "Return True if all values in the group are truthful , else False . With arguments `skipna`.", "question_id": 11464},
{"snippet": "DataFrameGroupBy.all()", "intent": "Return True if all values in the group are truthful , else False .", "question_id": 11465},
{"snippet": "DataFrameGroupBy.all(skipna=True)", "intent": "Return True if all values in the group are truthful , else False . With arguments `skipna`.", "question_id": 11466},
{"snippet": "DataFrameGroupBy.all()", "intent": "Return True if all values in the group are truthful , else False .", "question_id": 11467},
{"snippet": "DataFrameGroupBy.all(skipna=True)", "intent": "Return True if all values in the group are truthful , else False . With arguments `skipna`.", "question_id": 11468},
{"snippet": "DataFrameGroupBy.any()", "intent": "Return True if any value in the group is truthful , else False .", "question_id": 11469},
{"snippet": "DataFrameGroupBy.any(skipna=True)", "intent": "Return True if any value in the group is truthful , else False . With arguments `skipna`.", "question_id": 11470},
{"snippet": "DataFrameGroupBy.any()", "intent": "Return True if any value in the group is truthful , else False .", "question_id": 11471},
{"snippet": "DataFrameGroupBy.any(skipna=True)", "intent": "Return True if any value in the group is truthful , else False . With arguments `skipna`.", "question_id": 11472},
{"snippet": "DataFrameGroupBy.any()", "intent": "Return True if any value in the group is truthful , else False .", "question_id": 11473},
{"snippet": "DataFrameGroupBy.any(skipna=True)", "intent": "Return True if any value in the group is truthful , else False . With arguments `skipna`.", "question_id": 11474},
{"snippet": "DataFrameGroupBy.backfill()", "intent": "Backward fill the values .", "question_id": 11475},
{"snippet": "DataFrameGroupBy.backfill(limit=None)", "intent": "Backward fill the values . With arguments `limit`.", "question_id": 11476},
{"snippet": "DataFrameGroupBy.backfill()", "intent": "Backward fill the values .", "question_id": 11477},
{"snippet": "DataFrameGroupBy.backfill(limit=None)", "intent": "Backward fill the values . With arguments `limit`.", "question_id": 11478},
{"snippet": "DataFrameGroupBy.backfill()", "intent": "Backward fill the values .", "question_id": 11479},
{"snippet": "DataFrameGroupBy.backfill(limit=None)", "intent": "Backward fill the values . With arguments `limit`.", "question_id": 11480},
{"snippet": "DataFrameGroupBy.bfill()", "intent": "Backward fill the values .", "question_id": 11481},
{"snippet": "DataFrameGroupBy.bfill(limit=None)", "intent": "Backward fill the values . With arguments `limit`.", "question_id": 11482},
{"snippet": "DataFrameGroupBy.bfill()", "intent": "Backward fill the values .", "question_id": 11483},
{"snippet": "DataFrameGroupBy.bfill(limit=None)", "intent": "Backward fill the values . With arguments `limit`.", "question_id": 11484},
{"snippet": "DataFrameGroupBy.bfill()", "intent": "Backward fill the values .", "question_id": 11485},
{"snippet": "DataFrameGroupBy.bfill(limit=None)", "intent": "Backward fill the values . With arguments `limit`.", "question_id": 11486},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`.", "question_id": 11487},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, subplots=True)", "intent": "Make box plots from DataFrameGroupBy data . You can create boxplots for grouped data and show them as separate `subplots` : With arguments `**kwargs`.", "question_id": 11488},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, column=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `column`.", "question_id": 11489},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, fontsize=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `fontsize`.", "question_id": 11490},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, rot=0)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `rot`.", "question_id": 11491},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, grid=True)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `grid`.", "question_id": 11492},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, ax=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `ax`.", "question_id": 11493},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, figsize=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `figsize`.", "question_id": 11494},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, layout=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `layout`.", "question_id": 11495},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, sharex=False)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `sharex`.", "question_id": 11496},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`.", "question_id": 11497},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, subplots=True)", "intent": "Make box plots from DataFrameGroupBy data . You can create boxplots for grouped data and show them as separate `subplots` : With arguments `**kwargs`.", "question_id": 11498},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, column=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `column`.", "question_id": 11499},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, fontsize=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `fontsize`.", "question_id": 11500},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, rot=0)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `rot`.", "question_id": 11501},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, grid=True)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `grid`.", "question_id": 11502},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, ax=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `ax`.", "question_id": 11503},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, figsize=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `figsize`.", "question_id": 11504},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, layout=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `layout`.", "question_id": 11505},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, sharex=False)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `sharex`.", "question_id": 11506},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`.", "question_id": 11507},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, subplots=True)", "intent": "Make box plots from DataFrameGroupBy data . You can create boxplots for grouped data and show them as separate `subplots` : With arguments `**kwargs`.", "question_id": 11508},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, column=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `column`.", "question_id": 11509},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, fontsize=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `fontsize`.", "question_id": 11510},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, rot=0)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `rot`.", "question_id": 11511},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, grid=True)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `grid`.", "question_id": 11512},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, ax=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `ax`.", "question_id": 11513},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, figsize=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `figsize`.", "question_id": 11514},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, layout=None)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `layout`.", "question_id": 11515},
{"snippet": "DataFrameGroupBy.boxplot(**kwargs, sharex=False)", "intent": "Make box plots from DataFrameGroupBy data . With arguments `**kwargs`, `sharex`.", "question_id": 11516},
{"snippet": "DataFrameGroupBy.count()", "intent": "Compute count of group , excluding missing values .", "question_id": 11517},
{"snippet": "DataFrameGroupBy.count()", "intent": "Compute count of group , excluding missing values .", "question_id": 11518},
{"snippet": "DataFrameGroupBy.count()", "intent": "Compute count of group , excluding missing values .", "question_id": 11519},
{"snippet": "DataFrameGroupBy.cumcount()", "intent": "Number each item in each group from 0 to the length of that group - 1 .", "question_id": 11520},
{"snippet": "DataFrameGroupBy.cumcount(ascending=True)", "intent": "Number each item in each group from 0 to the length of that group - 1 . With arguments `ascending`.", "question_id": 11521},
{"snippet": "DataFrameGroupBy.cumcount()", "intent": "Number each item in each group from 0 to the length of that group - 1 .", "question_id": 11522},
{"snippet": "DataFrameGroupBy.cumcount(ascending=True)", "intent": "Number each item in each group from 0 to the length of that group - 1 . With arguments `ascending`.", "question_id": 11523},
{"snippet": "DataFrameGroupBy.cumcount()", "intent": "Number each item in each group from 0 to the length of that group - 1 .", "question_id": 11524},
{"snippet": "DataFrameGroupBy.cumcount(ascending=True)", "intent": "Number each item in each group from 0 to the length of that group - 1 . With arguments `ascending`.", "question_id": 11525},
{"snippet": "DataFrameGroupBy.cummax(**kwargs)", "intent": "Cumulative max for each group . With arguments `**kwargs`.", "question_id": 11526},
{"snippet": "DataFrameGroupBy.cummax(**kwargs, axis=0)", "intent": "Cumulative max for each group . With arguments `**kwargs`, `axis`.", "question_id": 11527},
{"snippet": "DataFrameGroupBy.cummax(**kwargs)", "intent": "Cumulative max for each group . With arguments `**kwargs`.", "question_id": 11528},
{"snippet": "DataFrameGroupBy.cummax(**kwargs, axis=0)", "intent": "Cumulative max for each group . With arguments `**kwargs`, `axis`.", "question_id": 11529},
{"snippet": "DataFrameGroupBy.cummax(**kwargs)", "intent": "Cumulative max for each group . With arguments `**kwargs`.", "question_id": 11530},
{"snippet": "DataFrameGroupBy.cummax(**kwargs, axis=0)", "intent": "Cumulative max for each group . With arguments `**kwargs`, `axis`.", "question_id": 11531},
{"snippet": "DataFrameGroupBy.cummin(**kwargs)", "intent": "Cumulative min for each group . With arguments `**kwargs`.", "question_id": 11532},
{"snippet": "DataFrameGroupBy.cummin(**kwargs, axis=0)", "intent": "Cumulative min for each group . With arguments `**kwargs`, `axis`.", "question_id": 11533},
{"snippet": "DataFrameGroupBy.cummin(**kwargs)", "intent": "Cumulative min for each group . With arguments `**kwargs`.", "question_id": 11534},
{"snippet": "DataFrameGroupBy.cummin(**kwargs, axis=0)", "intent": "Cumulative min for each group . With arguments `**kwargs`, `axis`.", "question_id": 11535},
{"snippet": "DataFrameGroupBy.cummin(**kwargs)", "intent": "Cumulative min for each group . With arguments `**kwargs`.", "question_id": 11536},
{"snippet": "DataFrameGroupBy.cummin(**kwargs, axis=0)", "intent": "Cumulative min for each group . With arguments `**kwargs`, `axis`.", "question_id": 11537},
{"snippet": "DataFrameGroupBy.cumprod(*args, **kwargs)", "intent": "Cumulative product for each group . With arguments `*args`, `**kwargs`.", "question_id": 11538},
{"snippet": "DataFrameGroupBy.cumprod(*args, **kwargs, axis=0)", "intent": "Cumulative product for each group . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 11539},
{"snippet": "DataFrameGroupBy.cumprod(*args, **kwargs)", "intent": "Cumulative product for each group . With arguments `*args`, `**kwargs`.", "question_id": 11540},
{"snippet": "DataFrameGroupBy.cumprod(*args, **kwargs, axis=0)", "intent": "Cumulative product for each group . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 11541},
{"snippet": "DataFrameGroupBy.cumprod(*args, **kwargs)", "intent": "Cumulative product for each group . With arguments `*args`, `**kwargs`.", "question_id": 11542},
{"snippet": "DataFrameGroupBy.cumprod(*args, **kwargs, axis=0)", "intent": "Cumulative product for each group . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 11543},
{"snippet": "DataFrameGroupBy.cumsum(*args, **kwargs)", "intent": "Cumulative sum for each group . With arguments `*args`, `**kwargs`.", "question_id": 11544},
{"snippet": "DataFrameGroupBy.cumsum(*args, **kwargs, axis=0)", "intent": "Cumulative sum for each group . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 11545},
{"snippet": "DataFrameGroupBy.cumsum(*args, **kwargs)", "intent": "Cumulative sum for each group . With arguments `*args`, `**kwargs`.", "question_id": 11546},
{"snippet": "DataFrameGroupBy.cumsum(*args, **kwargs, axis=0)", "intent": "Cumulative sum for each group . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 11547},
{"snippet": "DataFrameGroupBy.cumsum(*args, **kwargs)", "intent": "Cumulative sum for each group . With arguments `*args`, `**kwargs`.", "question_id": 11548},
{"snippet": "DataFrameGroupBy.cumsum(*args, **kwargs, axis=0)", "intent": "Cumulative sum for each group . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 11549},
{"snippet": "DataFrameGroupBy.describe(**kwargs)", "intent": "Generate descriptive statistics . With arguments `**kwargs`.", "question_id": 11550},
{"snippet": "DataFrameGroupBy.describe(**kwargs)", "intent": "Generate descriptive statistics . With arguments `**kwargs`.", "question_id": 11551},
{"snippet": "DataFrameGroupBy.describe(**kwargs)", "intent": "Generate descriptive statistics . With arguments `**kwargs`.", "question_id": 11552},
{"snippet": "DataFrameGroupBy.ffill()", "intent": "Forward fill the values .", "question_id": 11553},
{"snippet": "DataFrameGroupBy.ffill(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 11554},
{"snippet": "DataFrameGroupBy.ffill()", "intent": "Forward fill the values .", "question_id": 11555},
{"snippet": "DataFrameGroupBy.ffill(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 11556},
{"snippet": "DataFrameGroupBy.ffill()", "intent": "Forward fill the values .", "question_id": 11557},
{"snippet": "DataFrameGroupBy.ffill(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 11558},
{"snippet": "DataFrameGroupBy.filter(func, *args, **kwargs)", "intent": "Return a copy of a DataFrame excluding filtered elements . Elements from groups are filtered if they do not satisfy the boolean criterion specified by `func` . With arguments `*args`, `**kwargs`.", "question_id": 11559},
{"snippet": "DataFrameGroupBy.filter(func, *args, **kwargs, dropna=True)", "intent": "Return a copy of a DataFrame excluding filtered elements . Elements from groups are filtered if they do not satisfy the boolean criterion specified by `func` . With arguments `*args`, `**kwargs`, `dropna`.", "question_id": 11560},
{"snippet": "DataFrameGroupBy.filter(func, *args, **kwargs)", "intent": "Return a copy of a DataFrame excluding filtered elements . Elements from groups are filtered if they do not satisfy the boolean criterion specified by `func` . With arguments `*args`, `**kwargs`.", "question_id": 11561},
{"snippet": "DataFrameGroupBy.filter(func, *args, **kwargs, dropna=True)", "intent": "Return a copy of a DataFrame excluding filtered elements . Elements from groups are filtered if they do not satisfy the boolean criterion specified by `func` . With arguments `*args`, `**kwargs`, `dropna`.", "question_id": 11562},
{"snippet": "DataFrameGroupBy.filter(func, *args, **kwargs)", "intent": "Return a copy of a DataFrame excluding filtered elements . Elements from groups are filtered if they do not satisfy the boolean criterion specified by `func` . With arguments `*args`, `**kwargs`.", "question_id": 11563},
{"snippet": "DataFrameGroupBy.filter(func, *args, **kwargs, dropna=True)", "intent": "Return a copy of a DataFrame excluding filtered elements . Elements from groups are filtered if they do not satisfy the boolean criterion specified by `func` . With arguments `*args`, `**kwargs`, `dropna`.", "question_id": 11564},
{"snippet": "DataFrameGroupBy.idxmax()", "intent": "Return index of first occurrence of maximum over requested `axis` .", "question_id": 11565},
{"snippet": "DataFrameGroupBy.idxmax(axis=0)", "intent": "Return index of first occurrence of maximum over requested `axis` .", "question_id": 11566},
{"snippet": "DataFrameGroupBy.idxmax(skipna=True)", "intent": "Return index of first occurrence of maximum over requested `axis` . With arguments `skipna`.", "question_id": 11567},
{"snippet": "DataFrameGroupBy.idxmax(axis=0, skipna=True)", "intent": "Return index of first occurrence of maximum over requested `axis` . With arguments `skipna`.", "question_id": 11568},
{"snippet": "DataFrameGroupBy.idxmax()", "intent": "Return index of first occurrence of maximum over requested `axis` .", "question_id": 11569},
{"snippet": "DataFrameGroupBy.idxmax(axis=0)", "intent": "Return index of first occurrence of maximum over requested `axis` .", "question_id": 11570},
{"snippet": "DataFrameGroupBy.idxmax(skipna=True)", "intent": "Return index of first occurrence of maximum over requested `axis` . With arguments `skipna`.", "question_id": 11571},
{"snippet": "DataFrameGroupBy.idxmax(axis=0, skipna=True)", "intent": "Return index of first occurrence of maximum over requested `axis` . With arguments `skipna`.", "question_id": 11572},
{"snippet": "DataFrameGroupBy.idxmax()", "intent": "Return index of first occurrence of maximum over requested `axis` .", "question_id": 11573},
{"snippet": "DataFrameGroupBy.idxmax(axis=0)", "intent": "Return index of first occurrence of maximum over requested `axis` .", "question_id": 11574},
{"snippet": "DataFrameGroupBy.idxmax(skipna=True)", "intent": "Return index of first occurrence of maximum over requested `axis` . With arguments `skipna`.", "question_id": 11575},
{"snippet": "DataFrameGroupBy.idxmax(axis=0, skipna=True)", "intent": "Return index of first occurrence of maximum over requested `axis` . With arguments `skipna`.", "question_id": 11576},
{"snippet": "DataFrameGroupBy.idxmin()", "intent": "Return index of first occurrence of minimum over requested `axis` .", "question_id": 11577},
{"snippet": "DataFrameGroupBy.idxmin(axis=0)", "intent": "Return index of first occurrence of minimum over requested `axis` .", "question_id": 11578},
{"snippet": "DataFrameGroupBy.idxmin(skipna=True)", "intent": "Return index of first occurrence of minimum over requested `axis` . With arguments `skipna`.", "question_id": 11579},
{"snippet": "DataFrameGroupBy.idxmin(axis=0, skipna=True)", "intent": "Return index of first occurrence of minimum over requested `axis` . With arguments `skipna`.", "question_id": 11580},
{"snippet": "DataFrameGroupBy.idxmin()", "intent": "Return index of first occurrence of minimum over requested `axis` .", "question_id": 11581},
{"snippet": "DataFrameGroupBy.idxmin(axis=0)", "intent": "Return index of first occurrence of minimum over requested `axis` .", "question_id": 11582},
{"snippet": "DataFrameGroupBy.idxmin(skipna=True)", "intent": "Return index of first occurrence of minimum over requested `axis` . With arguments `skipna`.", "question_id": 11583},
{"snippet": "DataFrameGroupBy.idxmin(axis=0, skipna=True)", "intent": "Return index of first occurrence of minimum over requested `axis` . With arguments `skipna`.", "question_id": 11584},
{"snippet": "DataFrameGroupBy.idxmin()", "intent": "Return index of first occurrence of minimum over requested `axis` .", "question_id": 11585},
{"snippet": "DataFrameGroupBy.idxmin(axis=0)", "intent": "Return index of first occurrence of minimum over requested `axis` .", "question_id": 11586},
{"snippet": "DataFrameGroupBy.idxmin(skipna=True)", "intent": "Return index of first occurrence of minimum over requested `axis` . With arguments `skipna`.", "question_id": 11587},
{"snippet": "DataFrameGroupBy.idxmin(axis=0, skipna=True)", "intent": "Return index of first occurrence of minimum over requested `axis` . With arguments `skipna`.", "question_id": 11588},
{"snippet": "DataFrameGroupBy.nunique()", "intent": "Return DataFrame with counts of unique elements in each position .", "question_id": 11589},
{"snippet": "DataFrameGroupBy.nunique(dropna=True)", "intent": "Return DataFrame with counts of unique elements in each position . With arguments `dropna`.", "question_id": 11590},
{"snippet": "DataFrameGroupBy.nunique()", "intent": "Return DataFrame with counts of unique elements in each position .", "question_id": 11591},
{"snippet": "DataFrameGroupBy.nunique(dropna=True)", "intent": "Return DataFrame with counts of unique elements in each position . With arguments `dropna`.", "question_id": 11592},
{"snippet": "DataFrameGroupBy.nunique()", "intent": "Return DataFrame with counts of unique elements in each position .", "question_id": 11593},
{"snippet": "DataFrameGroupBy.nunique(dropna=True)", "intent": "Return DataFrame with counts of unique elements in each position . With arguments `dropna`.", "question_id": 11594},
{"snippet": "DataFrameGroupBy.pad()", "intent": "Forward fill the values .", "question_id": 11595},
{"snippet": "DataFrameGroupBy.pad(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 11596},
{"snippet": "DataFrameGroupBy.pad()", "intent": "Forward fill the values .", "question_id": 11597},
{"snippet": "DataFrameGroupBy.pad(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 11598},
{"snippet": "DataFrameGroupBy.pad()", "intent": "Forward fill the values .", "question_id": 11599},
{"snippet": "DataFrameGroupBy.pad(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 11600},
{"snippet": "DataFrameGroupBy.pct_change()", "intent": "Calculate pct_change of each value to previous entry in group .", "question_id": 11601},
{"snippet": "DataFrameGroupBy.pct_change(periods=1)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`.", "question_id": 11602},
{"snippet": "DataFrameGroupBy.pct_change(fill_method='pad')", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `fill_method`.", "question_id": 11603},
{"snippet": "DataFrameGroupBy.pct_change(limit=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `limit`.", "question_id": 11604},
{"snippet": "DataFrameGroupBy.pct_change(freq=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `freq`.", "question_id": 11605},
{"snippet": "DataFrameGroupBy.pct_change(axis=0)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `axis`.", "question_id": 11606},
{"snippet": "DataFrameGroupBy.pct_change(periods=1, fill_method='pad')", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `fill_method`.", "question_id": 11607},
{"snippet": "DataFrameGroupBy.pct_change(periods=1, limit=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `limit`.", "question_id": 11608},
{"snippet": "DataFrameGroupBy.pct_change(periods=1, freq=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `freq`.", "question_id": 11609},
{"snippet": "DataFrameGroupBy.pct_change(periods=1, axis=0)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `axis`.", "question_id": 11610},
{"snippet": "DataFrameGroupBy.pct_change()", "intent": "Calculate pct_change of each value to previous entry in group .", "question_id": 11611},
{"snippet": "DataFrameGroupBy.pct_change(periods=1)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`.", "question_id": 11612},
{"snippet": "DataFrameGroupBy.pct_change(fill_method='pad')", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `fill_method`.", "question_id": 11613},
{"snippet": "DataFrameGroupBy.pct_change(limit=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `limit`.", "question_id": 11614},
{"snippet": "DataFrameGroupBy.pct_change(freq=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `freq`.", "question_id": 11615},
{"snippet": "DataFrameGroupBy.pct_change(axis=0)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `axis`.", "question_id": 11616},
{"snippet": "DataFrameGroupBy.pct_change(periods=1, fill_method='pad')", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `fill_method`.", "question_id": 11617},
{"snippet": "DataFrameGroupBy.pct_change(periods=1, limit=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `limit`.", "question_id": 11618},
{"snippet": "DataFrameGroupBy.pct_change(periods=1, freq=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `freq`.", "question_id": 11619},
{"snippet": "DataFrameGroupBy.pct_change(periods=1, axis=0)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `axis`.", "question_id": 11620},
{"snippet": "DataFrameGroupBy.pct_change()", "intent": "Calculate pct_change of each value to previous entry in group .", "question_id": 11621},
{"snippet": "DataFrameGroupBy.pct_change(periods=1)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`.", "question_id": 11622},
{"snippet": "DataFrameGroupBy.pct_change(fill_method='pad')", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `fill_method`.", "question_id": 11623},
{"snippet": "DataFrameGroupBy.pct_change(limit=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `limit`.", "question_id": 11624},
{"snippet": "DataFrameGroupBy.pct_change(freq=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `freq`.", "question_id": 11625},
{"snippet": "DataFrameGroupBy.pct_change(axis=0)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `axis`.", "question_id": 11626},
{"snippet": "DataFrameGroupBy.pct_change(periods=1, fill_method='pad')", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `fill_method`.", "question_id": 11627},
{"snippet": "DataFrameGroupBy.pct_change(periods=1, limit=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `limit`.", "question_id": 11628},
{"snippet": "DataFrameGroupBy.pct_change(periods=1, freq=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `freq`.", "question_id": 11629},
{"snippet": "DataFrameGroupBy.pct_change(periods=1, axis=0)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `axis`.", "question_id": 11630},
{"snippet": "DataFrameGroupBy.quantile()", "intent": "Return group values at the given quantile , a la numpy.percentile .", "question_id": 11631},
{"snippet": "DataFrameGroupBy.quantile(q=0.5)", "intent": "Return group values at the given quantile , a la numpy.percentile . With arguments `q`.", "question_id": 11632},
{"snippet": "DataFrameGroupBy.quantile(interpolation='linear')", "intent": "Return group values at the given quantile , a la numpy.percentile . With arguments `interpolation`.", "question_id": 11633},
{"snippet": "DataFrameGroupBy.quantile(q=0.5, interpolation='linear')", "intent": "Return group values at the given quantile , a la numpy.percentile . With arguments `q`, `interpolation`.", "question_id": 11634},
{"snippet": "DataFrameGroupBy.quantile()", "intent": "Return group values at the given quantile , a la numpy.percentile .", "question_id": 11635},
{"snippet": "DataFrameGroupBy.quantile(q=0.5)", "intent": "Return group values at the given quantile , a la numpy.percentile . With arguments `q`.", "question_id": 11636},
{"snippet": "DataFrameGroupBy.quantile(interpolation='linear')", "intent": "Return group values at the given quantile , a la numpy.percentile . With arguments `interpolation`.", "question_id": 11637},
{"snippet": "DataFrameGroupBy.quantile(q=0.5, interpolation='linear')", "intent": "Return group values at the given quantile , a la numpy.percentile . With arguments `q`, `interpolation`.", "question_id": 11638},
{"snippet": "DataFrameGroupBy.quantile()", "intent": "Return group values at the given quantile , a la numpy.percentile .", "question_id": 11639},
{"snippet": "DataFrameGroupBy.quantile(q=0.5)", "intent": "Return group values at the given quantile , a la numpy.percentile . With arguments `q`.", "question_id": 11640},
{"snippet": "DataFrameGroupBy.quantile(interpolation='linear')", "intent": "Return group values at the given quantile , a la numpy.percentile . With arguments `interpolation`.", "question_id": 11641},
{"snippet": "DataFrameGroupBy.quantile(q=0.5, interpolation='linear')", "intent": "Return group values at the given quantile , a la numpy.percentile . With arguments `q`, `interpolation`.", "question_id": 11642},
{"snippet": "DataFrameGroupBy.rank()", "intent": "Provide the rank of values within each group .", "question_id": 11643},
{"snippet": "DataFrameGroupBy.rank(method='average')", "intent": "Provide the rank of values within each group . With arguments `method`.", "question_id": 11644},
{"snippet": "DataFrameGroupBy.rank(ascending=True)", "intent": "Provide the rank of values within each group . With arguments `ascending`.", "question_id": 11645},
{"snippet": "DataFrameGroupBy.rank(na_option='keep')", "intent": "Provide the rank of values within each group . With arguments `na_option`.", "question_id": 11646},
{"snippet": "DataFrameGroupBy.rank(pct=False)", "intent": "Provide the rank of values within each group . With arguments `pct`.", "question_id": 11647},
{"snippet": "DataFrameGroupBy.rank(axis=0)", "intent": "Provide the rank of values within each group . With arguments `axis`.", "question_id": 11648},
{"snippet": "DataFrameGroupBy.rank(method='average', ascending=True)", "intent": "Provide the rank of values within each group . With arguments `method`, `ascending`.", "question_id": 11649},
{"snippet": "DataFrameGroupBy.rank(method='average', na_option='keep')", "intent": "Provide the rank of values within each group . With arguments `method`, `na_option`.", "question_id": 11650},
{"snippet": "DataFrameGroupBy.rank(method='average', pct=False)", "intent": "Provide the rank of values within each group . With arguments `method`, `pct`.", "question_id": 11651},
{"snippet": "DataFrameGroupBy.rank(method='average', axis=0)", "intent": "Provide the rank of values within each group . With arguments `method`, `axis`.", "question_id": 11652},
{"snippet": "DataFrameGroupBy.rank()", "intent": "Provide the rank of values within each group .", "question_id": 11653},
{"snippet": "DataFrameGroupBy.rank(method='average')", "intent": "Provide the rank of values within each group . With arguments `method`.", "question_id": 11654},
{"snippet": "DataFrameGroupBy.rank(ascending=True)", "intent": "Provide the rank of values within each group . With arguments `ascending`.", "question_id": 11655},
{"snippet": "DataFrameGroupBy.rank(na_option='keep')", "intent": "Provide the rank of values within each group . With arguments `na_option`.", "question_id": 11656},
{"snippet": "DataFrameGroupBy.rank(pct=False)", "intent": "Provide the rank of values within each group . With arguments `pct`.", "question_id": 11657},
{"snippet": "DataFrameGroupBy.rank(axis=0)", "intent": "Provide the rank of values within each group . With arguments `axis`.", "question_id": 11658},
{"snippet": "DataFrameGroupBy.rank(method='average', ascending=True)", "intent": "Provide the rank of values within each group . With arguments `method`, `ascending`.", "question_id": 11659},
{"snippet": "DataFrameGroupBy.rank(method='average', na_option='keep')", "intent": "Provide the rank of values within each group . With arguments `method`, `na_option`.", "question_id": 11660},
{"snippet": "DataFrameGroupBy.rank(method='average', pct=False)", "intent": "Provide the rank of values within each group . With arguments `method`, `pct`.", "question_id": 11661},
{"snippet": "DataFrameGroupBy.rank(method='average', axis=0)", "intent": "Provide the rank of values within each group . With arguments `method`, `axis`.", "question_id": 11662},
{"snippet": "DataFrameGroupBy.rank()", "intent": "Provide the rank of values within each group .", "question_id": 11663},
{"snippet": "DataFrameGroupBy.rank(method='average')", "intent": "Provide the rank of values within each group . With arguments `method`.", "question_id": 11664},
{"snippet": "DataFrameGroupBy.rank(ascending=True)", "intent": "Provide the rank of values within each group . With arguments `ascending`.", "question_id": 11665},
{"snippet": "DataFrameGroupBy.rank(na_option='keep')", "intent": "Provide the rank of values within each group . With arguments `na_option`.", "question_id": 11666},
{"snippet": "DataFrameGroupBy.rank(pct=False)", "intent": "Provide the rank of values within each group . With arguments `pct`.", "question_id": 11667},
{"snippet": "DataFrameGroupBy.rank(axis=0)", "intent": "Provide the rank of values within each group . With arguments `axis`.", "question_id": 11668},
{"snippet": "DataFrameGroupBy.rank(method='average', ascending=True)", "intent": "Provide the rank of values within each group . With arguments `method`, `ascending`.", "question_id": 11669},
{"snippet": "DataFrameGroupBy.rank(method='average', na_option='keep')", "intent": "Provide the rank of values within each group . With arguments `method`, `na_option`.", "question_id": 11670},
{"snippet": "DataFrameGroupBy.rank(method='average', pct=False)", "intent": "Provide the rank of values within each group . With arguments `method`, `pct`.", "question_id": 11671},
{"snippet": "DataFrameGroupBy.rank(method='average', axis=0)", "intent": "Provide the rank of values within each group . With arguments `method`, `axis`.", "question_id": 11672},
{"snippet": "DataFrameGroupBy.resample(rule, *args, **kwargs)", "intent": "Provide resampling when using a TimeGrouper . With arguments `rule`, `*args`, `**kwargs`.", "question_id": 11673},
{"snippet": "DataFrameGroupBy.resample(rule, *args, **kwargs)", "intent": "Provide resampling when using a TimeGrouper . With arguments `rule`, `*args`, `**kwargs`.", "question_id": 11674},
{"snippet": "DataFrameGroupBy.resample(rule, *args, **kwargs)", "intent": "Provide resampling when using a TimeGrouper . With arguments `rule`, `*args`, `**kwargs`.", "question_id": 11675},
{"snippet": "DataFrameGroupBy.sample()", "intent": "Return a random sample of items from each group .", "question_id": 11676},
{"snippet": "DataFrameGroupBy.sample(n=None)", "intent": "Return a random sample of items from each group . With arguments `n`.", "question_id": 11677},
{"snippet": "DataFrameGroupBy.sample(frac=None)", "intent": "Return a random sample of items from each group . Set `frac` to sample fixed proportions rather than counts :", "question_id": 11678},
{"snippet": "DataFrameGroupBy.sample(replace=False)", "intent": "Return a random sample of items from each group . With arguments `replace`.", "question_id": 11679},
{"snippet": "DataFrameGroupBy.sample(weights=None)", "intent": "Return a random sample of items from each group . Control sample probabilities within groups by setting `weights` :", "question_id": 11680},
{"snippet": "DataFrameGroupBy.sample(random_state=None)", "intent": "Return a random sample of items from each group . You can use `random_state` for reproducibility .", "question_id": 11681},
{"snippet": "DataFrameGroupBy.sample(n=None, frac=None)", "intent": "Return a random sample of items from each group . Set `frac` to sample fixed proportions rather than counts : With arguments `n`.", "question_id": 11682},
{"snippet": "DataFrameGroupBy.sample(n=None, replace=False)", "intent": "Return a random sample of items from each group . With arguments `n`, `replace`.", "question_id": 11683},
{"snippet": "DataFrameGroupBy.sample(n=None, weights=None)", "intent": "Return a random sample of items from each group . Control sample probabilities within groups by setting `weights` : With arguments `n`.", "question_id": 11684},
{"snippet": "DataFrameGroupBy.sample(n=None, random_state=None)", "intent": "Return a random sample of items from each group . You can use `random_state` for reproducibility . With arguments `n`.", "question_id": 11685},
{"snippet": "DataFrameGroupBy.sample()", "intent": "Return a random sample of items from each group .", "question_id": 11686},
{"snippet": "DataFrameGroupBy.sample(n=None)", "intent": "Return a random sample of items from each group . With arguments `n`.", "question_id": 11687},
{"snippet": "DataFrameGroupBy.sample(frac=None)", "intent": "Return a random sample of items from each group . Set `frac` to sample fixed proportions rather than counts :", "question_id": 11688},
{"snippet": "DataFrameGroupBy.sample(replace=False)", "intent": "Return a random sample of items from each group . With arguments `replace`.", "question_id": 11689},
{"snippet": "DataFrameGroupBy.sample(weights=None)", "intent": "Return a random sample of items from each group . Control sample probabilities within groups by setting `weights` :", "question_id": 11690},
{"snippet": "DataFrameGroupBy.sample(random_state=None)", "intent": "Return a random sample of items from each group . You can use `random_state` for reproducibility .", "question_id": 11691},
{"snippet": "DataFrameGroupBy.sample(n=None, frac=None)", "intent": "Return a random sample of items from each group . Set `frac` to sample fixed proportions rather than counts : With arguments `n`.", "question_id": 11692},
{"snippet": "DataFrameGroupBy.sample(n=None, replace=False)", "intent": "Return a random sample of items from each group . With arguments `n`, `replace`.", "question_id": 11693},
{"snippet": "DataFrameGroupBy.sample(n=None, weights=None)", "intent": "Return a random sample of items from each group . Control sample probabilities within groups by setting `weights` : With arguments `n`.", "question_id": 11694},
{"snippet": "DataFrameGroupBy.sample(n=None, random_state=None)", "intent": "Return a random sample of items from each group . You can use `random_state` for reproducibility . With arguments `n`.", "question_id": 11695},
{"snippet": "DataFrameGroupBy.sample()", "intent": "Return a random sample of items from each group .", "question_id": 11696},
{"snippet": "DataFrameGroupBy.sample(n=None)", "intent": "Return a random sample of items from each group . With arguments `n`.", "question_id": 11697},
{"snippet": "DataFrameGroupBy.sample(frac=None)", "intent": "Return a random sample of items from each group . Set `frac` to sample fixed proportions rather than counts :", "question_id": 11698},
{"snippet": "DataFrameGroupBy.sample(replace=False)", "intent": "Return a random sample of items from each group . With arguments `replace`.", "question_id": 11699},
{"snippet": "DataFrameGroupBy.sample(weights=None)", "intent": "Return a random sample of items from each group . Control sample probabilities within groups by setting `weights` :", "question_id": 11700},
{"snippet": "DataFrameGroupBy.sample(random_state=None)", "intent": "Return a random sample of items from each group . You can use `random_state` for reproducibility .", "question_id": 11701},
{"snippet": "DataFrameGroupBy.sample(n=None, frac=None)", "intent": "Return a random sample of items from each group . Set `frac` to sample fixed proportions rather than counts : With arguments `n`.", "question_id": 11702},
{"snippet": "DataFrameGroupBy.sample(n=None, replace=False)", "intent": "Return a random sample of items from each group . With arguments `n`, `replace`.", "question_id": 11703},
{"snippet": "DataFrameGroupBy.sample(n=None, weights=None)", "intent": "Return a random sample of items from each group . Control sample probabilities within groups by setting `weights` : With arguments `n`.", "question_id": 11704},
{"snippet": "DataFrameGroupBy.sample(n=None, random_state=None)", "intent": "Return a random sample of items from each group . You can use `random_state` for reproducibility . With arguments `n`.", "question_id": 11705},
{"snippet": "DataFrameGroupBy.shift()", "intent": "Shift each group by `periods` observations .", "question_id": 11706},
{"snippet": "DataFrameGroupBy.shift(periods=1)", "intent": "Shift each group by `periods` observations .", "question_id": 11707},
{"snippet": "DataFrameGroupBy.shift(freq=None)", "intent": "Shift each group by `periods` observations . If `freq` is passed , the index will be increased using the periods and the freq .", "question_id": 11708},
{"snippet": "DataFrameGroupBy.shift(axis=0)", "intent": "Shift each group by `periods` observations . With arguments `axis`.", "question_id": 11709},
{"snippet": "DataFrameGroupBy.shift(fill_value=None)", "intent": "Shift each group by `periods` observations . With arguments `fill_value`.", "question_id": 11710},
{"snippet": "DataFrameGroupBy.shift(periods=1, freq=None)", "intent": "Shift each group by `periods` observations . If `freq` is passed , the index will be increased using the periods and the freq .", "question_id": 11711},
{"snippet": "DataFrameGroupBy.shift(periods=1, axis=0)", "intent": "Shift each group by `periods` observations . With arguments `axis`.", "question_id": 11712},
{"snippet": "DataFrameGroupBy.shift(periods=1, fill_value=None)", "intent": "Shift each group by `periods` observations . With arguments `fill_value`.", "question_id": 11713},
{"snippet": "DataFrameGroupBy.shift(freq=None, axis=0)", "intent": "Shift each group by `periods` observations . If `freq` is passed , the index will be increased using the periods and the freq . With arguments `axis`.", "question_id": 11714},
{"snippet": "DataFrameGroupBy.shift(freq=None, fill_value=None)", "intent": "Shift each group by `periods` observations . If `freq` is passed , the index will be increased using the periods and the freq . With arguments `fill_value`.", "question_id": 11715},
{"snippet": "DataFrameGroupBy.shift()", "intent": "Shift each group by `periods` observations .", "question_id": 11716},
{"snippet": "DataFrameGroupBy.shift(periods=1)", "intent": "Shift each group by `periods` observations .", "question_id": 11717},
{"snippet": "DataFrameGroupBy.shift(freq=None)", "intent": "Shift each group by `periods` observations . If `freq` is passed , the index will be increased using the periods and the freq .", "question_id": 11718},
{"snippet": "DataFrameGroupBy.shift(axis=0)", "intent": "Shift each group by `periods` observations . With arguments `axis`.", "question_id": 11719},
{"snippet": "DataFrameGroupBy.shift(fill_value=None)", "intent": "Shift each group by `periods` observations . With arguments `fill_value`.", "question_id": 11720},
{"snippet": "DataFrameGroupBy.shift(periods=1, freq=None)", "intent": "Shift each group by `periods` observations . If `freq` is passed , the index will be increased using the periods and the freq .", "question_id": 11721},
{"snippet": "DataFrameGroupBy.shift(periods=1, axis=0)", "intent": "Shift each group by `periods` observations . With arguments `axis`.", "question_id": 11722},
{"snippet": "DataFrameGroupBy.shift(periods=1, fill_value=None)", "intent": "Shift each group by `periods` observations . With arguments `fill_value`.", "question_id": 11723},
{"snippet": "DataFrameGroupBy.shift(freq=None, axis=0)", "intent": "Shift each group by `periods` observations . If `freq` is passed , the index will be increased using the periods and the freq . With arguments `axis`.", "question_id": 11724},
{"snippet": "DataFrameGroupBy.shift(freq=None, fill_value=None)", "intent": "Shift each group by `periods` observations . If `freq` is passed , the index will be increased using the periods and the freq . With arguments `fill_value`.", "question_id": 11725},
{"snippet": "DataFrameGroupBy.shift()", "intent": "Shift each group by `periods` observations .", "question_id": 11726},
{"snippet": "DataFrameGroupBy.shift(periods=1)", "intent": "Shift each group by `periods` observations .", "question_id": 11727},
{"snippet": "DataFrameGroupBy.shift(freq=None)", "intent": "Shift each group by `periods` observations . If `freq` is passed , the index will be increased using the periods and the freq .", "question_id": 11728},
{"snippet": "DataFrameGroupBy.shift(axis=0)", "intent": "Shift each group by `periods` observations . With arguments `axis`.", "question_id": 11729},
{"snippet": "DataFrameGroupBy.shift(fill_value=None)", "intent": "Shift each group by `periods` observations . With arguments `fill_value`.", "question_id": 11730},
{"snippet": "DataFrameGroupBy.shift(periods=1, freq=None)", "intent": "Shift each group by `periods` observations . If `freq` is passed , the index will be increased using the periods and the freq .", "question_id": 11731},
{"snippet": "DataFrameGroupBy.shift(periods=1, axis=0)", "intent": "Shift each group by `periods` observations . With arguments `axis`.", "question_id": 11732},
{"snippet": "DataFrameGroupBy.shift(periods=1, fill_value=None)", "intent": "Shift each group by `periods` observations . With arguments `fill_value`.", "question_id": 11733},
{"snippet": "DataFrameGroupBy.shift(freq=None, axis=0)", "intent": "Shift each group by `periods` observations . If `freq` is passed , the index will be increased using the periods and the freq . With arguments `axis`.", "question_id": 11734},
{"snippet": "DataFrameGroupBy.shift(freq=None, fill_value=None)", "intent": "Shift each group by `periods` observations . If `freq` is passed , the index will be increased using the periods and the freq . With arguments `fill_value`.", "question_id": 11735},
{"snippet": "DataFrameGroupBy.size()", "intent": "Compute group sizes .", "question_id": 11736},
{"snippet": "DataFrameGroupBy.size()", "intent": "Compute group sizes .", "question_id": 11737},
{"snippet": "DataFrameGroupBy.size()", "intent": "Compute group sizes .", "question_id": 11738},
{"snippet": "DataFrameGroupBy.transform(func, *args, **kwargs)", "intent": "Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`.", "question_id": 11739},
{"snippet": "DataFrameGroupBy.transform(func, *args, **kwargs, engine=None)", "intent": "Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine`.", "question_id": 11740},
{"snippet": "DataFrameGroupBy.transform(func, *args, **kwargs, engine_kwargs=None)", "intent": "Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 11741},
{"snippet": "DataFrameGroupBy.transform(func, *args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine`, `engine_kwargs`.", "question_id": 11742},
{"snippet": "DataFrameGroupBy.transform(func, *args, **kwargs)", "intent": "Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`.", "question_id": 11743},
{"snippet": "DataFrameGroupBy.transform(func, *args, **kwargs, engine=None)", "intent": "Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine`.", "question_id": 11744},
{"snippet": "DataFrameGroupBy.transform(func, *args, **kwargs, engine_kwargs=None)", "intent": "Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 11745},
{"snippet": "DataFrameGroupBy.transform(func, *args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine`, `engine_kwargs`.", "question_id": 11746},
{"snippet": "DataFrameGroupBy.transform(func, *args, **kwargs)", "intent": "Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`.", "question_id": 11747},
{"snippet": "DataFrameGroupBy.transform(func, *args, **kwargs, engine=None)", "intent": "Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine`.", "question_id": 11748},
{"snippet": "DataFrameGroupBy.transform(func, *args, **kwargs, engine_kwargs=None)", "intent": "Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 11749},
{"snippet": "DataFrameGroupBy.transform(func, *args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine`, `engine_kwargs`.", "question_id": 11750},
{"snippet": "GroupBy.__iter__()", "intent": "Groupby iterator .", "question_id": 11751},
{"snippet": "GroupBy.__iter__()", "intent": "Groupby iterator .", "question_id": 11752},
{"snippet": "GroupBy.__iter__()", "intent": "Groupby iterator .", "question_id": 11753},
{"snippet": "GroupBy.all()", "intent": "Return True if all values in the group are truthful , else False .", "question_id": 11754},
{"snippet": "GroupBy.all(skipna=True)", "intent": "Return True if all values in the group are truthful , else False . With arguments `skipna`.", "question_id": 11755},
{"snippet": "GroupBy.all()", "intent": "Return True if all values in the group are truthful , else False .", "question_id": 11756},
{"snippet": "GroupBy.all(skipna=True)", "intent": "Return True if all values in the group are truthful , else False . With arguments `skipna`.", "question_id": 11757},
{"snippet": "GroupBy.all()", "intent": "Return True if all values in the group are truthful , else False .", "question_id": 11758},
{"snippet": "GroupBy.all(skipna=True)", "intent": "Return True if all values in the group are truthful , else False . With arguments `skipna`.", "question_id": 11759},
{"snippet": "GroupBy.any()", "intent": "Return True if any value in the group is truthful , else False .", "question_id": 11760},
{"snippet": "GroupBy.any(skipna=True)", "intent": "Return True if any value in the group is truthful , else False . With arguments `skipna`.", "question_id": 11761},
{"snippet": "GroupBy.any()", "intent": "Return True if any value in the group is truthful , else False .", "question_id": 11762},
{"snippet": "GroupBy.any(skipna=True)", "intent": "Return True if any value in the group is truthful , else False . With arguments `skipna`.", "question_id": 11763},
{"snippet": "GroupBy.any()", "intent": "Return True if any value in the group is truthful , else False .", "question_id": 11764},
{"snippet": "GroupBy.any(skipna=True)", "intent": "Return True if any value in the group is truthful , else False . With arguments `skipna`.", "question_id": 11765},
{"snippet": "GroupBy.apply(func, *args, **kwargs)", "intent": "Apply function `func` group-wise and combine the results together . With arguments `*args`, `**kwargs`.", "question_id": 11766},
{"snippet": "GroupBy.apply(func, *args, **kwargs)", "intent": "Apply function `func` group-wise and combine the results together . With arguments `*args`, `**kwargs`.", "question_id": 11767},
{"snippet": "GroupBy.apply(func, *args, **kwargs)", "intent": "Apply function `func` group-wise and combine the results together . With arguments `*args`, `**kwargs`.", "question_id": 11768},
{"snippet": "GroupBy.backfill()", "intent": "Backward fill the values .", "question_id": 11769},
{"snippet": "GroupBy.backfill(limit=None)", "intent": "Backward fill the values . With arguments `limit`.", "question_id": 11770},
{"snippet": "GroupBy.backfill()", "intent": "Backward fill the values .", "question_id": 11771},
{"snippet": "GroupBy.backfill(limit=None)", "intent": "Backward fill the values . With arguments `limit`.", "question_id": 11772},
{"snippet": "GroupBy.backfill()", "intent": "Backward fill the values .", "question_id": 11773},
{"snippet": "GroupBy.backfill(limit=None)", "intent": "Backward fill the values . With arguments `limit`.", "question_id": 11774},
{"snippet": "GroupBy.bfill()", "intent": "Backward fill the values .", "question_id": 11775},
{"snippet": "GroupBy.bfill(limit=None)", "intent": "Backward fill the values . With arguments `limit`.", "question_id": 11776},
{"snippet": "GroupBy.bfill()", "intent": "Backward fill the values .", "question_id": 11777},
{"snippet": "GroupBy.bfill(limit=None)", "intent": "Backward fill the values . With arguments `limit`.", "question_id": 11778},
{"snippet": "GroupBy.bfill()", "intent": "Backward fill the values .", "question_id": 11779},
{"snippet": "GroupBy.bfill(limit=None)", "intent": "Backward fill the values . With arguments `limit`.", "question_id": 11780},
{"snippet": "GroupBy.count()", "intent": "Compute count of group , excluding missing values .", "question_id": 11781},
{"snippet": "GroupBy.count()", "intent": "Compute count of group , excluding missing values .", "question_id": 11782},
{"snippet": "GroupBy.count()", "intent": "Compute count of group , excluding missing values .", "question_id": 11783},
{"snippet": "GroupBy.cumcount()", "intent": "Number each item in each group from 0 to the length of that group - 1 .", "question_id": 11784},
{"snippet": "GroupBy.cumcount(ascending=True)", "intent": "Number each item in each group from 0 to the length of that group - 1 . With arguments `ascending`.", "question_id": 11785},
{"snippet": "GroupBy.cumcount()", "intent": "Number each item in each group from 0 to the length of that group - 1 .", "question_id": 11786},
{"snippet": "GroupBy.cumcount(ascending=True)", "intent": "Number each item in each group from 0 to the length of that group - 1 . With arguments `ascending`.", "question_id": 11787},
{"snippet": "GroupBy.cumcount()", "intent": "Number each item in each group from 0 to the length of that group - 1 .", "question_id": 11788},
{"snippet": "GroupBy.cumcount(ascending=True)", "intent": "Number each item in each group from 0 to the length of that group - 1 . With arguments `ascending`.", "question_id": 11789},
{"snippet": "GroupBy.cummax(**kwargs)", "intent": "Cumulative max for each group . With arguments `**kwargs`.", "question_id": 11790},
{"snippet": "GroupBy.cummax(**kwargs, axis=0)", "intent": "Cumulative max for each group . With arguments `**kwargs`, `axis`.", "question_id": 11791},
{"snippet": "GroupBy.cummax(**kwargs)", "intent": "Cumulative max for each group . With arguments `**kwargs`.", "question_id": 11792},
{"snippet": "GroupBy.cummax(**kwargs, axis=0)", "intent": "Cumulative max for each group . With arguments `**kwargs`, `axis`.", "question_id": 11793},
{"snippet": "GroupBy.cummax(**kwargs)", "intent": "Cumulative max for each group . With arguments `**kwargs`.", "question_id": 11794},
{"snippet": "GroupBy.cummax(**kwargs, axis=0)", "intent": "Cumulative max for each group . With arguments `**kwargs`, `axis`.", "question_id": 11795},
{"snippet": "GroupBy.cummin(**kwargs)", "intent": "Cumulative min for each group . With arguments `**kwargs`.", "question_id": 11796},
{"snippet": "GroupBy.cummin(**kwargs, axis=0)", "intent": "Cumulative min for each group . With arguments `**kwargs`, `axis`.", "question_id": 11797},
{"snippet": "GroupBy.cummin(**kwargs)", "intent": "Cumulative min for each group . With arguments `**kwargs`.", "question_id": 11798},
{"snippet": "GroupBy.cummin(**kwargs, axis=0)", "intent": "Cumulative min for each group . With arguments `**kwargs`, `axis`.", "question_id": 11799},
{"snippet": "GroupBy.cummin(**kwargs)", "intent": "Cumulative min for each group . With arguments `**kwargs`.", "question_id": 11800},
{"snippet": "GroupBy.cummin(**kwargs, axis=0)", "intent": "Cumulative min for each group . With arguments `**kwargs`, `axis`.", "question_id": 11801},
{"snippet": "GroupBy.cumprod(*args, **kwargs)", "intent": "Cumulative product for each group . With arguments `*args`, `**kwargs`.", "question_id": 11802},
{"snippet": "GroupBy.cumprod(*args, **kwargs, axis=0)", "intent": "Cumulative product for each group . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 11803},
{"snippet": "GroupBy.cumprod(*args, **kwargs)", "intent": "Cumulative product for each group . With arguments `*args`, `**kwargs`.", "question_id": 11804},
{"snippet": "GroupBy.cumprod(*args, **kwargs, axis=0)", "intent": "Cumulative product for each group . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 11805},
{"snippet": "GroupBy.cumprod(*args, **kwargs)", "intent": "Cumulative product for each group . With arguments `*args`, `**kwargs`.", "question_id": 11806},
{"snippet": "GroupBy.cumprod(*args, **kwargs, axis=0)", "intent": "Cumulative product for each group . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 11807},
{"snippet": "GroupBy.cumsum(*args, **kwargs)", "intent": "Cumulative sum for each group . With arguments `*args`, `**kwargs`.", "question_id": 11808},
{"snippet": "GroupBy.cumsum(*args, **kwargs, axis=0)", "intent": "Cumulative sum for each group . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 11809},
{"snippet": "GroupBy.cumsum(*args, **kwargs)", "intent": "Cumulative sum for each group . With arguments `*args`, `**kwargs`.", "question_id": 11810},
{"snippet": "GroupBy.cumsum(*args, **kwargs, axis=0)", "intent": "Cumulative sum for each group . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 11811},
{"snippet": "GroupBy.cumsum(*args, **kwargs)", "intent": "Cumulative sum for each group . With arguments `*args`, `**kwargs`.", "question_id": 11812},
{"snippet": "GroupBy.cumsum(*args, **kwargs, axis=0)", "intent": "Cumulative sum for each group . With arguments `*args`, `**kwargs`, `axis`.", "question_id": 11813},
{"snippet": "GroupBy.ffill()", "intent": "Forward fill the values .", "question_id": 11814},
{"snippet": "GroupBy.ffill(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 11815},
{"snippet": "GroupBy.ffill()", "intent": "Forward fill the values .", "question_id": 11816},
{"snippet": "GroupBy.ffill(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 11817},
{"snippet": "GroupBy.ffill()", "intent": "Forward fill the values .", "question_id": 11818},
{"snippet": "GroupBy.ffill(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 11819},
{"snippet": "GroupBy.first()", "intent": "Compute first of group values .", "question_id": 11820},
{"snippet": "GroupBy.first(numeric_only=False)", "intent": "Compute first of group values . With arguments `numeric_only`.", "question_id": 11821},
{"snippet": "GroupBy.first(min_count=- 1)", "intent": "Compute first of group values . With arguments `min_count`.", "question_id": 11822},
{"snippet": "GroupBy.first(numeric_only=False, min_count=- 1)", "intent": "Compute first of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11823},
{"snippet": "GroupBy.first()", "intent": "Compute first of group values .", "question_id": 11824},
{"snippet": "GroupBy.first(numeric_only=False)", "intent": "Compute first of group values . With arguments `numeric_only`.", "question_id": 11825},
{"snippet": "GroupBy.first(min_count=- 1)", "intent": "Compute first of group values . With arguments `min_count`.", "question_id": 11826},
{"snippet": "GroupBy.first(numeric_only=False, min_count=- 1)", "intent": "Compute first of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11827},
{"snippet": "GroupBy.first()", "intent": "Compute first of group values .", "question_id": 11828},
{"snippet": "GroupBy.first(numeric_only=False)", "intent": "Compute first of group values . With arguments `numeric_only`.", "question_id": 11829},
{"snippet": "GroupBy.first(min_count=- 1)", "intent": "Compute first of group values . With arguments `min_count`.", "question_id": 11830},
{"snippet": "GroupBy.first(numeric_only=False, min_count=- 1)", "intent": "Compute first of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11831},
{"snippet": "GroupBy.get_group(name)", "intent": "Construct DataFrame from group with provided `name` .", "question_id": 11832},
{"snippet": "GroupBy.get_group(name, obj=None)", "intent": "Construct DataFrame from group with provided `name` . With arguments `obj`.", "question_id": 11833},
{"snippet": "GroupBy.get_group(name)", "intent": "Construct DataFrame from group with provided `name` .", "question_id": 11834},
{"snippet": "GroupBy.get_group(name, obj=None)", "intent": "Construct DataFrame from group with provided `name` . With arguments `obj`.", "question_id": 11835},
{"snippet": "GroupBy.get_group(name)", "intent": "Construct DataFrame from group with provided `name` .", "question_id": 11836},
{"snippet": "GroupBy.get_group(name, obj=None)", "intent": "Construct DataFrame from group with provided `name` . With arguments `obj`.", "question_id": 11837},
{"snippet": "GroupBy.head()", "intent": "Return first `n` rows of each group .", "question_id": 11838},
{"snippet": "GroupBy.head(n=5)", "intent": "Return first `n` rows of each group .", "question_id": 11839},
{"snippet": "GroupBy.head()", "intent": "Return first `n` rows of each group .", "question_id": 11840},
{"snippet": "GroupBy.head(n=5)", "intent": "Return first `n` rows of each group .", "question_id": 11841},
{"snippet": "GroupBy.head()", "intent": "Return first `n` rows of each group .", "question_id": 11842},
{"snippet": "GroupBy.head(n=5)", "intent": "Return first `n` rows of each group .", "question_id": 11843},
{"snippet": "GroupBy.last()", "intent": "Compute last of group values .", "question_id": 11844},
{"snippet": "GroupBy.last(numeric_only=False)", "intent": "Compute last of group values . With arguments `numeric_only`.", "question_id": 11845},
{"snippet": "GroupBy.last(min_count=- 1)", "intent": "Compute last of group values . With arguments `min_count`.", "question_id": 11846},
{"snippet": "GroupBy.last(numeric_only=False, min_count=- 1)", "intent": "Compute last of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11847},
{"snippet": "GroupBy.last()", "intent": "Compute last of group values .", "question_id": 11848},
{"snippet": "GroupBy.last(numeric_only=False)", "intent": "Compute last of group values . With arguments `numeric_only`.", "question_id": 11849},
{"snippet": "GroupBy.last(min_count=- 1)", "intent": "Compute last of group values . With arguments `min_count`.", "question_id": 11850},
{"snippet": "GroupBy.last(numeric_only=False, min_count=- 1)", "intent": "Compute last of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11851},
{"snippet": "GroupBy.last()", "intent": "Compute last of group values .", "question_id": 11852},
{"snippet": "GroupBy.last(numeric_only=False)", "intent": "Compute last of group values . With arguments `numeric_only`.", "question_id": 11853},
{"snippet": "GroupBy.last(min_count=- 1)", "intent": "Compute last of group values . With arguments `min_count`.", "question_id": 11854},
{"snippet": "GroupBy.last(numeric_only=False, min_count=- 1)", "intent": "Compute last of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11855},
{"snippet": "GroupBy.max()", "intent": "Compute max of group values .", "question_id": 11856},
{"snippet": "GroupBy.max(numeric_only=False)", "intent": "Compute max of group values . With arguments `numeric_only`.", "question_id": 11857},
{"snippet": "GroupBy.max(min_count=- 1)", "intent": "Compute max of group values . With arguments `min_count`.", "question_id": 11858},
{"snippet": "GroupBy.max(numeric_only=False, min_count=- 1)", "intent": "Compute max of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11859},
{"snippet": "GroupBy.max()", "intent": "Compute max of group values .", "question_id": 11860},
{"snippet": "GroupBy.max(numeric_only=False)", "intent": "Compute max of group values . With arguments `numeric_only`.", "question_id": 11861},
{"snippet": "GroupBy.max(min_count=- 1)", "intent": "Compute max of group values . With arguments `min_count`.", "question_id": 11862},
{"snippet": "GroupBy.max(numeric_only=False, min_count=- 1)", "intent": "Compute max of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11863},
{"snippet": "GroupBy.max()", "intent": "Compute max of group values .", "question_id": 11864},
{"snippet": "GroupBy.max(numeric_only=False)", "intent": "Compute max of group values . With arguments `numeric_only`.", "question_id": 11865},
{"snippet": "GroupBy.max(min_count=- 1)", "intent": "Compute max of group values . With arguments `min_count`.", "question_id": 11866},
{"snippet": "GroupBy.max(numeric_only=False, min_count=- 1)", "intent": "Compute max of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11867},
{"snippet": "GroupBy.mean()", "intent": "Compute mean of groups , excluding missing values .", "question_id": 11868},
{"snippet": "GroupBy.mean(numeric_only=NoDefault.no_default)", "intent": "Compute mean of groups , excluding missing values . With arguments `numeric_only`.", "question_id": 11869},
{"snippet": "GroupBy.mean()", "intent": "Compute mean of groups , excluding missing values .", "question_id": 11870},
{"snippet": "GroupBy.mean(numeric_only=NoDefault.no_default)", "intent": "Compute mean of groups , excluding missing values . With arguments `numeric_only`.", "question_id": 11871},
{"snippet": "GroupBy.mean()", "intent": "Compute mean of groups , excluding missing values .", "question_id": 11872},
{"snippet": "GroupBy.mean(numeric_only=NoDefault.no_default)", "intent": "Compute mean of groups , excluding missing values . With arguments `numeric_only`.", "question_id": 11873},
{"snippet": "GroupBy.median()", "intent": "Compute median of groups , excluding missing values .", "question_id": 11874},
{"snippet": "GroupBy.median(numeric_only=NoDefault.no_default)", "intent": "Compute median of groups , excluding missing values . With arguments `numeric_only`.", "question_id": 11875},
{"snippet": "GroupBy.median()", "intent": "Compute median of groups , excluding missing values .", "question_id": 11876},
{"snippet": "GroupBy.median(numeric_only=NoDefault.no_default)", "intent": "Compute median of groups , excluding missing values . With arguments `numeric_only`.", "question_id": 11877},
{"snippet": "GroupBy.median()", "intent": "Compute median of groups , excluding missing values .", "question_id": 11878},
{"snippet": "GroupBy.median(numeric_only=NoDefault.no_default)", "intent": "Compute median of groups , excluding missing values . With arguments `numeric_only`.", "question_id": 11879},
{"snippet": "GroupBy.min()", "intent": "Compute min of group values .", "question_id": 11880},
{"snippet": "GroupBy.min(numeric_only=False)", "intent": "Compute min of group values . With arguments `numeric_only`.", "question_id": 11881},
{"snippet": "GroupBy.min(min_count=- 1)", "intent": "Compute min of group values . With arguments `min_count`.", "question_id": 11882},
{"snippet": "GroupBy.min(numeric_only=False, min_count=- 1)", "intent": "Compute min of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11883},
{"snippet": "GroupBy.min()", "intent": "Compute min of group values .", "question_id": 11884},
{"snippet": "GroupBy.min(numeric_only=False)", "intent": "Compute min of group values . With arguments `numeric_only`.", "question_id": 11885},
{"snippet": "GroupBy.min(min_count=- 1)", "intent": "Compute min of group values . With arguments `min_count`.", "question_id": 11886},
{"snippet": "GroupBy.min(numeric_only=False, min_count=- 1)", "intent": "Compute min of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11887},
{"snippet": "GroupBy.min()", "intent": "Compute min of group values .", "question_id": 11888},
{"snippet": "GroupBy.min(numeric_only=False)", "intent": "Compute min of group values . With arguments `numeric_only`.", "question_id": 11889},
{"snippet": "GroupBy.min(min_count=- 1)", "intent": "Compute min of group values . With arguments `min_count`.", "question_id": 11890},
{"snippet": "GroupBy.min(numeric_only=False, min_count=- 1)", "intent": "Compute min of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11891},
{"snippet": "GroupBy.ngroup()", "intent": "Number each group from 0 to the number of groups - 1 .", "question_id": 11892},
{"snippet": "GroupBy.ngroup(ascending=True)", "intent": "Number each group from 0 to the number of groups - 1 . With arguments `ascending`.", "question_id": 11893},
{"snippet": "GroupBy.ngroup()", "intent": "Number each group from 0 to the number of groups - 1 .", "question_id": 11894},
{"snippet": "GroupBy.ngroup(ascending=True)", "intent": "Number each group from 0 to the number of groups - 1 . With arguments `ascending`.", "question_id": 11895},
{"snippet": "GroupBy.ngroup()", "intent": "Number each group from 0 to the number of groups - 1 .", "question_id": 11896},
{"snippet": "GroupBy.ngroup(ascending=True)", "intent": "Number each group from 0 to the number of groups - 1 . With arguments `ascending`.", "question_id": 11897},
{"snippet": "GroupBy.nth(n)", "intent": "Take the nth row from each group if `n` is an int , or a subset of rows if n is a list of ints .", "question_id": 11898},
{"snippet": "GroupBy.nth(n, dropna=None)", "intent": "Take the nth row from each group if `n` is an int , or a subset of rows if n is a list of ints . If `dropna` , will take the nth non-null row , dropna is either \u2018 all \u2019 or \u2018 any \u2019 ; this is equivalent to calling dropna ( how=dropna ) before the groupby .", "question_id": 11899},
{"snippet": "GroupBy.nth(n)", "intent": "Take the nth row from each group if `n` is an int , or a subset of rows if n is a list of ints .", "question_id": 11900},
{"snippet": "GroupBy.nth(n, dropna=None)", "intent": "Take the nth row from each group if `n` is an int , or a subset of rows if n is a list of ints . If `dropna` , will take the nth non-null row , dropna is either \u2018 all \u2019 or \u2018 any \u2019 ; this is equivalent to calling dropna ( how=dropna ) before the groupby .", "question_id": 11901},
{"snippet": "GroupBy.nth(n)", "intent": "Take the nth row from each group if `n` is an int , or a subset of rows if n is a list of ints .", "question_id": 11902},
{"snippet": "GroupBy.nth(n, dropna=None)", "intent": "Take the nth row from each group if `n` is an int , or a subset of rows if n is a list of ints . If `dropna` , will take the nth non-null row , dropna is either \u2018 all \u2019 or \u2018 any \u2019 ; this is equivalent to calling dropna ( how=dropna ) before the groupby .", "question_id": 11903},
{"snippet": "GroupBy.ohlc()", "intent": "Compute open , high , low and close values of a group , excluding missing values .", "question_id": 11904},
{"snippet": "GroupBy.ohlc()", "intent": "Compute open , high , low and close values of a group , excluding missing values .", "question_id": 11905},
{"snippet": "GroupBy.ohlc()", "intent": "Compute open , high , low and close values of a group , excluding missing values .", "question_id": 11906},
{"snippet": "GroupBy.pad()", "intent": "Forward fill the values .", "question_id": 11907},
{"snippet": "GroupBy.pad(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 11908},
{"snippet": "GroupBy.pad()", "intent": "Forward fill the values .", "question_id": 11909},
{"snippet": "GroupBy.pad(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 11910},
{"snippet": "GroupBy.pad()", "intent": "Forward fill the values .", "question_id": 11911},
{"snippet": "GroupBy.pad(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 11912},
{"snippet": "GroupBy.pct_change()", "intent": "Calculate pct_change of each value to previous entry in group .", "question_id": 11913},
{"snippet": "GroupBy.pct_change(periods=1)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`.", "question_id": 11914},
{"snippet": "GroupBy.pct_change(fill_method='pad')", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `fill_method`.", "question_id": 11915},
{"snippet": "GroupBy.pct_change(limit=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `limit`.", "question_id": 11916},
{"snippet": "GroupBy.pct_change(freq=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `freq`.", "question_id": 11917},
{"snippet": "GroupBy.pct_change(axis=0)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `axis`.", "question_id": 11918},
{"snippet": "GroupBy.pct_change(periods=1, fill_method='pad')", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `fill_method`.", "question_id": 11919},
{"snippet": "GroupBy.pct_change(periods=1, limit=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `limit`.", "question_id": 11920},
{"snippet": "GroupBy.pct_change(periods=1, freq=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `freq`.", "question_id": 11921},
{"snippet": "GroupBy.pct_change(periods=1, axis=0)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `axis`.", "question_id": 11922},
{"snippet": "GroupBy.pct_change()", "intent": "Calculate pct_change of each value to previous entry in group .", "question_id": 11923},
{"snippet": "GroupBy.pct_change(periods=1)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`.", "question_id": 11924},
{"snippet": "GroupBy.pct_change(fill_method='pad')", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `fill_method`.", "question_id": 11925},
{"snippet": "GroupBy.pct_change(limit=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `limit`.", "question_id": 11926},
{"snippet": "GroupBy.pct_change(freq=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `freq`.", "question_id": 11927},
{"snippet": "GroupBy.pct_change(axis=0)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `axis`.", "question_id": 11928},
{"snippet": "GroupBy.pct_change(periods=1, fill_method='pad')", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `fill_method`.", "question_id": 11929},
{"snippet": "GroupBy.pct_change(periods=1, limit=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `limit`.", "question_id": 11930},
{"snippet": "GroupBy.pct_change(periods=1, freq=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `freq`.", "question_id": 11931},
{"snippet": "GroupBy.pct_change(periods=1, axis=0)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `axis`.", "question_id": 11932},
{"snippet": "GroupBy.pct_change()", "intent": "Calculate pct_change of each value to previous entry in group .", "question_id": 11933},
{"snippet": "GroupBy.pct_change(periods=1)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`.", "question_id": 11934},
{"snippet": "GroupBy.pct_change(fill_method='pad')", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `fill_method`.", "question_id": 11935},
{"snippet": "GroupBy.pct_change(limit=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `limit`.", "question_id": 11936},
{"snippet": "GroupBy.pct_change(freq=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `freq`.", "question_id": 11937},
{"snippet": "GroupBy.pct_change(axis=0)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `axis`.", "question_id": 11938},
{"snippet": "GroupBy.pct_change(periods=1, fill_method='pad')", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `fill_method`.", "question_id": 11939},
{"snippet": "GroupBy.pct_change(periods=1, limit=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `limit`.", "question_id": 11940},
{"snippet": "GroupBy.pct_change(periods=1, freq=None)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `freq`.", "question_id": 11941},
{"snippet": "GroupBy.pct_change(periods=1, axis=0)", "intent": "Calculate pct_change of each value to previous entry in group . With arguments `periods`, `axis`.", "question_id": 11942},
{"snippet": "GroupBy.pipe(func, *args, **kwargs)", "intent": "Apply a function `func` with arguments to this GroupBy object and return the function \u2019 s result . With arguments `*args`, `**kwargs`.", "question_id": 11943},
{"snippet": "GroupBy.pipe(func, *args, **kwargs)", "intent": "Apply a function `func` with arguments to this GroupBy object and return the function \u2019 s result . With arguments `*args`, `**kwargs`.", "question_id": 11944},
{"snippet": "GroupBy.pipe(func, *args, **kwargs)", "intent": "Apply a function `func` with arguments to this GroupBy object and return the function \u2019 s result . With arguments `*args`, `**kwargs`.", "question_id": 11945},
{"snippet": "GroupBy.prod()", "intent": "Compute prod of group values .", "question_id": 11946},
{"snippet": "GroupBy.prod(numeric_only=NoDefault.no_default)", "intent": "Compute prod of group values . With arguments `numeric_only`.", "question_id": 11947},
{"snippet": "GroupBy.prod(min_count=0)", "intent": "Compute prod of group values . With arguments `min_count`.", "question_id": 11948},
{"snippet": "GroupBy.prod(numeric_only=NoDefault.no_default, min_count=0)", "intent": "Compute prod of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11949},
{"snippet": "GroupBy.prod()", "intent": "Compute prod of group values .", "question_id": 11950},
{"snippet": "GroupBy.prod(numeric_only=NoDefault.no_default)", "intent": "Compute prod of group values . With arguments `numeric_only`.", "question_id": 11951},
{"snippet": "GroupBy.prod(min_count=0)", "intent": "Compute prod of group values . With arguments `min_count`.", "question_id": 11952},
{"snippet": "GroupBy.prod(numeric_only=NoDefault.no_default, min_count=0)", "intent": "Compute prod of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11953},
{"snippet": "GroupBy.prod()", "intent": "Compute prod of group values .", "question_id": 11954},
{"snippet": "GroupBy.prod(numeric_only=NoDefault.no_default)", "intent": "Compute prod of group values . With arguments `numeric_only`.", "question_id": 11955},
{"snippet": "GroupBy.prod(min_count=0)", "intent": "Compute prod of group values . With arguments `min_count`.", "question_id": 11956},
{"snippet": "GroupBy.prod(numeric_only=NoDefault.no_default, min_count=0)", "intent": "Compute prod of group values . With arguments `numeric_only`, `min_count`.", "question_id": 11957},
{"snippet": "GroupBy.rank()", "intent": "Provide the rank of values within each group .", "question_id": 11958},
{"snippet": "GroupBy.rank(method='average')", "intent": "Provide the rank of values within each group . With arguments `method`.", "question_id": 11959},
{"snippet": "GroupBy.rank(ascending=True)", "intent": "Provide the rank of values within each group . With arguments `ascending`.", "question_id": 11960},
{"snippet": "GroupBy.rank(na_option='keep')", "intent": "Provide the rank of values within each group . With arguments `na_option`.", "question_id": 11961},
{"snippet": "GroupBy.rank(pct=False)", "intent": "Provide the rank of values within each group . With arguments `pct`.", "question_id": 11962},
{"snippet": "GroupBy.rank(axis=0)", "intent": "Provide the rank of values within each group . With arguments `axis`.", "question_id": 11963},
{"snippet": "GroupBy.rank(method='average', ascending=True)", "intent": "Provide the rank of values within each group . With arguments `method`, `ascending`.", "question_id": 11964},
{"snippet": "GroupBy.rank(method='average', na_option='keep')", "intent": "Provide the rank of values within each group . With arguments `method`, `na_option`.", "question_id": 11965},
{"snippet": "GroupBy.rank(method='average', pct=False)", "intent": "Provide the rank of values within each group . With arguments `method`, `pct`.", "question_id": 11966},
{"snippet": "GroupBy.rank(method='average', axis=0)", "intent": "Provide the rank of values within each group . With arguments `method`, `axis`.", "question_id": 11967},
{"snippet": "GroupBy.rank()", "intent": "Provide the rank of values within each group .", "question_id": 11968},
{"snippet": "GroupBy.rank(method='average')", "intent": "Provide the rank of values within each group . With arguments `method`.", "question_id": 11969},
{"snippet": "GroupBy.rank(ascending=True)", "intent": "Provide the rank of values within each group . With arguments `ascending`.", "question_id": 11970},
{"snippet": "GroupBy.rank(na_option='keep')", "intent": "Provide the rank of values within each group . With arguments `na_option`.", "question_id": 11971},
{"snippet": "GroupBy.rank(pct=False)", "intent": "Provide the rank of values within each group . With arguments `pct`.", "question_id": 11972},
{"snippet": "GroupBy.rank(axis=0)", "intent": "Provide the rank of values within each group . With arguments `axis`.", "question_id": 11973},
{"snippet": "GroupBy.rank(method='average', ascending=True)", "intent": "Provide the rank of values within each group . With arguments `method`, `ascending`.", "question_id": 11974},
{"snippet": "GroupBy.rank(method='average', na_option='keep')", "intent": "Provide the rank of values within each group . With arguments `method`, `na_option`.", "question_id": 11975},
{"snippet": "GroupBy.rank(method='average', pct=False)", "intent": "Provide the rank of values within each group . With arguments `method`, `pct`.", "question_id": 11976},
{"snippet": "GroupBy.rank(method='average', axis=0)", "intent": "Provide the rank of values within each group . With arguments `method`, `axis`.", "question_id": 11977},
{"snippet": "GroupBy.rank()", "intent": "Provide the rank of values within each group .", "question_id": 11978},
{"snippet": "GroupBy.rank(method='average')", "intent": "Provide the rank of values within each group . With arguments `method`.", "question_id": 11979},
{"snippet": "GroupBy.rank(ascending=True)", "intent": "Provide the rank of values within each group . With arguments `ascending`.", "question_id": 11980},
{"snippet": "GroupBy.rank(na_option='keep')", "intent": "Provide the rank of values within each group . With arguments `na_option`.", "question_id": 11981},
{"snippet": "GroupBy.rank(pct=False)", "intent": "Provide the rank of values within each group . With arguments `pct`.", "question_id": 11982},
{"snippet": "GroupBy.rank(axis=0)", "intent": "Provide the rank of values within each group . With arguments `axis`.", "question_id": 11983},
{"snippet": "GroupBy.rank(method='average', ascending=True)", "intent": "Provide the rank of values within each group . With arguments `method`, `ascending`.", "question_id": 11984},
{"snippet": "GroupBy.rank(method='average', na_option='keep')", "intent": "Provide the rank of values within each group . With arguments `method`, `na_option`.", "question_id": 11985},
{"snippet": "GroupBy.rank(method='average', pct=False)", "intent": "Provide the rank of values within each group . With arguments `method`, `pct`.", "question_id": 11986},
{"snippet": "GroupBy.rank(method='average', axis=0)", "intent": "Provide the rank of values within each group . With arguments `method`, `axis`.", "question_id": 11987},
{"snippet": "GroupBy.sem()", "intent": "Compute standard error of the mean of groups , excluding missing values .", "question_id": 11988},
{"snippet": "GroupBy.sem(ddof=1)", "intent": "Compute standard error of the mean of groups , excluding missing values . With arguments `ddof`.", "question_id": 11989},
{"snippet": "GroupBy.sem()", "intent": "Compute standard error of the mean of groups , excluding missing values .", "question_id": 11990},
{"snippet": "GroupBy.sem(ddof=1)", "intent": "Compute standard error of the mean of groups , excluding missing values . With arguments `ddof`.", "question_id": 11991},
{"snippet": "GroupBy.sem()", "intent": "Compute standard error of the mean of groups , excluding missing values .", "question_id": 11992},
{"snippet": "GroupBy.sem(ddof=1)", "intent": "Compute standard error of the mean of groups , excluding missing values . With arguments `ddof`.", "question_id": 11993},
{"snippet": "GroupBy.size()", "intent": "Compute group sizes .", "question_id": 11994},
{"snippet": "GroupBy.size()", "intent": "Compute group sizes .", "question_id": 11995},
{"snippet": "GroupBy.size()", "intent": "Compute group sizes .", "question_id": 11996},
{"snippet": "GroupBy.std()", "intent": "Compute standard deviation of groups , excluding missing values .", "question_id": 11997},
{"snippet": "GroupBy.std(ddof=1)", "intent": "Compute standard deviation of groups , excluding missing values . With arguments `ddof`.", "question_id": 11998},
{"snippet": "GroupBy.std()", "intent": "Compute standard deviation of groups , excluding missing values .", "question_id": 11999},
{"snippet": "GroupBy.std(ddof=1)", "intent": "Compute standard deviation of groups , excluding missing values . With arguments `ddof`.", "question_id": 12000},
{"snippet": "GroupBy.std()", "intent": "Compute standard deviation of groups , excluding missing values .", "question_id": 12001},
{"snippet": "GroupBy.std(ddof=1)", "intent": "Compute standard deviation of groups , excluding missing values . With arguments `ddof`.", "question_id": 12002},
{"snippet": "GroupBy.sum()", "intent": "Compute sum of group values .", "question_id": 12003},
{"snippet": "GroupBy.sum(numeric_only=NoDefault.no_default)", "intent": "Compute sum of group values . With arguments `numeric_only`.", "question_id": 12004},
{"snippet": "GroupBy.sum(min_count=0)", "intent": "Compute sum of group values . With arguments `min_count`.", "question_id": 12005},
{"snippet": "GroupBy.sum(numeric_only=NoDefault.no_default, min_count=0)", "intent": "Compute sum of group values . With arguments `numeric_only`, `min_count`.", "question_id": 12006},
{"snippet": "GroupBy.sum()", "intent": "Compute sum of group values .", "question_id": 12007},
{"snippet": "GroupBy.sum(numeric_only=NoDefault.no_default)", "intent": "Compute sum of group values . With arguments `numeric_only`.", "question_id": 12008},
{"snippet": "GroupBy.sum(min_count=0)", "intent": "Compute sum of group values . With arguments `min_count`.", "question_id": 12009},
{"snippet": "GroupBy.sum(numeric_only=NoDefault.no_default, min_count=0)", "intent": "Compute sum of group values . With arguments `numeric_only`, `min_count`.", "question_id": 12010},
{"snippet": "GroupBy.sum()", "intent": "Compute sum of group values .", "question_id": 12011},
{"snippet": "GroupBy.sum(numeric_only=NoDefault.no_default)", "intent": "Compute sum of group values . With arguments `numeric_only`.", "question_id": 12012},
{"snippet": "GroupBy.sum(min_count=0)", "intent": "Compute sum of group values . With arguments `min_count`.", "question_id": 12013},
{"snippet": "GroupBy.sum(numeric_only=NoDefault.no_default, min_count=0)", "intent": "Compute sum of group values . With arguments `numeric_only`, `min_count`.", "question_id": 12014},
{"snippet": "GroupBy.tail()", "intent": "Return last `n` rows of each group .", "question_id": 12015},
{"snippet": "GroupBy.tail(n=5)", "intent": "Return last `n` rows of each group .", "question_id": 12016},
{"snippet": "GroupBy.tail()", "intent": "Return last `n` rows of each group .", "question_id": 12017},
{"snippet": "GroupBy.tail(n=5)", "intent": "Return last `n` rows of each group .", "question_id": 12018},
{"snippet": "GroupBy.tail()", "intent": "Return last `n` rows of each group .", "question_id": 12019},
{"snippet": "GroupBy.tail(n=5)", "intent": "Return last `n` rows of each group .", "question_id": 12020},
{"snippet": "GroupBy.var()", "intent": "Compute variance of groups , excluding missing values .", "question_id": 12021},
{"snippet": "GroupBy.var(ddof=1)", "intent": "Compute variance of groups , excluding missing values . With arguments `ddof`.", "question_id": 12022},
{"snippet": "GroupBy.var()", "intent": "Compute variance of groups , excluding missing values .", "question_id": 12023},
{"snippet": "GroupBy.var(ddof=1)", "intent": "Compute variance of groups , excluding missing values . With arguments `ddof`.", "question_id": 12024},
{"snippet": "GroupBy.var()", "intent": "Compute variance of groups , excluding missing values .", "question_id": 12025},
{"snippet": "GroupBy.var(ddof=1)", "intent": "Compute variance of groups , excluding missing values . With arguments `ddof`.", "question_id": 12026},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`.", "question_id": 12027},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`.", "question_id": 12028},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, engine=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine`.", "question_id": 12029},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12030},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, func=None, engine=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine`.", "question_id": 12031},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, func=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine_kwargs`.", "question_id": 12032},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine`, `engine_kwargs`.", "question_id": 12033},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, func=None, engine=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine`, `engine_kwargs`.", "question_id": 12034},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`.", "question_id": 12035},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`.", "question_id": 12036},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, engine=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine`.", "question_id": 12037},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12038},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, func=None, engine=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine`.", "question_id": 12039},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, func=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine_kwargs`.", "question_id": 12040},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine`, `engine_kwargs`.", "question_id": 12041},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, func=None, engine=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine`, `engine_kwargs`.", "question_id": 12042},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`.", "question_id": 12043},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, func=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`.", "question_id": 12044},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, engine=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine`.", "question_id": 12045},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12046},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, func=None, engine=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine`.", "question_id": 12047},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, func=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine_kwargs`.", "question_id": 12048},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `engine`, `engine_kwargs`.", "question_id": 12049},
{"snippet": "SeriesGroupBy.aggregate(*args, **kwargs, func=None, engine=None, engine_kwargs=None)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `*args`, `**kwargs`, `func`, `engine`, `engine_kwargs`.", "question_id": 12050},
{"snippet": "SeriesGroupBy.nunique()", "intent": "Return number of unique elements in the group .", "question_id": 12051},
{"snippet": "SeriesGroupBy.nunique(dropna=True)", "intent": "Return number of unique elements in the group . With arguments `dropna`.", "question_id": 12052},
{"snippet": "SeriesGroupBy.nunique()", "intent": "Return number of unique elements in the group .", "question_id": 12053},
{"snippet": "SeriesGroupBy.nunique(dropna=True)", "intent": "Return number of unique elements in the group . With arguments `dropna`.", "question_id": 12054},
{"snippet": "SeriesGroupBy.nunique()", "intent": "Return number of unique elements in the group .", "question_id": 12055},
{"snippet": "SeriesGroupBy.nunique(dropna=True)", "intent": "Return number of unique elements in the group . With arguments `dropna`.", "question_id": 12056},
{"snippet": "SeriesGroupBy.transform(func, *args, **kwargs)", "intent": "Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`.", "question_id": 12057},
{"snippet": "SeriesGroupBy.transform(func, *args, **kwargs, engine=None)", "intent": "Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine`.", "question_id": 12058},
{"snippet": "SeriesGroupBy.transform(func, *args, **kwargs, engine_kwargs=None)", "intent": "Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12059},
{"snippet": "SeriesGroupBy.transform(func, *args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine`, `engine_kwargs`.", "question_id": 12060},
{"snippet": "SeriesGroupBy.transform(func, *args, **kwargs)", "intent": "Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`.", "question_id": 12061},
{"snippet": "SeriesGroupBy.transform(func, *args, **kwargs, engine=None)", "intent": "Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine`.", "question_id": 12062},
{"snippet": "SeriesGroupBy.transform(func, *args, **kwargs, engine_kwargs=None)", "intent": "Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12063},
{"snippet": "SeriesGroupBy.transform(func, *args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine`, `engine_kwargs`.", "question_id": 12064},
{"snippet": "SeriesGroupBy.transform(func, *args, **kwargs)", "intent": "Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`.", "question_id": 12065},
{"snippet": "SeriesGroupBy.transform(func, *args, **kwargs, engine=None)", "intent": "Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine`.", "question_id": 12066},
{"snippet": "SeriesGroupBy.transform(func, *args, **kwargs, engine_kwargs=None)", "intent": "Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12067},
{"snippet": "SeriesGroupBy.transform(func, *args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values With arguments `func`, `*args`, `**kwargs`, `engine`, `engine_kwargs`.", "question_id": 12068},
{"snippet": "Resampler.__iter__()", "intent": "Groupby iterator .", "question_id": 12069},
{"snippet": "Resampler.__iter__()", "intent": "Groupby iterator .", "question_id": 12070},
{"snippet": "Resampler.__iter__()", "intent": "Groupby iterator .", "question_id": 12071},
{"snippet": "Resampler.aggregate(func, *args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `func`, `*args`, `**kwargs`.", "question_id": 12072},
{"snippet": "Resampler.aggregate(func, *args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `func`, `*args`, `**kwargs`.", "question_id": 12073},
{"snippet": "Resampler.aggregate(func, *args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `func`, `*args`, `**kwargs`.", "question_id": 12074},
{"snippet": "Resampler.apply(func, *args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `func`, `*args`, `**kwargs`.", "question_id": 12075},
{"snippet": "Resampler.apply(func, *args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `func`, `*args`, `**kwargs`.", "question_id": 12076},
{"snippet": "Resampler.apply(func, *args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `func`, `*args`, `**kwargs`.", "question_id": 12077},
{"snippet": "Resampler.asfreq()", "intent": "Return the values at the new freq , essentially a reindex .", "question_id": 12078},
{"snippet": "Resampler.asfreq(fill_value=None)", "intent": "Return the values at the new freq , essentially a reindex . With arguments `fill_value`.", "question_id": 12079},
{"snippet": "Resampler.asfreq()", "intent": "Return the values at the new freq , essentially a reindex .", "question_id": 12080},
{"snippet": "Resampler.asfreq(fill_value=None)", "intent": "Return the values at the new freq , essentially a reindex . With arguments `fill_value`.", "question_id": 12081},
{"snippet": "Resampler.asfreq()", "intent": "Return the values at the new freq , essentially a reindex .", "question_id": 12082},
{"snippet": "Resampler.asfreq(fill_value=None)", "intent": "Return the values at the new freq , essentially a reindex . With arguments `fill_value`.", "question_id": 12083},
{"snippet": "Resampler.backfill()", "intent": "Backward fill the new missing values in the resampled data .", "question_id": 12084},
{"snippet": "Resampler.backfill(limit=None)", "intent": "Backward fill the new missing values in the resampled data . With arguments `limit`.", "question_id": 12085},
{"snippet": "Resampler.backfill()", "intent": "Backward fill the new missing values in the resampled data .", "question_id": 12086},
{"snippet": "Resampler.backfill(limit=None)", "intent": "Backward fill the new missing values in the resampled data . With arguments `limit`.", "question_id": 12087},
{"snippet": "Resampler.backfill()", "intent": "Backward fill the new missing values in the resampled data .", "question_id": 12088},
{"snippet": "Resampler.backfill(limit=None)", "intent": "Backward fill the new missing values in the resampled data . With arguments `limit`.", "question_id": 12089},
{"snippet": "Resampler.bfill()", "intent": "Backward fill the new missing values in the resampled data .", "question_id": 12090},
{"snippet": "Resampler.bfill(limit=None)", "intent": "Backward fill the new missing values in the resampled data . With arguments `limit`.", "question_id": 12091},
{"snippet": "Resampler.bfill()", "intent": "Backward fill the new missing values in the resampled data .", "question_id": 12092},
{"snippet": "Resampler.bfill(limit=None)", "intent": "Backward fill the new missing values in the resampled data . With arguments `limit`.", "question_id": 12093},
{"snippet": "Resampler.bfill()", "intent": "Backward fill the new missing values in the resampled data .", "question_id": 12094},
{"snippet": "Resampler.bfill(limit=None)", "intent": "Backward fill the new missing values in the resampled data . With arguments `limit`.", "question_id": 12095},
{"snippet": "Resampler.count()", "intent": "Compute count of group , excluding missing values .", "question_id": 12096},
{"snippet": "Resampler.count()", "intent": "Compute count of group , excluding missing values .", "question_id": 12097},
{"snippet": "Resampler.count()", "intent": "Compute count of group , excluding missing values .", "question_id": 12098},
{"snippet": "Resampler.ffill()", "intent": "Forward fill the values .", "question_id": 12099},
{"snippet": "Resampler.ffill(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 12100},
{"snippet": "Resampler.ffill()", "intent": "Forward fill the values .", "question_id": 12101},
{"snippet": "Resampler.ffill(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 12102},
{"snippet": "Resampler.ffill()", "intent": "Forward fill the values .", "question_id": 12103},
{"snippet": "Resampler.ffill(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 12104},
{"snippet": "Resampler.fillna(method)", "intent": "Fill missing values introduced by upsampling . With arguments `method`.", "question_id": 12105},
{"snippet": "Resampler.fillna(method, limit=None)", "intent": "Fill missing values introduced by upsampling . With arguments `method`, `limit`.", "question_id": 12106},
{"snippet": "Resampler.fillna(method)", "intent": "Fill missing values introduced by upsampling . With arguments `method`.", "question_id": 12107},
{"snippet": "Resampler.fillna(method, limit=None)", "intent": "Fill missing values introduced by upsampling . With arguments `method`, `limit`.", "question_id": 12108},
{"snippet": "Resampler.fillna(method)", "intent": "Fill missing values introduced by upsampling . With arguments `method`.", "question_id": 12109},
{"snippet": "Resampler.fillna(method, limit=None)", "intent": "Fill missing values introduced by upsampling . With arguments `method`, `limit`.", "question_id": 12110},
{"snippet": "Resampler.first(*args, **kwargs)", "intent": "Compute first of group values . With arguments `*args`, `**kwargs`.", "question_id": 12111},
{"snippet": "Resampler.first(*args, **kwargs, _method='first')", "intent": "Compute first of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12112},
{"snippet": "Resampler.first(*args, **kwargs, min_count=0)", "intent": "Compute first of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12113},
{"snippet": "Resampler.first(*args, **kwargs, _method='first', min_count=0)", "intent": "Compute first of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12114},
{"snippet": "Resampler.first(*args, **kwargs)", "intent": "Compute first of group values . With arguments `*args`, `**kwargs`.", "question_id": 12115},
{"snippet": "Resampler.first(*args, **kwargs, _method='first')", "intent": "Compute first of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12116},
{"snippet": "Resampler.first(*args, **kwargs, min_count=0)", "intent": "Compute first of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12117},
{"snippet": "Resampler.first(*args, **kwargs, _method='first', min_count=0)", "intent": "Compute first of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12118},
{"snippet": "Resampler.first(*args, **kwargs)", "intent": "Compute first of group values . With arguments `*args`, `**kwargs`.", "question_id": 12119},
{"snippet": "Resampler.first(*args, **kwargs, _method='first')", "intent": "Compute first of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12120},
{"snippet": "Resampler.first(*args, **kwargs, min_count=0)", "intent": "Compute first of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12121},
{"snippet": "Resampler.first(*args, **kwargs, _method='first', min_count=0)", "intent": "Compute first of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12122},
{"snippet": "Resampler.get_group(name)", "intent": "Construct DataFrame from group with provided `name` .", "question_id": 12123},
{"snippet": "Resampler.get_group(name, obj=None)", "intent": "Construct DataFrame from group with provided `name` . With arguments `obj`.", "question_id": 12124},
{"snippet": "Resampler.get_group(name)", "intent": "Construct DataFrame from group with provided `name` .", "question_id": 12125},
{"snippet": "Resampler.get_group(name, obj=None)", "intent": "Construct DataFrame from group with provided `name` . With arguments `obj`.", "question_id": 12126},
{"snippet": "Resampler.get_group(name)", "intent": "Construct DataFrame from group with provided `name` .", "question_id": 12127},
{"snippet": "Resampler.get_group(name, obj=None)", "intent": "Construct DataFrame from group with provided `name` . With arguments `obj`.", "question_id": 12128},
{"snippet": "Resampler.interpolate(**kwargs)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`.", "question_id": 12129},
{"snippet": "Resampler.interpolate(**kwargs, method='linear')", "intent": "Interpolate values according to different methods . Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 12130},
{"snippet": "Resampler.interpolate(**kwargs, axis=0)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `axis`.", "question_id": 12131},
{"snippet": "Resampler.interpolate(**kwargs, limit=None)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `limit`.", "question_id": 12132},
{"snippet": "Resampler.interpolate(**kwargs, inplace=False)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `inplace`.", "question_id": 12133},
{"snippet": "Resampler.interpolate(**kwargs, limit_direction='forward')", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `limit_direction`.", "question_id": 12134},
{"snippet": "Resampler.interpolate(**kwargs, limit_area=None)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `limit_area`.", "question_id": 12135},
{"snippet": "Resampler.interpolate(**kwargs, downcast=None)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `downcast`.", "question_id": 12136},
{"snippet": "Resampler.interpolate(**kwargs, method='linear', axis=0)", "intent": "Interpolate values according to different methods . Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 12137},
{"snippet": "Resampler.interpolate(**kwargs, method='linear', limit=None)", "intent": "Interpolate values according to different methods . Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 12138},
{"snippet": "Resampler.interpolate(**kwargs)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`.", "question_id": 12139},
{"snippet": "Resampler.interpolate(**kwargs, method='linear')", "intent": "Interpolate values according to different methods . Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 12140},
{"snippet": "Resampler.interpolate(**kwargs, axis=0)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `axis`.", "question_id": 12141},
{"snippet": "Resampler.interpolate(**kwargs, limit=None)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `limit`.", "question_id": 12142},
{"snippet": "Resampler.interpolate(**kwargs, inplace=False)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `inplace`.", "question_id": 12143},
{"snippet": "Resampler.interpolate(**kwargs, limit_direction='forward')", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `limit_direction`.", "question_id": 12144},
{"snippet": "Resampler.interpolate(**kwargs, limit_area=None)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `limit_area`.", "question_id": 12145},
{"snippet": "Resampler.interpolate(**kwargs, downcast=None)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `downcast`.", "question_id": 12146},
{"snippet": "Resampler.interpolate(**kwargs, method='linear', axis=0)", "intent": "Interpolate values according to different methods . Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 12147},
{"snippet": "Resampler.interpolate(**kwargs, method='linear', limit=None)", "intent": "Interpolate values according to different methods . Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 12148},
{"snippet": "Resampler.interpolate(**kwargs)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`.", "question_id": 12149},
{"snippet": "Resampler.interpolate(**kwargs, method='linear')", "intent": "Interpolate values according to different methods . Fill NaN values using an interpolation `method` . With arguments `**kwargs`.", "question_id": 12150},
{"snippet": "Resampler.interpolate(**kwargs, axis=0)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `axis`.", "question_id": 12151},
{"snippet": "Resampler.interpolate(**kwargs, limit=None)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `limit`.", "question_id": 12152},
{"snippet": "Resampler.interpolate(**kwargs, inplace=False)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `inplace`.", "question_id": 12153},
{"snippet": "Resampler.interpolate(**kwargs, limit_direction='forward')", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `limit_direction`.", "question_id": 12154},
{"snippet": "Resampler.interpolate(**kwargs, limit_area=None)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `limit_area`.", "question_id": 12155},
{"snippet": "Resampler.interpolate(**kwargs, downcast=None)", "intent": "Interpolate values according to different methods . With arguments `**kwargs`, `downcast`.", "question_id": 12156},
{"snippet": "Resampler.interpolate(**kwargs, method='linear', axis=0)", "intent": "Interpolate values according to different methods . Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `axis`.", "question_id": 12157},
{"snippet": "Resampler.interpolate(**kwargs, method='linear', limit=None)", "intent": "Interpolate values according to different methods . Fill NaN values using an interpolation `method` . With arguments `**kwargs`, `limit`.", "question_id": 12158},
{"snippet": "Resampler.last(*args, **kwargs)", "intent": "Compute last of group values . With arguments `*args`, `**kwargs`.", "question_id": 12159},
{"snippet": "Resampler.last(*args, **kwargs, _method='last')", "intent": "Compute last of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12160},
{"snippet": "Resampler.last(*args, **kwargs, min_count=0)", "intent": "Compute last of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12161},
{"snippet": "Resampler.last(*args, **kwargs, _method='last', min_count=0)", "intent": "Compute last of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12162},
{"snippet": "Resampler.last(*args, **kwargs)", "intent": "Compute last of group values . With arguments `*args`, `**kwargs`.", "question_id": 12163},
{"snippet": "Resampler.last(*args, **kwargs, _method='last')", "intent": "Compute last of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12164},
{"snippet": "Resampler.last(*args, **kwargs, min_count=0)", "intent": "Compute last of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12165},
{"snippet": "Resampler.last(*args, **kwargs, _method='last', min_count=0)", "intent": "Compute last of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12166},
{"snippet": "Resampler.last(*args, **kwargs)", "intent": "Compute last of group values . With arguments `*args`, `**kwargs`.", "question_id": 12167},
{"snippet": "Resampler.last(*args, **kwargs, _method='last')", "intent": "Compute last of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12168},
{"snippet": "Resampler.last(*args, **kwargs, min_count=0)", "intent": "Compute last of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12169},
{"snippet": "Resampler.last(*args, **kwargs, _method='last', min_count=0)", "intent": "Compute last of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12170},
{"snippet": "Resampler.max(*args, **kwargs)", "intent": "Compute max of group values . With arguments `*args`, `**kwargs`.", "question_id": 12171},
{"snippet": "Resampler.max(*args, **kwargs, _method='max')", "intent": "Compute max of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12172},
{"snippet": "Resampler.max(*args, **kwargs, min_count=0)", "intent": "Compute max of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12173},
{"snippet": "Resampler.max(*args, **kwargs, _method='max', min_count=0)", "intent": "Compute max of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12174},
{"snippet": "Resampler.max(*args, **kwargs)", "intent": "Compute max of group values . With arguments `*args`, `**kwargs`.", "question_id": 12175},
{"snippet": "Resampler.max(*args, **kwargs, _method='max')", "intent": "Compute max of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12176},
{"snippet": "Resampler.max(*args, **kwargs, min_count=0)", "intent": "Compute max of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12177},
{"snippet": "Resampler.max(*args, **kwargs, _method='max', min_count=0)", "intent": "Compute max of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12178},
{"snippet": "Resampler.max(*args, **kwargs)", "intent": "Compute max of group values . With arguments `*args`, `**kwargs`.", "question_id": 12179},
{"snippet": "Resampler.max(*args, **kwargs, _method='max')", "intent": "Compute max of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12180},
{"snippet": "Resampler.max(*args, **kwargs, min_count=0)", "intent": "Compute max of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12181},
{"snippet": "Resampler.max(*args, **kwargs, _method='max', min_count=0)", "intent": "Compute max of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12182},
{"snippet": "Resampler.mean(*args, **kwargs)", "intent": "Compute mean of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12183},
{"snippet": "Resampler.mean(*args, **kwargs, _method='mean')", "intent": "Compute mean of groups , excluding missing values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12184},
{"snippet": "Resampler.mean(*args, **kwargs)", "intent": "Compute mean of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12185},
{"snippet": "Resampler.mean(*args, **kwargs, _method='mean')", "intent": "Compute mean of groups , excluding missing values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12186},
{"snippet": "Resampler.mean(*args, **kwargs)", "intent": "Compute mean of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12187},
{"snippet": "Resampler.mean(*args, **kwargs, _method='mean')", "intent": "Compute mean of groups , excluding missing values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12188},
{"snippet": "Resampler.median(*args, **kwargs)", "intent": "Compute median of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12189},
{"snippet": "Resampler.median(*args, **kwargs, _method='median')", "intent": "Compute median of groups , excluding missing values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12190},
{"snippet": "Resampler.median(*args, **kwargs)", "intent": "Compute median of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12191},
{"snippet": "Resampler.median(*args, **kwargs, _method='median')", "intent": "Compute median of groups , excluding missing values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12192},
{"snippet": "Resampler.median(*args, **kwargs)", "intent": "Compute median of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12193},
{"snippet": "Resampler.median(*args, **kwargs, _method='median')", "intent": "Compute median of groups , excluding missing values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12194},
{"snippet": "Resampler.min(*args, **kwargs)", "intent": "Compute min of group values . With arguments `*args`, `**kwargs`.", "question_id": 12195},
{"snippet": "Resampler.min(*args, **kwargs, _method='min')", "intent": "Compute min of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12196},
{"snippet": "Resampler.min(*args, **kwargs, min_count=0)", "intent": "Compute min of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12197},
{"snippet": "Resampler.min(*args, **kwargs, _method='min', min_count=0)", "intent": "Compute min of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12198},
{"snippet": "Resampler.min(*args, **kwargs)", "intent": "Compute min of group values . With arguments `*args`, `**kwargs`.", "question_id": 12199},
{"snippet": "Resampler.min(*args, **kwargs, _method='min')", "intent": "Compute min of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12200},
{"snippet": "Resampler.min(*args, **kwargs, min_count=0)", "intent": "Compute min of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12201},
{"snippet": "Resampler.min(*args, **kwargs, _method='min', min_count=0)", "intent": "Compute min of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12202},
{"snippet": "Resampler.min(*args, **kwargs)", "intent": "Compute min of group values . With arguments `*args`, `**kwargs`.", "question_id": 12203},
{"snippet": "Resampler.min(*args, **kwargs, _method='min')", "intent": "Compute min of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12204},
{"snippet": "Resampler.min(*args, **kwargs, min_count=0)", "intent": "Compute min of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12205},
{"snippet": "Resampler.min(*args, **kwargs, _method='min', min_count=0)", "intent": "Compute min of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12206},
{"snippet": "Resampler.nearest()", "intent": "Resample by using the nearest value .", "question_id": 12207},
{"snippet": "Resampler.nearest(limit=None)", "intent": "Resample by using the nearest value . If `limit` is given , fill only this many values in each direction for each of the original values .", "question_id": 12208},
{"snippet": "Resampler.nearest()", "intent": "Resample by using the nearest value .", "question_id": 12209},
{"snippet": "Resampler.nearest(limit=None)", "intent": "Resample by using the nearest value . If `limit` is given , fill only this many values in each direction for each of the original values .", "question_id": 12210},
{"snippet": "Resampler.nearest()", "intent": "Resample by using the nearest value .", "question_id": 12211},
{"snippet": "Resampler.nearest(limit=None)", "intent": "Resample by using the nearest value . If `limit` is given , fill only this many values in each direction for each of the original values .", "question_id": 12212},
{"snippet": "Resampler.nunique()", "intent": "Return number of unique elements in the group .", "question_id": 12213},
{"snippet": "Resampler.nunique(_method='nunique')", "intent": "Return number of unique elements in the group . With arguments `_method`.", "question_id": 12214},
{"snippet": "Resampler.nunique()", "intent": "Return number of unique elements in the group .", "question_id": 12215},
{"snippet": "Resampler.nunique(_method='nunique')", "intent": "Return number of unique elements in the group . With arguments `_method`.", "question_id": 12216},
{"snippet": "Resampler.nunique()", "intent": "Return number of unique elements in the group .", "question_id": 12217},
{"snippet": "Resampler.nunique(_method='nunique')", "intent": "Return number of unique elements in the group . With arguments `_method`.", "question_id": 12218},
{"snippet": "Resampler.ohlc(*args, **kwargs)", "intent": "Compute open , high , low and close values of a group , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12219},
{"snippet": "Resampler.ohlc(*args, **kwargs, _method='ohlc')", "intent": "Compute open , high , low and close values of a group , excluding missing values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12220},
{"snippet": "Resampler.ohlc(*args, **kwargs)", "intent": "Compute open , high , low and close values of a group , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12221},
{"snippet": "Resampler.ohlc(*args, **kwargs, _method='ohlc')", "intent": "Compute open , high , low and close values of a group , excluding missing values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12222},
{"snippet": "Resampler.ohlc(*args, **kwargs)", "intent": "Compute open , high , low and close values of a group , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12223},
{"snippet": "Resampler.ohlc(*args, **kwargs, _method='ohlc')", "intent": "Compute open , high , low and close values of a group , excluding missing values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12224},
{"snippet": "Resampler.pad()", "intent": "Forward fill the values .", "question_id": 12225},
{"snippet": "Resampler.pad(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 12226},
{"snippet": "Resampler.pad()", "intent": "Forward fill the values .", "question_id": 12227},
{"snippet": "Resampler.pad(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 12228},
{"snippet": "Resampler.pad()", "intent": "Forward fill the values .", "question_id": 12229},
{"snippet": "Resampler.pad(limit=None)", "intent": "Forward fill the values . With arguments `limit`.", "question_id": 12230},
{"snippet": "Resampler.pipe(func, *args, **kwargs)", "intent": "Apply a function `func` with arguments to this Resampler object and return the function \u2019 s result . With arguments `*args`, `**kwargs`.", "question_id": 12231},
{"snippet": "Resampler.pipe(func, *args, **kwargs)", "intent": "Apply a function `func` with arguments to this Resampler object and return the function \u2019 s result . With arguments `*args`, `**kwargs`.", "question_id": 12232},
{"snippet": "Resampler.pipe(func, *args, **kwargs)", "intent": "Apply a function `func` with arguments to this Resampler object and return the function \u2019 s result . With arguments `*args`, `**kwargs`.", "question_id": 12233},
{"snippet": "Resampler.prod(*args, **kwargs)", "intent": "Compute prod of group values . With arguments `*args`, `**kwargs`.", "question_id": 12234},
{"snippet": "Resampler.prod(*args, **kwargs, _method='prod')", "intent": "Compute prod of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12235},
{"snippet": "Resampler.prod(*args, **kwargs, min_count=0)", "intent": "Compute prod of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12236},
{"snippet": "Resampler.prod(*args, **kwargs, _method='prod', min_count=0)", "intent": "Compute prod of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12237},
{"snippet": "Resampler.prod(*args, **kwargs)", "intent": "Compute prod of group values . With arguments `*args`, `**kwargs`.", "question_id": 12238},
{"snippet": "Resampler.prod(*args, **kwargs, _method='prod')", "intent": "Compute prod of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12239},
{"snippet": "Resampler.prod(*args, **kwargs, min_count=0)", "intent": "Compute prod of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12240},
{"snippet": "Resampler.prod(*args, **kwargs, _method='prod', min_count=0)", "intent": "Compute prod of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12241},
{"snippet": "Resampler.prod(*args, **kwargs)", "intent": "Compute prod of group values . With arguments `*args`, `**kwargs`.", "question_id": 12242},
{"snippet": "Resampler.prod(*args, **kwargs, _method='prod')", "intent": "Compute prod of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12243},
{"snippet": "Resampler.prod(*args, **kwargs, min_count=0)", "intent": "Compute prod of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12244},
{"snippet": "Resampler.prod(*args, **kwargs, _method='prod', min_count=0)", "intent": "Compute prod of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12245},
{"snippet": "Resampler.quantile(**kwargs)", "intent": "Return value at the given quantile . With arguments `**kwargs`.", "question_id": 12246},
{"snippet": "Resampler.quantile(**kwargs, q=0.5)", "intent": "Return value at the given quantile . With arguments `**kwargs`, `q`.", "question_id": 12247},
{"snippet": "Resampler.quantile(**kwargs)", "intent": "Return value at the given quantile . With arguments `**kwargs`.", "question_id": 12248},
{"snippet": "Resampler.quantile(**kwargs, q=0.5)", "intent": "Return value at the given quantile . With arguments `**kwargs`, `q`.", "question_id": 12249},
{"snippet": "Resampler.quantile(**kwargs)", "intent": "Return value at the given quantile . With arguments `**kwargs`.", "question_id": 12250},
{"snippet": "Resampler.quantile(**kwargs, q=0.5)", "intent": "Return value at the given quantile . With arguments `**kwargs`, `q`.", "question_id": 12251},
{"snippet": "Resampler.sem(*args, **kwargs)", "intent": "Compute standard error of the mean of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12252},
{"snippet": "Resampler.sem(*args, **kwargs, _method='sem')", "intent": "Compute standard error of the mean of groups , excluding missing values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12253},
{"snippet": "Resampler.sem(*args, **kwargs)", "intent": "Compute standard error of the mean of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12254},
{"snippet": "Resampler.sem(*args, **kwargs, _method='sem')", "intent": "Compute standard error of the mean of groups , excluding missing values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12255},
{"snippet": "Resampler.sem(*args, **kwargs)", "intent": "Compute standard error of the mean of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12256},
{"snippet": "Resampler.sem(*args, **kwargs, _method='sem')", "intent": "Compute standard error of the mean of groups , excluding missing values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12257},
{"snippet": "Resampler.size()", "intent": "Compute group sizes .", "question_id": 12258},
{"snippet": "Resampler.size()", "intent": "Compute group sizes .", "question_id": 12259},
{"snippet": "Resampler.size()", "intent": "Compute group sizes .", "question_id": 12260},
{"snippet": "Resampler.std(*args, **kwargs)", "intent": "Compute standard deviation of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12261},
{"snippet": "Resampler.std(*args, **kwargs, ddof=1)", "intent": "Compute standard deviation of groups , excluding missing values . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12262},
{"snippet": "Resampler.std(*args, **kwargs)", "intent": "Compute standard deviation of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12263},
{"snippet": "Resampler.std(*args, **kwargs, ddof=1)", "intent": "Compute standard deviation of groups , excluding missing values . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12264},
{"snippet": "Resampler.std(*args, **kwargs)", "intent": "Compute standard deviation of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12265},
{"snippet": "Resampler.std(*args, **kwargs, ddof=1)", "intent": "Compute standard deviation of groups , excluding missing values . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12266},
{"snippet": "Resampler.sum(*args, **kwargs)", "intent": "Compute sum of group values . With arguments `*args`, `**kwargs`.", "question_id": 12267},
{"snippet": "Resampler.sum(*args, **kwargs, _method='sum')", "intent": "Compute sum of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12268},
{"snippet": "Resampler.sum(*args, **kwargs, min_count=0)", "intent": "Compute sum of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12269},
{"snippet": "Resampler.sum(*args, **kwargs, _method='sum', min_count=0)", "intent": "Compute sum of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12270},
{"snippet": "Resampler.sum(*args, **kwargs)", "intent": "Compute sum of group values . With arguments `*args`, `**kwargs`.", "question_id": 12271},
{"snippet": "Resampler.sum(*args, **kwargs, _method='sum')", "intent": "Compute sum of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12272},
{"snippet": "Resampler.sum(*args, **kwargs, min_count=0)", "intent": "Compute sum of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12273},
{"snippet": "Resampler.sum(*args, **kwargs, _method='sum', min_count=0)", "intent": "Compute sum of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12274},
{"snippet": "Resampler.sum(*args, **kwargs)", "intent": "Compute sum of group values . With arguments `*args`, `**kwargs`.", "question_id": 12275},
{"snippet": "Resampler.sum(*args, **kwargs, _method='sum')", "intent": "Compute sum of group values . With arguments `*args`, `**kwargs`, `_method`.", "question_id": 12276},
{"snippet": "Resampler.sum(*args, **kwargs, min_count=0)", "intent": "Compute sum of group values . With arguments `*args`, `**kwargs`, `min_count`.", "question_id": 12277},
{"snippet": "Resampler.sum(*args, **kwargs, _method='sum', min_count=0)", "intent": "Compute sum of group values . With arguments `*args`, `**kwargs`, `_method`, `min_count`.", "question_id": 12278},
{"snippet": "Resampler.transform(arg, *args, **kwargs)", "intent": "Call function producing a like-indexed Series on each group and return a Series with the transformed values . With arguments `arg`, `*args`, `**kwargs`.", "question_id": 12279},
{"snippet": "Resampler.transform(arg, *args, **kwargs)", "intent": "Call function producing a like-indexed Series on each group and return a Series with the transformed values . With arguments `arg`, `*args`, `**kwargs`.", "question_id": 12280},
{"snippet": "Resampler.transform(arg, *args, **kwargs)", "intent": "Call function producing a like-indexed Series on each group and return a Series with the transformed values . With arguments `arg`, `*args`, `**kwargs`.", "question_id": 12281},
{"snippet": "Resampler.var(*args, **kwargs)", "intent": "Compute variance of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12282},
{"snippet": "Resampler.var(*args, **kwargs, ddof=1)", "intent": "Compute variance of groups , excluding missing values . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12283},
{"snippet": "Resampler.var(*args, **kwargs)", "intent": "Compute variance of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12284},
{"snippet": "Resampler.var(*args, **kwargs, ddof=1)", "intent": "Compute variance of groups , excluding missing values . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12285},
{"snippet": "Resampler.var(*args, **kwargs)", "intent": "Compute variance of groups , excluding missing values . With arguments `*args`, `**kwargs`.", "question_id": 12286},
{"snippet": "Resampler.var(*args, **kwargs, ddof=1)", "intent": "Compute variance of groups , excluding missing values . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12287},
{"snippet": "ExponentialMovingWindow.corr(**kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) sample correlation . With arguments `**kwargs`.", "question_id": 12288},
{"snippet": "ExponentialMovingWindow.corr(**kwargs, other=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample correlation . With arguments `**kwargs`, `other`.", "question_id": 12289},
{"snippet": "ExponentialMovingWindow.corr(**kwargs, pairwise=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample correlation . With arguments `**kwargs`, `pairwise`.", "question_id": 12290},
{"snippet": "ExponentialMovingWindow.corr(**kwargs, other=None, pairwise=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample correlation . With arguments `**kwargs`, `other`, `pairwise`.", "question_id": 12291},
{"snippet": "ExponentialMovingWindow.corr(**kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) sample correlation . With arguments `**kwargs`.", "question_id": 12292},
{"snippet": "ExponentialMovingWindow.corr(**kwargs, other=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample correlation . With arguments `**kwargs`, `other`.", "question_id": 12293},
{"snippet": "ExponentialMovingWindow.corr(**kwargs, pairwise=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample correlation . With arguments `**kwargs`, `pairwise`.", "question_id": 12294},
{"snippet": "ExponentialMovingWindow.corr(**kwargs, other=None, pairwise=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample correlation . With arguments `**kwargs`, `other`, `pairwise`.", "question_id": 12295},
{"snippet": "ExponentialMovingWindow.corr(**kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) sample correlation . With arguments `**kwargs`.", "question_id": 12296},
{"snippet": "ExponentialMovingWindow.corr(**kwargs, other=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample correlation . With arguments `**kwargs`, `other`.", "question_id": 12297},
{"snippet": "ExponentialMovingWindow.corr(**kwargs, pairwise=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample correlation . With arguments `**kwargs`, `pairwise`.", "question_id": 12298},
{"snippet": "ExponentialMovingWindow.corr(**kwargs, other=None, pairwise=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample correlation . With arguments `**kwargs`, `other`, `pairwise`.", "question_id": 12299},
{"snippet": "ExponentialMovingWindow.cov(**kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`.", "question_id": 12300},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, other=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `other`.", "question_id": 12301},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, pairwise=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `pairwise`.", "question_id": 12302},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `bias`.", "question_id": 12303},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, other=None, pairwise=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `other`, `pairwise`.", "question_id": 12304},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, other=None, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `other`, `bias`.", "question_id": 12305},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, pairwise=None, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `pairwise`, `bias`.", "question_id": 12306},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, other=None, pairwise=None, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `other`, `pairwise`, `bias`.", "question_id": 12307},
{"snippet": "ExponentialMovingWindow.cov(**kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`.", "question_id": 12308},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, other=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `other`.", "question_id": 12309},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, pairwise=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `pairwise`.", "question_id": 12310},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `bias`.", "question_id": 12311},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, other=None, pairwise=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `other`, `pairwise`.", "question_id": 12312},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, other=None, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `other`, `bias`.", "question_id": 12313},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, pairwise=None, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `pairwise`, `bias`.", "question_id": 12314},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, other=None, pairwise=None, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `other`, `pairwise`, `bias`.", "question_id": 12315},
{"snippet": "ExponentialMovingWindow.cov(**kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`.", "question_id": 12316},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, other=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `other`.", "question_id": 12317},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, pairwise=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `pairwise`.", "question_id": 12318},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `bias`.", "question_id": 12319},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, other=None, pairwise=None)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `other`, `pairwise`.", "question_id": 12320},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, other=None, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `other`, `bias`.", "question_id": 12321},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, pairwise=None, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `pairwise`, `bias`.", "question_id": 12322},
{"snippet": "ExponentialMovingWindow.cov(**kwargs, other=None, pairwise=None, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) sample covariance . With arguments `**kwargs`, `other`, `pairwise`, `bias`.", "question_id": 12323},
{"snippet": "ExponentialMovingWindow.mean(*args, **kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) mean . With arguments `*args`, `**kwargs`.", "question_id": 12324},
{"snippet": "ExponentialMovingWindow.mean(*args, **kwargs, engine=None)", "intent": "Calculate the ewm ( exponential weighted moment ) mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12325},
{"snippet": "ExponentialMovingWindow.mean(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the ewm ( exponential weighted moment ) mean . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12326},
{"snippet": "ExponentialMovingWindow.mean(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the ewm ( exponential weighted moment ) mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12327},
{"snippet": "ExponentialMovingWindow.mean(*args, **kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) mean . With arguments `*args`, `**kwargs`.", "question_id": 12328},
{"snippet": "ExponentialMovingWindow.mean(*args, **kwargs, engine=None)", "intent": "Calculate the ewm ( exponential weighted moment ) mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12329},
{"snippet": "ExponentialMovingWindow.mean(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the ewm ( exponential weighted moment ) mean . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12330},
{"snippet": "ExponentialMovingWindow.mean(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the ewm ( exponential weighted moment ) mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12331},
{"snippet": "ExponentialMovingWindow.mean(*args, **kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) mean . With arguments `*args`, `**kwargs`.", "question_id": 12332},
{"snippet": "ExponentialMovingWindow.mean(*args, **kwargs, engine=None)", "intent": "Calculate the ewm ( exponential weighted moment ) mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12333},
{"snippet": "ExponentialMovingWindow.mean(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the ewm ( exponential weighted moment ) mean . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12334},
{"snippet": "ExponentialMovingWindow.mean(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the ewm ( exponential weighted moment ) mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12335},
{"snippet": "ExponentialMovingWindow.std(*args, **kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) standard deviation . With arguments `*args`, `**kwargs`.", "question_id": 12336},
{"snippet": "ExponentialMovingWindow.std(*args, **kwargs, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) standard deviation . With arguments `*args`, `**kwargs`, `bias`.", "question_id": 12337},
{"snippet": "ExponentialMovingWindow.std(*args, **kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) standard deviation . With arguments `*args`, `**kwargs`.", "question_id": 12338},
{"snippet": "ExponentialMovingWindow.std(*args, **kwargs, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) standard deviation . With arguments `*args`, `**kwargs`, `bias`.", "question_id": 12339},
{"snippet": "ExponentialMovingWindow.std(*args, **kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) standard deviation . With arguments `*args`, `**kwargs`.", "question_id": 12340},
{"snippet": "ExponentialMovingWindow.std(*args, **kwargs, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) standard deviation . With arguments `*args`, `**kwargs`, `bias`.", "question_id": 12341},
{"snippet": "ExponentialMovingWindow.var(*args, **kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) variance . With arguments `*args`, `**kwargs`.", "question_id": 12342},
{"snippet": "ExponentialMovingWindow.var(*args, **kwargs, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) variance . With arguments `*args`, `**kwargs`, `bias`.", "question_id": 12343},
{"snippet": "ExponentialMovingWindow.var(*args, **kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) variance . With arguments `*args`, `**kwargs`.", "question_id": 12344},
{"snippet": "ExponentialMovingWindow.var(*args, **kwargs, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) variance . With arguments `*args`, `**kwargs`, `bias`.", "question_id": 12345},
{"snippet": "ExponentialMovingWindow.var(*args, **kwargs)", "intent": "Calculate the ewm ( exponential weighted moment ) variance . With arguments `*args`, `**kwargs`.", "question_id": 12346},
{"snippet": "ExponentialMovingWindow.var(*args, **kwargs, bias=False)", "intent": "Calculate the ewm ( exponential weighted moment ) variance . With arguments `*args`, `**kwargs`, `bias`.", "question_id": 12347},
{"snippet": "Expanding.aggregate(func, *args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `func`, `*args`, `**kwargs`.", "question_id": 12348},
{"snippet": "Expanding.aggregate(func, *args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `func`, `*args`, `**kwargs`.", "question_id": 12349},
{"snippet": "Expanding.aggregate(func, *args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `func`, `*args`, `**kwargs`.", "question_id": 12350},
{"snippet": "Expanding.apply(func)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`.", "question_id": 12351},
{"snippet": "Expanding.apply(func, raw=False)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`.", "question_id": 12352},
{"snippet": "Expanding.apply(func, engine=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `engine`.", "question_id": 12353},
{"snippet": "Expanding.apply(func, engine_kwargs=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `engine_kwargs`.", "question_id": 12354},
{"snippet": "Expanding.apply(func, args=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `args`.", "question_id": 12355},
{"snippet": "Expanding.apply(func, kwargs=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `kwargs`.", "question_id": 12356},
{"snippet": "Expanding.apply(func, raw=False, engine=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`, `engine`.", "question_id": 12357},
{"snippet": "Expanding.apply(func, raw=False, engine_kwargs=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`, `engine_kwargs`.", "question_id": 12358},
{"snippet": "Expanding.apply(func, raw=False, args=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`, `args`.", "question_id": 12359},
{"snippet": "Expanding.apply(func, raw=False, kwargs=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`, `kwargs`.", "question_id": 12360},
{"snippet": "Expanding.apply(func)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`.", "question_id": 12361},
{"snippet": "Expanding.apply(func, raw=False)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`.", "question_id": 12362},
{"snippet": "Expanding.apply(func, engine=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `engine`.", "question_id": 12363},
{"snippet": "Expanding.apply(func, engine_kwargs=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `engine_kwargs`.", "question_id": 12364},
{"snippet": "Expanding.apply(func, args=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `args`.", "question_id": 12365},
{"snippet": "Expanding.apply(func, kwargs=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `kwargs`.", "question_id": 12366},
{"snippet": "Expanding.apply(func, raw=False, engine=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`, `engine`.", "question_id": 12367},
{"snippet": "Expanding.apply(func, raw=False, engine_kwargs=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`, `engine_kwargs`.", "question_id": 12368},
{"snippet": "Expanding.apply(func, raw=False, args=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`, `args`.", "question_id": 12369},
{"snippet": "Expanding.apply(func, raw=False, kwargs=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`, `kwargs`.", "question_id": 12370},
{"snippet": "Expanding.apply(func)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`.", "question_id": 12371},
{"snippet": "Expanding.apply(func, raw=False)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`.", "question_id": 12372},
{"snippet": "Expanding.apply(func, engine=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `engine`.", "question_id": 12373},
{"snippet": "Expanding.apply(func, engine_kwargs=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `engine_kwargs`.", "question_id": 12374},
{"snippet": "Expanding.apply(func, args=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `args`.", "question_id": 12375},
{"snippet": "Expanding.apply(func, kwargs=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `kwargs`.", "question_id": 12376},
{"snippet": "Expanding.apply(func, raw=False, engine=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`, `engine`.", "question_id": 12377},
{"snippet": "Expanding.apply(func, raw=False, engine_kwargs=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`, `engine_kwargs`.", "question_id": 12378},
{"snippet": "Expanding.apply(func, raw=False, args=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`, `args`.", "question_id": 12379},
{"snippet": "Expanding.apply(func, raw=False, kwargs=None)", "intent": "Calculate the expanding custom aggregation function . With arguments `func`, `raw`, `kwargs`.", "question_id": 12380},
{"snippet": "Expanding.corr(**kwargs)", "intent": "Calculate the expanding correlation . With arguments `**kwargs`.", "question_id": 12381},
{"snippet": "Expanding.corr(**kwargs, other=None)", "intent": "Calculate the expanding correlation . When `other` is not specified , the output will be self correlation ( e.g . With arguments `**kwargs`.", "question_id": 12382},
{"snippet": "Expanding.corr(**kwargs, pairwise=None)", "intent": "Calculate the expanding correlation . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`.", "question_id": 12383},
{"snippet": "Expanding.corr(**kwargs, ddof=1)", "intent": "Calculate the expanding correlation . With arguments `**kwargs`, `ddof`.", "question_id": 12384},
{"snippet": "Expanding.corr(**kwargs, other=None, pairwise=None)", "intent": "Calculate the expanding correlation . When `other` is not specified , the output will be self correlation ( e.g . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`.", "question_id": 12385},
{"snippet": "Expanding.corr(**kwargs, other=None, ddof=1)", "intent": "Calculate the expanding correlation . When `other` is not specified , the output will be self correlation ( e.g . With arguments `**kwargs`, `ddof`.", "question_id": 12386},
{"snippet": "Expanding.corr(**kwargs, pairwise=None, ddof=1)", "intent": "Calculate the expanding correlation . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`, `ddof`.", "question_id": 12387},
{"snippet": "Expanding.corr(**kwargs, other=None, pairwise=None, ddof=1)", "intent": "Calculate the expanding correlation . When `other` is not specified , the output will be self correlation ( e.g . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`, `ddof`.", "question_id": 12388},
{"snippet": "Expanding.corr(**kwargs)", "intent": "Calculate the expanding correlation . With arguments `**kwargs`.", "question_id": 12389},
{"snippet": "Expanding.corr(**kwargs, other=None)", "intent": "Calculate the expanding correlation . When `other` is not specified , the output will be self correlation ( e.g . With arguments `**kwargs`.", "question_id": 12390},
{"snippet": "Expanding.corr(**kwargs, pairwise=None)", "intent": "Calculate the expanding correlation . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`.", "question_id": 12391},
{"snippet": "Expanding.corr(**kwargs, ddof=1)", "intent": "Calculate the expanding correlation . With arguments `**kwargs`, `ddof`.", "question_id": 12392},
{"snippet": "Expanding.corr(**kwargs, other=None, pairwise=None)", "intent": "Calculate the expanding correlation . When `other` is not specified , the output will be self correlation ( e.g . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`.", "question_id": 12393},
{"snippet": "Expanding.corr(**kwargs, other=None, ddof=1)", "intent": "Calculate the expanding correlation . When `other` is not specified , the output will be self correlation ( e.g . With arguments `**kwargs`, `ddof`.", "question_id": 12394},
{"snippet": "Expanding.corr(**kwargs, pairwise=None, ddof=1)", "intent": "Calculate the expanding correlation . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`, `ddof`.", "question_id": 12395},
{"snippet": "Expanding.corr(**kwargs, other=None, pairwise=None, ddof=1)", "intent": "Calculate the expanding correlation . When `other` is not specified , the output will be self correlation ( e.g . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`, `ddof`.", "question_id": 12396},
{"snippet": "Expanding.corr(**kwargs)", "intent": "Calculate the expanding correlation . With arguments `**kwargs`.", "question_id": 12397},
{"snippet": "Expanding.corr(**kwargs, other=None)", "intent": "Calculate the expanding correlation . When `other` is not specified , the output will be self correlation ( e.g . With arguments `**kwargs`.", "question_id": 12398},
{"snippet": "Expanding.corr(**kwargs, pairwise=None)", "intent": "Calculate the expanding correlation . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`.", "question_id": 12399},
{"snippet": "Expanding.corr(**kwargs, ddof=1)", "intent": "Calculate the expanding correlation . With arguments `**kwargs`, `ddof`.", "question_id": 12400},
{"snippet": "Expanding.corr(**kwargs, other=None, pairwise=None)", "intent": "Calculate the expanding correlation . When `other` is not specified , the output will be self correlation ( e.g . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`.", "question_id": 12401},
{"snippet": "Expanding.corr(**kwargs, other=None, ddof=1)", "intent": "Calculate the expanding correlation . When `other` is not specified , the output will be self correlation ( e.g . With arguments `**kwargs`, `ddof`.", "question_id": 12402},
{"snippet": "Expanding.corr(**kwargs, pairwise=None, ddof=1)", "intent": "Calculate the expanding correlation . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`, `ddof`.", "question_id": 12403},
{"snippet": "Expanding.corr(**kwargs, other=None, pairwise=None, ddof=1)", "intent": "Calculate the expanding correlation . When `other` is not specified , the output will be self correlation ( e.g . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`, `ddof`.", "question_id": 12404},
{"snippet": "Expanding.count()", "intent": "Calculate the expanding count of non NaN observations .", "question_id": 12405},
{"snippet": "Expanding.count()", "intent": "Calculate the expanding count of non NaN observations .", "question_id": 12406},
{"snippet": "Expanding.count()", "intent": "Calculate the expanding count of non NaN observations .", "question_id": 12407},
{"snippet": "Expanding.cov(**kwargs)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`.", "question_id": 12408},
{"snippet": "Expanding.cov(**kwargs, other=None)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `other`.", "question_id": 12409},
{"snippet": "Expanding.cov(**kwargs, pairwise=None)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `pairwise`.", "question_id": 12410},
{"snippet": "Expanding.cov(**kwargs, ddof=1)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `ddof`.", "question_id": 12411},
{"snippet": "Expanding.cov(**kwargs, other=None, pairwise=None)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `other`, `pairwise`.", "question_id": 12412},
{"snippet": "Expanding.cov(**kwargs, other=None, ddof=1)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `other`, `ddof`.", "question_id": 12413},
{"snippet": "Expanding.cov(**kwargs, pairwise=None, ddof=1)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `pairwise`, `ddof`.", "question_id": 12414},
{"snippet": "Expanding.cov(**kwargs, other=None, pairwise=None, ddof=1)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `other`, `pairwise`, `ddof`.", "question_id": 12415},
{"snippet": "Expanding.cov(**kwargs)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`.", "question_id": 12416},
{"snippet": "Expanding.cov(**kwargs, other=None)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `other`.", "question_id": 12417},
{"snippet": "Expanding.cov(**kwargs, pairwise=None)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `pairwise`.", "question_id": 12418},
{"snippet": "Expanding.cov(**kwargs, ddof=1)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `ddof`.", "question_id": 12419},
{"snippet": "Expanding.cov(**kwargs, other=None, pairwise=None)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `other`, `pairwise`.", "question_id": 12420},
{"snippet": "Expanding.cov(**kwargs, other=None, ddof=1)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `other`, `ddof`.", "question_id": 12421},
{"snippet": "Expanding.cov(**kwargs, pairwise=None, ddof=1)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `pairwise`, `ddof`.", "question_id": 12422},
{"snippet": "Expanding.cov(**kwargs, other=None, pairwise=None, ddof=1)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `other`, `pairwise`, `ddof`.", "question_id": 12423},
{"snippet": "Expanding.cov(**kwargs)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`.", "question_id": 12424},
{"snippet": "Expanding.cov(**kwargs, other=None)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `other`.", "question_id": 12425},
{"snippet": "Expanding.cov(**kwargs, pairwise=None)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `pairwise`.", "question_id": 12426},
{"snippet": "Expanding.cov(**kwargs, ddof=1)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `ddof`.", "question_id": 12427},
{"snippet": "Expanding.cov(**kwargs, other=None, pairwise=None)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `other`, `pairwise`.", "question_id": 12428},
{"snippet": "Expanding.cov(**kwargs, other=None, ddof=1)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `other`, `ddof`.", "question_id": 12429},
{"snippet": "Expanding.cov(**kwargs, pairwise=None, ddof=1)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `pairwise`, `ddof`.", "question_id": 12430},
{"snippet": "Expanding.cov(**kwargs, other=None, pairwise=None, ddof=1)", "intent": "Calculate the expanding sample covariance . With arguments `**kwargs`, `other`, `pairwise`, `ddof`.", "question_id": 12431},
{"snippet": "Expanding.kurt(**kwargs)", "intent": "Calculate the expanding Fisher \u2019 s definition of kurtosis without bias . With arguments `**kwargs`.", "question_id": 12432},
{"snippet": "Expanding.kurt(**kwargs)", "intent": "Calculate the expanding Fisher \u2019 s definition of kurtosis without bias . With arguments `**kwargs`.", "question_id": 12433},
{"snippet": "Expanding.kurt(**kwargs)", "intent": "Calculate the expanding Fisher \u2019 s definition of kurtosis without bias . With arguments `**kwargs`.", "question_id": 12434},
{"snippet": "Expanding.max(*args, **kwargs)", "intent": "Calculate the expanding maximum . With arguments `*args`, `**kwargs`.", "question_id": 12435},
{"snippet": "Expanding.max(*args, **kwargs, engine=None)", "intent": "Calculate the expanding maximum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12436},
{"snippet": "Expanding.max(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the expanding maximum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12437},
{"snippet": "Expanding.max(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding maximum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12438},
{"snippet": "Expanding.max(*args, **kwargs)", "intent": "Calculate the expanding maximum . With arguments `*args`, `**kwargs`.", "question_id": 12439},
{"snippet": "Expanding.max(*args, **kwargs, engine=None)", "intent": "Calculate the expanding maximum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12440},
{"snippet": "Expanding.max(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the expanding maximum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12441},
{"snippet": "Expanding.max(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding maximum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12442},
{"snippet": "Expanding.max(*args, **kwargs)", "intent": "Calculate the expanding maximum . With arguments `*args`, `**kwargs`.", "question_id": 12443},
{"snippet": "Expanding.max(*args, **kwargs, engine=None)", "intent": "Calculate the expanding maximum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12444},
{"snippet": "Expanding.max(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the expanding maximum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12445},
{"snippet": "Expanding.max(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding maximum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12446},
{"snippet": "Expanding.mean(*args, **kwargs)", "intent": "Calculate the expanding mean . With arguments `*args`, `**kwargs`.", "question_id": 12447},
{"snippet": "Expanding.mean(*args, **kwargs, engine=None)", "intent": "Calculate the expanding mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12448},
{"snippet": "Expanding.mean(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the expanding mean . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12449},
{"snippet": "Expanding.mean(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12450},
{"snippet": "Expanding.mean(*args, **kwargs)", "intent": "Calculate the expanding mean . With arguments `*args`, `**kwargs`.", "question_id": 12451},
{"snippet": "Expanding.mean(*args, **kwargs, engine=None)", "intent": "Calculate the expanding mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12452},
{"snippet": "Expanding.mean(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the expanding mean . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12453},
{"snippet": "Expanding.mean(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12454},
{"snippet": "Expanding.mean(*args, **kwargs)", "intent": "Calculate the expanding mean . With arguments `*args`, `**kwargs`.", "question_id": 12455},
{"snippet": "Expanding.mean(*args, **kwargs, engine=None)", "intent": "Calculate the expanding mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12456},
{"snippet": "Expanding.mean(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the expanding mean . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12457},
{"snippet": "Expanding.mean(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12458},
{"snippet": "Expanding.median(**kwargs)", "intent": "Calculate the expanding median . With arguments `**kwargs`.", "question_id": 12459},
{"snippet": "Expanding.median(**kwargs, engine=None)", "intent": "Calculate the expanding median . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `**kwargs`.", "question_id": 12460},
{"snippet": "Expanding.median(**kwargs, engine_kwargs=None)", "intent": "Calculate the expanding median . With arguments `**kwargs`, `engine_kwargs`.", "question_id": 12461},
{"snippet": "Expanding.median(**kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding median . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `**kwargs`, `engine_kwargs`.", "question_id": 12462},
{"snippet": "Expanding.median(**kwargs)", "intent": "Calculate the expanding median . With arguments `**kwargs`.", "question_id": 12463},
{"snippet": "Expanding.median(**kwargs, engine=None)", "intent": "Calculate the expanding median . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `**kwargs`.", "question_id": 12464},
{"snippet": "Expanding.median(**kwargs, engine_kwargs=None)", "intent": "Calculate the expanding median . With arguments `**kwargs`, `engine_kwargs`.", "question_id": 12465},
{"snippet": "Expanding.median(**kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding median . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `**kwargs`, `engine_kwargs`.", "question_id": 12466},
{"snippet": "Expanding.median(**kwargs)", "intent": "Calculate the expanding median . With arguments `**kwargs`.", "question_id": 12467},
{"snippet": "Expanding.median(**kwargs, engine=None)", "intent": "Calculate the expanding median . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `**kwargs`.", "question_id": 12468},
{"snippet": "Expanding.median(**kwargs, engine_kwargs=None)", "intent": "Calculate the expanding median . With arguments `**kwargs`, `engine_kwargs`.", "question_id": 12469},
{"snippet": "Expanding.median(**kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding median . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `**kwargs`, `engine_kwargs`.", "question_id": 12470},
{"snippet": "Expanding.min(*args, **kwargs)", "intent": "Calculate the expanding minimum . With arguments `*args`, `**kwargs`.", "question_id": 12471},
{"snippet": "Expanding.min(*args, **kwargs, engine=None)", "intent": "Calculate the expanding minimum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12472},
{"snippet": "Expanding.min(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the expanding minimum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12473},
{"snippet": "Expanding.min(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding minimum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12474},
{"snippet": "Expanding.min(*args, **kwargs)", "intent": "Calculate the expanding minimum . With arguments `*args`, `**kwargs`.", "question_id": 12475},
{"snippet": "Expanding.min(*args, **kwargs, engine=None)", "intent": "Calculate the expanding minimum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12476},
{"snippet": "Expanding.min(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the expanding minimum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12477},
{"snippet": "Expanding.min(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding minimum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12478},
{"snippet": "Expanding.min(*args, **kwargs)", "intent": "Calculate the expanding minimum . With arguments `*args`, `**kwargs`.", "question_id": 12479},
{"snippet": "Expanding.min(*args, **kwargs, engine=None)", "intent": "Calculate the expanding minimum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12480},
{"snippet": "Expanding.min(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the expanding minimum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12481},
{"snippet": "Expanding.min(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding minimum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12482},
{"snippet": "Expanding.quantile(quantile, **kwargs)", "intent": "Calculate the expanding `quantile` . With arguments `**kwargs`.", "question_id": 12483},
{"snippet": "Expanding.quantile(quantile, **kwargs, interpolation='linear')", "intent": "Calculate the expanding `quantile` . With arguments `**kwargs`, `interpolation`.", "question_id": 12484},
{"snippet": "Expanding.quantile(quantile, **kwargs)", "intent": "Calculate the expanding `quantile` . With arguments `**kwargs`.", "question_id": 12485},
{"snippet": "Expanding.quantile(quantile, **kwargs, interpolation='linear')", "intent": "Calculate the expanding `quantile` . With arguments `**kwargs`, `interpolation`.", "question_id": 12486},
{"snippet": "Expanding.quantile(quantile, **kwargs)", "intent": "Calculate the expanding `quantile` . With arguments `**kwargs`.", "question_id": 12487},
{"snippet": "Expanding.quantile(quantile, **kwargs, interpolation='linear')", "intent": "Calculate the expanding `quantile` . With arguments `**kwargs`, `interpolation`.", "question_id": 12488},
{"snippet": "Expanding.sem(*args, **kwargs)", "intent": "Calculate the expanding standard error of mean . With arguments `*args`, `**kwargs`.", "question_id": 12489},
{"snippet": "Expanding.sem(*args, **kwargs, ddof=1)", "intent": "Calculate the expanding standard error of mean . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12490},
{"snippet": "Expanding.sem(*args, **kwargs)", "intent": "Calculate the expanding standard error of mean . With arguments `*args`, `**kwargs`.", "question_id": 12491},
{"snippet": "Expanding.sem(*args, **kwargs, ddof=1)", "intent": "Calculate the expanding standard error of mean . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12492},
{"snippet": "Expanding.sem(*args, **kwargs)", "intent": "Calculate the expanding standard error of mean . With arguments `*args`, `**kwargs`.", "question_id": 12493},
{"snippet": "Expanding.sem(*args, **kwargs, ddof=1)", "intent": "Calculate the expanding standard error of mean . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12494},
{"snippet": "Expanding.skew(**kwargs)", "intent": "Calculate the expanding unbiased skewness . With arguments `**kwargs`.", "question_id": 12495},
{"snippet": "Expanding.skew(**kwargs)", "intent": "Calculate the expanding unbiased skewness . With arguments `**kwargs`.", "question_id": 12496},
{"snippet": "Expanding.skew(**kwargs)", "intent": "Calculate the expanding unbiased skewness . With arguments `**kwargs`.", "question_id": 12497},
{"snippet": "Expanding.std(*args, **kwargs)", "intent": "Calculate the expanding standard deviation . With arguments `*args`, `**kwargs`.", "question_id": 12498},
{"snippet": "Expanding.std(*args, **kwargs, ddof=1)", "intent": "Calculate the expanding standard deviation . The default `ddof` of 1 used in Series.std ( ) is different than the default ddof of 0 in numpy.std ( ) . With arguments `*args`, `**kwargs`.", "question_id": 12499},
{"snippet": "Expanding.std(*args, **kwargs)", "intent": "Calculate the expanding standard deviation . With arguments `*args`, `**kwargs`.", "question_id": 12500},
{"snippet": "Expanding.std(*args, **kwargs, ddof=1)", "intent": "Calculate the expanding standard deviation . The default `ddof` of 1 used in Series.std ( ) is different than the default ddof of 0 in numpy.std ( ) . With arguments `*args`, `**kwargs`.", "question_id": 12501},
{"snippet": "Expanding.std(*args, **kwargs)", "intent": "Calculate the expanding standard deviation . With arguments `*args`, `**kwargs`.", "question_id": 12502},
{"snippet": "Expanding.std(*args, **kwargs, ddof=1)", "intent": "Calculate the expanding standard deviation . The default `ddof` of 1 used in Series.std ( ) is different than the default ddof of 0 in numpy.std ( ) . With arguments `*args`, `**kwargs`.", "question_id": 12503},
{"snippet": "Expanding.sum(*args, **kwargs)", "intent": "Calculate the expanding sum . With arguments `*args`, `**kwargs`.", "question_id": 12504},
{"snippet": "Expanding.sum(*args, **kwargs, engine=None)", "intent": "Calculate the expanding sum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12505},
{"snippet": "Expanding.sum(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the expanding sum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12506},
{"snippet": "Expanding.sum(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding sum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12507},
{"snippet": "Expanding.sum(*args, **kwargs)", "intent": "Calculate the expanding sum . With arguments `*args`, `**kwargs`.", "question_id": 12508},
{"snippet": "Expanding.sum(*args, **kwargs, engine=None)", "intent": "Calculate the expanding sum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12509},
{"snippet": "Expanding.sum(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the expanding sum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12510},
{"snippet": "Expanding.sum(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding sum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12511},
{"snippet": "Expanding.sum(*args, **kwargs)", "intent": "Calculate the expanding sum . With arguments `*args`, `**kwargs`.", "question_id": 12512},
{"snippet": "Expanding.sum(*args, **kwargs, engine=None)", "intent": "Calculate the expanding sum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12513},
{"snippet": "Expanding.sum(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the expanding sum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12514},
{"snippet": "Expanding.sum(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the expanding sum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12515},
{"snippet": "Expanding.var(*args, **kwargs)", "intent": "Calculate the expanding variance . With arguments `*args`, `**kwargs`.", "question_id": 12516},
{"snippet": "Expanding.var(*args, **kwargs, ddof=1)", "intent": "Calculate the expanding variance . The default `ddof` of 1 used in Series.var ( ) is different than the default ddof of 0 in numpy.var ( ) . With arguments `*args`, `**kwargs`.", "question_id": 12517},
{"snippet": "Expanding.var(*args, **kwargs)", "intent": "Calculate the expanding variance . With arguments `*args`, `**kwargs`.", "question_id": 12518},
{"snippet": "Expanding.var(*args, **kwargs, ddof=1)", "intent": "Calculate the expanding variance . The default `ddof` of 1 used in Series.var ( ) is different than the default ddof of 0 in numpy.var ( ) . With arguments `*args`, `**kwargs`.", "question_id": 12519},
{"snippet": "Expanding.var(*args, **kwargs)", "intent": "Calculate the expanding variance . With arguments `*args`, `**kwargs`.", "question_id": 12520},
{"snippet": "Expanding.var(*args, **kwargs, ddof=1)", "intent": "Calculate the expanding variance . The default `ddof` of 1 used in Series.var ( ) is different than the default ddof of 0 in numpy.var ( ) . With arguments `*args`, `**kwargs`.", "question_id": 12521},
{"snippet": "Rolling.aggregate(func, *args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `func`, `*args`, `**kwargs`.", "question_id": 12522},
{"snippet": "Rolling.aggregate(func, *args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `func`, `*args`, `**kwargs`.", "question_id": 12523},
{"snippet": "Rolling.aggregate(func, *args, **kwargs)", "intent": "Aggregate using one or more operations over the specified axis . With arguments `func`, `*args`, `**kwargs`.", "question_id": 12524},
{"snippet": "Rolling.apply(func)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`.", "question_id": 12525},
{"snippet": "Rolling.apply(func, raw=False)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`.", "question_id": 12526},
{"snippet": "Rolling.apply(func, engine=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `engine`.", "question_id": 12527},
{"snippet": "Rolling.apply(func, engine_kwargs=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `engine_kwargs`.", "question_id": 12528},
{"snippet": "Rolling.apply(func, args=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `args`.", "question_id": 12529},
{"snippet": "Rolling.apply(func, kwargs=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `kwargs`.", "question_id": 12530},
{"snippet": "Rolling.apply(func, raw=False, engine=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`, `engine`.", "question_id": 12531},
{"snippet": "Rolling.apply(func, raw=False, engine_kwargs=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`, `engine_kwargs`.", "question_id": 12532},
{"snippet": "Rolling.apply(func, raw=False, args=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`, `args`.", "question_id": 12533},
{"snippet": "Rolling.apply(func, raw=False, kwargs=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`, `kwargs`.", "question_id": 12534},
{"snippet": "Rolling.apply(func)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`.", "question_id": 12535},
{"snippet": "Rolling.apply(func, raw=False)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`.", "question_id": 12536},
{"snippet": "Rolling.apply(func, engine=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `engine`.", "question_id": 12537},
{"snippet": "Rolling.apply(func, engine_kwargs=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `engine_kwargs`.", "question_id": 12538},
{"snippet": "Rolling.apply(func, args=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `args`.", "question_id": 12539},
{"snippet": "Rolling.apply(func, kwargs=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `kwargs`.", "question_id": 12540},
{"snippet": "Rolling.apply(func, raw=False, engine=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`, `engine`.", "question_id": 12541},
{"snippet": "Rolling.apply(func, raw=False, engine_kwargs=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`, `engine_kwargs`.", "question_id": 12542},
{"snippet": "Rolling.apply(func, raw=False, args=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`, `args`.", "question_id": 12543},
{"snippet": "Rolling.apply(func, raw=False, kwargs=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`, `kwargs`.", "question_id": 12544},
{"snippet": "Rolling.apply(func)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`.", "question_id": 12545},
{"snippet": "Rolling.apply(func, raw=False)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`.", "question_id": 12546},
{"snippet": "Rolling.apply(func, engine=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `engine`.", "question_id": 12547},
{"snippet": "Rolling.apply(func, engine_kwargs=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `engine_kwargs`.", "question_id": 12548},
{"snippet": "Rolling.apply(func, args=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `args`.", "question_id": 12549},
{"snippet": "Rolling.apply(func, kwargs=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `kwargs`.", "question_id": 12550},
{"snippet": "Rolling.apply(func, raw=False, engine=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`, `engine`.", "question_id": 12551},
{"snippet": "Rolling.apply(func, raw=False, engine_kwargs=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`, `engine_kwargs`.", "question_id": 12552},
{"snippet": "Rolling.apply(func, raw=False, args=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`, `args`.", "question_id": 12553},
{"snippet": "Rolling.apply(func, raw=False, kwargs=None)", "intent": "Calculate the rolling custom aggregation function . With arguments `func`, `raw`, `kwargs`.", "question_id": 12554},
{"snippet": "Rolling.corr(**kwargs)", "intent": "Calculate the rolling correlation . With arguments `**kwargs`.", "question_id": 12555},
{"snippet": "Rolling.corr(**kwargs, other=None)", "intent": "Calculate the rolling correlation . When `other` is not specified , the output will be self correlation ( e.g . With arguments `**kwargs`.", "question_id": 12556},
{"snippet": "Rolling.corr(**kwargs, pairwise=None)", "intent": "Calculate the rolling correlation . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`.", "question_id": 12557},
{"snippet": "Rolling.corr(**kwargs, ddof=1)", "intent": "Calculate the rolling correlation . With arguments `**kwargs`, `ddof`.", "question_id": 12558},
{"snippet": "Rolling.corr(**kwargs, other=None, pairwise=None)", "intent": "Calculate the rolling correlation . When `other` is not specified , the output will be self correlation ( e.g . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`.", "question_id": 12559},
{"snippet": "Rolling.corr(**kwargs, other=None, ddof=1)", "intent": "Calculate the rolling correlation . When `other` is not specified , the output will be self correlation ( e.g . With arguments `**kwargs`, `ddof`.", "question_id": 12560},
{"snippet": "Rolling.corr(**kwargs, pairwise=None, ddof=1)", "intent": "Calculate the rolling correlation . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`, `ddof`.", "question_id": 12561},
{"snippet": "Rolling.corr(**kwargs, other=None, pairwise=None, ddof=1)", "intent": "Calculate the rolling correlation . When `other` is not specified , the output will be self correlation ( e.g . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`, `ddof`.", "question_id": 12562},
{"snippet": "Rolling.corr(**kwargs)", "intent": "Calculate the rolling correlation . With arguments `**kwargs`.", "question_id": 12563},
{"snippet": "Rolling.corr(**kwargs, other=None)", "intent": "Calculate the rolling correlation . When `other` is not specified , the output will be self correlation ( e.g . With arguments `**kwargs`.", "question_id": 12564},
{"snippet": "Rolling.corr(**kwargs, pairwise=None)", "intent": "Calculate the rolling correlation . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`.", "question_id": 12565},
{"snippet": "Rolling.corr(**kwargs, ddof=1)", "intent": "Calculate the rolling correlation . With arguments `**kwargs`, `ddof`.", "question_id": 12566},
{"snippet": "Rolling.corr(**kwargs, other=None, pairwise=None)", "intent": "Calculate the rolling correlation . When `other` is not specified , the output will be self correlation ( e.g . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`.", "question_id": 12567},
{"snippet": "Rolling.corr(**kwargs, other=None, ddof=1)", "intent": "Calculate the rolling correlation . When `other` is not specified , the output will be self correlation ( e.g . With arguments `**kwargs`, `ddof`.", "question_id": 12568},
{"snippet": "Rolling.corr(**kwargs, pairwise=None, ddof=1)", "intent": "Calculate the rolling correlation . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`, `ddof`.", "question_id": 12569},
{"snippet": "Rolling.corr(**kwargs, other=None, pairwise=None, ddof=1)", "intent": "Calculate the rolling correlation . When `other` is not specified , the output will be self correlation ( e.g . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`, `ddof`.", "question_id": 12570},
{"snippet": "Rolling.corr(**kwargs)", "intent": "Calculate the rolling correlation . With arguments `**kwargs`.", "question_id": 12571},
{"snippet": "Rolling.corr(**kwargs, other=None)", "intent": "Calculate the rolling correlation . When `other` is not specified , the output will be self correlation ( e.g . With arguments `**kwargs`.", "question_id": 12572},
{"snippet": "Rolling.corr(**kwargs, pairwise=None)", "intent": "Calculate the rolling correlation . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`.", "question_id": 12573},
{"snippet": "Rolling.corr(**kwargs, ddof=1)", "intent": "Calculate the rolling correlation . With arguments `**kwargs`, `ddof`.", "question_id": 12574},
{"snippet": "Rolling.corr(**kwargs, other=None, pairwise=None)", "intent": "Calculate the rolling correlation . When `other` is not specified , the output will be self correlation ( e.g . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`.", "question_id": 12575},
{"snippet": "Rolling.corr(**kwargs, other=None, ddof=1)", "intent": "Calculate the rolling correlation . When `other` is not specified , the output will be self correlation ( e.g . With arguments `**kwargs`, `ddof`.", "question_id": 12576},
{"snippet": "Rolling.corr(**kwargs, pairwise=None, ddof=1)", "intent": "Calculate the rolling correlation . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`, `ddof`.", "question_id": 12577},
{"snippet": "Rolling.corr(**kwargs, other=None, pairwise=None, ddof=1)", "intent": "Calculate the rolling correlation . When `other` is not specified , the output will be self correlation ( e.g . all 1 \u2019 s ) , except for DataFrame inputs with `pairwise` set to True . With arguments `**kwargs`, `ddof`.", "question_id": 12578},
{"snippet": "Rolling.count()", "intent": "Calculate the rolling count of non NaN observations .", "question_id": 12579},
{"snippet": "Rolling.count()", "intent": "Calculate the rolling count of non NaN observations .", "question_id": 12580},
{"snippet": "Rolling.count()", "intent": "Calculate the rolling count of non NaN observations .", "question_id": 12581},
{"snippet": "Rolling.cov(**kwargs)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`.", "question_id": 12582},
{"snippet": "Rolling.cov(**kwargs, other=None)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `other`.", "question_id": 12583},
{"snippet": "Rolling.cov(**kwargs, pairwise=None)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `pairwise`.", "question_id": 12584},
{"snippet": "Rolling.cov(**kwargs, ddof=1)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `ddof`.", "question_id": 12585},
{"snippet": "Rolling.cov(**kwargs, other=None, pairwise=None)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `other`, `pairwise`.", "question_id": 12586},
{"snippet": "Rolling.cov(**kwargs, other=None, ddof=1)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `other`, `ddof`.", "question_id": 12587},
{"snippet": "Rolling.cov(**kwargs, pairwise=None, ddof=1)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `pairwise`, `ddof`.", "question_id": 12588},
{"snippet": "Rolling.cov(**kwargs, other=None, pairwise=None, ddof=1)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `other`, `pairwise`, `ddof`.", "question_id": 12589},
{"snippet": "Rolling.cov(**kwargs)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`.", "question_id": 12590},
{"snippet": "Rolling.cov(**kwargs, other=None)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `other`.", "question_id": 12591},
{"snippet": "Rolling.cov(**kwargs, pairwise=None)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `pairwise`.", "question_id": 12592},
{"snippet": "Rolling.cov(**kwargs, ddof=1)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `ddof`.", "question_id": 12593},
{"snippet": "Rolling.cov(**kwargs, other=None, pairwise=None)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `other`, `pairwise`.", "question_id": 12594},
{"snippet": "Rolling.cov(**kwargs, other=None, ddof=1)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `other`, `ddof`.", "question_id": 12595},
{"snippet": "Rolling.cov(**kwargs, pairwise=None, ddof=1)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `pairwise`, `ddof`.", "question_id": 12596},
{"snippet": "Rolling.cov(**kwargs, other=None, pairwise=None, ddof=1)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `other`, `pairwise`, `ddof`.", "question_id": 12597},
{"snippet": "Rolling.cov(**kwargs)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`.", "question_id": 12598},
{"snippet": "Rolling.cov(**kwargs, other=None)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `other`.", "question_id": 12599},
{"snippet": "Rolling.cov(**kwargs, pairwise=None)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `pairwise`.", "question_id": 12600},
{"snippet": "Rolling.cov(**kwargs, ddof=1)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `ddof`.", "question_id": 12601},
{"snippet": "Rolling.cov(**kwargs, other=None, pairwise=None)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `other`, `pairwise`.", "question_id": 12602},
{"snippet": "Rolling.cov(**kwargs, other=None, ddof=1)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `other`, `ddof`.", "question_id": 12603},
{"snippet": "Rolling.cov(**kwargs, pairwise=None, ddof=1)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `pairwise`, `ddof`.", "question_id": 12604},
{"snippet": "Rolling.cov(**kwargs, other=None, pairwise=None, ddof=1)", "intent": "Calculate the rolling sample covariance . With arguments `**kwargs`, `other`, `pairwise`, `ddof`.", "question_id": 12605},
{"snippet": "Rolling.kurt(**kwargs)", "intent": "Calculate the rolling Fisher \u2019 s definition of kurtosis without bias . With arguments `**kwargs`.", "question_id": 12606},
{"snippet": "Rolling.kurt(**kwargs)", "intent": "Calculate the rolling Fisher \u2019 s definition of kurtosis without bias . With arguments `**kwargs`.", "question_id": 12607},
{"snippet": "Rolling.kurt(**kwargs)", "intent": "Calculate the rolling Fisher \u2019 s definition of kurtosis without bias . With arguments `**kwargs`.", "question_id": 12608},
{"snippet": "Rolling.max(*args, **kwargs)", "intent": "Calculate the rolling maximum . With arguments `*args`, `**kwargs`.", "question_id": 12609},
{"snippet": "Rolling.max(*args, **kwargs, engine=None)", "intent": "Calculate the rolling maximum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12610},
{"snippet": "Rolling.max(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the rolling maximum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12611},
{"snippet": "Rolling.max(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling maximum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12612},
{"snippet": "Rolling.max(*args, **kwargs)", "intent": "Calculate the rolling maximum . With arguments `*args`, `**kwargs`.", "question_id": 12613},
{"snippet": "Rolling.max(*args, **kwargs, engine=None)", "intent": "Calculate the rolling maximum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12614},
{"snippet": "Rolling.max(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the rolling maximum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12615},
{"snippet": "Rolling.max(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling maximum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12616},
{"snippet": "Rolling.max(*args, **kwargs)", "intent": "Calculate the rolling maximum . With arguments `*args`, `**kwargs`.", "question_id": 12617},
{"snippet": "Rolling.max(*args, **kwargs, engine=None)", "intent": "Calculate the rolling maximum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12618},
{"snippet": "Rolling.max(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the rolling maximum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12619},
{"snippet": "Rolling.max(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling maximum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12620},
{"snippet": "Rolling.mean(*args, **kwargs)", "intent": "Calculate the rolling mean . With arguments `*args`, `**kwargs`.", "question_id": 12621},
{"snippet": "Rolling.mean(*args, **kwargs, engine=None)", "intent": "Calculate the rolling mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12622},
{"snippet": "Rolling.mean(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the rolling mean . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12623},
{"snippet": "Rolling.mean(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12624},
{"snippet": "Rolling.mean(*args, **kwargs)", "intent": "Calculate the rolling mean . With arguments `*args`, `**kwargs`.", "question_id": 12625},
{"snippet": "Rolling.mean(*args, **kwargs, engine=None)", "intent": "Calculate the rolling mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12626},
{"snippet": "Rolling.mean(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the rolling mean . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12627},
{"snippet": "Rolling.mean(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12628},
{"snippet": "Rolling.mean(*args, **kwargs)", "intent": "Calculate the rolling mean . With arguments `*args`, `**kwargs`.", "question_id": 12629},
{"snippet": "Rolling.mean(*args, **kwargs, engine=None)", "intent": "Calculate the rolling mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12630},
{"snippet": "Rolling.mean(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the rolling mean . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12631},
{"snippet": "Rolling.mean(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling mean . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12632},
{"snippet": "Rolling.median(**kwargs)", "intent": "Calculate the rolling median . With arguments `**kwargs`.", "question_id": 12633},
{"snippet": "Rolling.median(**kwargs, engine=None)", "intent": "Calculate the rolling median . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `**kwargs`.", "question_id": 12634},
{"snippet": "Rolling.median(**kwargs, engine_kwargs=None)", "intent": "Calculate the rolling median . With arguments `**kwargs`, `engine_kwargs`.", "question_id": 12635},
{"snippet": "Rolling.median(**kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling median . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `**kwargs`, `engine_kwargs`.", "question_id": 12636},
{"snippet": "Rolling.median(**kwargs)", "intent": "Calculate the rolling median . With arguments `**kwargs`.", "question_id": 12637},
{"snippet": "Rolling.median(**kwargs, engine=None)", "intent": "Calculate the rolling median . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `**kwargs`.", "question_id": 12638},
{"snippet": "Rolling.median(**kwargs, engine_kwargs=None)", "intent": "Calculate the rolling median . With arguments `**kwargs`, `engine_kwargs`.", "question_id": 12639},
{"snippet": "Rolling.median(**kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling median . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `**kwargs`, `engine_kwargs`.", "question_id": 12640},
{"snippet": "Rolling.median(**kwargs)", "intent": "Calculate the rolling median . With arguments `**kwargs`.", "question_id": 12641},
{"snippet": "Rolling.median(**kwargs, engine=None)", "intent": "Calculate the rolling median . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `**kwargs`.", "question_id": 12642},
{"snippet": "Rolling.median(**kwargs, engine_kwargs=None)", "intent": "Calculate the rolling median . With arguments `**kwargs`, `engine_kwargs`.", "question_id": 12643},
{"snippet": "Rolling.median(**kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling median . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `**kwargs`, `engine_kwargs`.", "question_id": 12644},
{"snippet": "Rolling.min(*args, **kwargs)", "intent": "Calculate the rolling minimum . With arguments `*args`, `**kwargs`.", "question_id": 12645},
{"snippet": "Rolling.min(*args, **kwargs, engine=None)", "intent": "Calculate the rolling minimum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12646},
{"snippet": "Rolling.min(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the rolling minimum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12647},
{"snippet": "Rolling.min(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling minimum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12648},
{"snippet": "Rolling.min(*args, **kwargs)", "intent": "Calculate the rolling minimum . With arguments `*args`, `**kwargs`.", "question_id": 12649},
{"snippet": "Rolling.min(*args, **kwargs, engine=None)", "intent": "Calculate the rolling minimum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12650},
{"snippet": "Rolling.min(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the rolling minimum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12651},
{"snippet": "Rolling.min(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling minimum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12652},
{"snippet": "Rolling.min(*args, **kwargs)", "intent": "Calculate the rolling minimum . With arguments `*args`, `**kwargs`.", "question_id": 12653},
{"snippet": "Rolling.min(*args, **kwargs, engine=None)", "intent": "Calculate the rolling minimum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12654},
{"snippet": "Rolling.min(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the rolling minimum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12655},
{"snippet": "Rolling.min(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling minimum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12656},
{"snippet": "Rolling.quantile(quantile, **kwargs)", "intent": "Calculate the rolling `quantile` . With arguments `**kwargs`.", "question_id": 12657},
{"snippet": "Rolling.quantile(quantile, **kwargs, interpolation='linear')", "intent": "Calculate the rolling `quantile` . With arguments `**kwargs`, `interpolation`.", "question_id": 12658},
{"snippet": "Rolling.quantile(quantile, **kwargs)", "intent": "Calculate the rolling `quantile` . With arguments `**kwargs`.", "question_id": 12659},
{"snippet": "Rolling.quantile(quantile, **kwargs, interpolation='linear')", "intent": "Calculate the rolling `quantile` . With arguments `**kwargs`, `interpolation`.", "question_id": 12660},
{"snippet": "Rolling.quantile(quantile, **kwargs)", "intent": "Calculate the rolling `quantile` . With arguments `**kwargs`.", "question_id": 12661},
{"snippet": "Rolling.quantile(quantile, **kwargs, interpolation='linear')", "intent": "Calculate the rolling `quantile` . With arguments `**kwargs`, `interpolation`.", "question_id": 12662},
{"snippet": "Rolling.sem(*args, **kwargs)", "intent": "Calculate the rolling standard error of mean . With arguments `*args`, `**kwargs`.", "question_id": 12663},
{"snippet": "Rolling.sem(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling standard error of mean . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12664},
{"snippet": "Rolling.sem(*args, **kwargs)", "intent": "Calculate the rolling standard error of mean . With arguments `*args`, `**kwargs`.", "question_id": 12665},
{"snippet": "Rolling.sem(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling standard error of mean . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12666},
{"snippet": "Rolling.sem(*args, **kwargs)", "intent": "Calculate the rolling standard error of mean . With arguments `*args`, `**kwargs`.", "question_id": 12667},
{"snippet": "Rolling.sem(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling standard error of mean . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12668},
{"snippet": "Rolling.skew(**kwargs)", "intent": "Calculate the rolling unbiased skewness . With arguments `**kwargs`.", "question_id": 12669},
{"snippet": "Rolling.skew(**kwargs)", "intent": "Calculate the rolling unbiased skewness . With arguments `**kwargs`.", "question_id": 12670},
{"snippet": "Rolling.skew(**kwargs)", "intent": "Calculate the rolling unbiased skewness . With arguments `**kwargs`.", "question_id": 12671},
{"snippet": "Rolling.std(*args, **kwargs)", "intent": "Calculate the rolling standard deviation . With arguments `*args`, `**kwargs`.", "question_id": 12672},
{"snippet": "Rolling.std(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling standard deviation . The default `ddof` of 1 used in Series.std ( ) is different than the default ddof of 0 in numpy.std ( ) . With arguments `*args`, `**kwargs`.", "question_id": 12673},
{"snippet": "Rolling.std(*args, **kwargs)", "intent": "Calculate the rolling standard deviation . With arguments `*args`, `**kwargs`.", "question_id": 12674},
{"snippet": "Rolling.std(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling standard deviation . The default `ddof` of 1 used in Series.std ( ) is different than the default ddof of 0 in numpy.std ( ) . With arguments `*args`, `**kwargs`.", "question_id": 12675},
{"snippet": "Rolling.std(*args, **kwargs)", "intent": "Calculate the rolling standard deviation . With arguments `*args`, `**kwargs`.", "question_id": 12676},
{"snippet": "Rolling.std(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling standard deviation . The default `ddof` of 1 used in Series.std ( ) is different than the default ddof of 0 in numpy.std ( ) . With arguments `*args`, `**kwargs`.", "question_id": 12677},
{"snippet": "Rolling.sum(*args, **kwargs)", "intent": "Calculate the rolling sum . With arguments `*args`, `**kwargs`.", "question_id": 12678},
{"snippet": "Rolling.sum(*args, **kwargs, engine=None)", "intent": "Calculate the rolling sum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12679},
{"snippet": "Rolling.sum(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the rolling sum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12680},
{"snippet": "Rolling.sum(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling sum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12681},
{"snippet": "Rolling.sum(*args, **kwargs)", "intent": "Calculate the rolling sum . With arguments `*args`, `**kwargs`.", "question_id": 12682},
{"snippet": "Rolling.sum(*args, **kwargs, engine=None)", "intent": "Calculate the rolling sum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12683},
{"snippet": "Rolling.sum(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the rolling sum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12684},
{"snippet": "Rolling.sum(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling sum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12685},
{"snippet": "Rolling.sum(*args, **kwargs)", "intent": "Calculate the rolling sum . With arguments `*args`, `**kwargs`.", "question_id": 12686},
{"snippet": "Rolling.sum(*args, **kwargs, engine=None)", "intent": "Calculate the rolling sum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`.", "question_id": 12687},
{"snippet": "Rolling.sum(*args, **kwargs, engine_kwargs=None)", "intent": "Calculate the rolling sum . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12688},
{"snippet": "Rolling.sum(*args, **kwargs, engine=None, engine_kwargs=None)", "intent": "Calculate the rolling sum . See Numba `engine` and Numba ( JIT compilation ) for extended documentation and performance considerations for the Numba engine . With arguments `*args`, `**kwargs`, `engine_kwargs`.", "question_id": 12689},
{"snippet": "Rolling.var(*args, **kwargs)", "intent": "Calculate the rolling variance . With arguments `*args`, `**kwargs`.", "question_id": 12690},
{"snippet": "Rolling.var(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling variance . The default `ddof` of 1 used in Series.var ( ) is different than the default ddof of 0 in numpy.var ( ) . With arguments `*args`, `**kwargs`.", "question_id": 12691},
{"snippet": "Rolling.var(*args, **kwargs)", "intent": "Calculate the rolling variance . With arguments `*args`, `**kwargs`.", "question_id": 12692},
{"snippet": "Rolling.var(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling variance . The default `ddof` of 1 used in Series.var ( ) is different than the default ddof of 0 in numpy.var ( ) . With arguments `*args`, `**kwargs`.", "question_id": 12693},
{"snippet": "Rolling.var(*args, **kwargs)", "intent": "Calculate the rolling variance . With arguments `*args`, `**kwargs`.", "question_id": 12694},
{"snippet": "Rolling.var(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling variance . The default `ddof` of 1 used in Series.var ( ) is different than the default ddof of 0 in numpy.var ( ) . With arguments `*args`, `**kwargs`.", "question_id": 12695},
{"snippet": "Window.mean(*args, **kwargs)", "intent": "Calculate the rolling weighted window mean . With arguments `*args`, `**kwargs`.", "question_id": 12696},
{"snippet": "Window.mean(*args, **kwargs)", "intent": "Calculate the rolling weighted window mean . With arguments `*args`, `**kwargs`.", "question_id": 12697},
{"snippet": "Window.mean(*args, **kwargs)", "intent": "Calculate the rolling weighted window mean . With arguments `*args`, `**kwargs`.", "question_id": 12698},
{"snippet": "Window.std(*args, **kwargs)", "intent": "Calculate the rolling weighted window standard deviation . With arguments `*args`, `**kwargs`.", "question_id": 12699},
{"snippet": "Window.std(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling weighted window standard deviation . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12700},
{"snippet": "Window.std(*args, **kwargs)", "intent": "Calculate the rolling weighted window standard deviation . With arguments `*args`, `**kwargs`.", "question_id": 12701},
{"snippet": "Window.std(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling weighted window standard deviation . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12702},
{"snippet": "Window.std(*args, **kwargs)", "intent": "Calculate the rolling weighted window standard deviation . With arguments `*args`, `**kwargs`.", "question_id": 12703},
{"snippet": "Window.std(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling weighted window standard deviation . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12704},
{"snippet": "Window.sum(*args, **kwargs)", "intent": "Calculate the rolling weighted window sum . With arguments `*args`, `**kwargs`.", "question_id": 12705},
{"snippet": "Window.sum(*args, **kwargs)", "intent": "Calculate the rolling weighted window sum . With arguments `*args`, `**kwargs`.", "question_id": 12706},
{"snippet": "Window.sum(*args, **kwargs)", "intent": "Calculate the rolling weighted window sum . With arguments `*args`, `**kwargs`.", "question_id": 12707},
{"snippet": "Window.var(*args, **kwargs)", "intent": "Calculate the rolling weighted window variance . With arguments `*args`, `**kwargs`.", "question_id": 12708},
{"snippet": "Window.var(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling weighted window variance . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12709},
{"snippet": "Window.var(*args, **kwargs)", "intent": "Calculate the rolling weighted window variance . With arguments `*args`, `**kwargs`.", "question_id": 12710},
{"snippet": "Window.var(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling weighted window variance . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12711},
{"snippet": "Window.var(*args, **kwargs)", "intent": "Calculate the rolling weighted window variance . With arguments `*args`, `**kwargs`.", "question_id": 12712},
{"snippet": "Window.var(*args, **kwargs, ddof=1)", "intent": "Calculate the rolling weighted window variance . With arguments `*args`, `**kwargs`, `ddof`.", "question_id": 12713},
{"snippet": "pandas.crosstab(index, columns)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`.", "question_id": 12714},
{"snippet": "pandas.crosstab(index, columns, values=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . By default computes a frequency table of the factors unless an array of `values` and an aggregation function are passed . With arguments `index`, `columns`.", "question_id": 12715},
{"snippet": "pandas.crosstab(index, columns, rownames=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `rownames`.", "question_id": 12716},
{"snippet": "pandas.crosstab(index, columns, colnames=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `colnames`.", "question_id": 12717},
{"snippet": "pandas.crosstab(index, columns, aggfunc=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `aggfunc`.", "question_id": 12718},
{"snippet": "pandas.crosstab(index, columns, margins=False)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `margins`.", "question_id": 12719},
{"snippet": "pandas.crosstab(index, columns, margins_name='All')", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `margins_name`.", "question_id": 12720},
{"snippet": "pandas.crosstab(index, columns, dropna=True)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . Here \u2018 c \u2019 and \u2018 f \u2019 are not represented in the data and will not be shown in the output because `dropna` is True by default . With arguments `index`, `columns`.", "question_id": 12721},
{"snippet": "pandas.crosstab(index, columns, normalize=False)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `normalize`.", "question_id": 12722},
{"snippet": "pandas.crosstab(index, columns, values=None, rownames=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . By default computes a frequency table of the factors unless an array of `values` and an aggregation function are passed . With arguments `index`, `columns`, `rownames`.", "question_id": 12723},
{"snippet": "pandas.crosstab(index, columns)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`.", "question_id": 12724},
{"snippet": "pandas.crosstab(index, columns, values=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . By default computes a frequency table of the factors unless an array of `values` and an aggregation function are passed . With arguments `index`, `columns`.", "question_id": 12725},
{"snippet": "pandas.crosstab(index, columns, rownames=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `rownames`.", "question_id": 12726},
{"snippet": "pandas.crosstab(index, columns, colnames=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `colnames`.", "question_id": 12727},
{"snippet": "pandas.crosstab(index, columns, aggfunc=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `aggfunc`.", "question_id": 12728},
{"snippet": "pandas.crosstab(index, columns, margins=False)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `margins`.", "question_id": 12729},
{"snippet": "pandas.crosstab(index, columns, margins_name='All')", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `margins_name`.", "question_id": 12730},
{"snippet": "pandas.crosstab(index, columns, dropna=True)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . Here \u2018 c \u2019 and \u2018 f \u2019 are not represented in the data and will not be shown in the output because `dropna` is True by default . With arguments `index`, `columns`.", "question_id": 12731},
{"snippet": "pandas.crosstab(index, columns, normalize=False)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `normalize`.", "question_id": 12732},
{"snippet": "pandas.crosstab(index, columns, values=None, rownames=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . By default computes a frequency table of the factors unless an array of `values` and an aggregation function are passed . With arguments `index`, `columns`, `rownames`.", "question_id": 12733},
{"snippet": "pandas.crosstab(index, columns)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`.", "question_id": 12734},
{"snippet": "pandas.crosstab(index, columns, values=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . By default computes a frequency table of the factors unless an array of `values` and an aggregation function are passed . With arguments `index`, `columns`.", "question_id": 12735},
{"snippet": "pandas.crosstab(index, columns, rownames=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `rownames`.", "question_id": 12736},
{"snippet": "pandas.crosstab(index, columns, colnames=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `colnames`.", "question_id": 12737},
{"snippet": "pandas.crosstab(index, columns, aggfunc=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `aggfunc`.", "question_id": 12738},
{"snippet": "pandas.crosstab(index, columns, margins=False)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `margins`.", "question_id": 12739},
{"snippet": "pandas.crosstab(index, columns, margins_name='All')", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `margins_name`.", "question_id": 12740},
{"snippet": "pandas.crosstab(index, columns, dropna=True)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . Here \u2018 c \u2019 and \u2018 f \u2019 are not represented in the data and will not be shown in the output because `dropna` is True by default . With arguments `index`, `columns`.", "question_id": 12741},
{"snippet": "pandas.crosstab(index, columns, normalize=False)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . With arguments `index`, `columns`, `normalize`.", "question_id": 12742},
{"snippet": "pandas.crosstab(index, columns, values=None, rownames=None)", "intent": "Compute a simple cross tabulation of two ( or more ) factors . By default computes a frequency table of the factors unless an array of `values` and an aggregation function are passed . With arguments `index`, `columns`, `rownames`.", "question_id": 12743},
{"snippet": "pandas.cut(x, bins)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`.", "question_id": 12744},
{"snippet": "pandas.cut(x, bins, right=True)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . 0 is to the left of the first bin ( which is closed on the `right` ) , and 1.5 falls between two bins . With arguments `x`.", "question_id": 12745},
{"snippet": "pandas.cut(x, bins, labels=None)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . Discovers the same bins , but assign them specific `labels` . With arguments `x`.", "question_id": 12746},
{"snippet": "pandas.cut(x, bins, retbins=False)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`, `retbins`.", "question_id": 12747},
{"snippet": "pandas.cut(x, bins, precision=3)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`, `precision`.", "question_id": 12748},
{"snippet": "pandas.cut(x, bins, include_lowest=False)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`, `include_lowest`.", "question_id": 12749},
{"snippet": "pandas.cut(x, bins, duplicates='raise')", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`, `duplicates`.", "question_id": 12750},
{"snippet": "pandas.cut(x, bins, ordered=True)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . Notice that the returned Categorical \u2019 s categories are labels and is `ordered` . With arguments `x`.", "question_id": 12751},
{"snippet": "pandas.cut(x, bins, right=True, labels=None)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . 0 is to the left of the first bin ( which is closed on the `right` ) , and 1.5 falls between two bins . Discovers the same bins , but assign them specific `labels` . With arguments `x`.", "question_id": 12752},
{"snippet": "pandas.cut(x, bins, right=True, retbins=False)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . 0 is to the left of the first bin ( which is closed on the `right` ) , and 1.5 falls between two bins . With arguments `x`, `retbins`.", "question_id": 12753},
{"snippet": "pandas.cut(x, bins)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`.", "question_id": 12754},
{"snippet": "pandas.cut(x, bins, right=True)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . 0 is to the left of the first bin ( which is closed on the `right` ) , and 1.5 falls between two bins . With arguments `x`.", "question_id": 12755},
{"snippet": "pandas.cut(x, bins, labels=None)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . Discovers the same bins , but assign them specific `labels` . With arguments `x`.", "question_id": 12756},
{"snippet": "pandas.cut(x, bins, retbins=False)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`, `retbins`.", "question_id": 12757},
{"snippet": "pandas.cut(x, bins, precision=3)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`, `precision`.", "question_id": 12758},
{"snippet": "pandas.cut(x, bins, include_lowest=False)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`, `include_lowest`.", "question_id": 12759},
{"snippet": "pandas.cut(x, bins, duplicates='raise')", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`, `duplicates`.", "question_id": 12760},
{"snippet": "pandas.cut(x, bins, ordered=True)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . Notice that the returned Categorical \u2019 s categories are labels and is `ordered` . With arguments `x`.", "question_id": 12761},
{"snippet": "pandas.cut(x, bins, right=True, labels=None)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . 0 is to the left of the first bin ( which is closed on the `right` ) , and 1.5 falls between two bins . Discovers the same bins , but assign them specific `labels` . With arguments `x`.", "question_id": 12762},
{"snippet": "pandas.cut(x, bins, right=True, retbins=False)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . 0 is to the left of the first bin ( which is closed on the `right` ) , and 1.5 falls between two bins . With arguments `x`, `retbins`.", "question_id": 12763},
{"snippet": "pandas.cut(x, bins)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`.", "question_id": 12764},
{"snippet": "pandas.cut(x, bins, right=True)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . 0 is to the left of the first bin ( which is closed on the `right` ) , and 1.5 falls between two bins . With arguments `x`.", "question_id": 12765},
{"snippet": "pandas.cut(x, bins, labels=None)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . Discovers the same bins , but assign them specific `labels` . With arguments `x`.", "question_id": 12766},
{"snippet": "pandas.cut(x, bins, retbins=False)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`, `retbins`.", "question_id": 12767},
{"snippet": "pandas.cut(x, bins, precision=3)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`, `precision`.", "question_id": 12768},
{"snippet": "pandas.cut(x, bins, include_lowest=False)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`, `include_lowest`.", "question_id": 12769},
{"snippet": "pandas.cut(x, bins, duplicates='raise')", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . With arguments `x`, `duplicates`.", "question_id": 12770},
{"snippet": "pandas.cut(x, bins, ordered=True)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . Notice that the returned Categorical \u2019 s categories are labels and is `ordered` . With arguments `x`.", "question_id": 12771},
{"snippet": "pandas.cut(x, bins, right=True, labels=None)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . 0 is to the left of the first bin ( which is closed on the `right` ) , and 1.5 falls between two bins . Discovers the same bins , but assign them specific `labels` . With arguments `x`.", "question_id": 12772},
{"snippet": "pandas.cut(x, bins, right=True, retbins=False)", "intent": "Bin values into discrete intervals . Use cut when you need to segment and sort data values into `bins` . 0 is to the left of the first bin ( which is closed on the `right` ) , and 1.5 falls between two bins . With arguments `x`, `retbins`.", "question_id": 12773},
{"snippet": "pandas.date_range(**kwargs)", "intent": "Return a fixed frequency DatetimeIndex . With arguments `**kwargs`.", "question_id": 12774},
{"snippet": "pandas.date_range(**kwargs, start=None)", "intent": "Return a fixed frequency DatetimeIndex . Returns the range of equally spaced time points ( where the difference between any two adjacent points is specified by the given frequency ) such that they all satisfy `start` < [ = ] x < [ = ] `end` , where the first one and the last one are , resp. , the first and last time points in that range that fall on the boundary of `freq` ( if given as a frequency string ) or that are valid for freq ( if given as a pandas.tseries.offsets.DateOffset ) . With arguments `**kwargs`.", "question_id": 12775},
{"snippet": "pandas.date_range(**kwargs, end=None)", "intent": "Return a fixed frequency DatetimeIndex . Returns the range of equally spaced time points ( where the difference between any two adjacent points is specified by the given frequency ) such that they all satisfy `start` < [ = ] x < [ = ] `end` , where the first one and the last one are , resp. , the first and last time points in that range that fall on the boundary of `freq` ( if given as a frequency string ) or that are valid for freq ( if given as a pandas.tseries.offsets.DateOffset ) . With arguments `**kwargs`.", "question_id": 12776},
{"snippet": "pandas.date_range(**kwargs, periods=None)", "intent": "Return a fixed frequency DatetimeIndex . ( If exactly one of start , end , or freq is not specified , this missing parameter can be computed given `periods` , the number of timesteps in the range . With arguments `**kwargs`.", "question_id": 12777},
{"snippet": "pandas.date_range(**kwargs, freq=None)", "intent": "Return a fixed frequency DatetimeIndex . Returns the range of equally spaced time points ( where the difference between any two adjacent points is specified by the given frequency ) such that they all satisfy `start` < [ = ] x < [ = ] `end` , where the first one and the last one are , resp. , the first and last time points in that range that fall on the boundary of `freq` ( if given as a frequency string ) or that are valid for freq ( if given as a pandas.tseries.offsets.DateOffset ) . With arguments `**kwargs`.", "question_id": 12778},
{"snippet": "pandas.date_range(**kwargs, tz=None)", "intent": "Return a fixed frequency DatetimeIndex . Specify `tz` to set the timezone . With arguments `**kwargs`.", "question_id": 12779},
{"snippet": "pandas.date_range(**kwargs, normalize=False)", "intent": "Return a fixed frequency DatetimeIndex . With arguments `**kwargs`, `normalize`.", "question_id": 12780},
{"snippet": "pandas.date_range(**kwargs, name=None)", "intent": "Return a fixed frequency DatetimeIndex . With arguments `**kwargs`, `name`.", "question_id": 12781},
{"snippet": "pandas.date_range(**kwargs, closed=None)", "intent": "Return a fixed frequency DatetimeIndex . If freq is omitted , the resulting DatetimeIndex will have periods linearly spaced elements between start and end ( `closed` on both sides ) . With arguments `**kwargs`.", "question_id": 12782},
{"snippet": "pandas.date_range(**kwargs, start=None, end=None)", "intent": "Return a fixed frequency DatetimeIndex . Returns the range of equally spaced time points ( where the difference between any two adjacent points is specified by the given frequency ) such that they all satisfy `start` < [ = ] x < [ = ] `end` , where the first one and the last one are , resp. , the first and last time points in that range that fall on the boundary of `freq` ( if given as a frequency string ) or that are valid for freq ( if given as a pandas.tseries.offsets.DateOffset ) . With arguments `**kwargs`.", "question_id": 12783},
{"snippet": "pandas.date_range(**kwargs)", "intent": "Return a fixed frequency DatetimeIndex . With arguments `**kwargs`.", "question_id": 12784},
{"snippet": "pandas.date_range(**kwargs, start=None)", "intent": "Return a fixed frequency DatetimeIndex . Returns the range of equally spaced time points ( where the difference between any two adjacent points is specified by the given frequency ) such that they all satisfy `start` < [ = ] x < [ = ] `end` , where the first one and the last one are , resp. , the first and last time points in that range that fall on the boundary of `freq` ( if given as a frequency string ) or that are valid for freq ( if given as a pandas.tseries.offsets.DateOffset ) . With arguments `**kwargs`.", "question_id": 12785},
{"snippet": "pandas.date_range(**kwargs, end=None)", "intent": "Return a fixed frequency DatetimeIndex . Returns the range of equally spaced time points ( where the difference between any two adjacent points is specified by the given frequency ) such that they all satisfy `start` < [ = ] x < [ = ] `end` , where the first one and the last one are , resp. , the first and last time points in that range that fall on the boundary of `freq` ( if given as a frequency string ) or that are valid for freq ( if given as a pandas.tseries.offsets.DateOffset ) . With arguments `**kwargs`.", "question_id": 12786},
{"snippet": "pandas.date_range(**kwargs, periods=None)", "intent": "Return a fixed frequency DatetimeIndex . ( If exactly one of start , end , or freq is not specified , this missing parameter can be computed given `periods` , the number of timesteps in the range . With arguments `**kwargs`.", "question_id": 12787},
{"snippet": "pandas.date_range(**kwargs, freq=None)", "intent": "Return a fixed frequency DatetimeIndex . Returns the range of equally spaced time points ( where the difference between any two adjacent points is specified by the given frequency ) such that they all satisfy `start` < [ = ] x < [ = ] `end` , where the first one and the last one are , resp. , the first and last time points in that range that fall on the boundary of `freq` ( if given as a frequency string ) or that are valid for freq ( if given as a pandas.tseries.offsets.DateOffset ) . With arguments `**kwargs`.", "question_id": 12788},
{"snippet": "pandas.date_range(**kwargs, tz=None)", "intent": "Return a fixed frequency DatetimeIndex . Specify `tz` to set the timezone . With arguments `**kwargs`.", "question_id": 12789},
{"snippet": "pandas.date_range(**kwargs, normalize=False)", "intent": "Return a fixed frequency DatetimeIndex . With arguments `**kwargs`, `normalize`.", "question_id": 12790},
{"snippet": "pandas.date_range(**kwargs, name=None)", "intent": "Return a fixed frequency DatetimeIndex . With arguments `**kwargs`, `name`.", "question_id": 12791},
{"snippet": "pandas.date_range(**kwargs, closed=None)", "intent": "Return a fixed frequency DatetimeIndex . If freq is omitted , the resulting DatetimeIndex will have periods linearly spaced elements between start and end ( `closed` on both sides ) . With arguments `**kwargs`.", "question_id": 12792},
{"snippet": "pandas.date_range(**kwargs, start=None, end=None)", "intent": "Return a fixed frequency DatetimeIndex . Returns the range of equally spaced time points ( where the difference between any two adjacent points is specified by the given frequency ) such that they all satisfy `start` < [ = ] x < [ = ] `end` , where the first one and the last one are , resp. , the first and last time points in that range that fall on the boundary of `freq` ( if given as a frequency string ) or that are valid for freq ( if given as a pandas.tseries.offsets.DateOffset ) . With arguments `**kwargs`.", "question_id": 12793},
{"snippet": "pandas.date_range(**kwargs)", "intent": "Return a fixed frequency DatetimeIndex . With arguments `**kwargs`.", "question_id": 12794},
{"snippet": "pandas.date_range(**kwargs, start=None)", "intent": "Return a fixed frequency DatetimeIndex . Returns the range of equally spaced time points ( where the difference between any two adjacent points is specified by the given frequency ) such that they all satisfy `start` < [ = ] x < [ = ] `end` , where the first one and the last one are , resp. , the first and last time points in that range that fall on the boundary of `freq` ( if given as a frequency string ) or that are valid for freq ( if given as a pandas.tseries.offsets.DateOffset ) . With arguments `**kwargs`.", "question_id": 12795},
{"snippet": "pandas.date_range(**kwargs, end=None)", "intent": "Return a fixed frequency DatetimeIndex . Returns the range of equally spaced time points ( where the difference between any two adjacent points is specified by the given frequency ) such that they all satisfy `start` < [ = ] x < [ = ] `end` , where the first one and the last one are , resp. , the first and last time points in that range that fall on the boundary of `freq` ( if given as a frequency string ) or that are valid for freq ( if given as a pandas.tseries.offsets.DateOffset ) . With arguments `**kwargs`.", "question_id": 12796},
{"snippet": "pandas.date_range(**kwargs, periods=None)", "intent": "Return a fixed frequency DatetimeIndex . ( If exactly one of start , end , or freq is not specified , this missing parameter can be computed given `periods` , the number of timesteps in the range . With arguments `**kwargs`.", "question_id": 12797},
{"snippet": "pandas.date_range(**kwargs, freq=None)", "intent": "Return a fixed frequency DatetimeIndex . Returns the range of equally spaced time points ( where the difference between any two adjacent points is specified by the given frequency ) such that they all satisfy `start` < [ = ] x < [ = ] `end` , where the first one and the last one are , resp. , the first and last time points in that range that fall on the boundary of `freq` ( if given as a frequency string ) or that are valid for freq ( if given as a pandas.tseries.offsets.DateOffset ) . With arguments `**kwargs`.", "question_id": 12798},
{"snippet": "pandas.date_range(**kwargs, tz=None)", "intent": "Return a fixed frequency DatetimeIndex . Specify `tz` to set the timezone . With arguments `**kwargs`.", "question_id": 12799},
{"snippet": "pandas.date_range(**kwargs, normalize=False)", "intent": "Return a fixed frequency DatetimeIndex . With arguments `**kwargs`, `normalize`.", "question_id": 12800},
{"snippet": "pandas.date_range(**kwargs, name=None)", "intent": "Return a fixed frequency DatetimeIndex . With arguments `**kwargs`, `name`.", "question_id": 12801},
{"snippet": "pandas.date_range(**kwargs, closed=None)", "intent": "Return a fixed frequency DatetimeIndex . If freq is omitted , the resulting DatetimeIndex will have periods linearly spaced elements between start and end ( `closed` on both sides ) . With arguments `**kwargs`.", "question_id": 12802},
{"snippet": "pandas.date_range(**kwargs, start=None, end=None)", "intent": "Return a fixed frequency DatetimeIndex . Returns the range of equally spaced time points ( where the difference between any two adjacent points is specified by the given frequency ) such that they all satisfy `start` < [ = ] x < [ = ] `end` , where the first one and the last one are , resp. , the first and last time points in that range that fall on the boundary of `freq` ( if given as a frequency string ) or that are valid for freq ( if given as a pandas.tseries.offsets.DateOffset ) . With arguments `**kwargs`.", "question_id": 12803},
{"snippet": "pandas.describe_option(pat)", "intent": "Prints the description for one or more registered options . With arguments `pat`.", "question_id": 12804},
{"snippet": "pandas.describe_option(pat, _print_desc=False)", "intent": "Prints the description for one or more registered options . With arguments `pat`, `_print_desc`.", "question_id": 12805},
{"snippet": "pandas.describe_option(pat)", "intent": "Prints the description for one or more registered options . With arguments `pat`.", "question_id": 12806},
{"snippet": "pandas.describe_option(pat, _print_desc=False)", "intent": "Prints the description for one or more registered options . With arguments `pat`, `_print_desc`.", "question_id": 12807},
{"snippet": "pandas.describe_option(pat)", "intent": "Prints the description for one or more registered options . With arguments `pat`.", "question_id": 12808},
{"snippet": "pandas.describe_option(pat, _print_desc=False)", "intent": "Prints the description for one or more registered options . With arguments `pat`, `_print_desc`.", "question_id": 12809},
{"snippet": "pandas.errors.AccessorRegistrationWarning", "intent": "Warning for attribute conflicts in accessor registration.", "question_id": 12810},
{"snippet": "pandas.errors.AccessorRegistrationWarning", "intent": "Warning for attribute conflicts in accessor registration.", "question_id": 12811},
{"snippet": "pandas.errors.AccessorRegistrationWarning", "intent": "Warning for attribute conflicts in accessor registration.", "question_id": 12812},
{"snippet": "pandas.errors.DtypeWarning", "intent": "Warning raised when reading different dtypes in a column from a file.", "question_id": 12813},
{"snippet": "pandas.errors.DtypeWarning", "intent": "Warning raised when reading different dtypes in a column from a file.", "question_id": 12814},
{"snippet": "pandas.errors.DtypeWarning", "intent": "Warning raised when reading different dtypes in a column from a file.", "question_id": 12815},
{"snippet": "pandas.errors.DuplicateLabelError", "intent": "Error raised when an operation would introduce duplicate labels.", "question_id": 12816},
{"snippet": "pandas.errors.DuplicateLabelError", "intent": "Error raised when an operation would introduce duplicate labels.", "question_id": 12817},
{"snippet": "pandas.errors.DuplicateLabelError", "intent": "Error raised when an operation would introduce duplicate labels.", "question_id": 12818},
{"snippet": "pandas.errors.EmptyDataError", "intent": "Exception that is thrown in pd.read_csv (by both the C and Python engines) when empty data or header is encountered.", "question_id": 12819},
{"snippet": "pandas.errors.EmptyDataError", "intent": "Exception that is thrown in pd.read_csv (by both the C and Python engines) when empty data or header is encountered.", "question_id": 12820},
{"snippet": "pandas.errors.EmptyDataError", "intent": "Exception that is thrown in pd.read_csv (by both the C and Python engines) when empty data or header is encountered.", "question_id": 12821},
{"snippet": "pandas.errors.InvalidIndexError", "intent": "Exception raised when attempting to use an invalid index key.", "question_id": 12822},
{"snippet": "pandas.errors.InvalidIndexError", "intent": "Exception raised when attempting to use an invalid index key.", "question_id": 12823},
{"snippet": "pandas.errors.InvalidIndexError", "intent": "Exception raised when attempting to use an invalid index key.", "question_id": 12824},
{"snippet": "pandas.errors.MergeError", "intent": "Error raised when problems arise during merging due to problems with input data.", "question_id": 12825},
{"snippet": "pandas.errors.MergeError", "intent": "Error raised when problems arise during merging due to problems with input data.", "question_id": 12826},
{"snippet": "pandas.errors.MergeError", "intent": "Error raised when problems arise during merging due to problems with input data.", "question_id": 12827},
{"snippet": "pandas.errors.NullFrequencyError", "intent": "Error raised when a null freq attribute is used in an operation that needs a non-null frequency, particularly DatetimeIndex.shift, TimedeltaIndex.shift, PeriodIndex.shift.", "question_id": 12828},
{"snippet": "pandas.errors.NullFrequencyError", "intent": "Error raised when a null freq attribute is used in an operation that needs a non-null frequency, particularly DatetimeIndex.shift, TimedeltaIndex.shift, PeriodIndex.shift.", "question_id": 12829},
{"snippet": "pandas.errors.NullFrequencyError", "intent": "Error raised when a null freq attribute is used in an operation that needs a non-null frequency, particularly DatetimeIndex.shift, TimedeltaIndex.shift, PeriodIndex.shift.", "question_id": 12830},
{"snippet": "pandas.errors.NumbaUtilError", "intent": "Error raised for unsupported Numba engine routines.", "question_id": 12831},
{"snippet": "pandas.errors.NumbaUtilError", "intent": "Error raised for unsupported Numba engine routines.", "question_id": 12832},
{"snippet": "pandas.errors.NumbaUtilError", "intent": "Error raised for unsupported Numba engine routines.", "question_id": 12833},
{"snippet": "pandas.errors.OutOfBoundsTimedelta", "intent": "Raised when encountering a timedelta value that cannot be represented as a timedelta64[ns].", "question_id": 12834},
{"snippet": "pandas.errors.OutOfBoundsTimedelta", "intent": "Raised when encountering a timedelta value that cannot be represented as a timedelta64[ns].", "question_id": 12835},
{"snippet": "pandas.errors.OutOfBoundsTimedelta", "intent": "Raised when encountering a timedelta value that cannot be represented as a timedelta64[ns].", "question_id": 12836},
{"snippet": "pandas.errors.ParserError", "intent": "Exception that is raised by an error encountered in parsing file contents.", "question_id": 12837},
{"snippet": "pandas.errors.ParserError", "intent": "Exception that is raised by an error encountered in parsing file contents.", "question_id": 12838},
{"snippet": "pandas.errors.ParserError", "intent": "Exception that is raised by an error encountered in parsing file contents.", "question_id": 12839},
{"snippet": "pandas.errors.ParserWarning", "intent": "Warning raised when reading a file that doesn\u2019t use the default \u2018c\u2019 parser.", "question_id": 12840},
{"snippet": "pandas.errors.ParserWarning", "intent": "Warning raised when reading a file that doesn\u2019t use the default \u2018c\u2019 parser.", "question_id": 12841},
{"snippet": "pandas.errors.ParserWarning", "intent": "Warning raised when reading a file that doesn\u2019t use the default \u2018c\u2019 parser.", "question_id": 12842},
{"snippet": "pandas.errors.PerformanceWarning", "intent": "Warning raised when there is a possible performance impact.", "question_id": 12843},
{"snippet": "pandas.errors.PerformanceWarning", "intent": "Warning raised when there is a possible performance impact.", "question_id": 12844},
{"snippet": "pandas.errors.PerformanceWarning", "intent": "Warning raised when there is a possible performance impact.", "question_id": 12845},
{"snippet": "pandas.errors.UnsortedIndexError", "intent": "Error raised when attempting to get a slice of a MultiIndex, and the index has not been lexsorted.", "question_id": 12846},
{"snippet": "pandas.errors.UnsortedIndexError", "intent": "Error raised when attempting to get a slice of a MultiIndex, and the index has not been lexsorted.", "question_id": 12847},
{"snippet": "pandas.errors.UnsortedIndexError", "intent": "Error raised when attempting to get a slice of a MultiIndex, and the index has not been lexsorted.", "question_id": 12848},
{"snippet": "pandas.errors.UnsupportedFunctionCall", "intent": "Exception raised when attempting to call a numpy function on a pandas object, but that function is not supported by the object e.g.", "question_id": 12849},
{"snippet": "pandas.errors.UnsupportedFunctionCall", "intent": "Exception raised when attempting to call a numpy function on a pandas object, but that function is not supported by the object e.g.", "question_id": 12850},
{"snippet": "pandas.errors.UnsupportedFunctionCall", "intent": "Exception raised when attempting to call a numpy function on a pandas object, but that function is not supported by the object e.g.", "question_id": 12851},
{"snippet": "pandas.eval(expr)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`.", "question_id": 12852},
{"snippet": "pandas.eval(expr, parser='pandas')", "intent": "Evaluate a Python expression as a string using various backends . Additionally , the 'pandas ' `parser` allows the use of and , or , and not with the same semantics as the corresponding bitwise operators . With arguments `expr`.", "question_id": 12853},
{"snippet": "pandas.eval(expr, engine=None)", "intent": "Evaluate a Python expression as a string using various backends . The following arithmetic operations are supported : + , - , * , / , * * , % , // ( python `engine` only ) along with the following boolean operations : | ( or ) , & ( and ) , and ~ ( not ) . With arguments `expr`.", "question_id": 12854},
{"snippet": "pandas.eval(expr, truediv=NoDefault.no_default)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `truediv`.", "question_id": 12855},
{"snippet": "pandas.eval(expr, local_dict=None)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `local_dict`.", "question_id": 12856},
{"snippet": "pandas.eval(expr, global_dict=None)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `global_dict`.", "question_id": 12857},
{"snippet": "pandas.eval(expr, resolvers=())", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `resolvers`.", "question_id": 12858},
{"snippet": "pandas.eval(expr, level=0)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `level`.", "question_id": 12859},
{"snippet": "pandas.eval(expr, target=None)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `target`.", "question_id": 12860},
{"snippet": "pandas.eval(expr, inplace=False)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `inplace`.", "question_id": 12861},
{"snippet": "pandas.eval(expr)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`.", "question_id": 12862},
{"snippet": "pandas.eval(expr, parser='pandas')", "intent": "Evaluate a Python expression as a string using various backends . Additionally , the 'pandas ' `parser` allows the use of and , or , and not with the same semantics as the corresponding bitwise operators . With arguments `expr`.", "question_id": 12863},
{"snippet": "pandas.eval(expr, engine=None)", "intent": "Evaluate a Python expression as a string using various backends . The following arithmetic operations are supported : + , - , * , / , * * , % , // ( python `engine` only ) along with the following boolean operations : | ( or ) , & ( and ) , and ~ ( not ) . With arguments `expr`.", "question_id": 12864},
{"snippet": "pandas.eval(expr, truediv=NoDefault.no_default)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `truediv`.", "question_id": 12865},
{"snippet": "pandas.eval(expr, local_dict=None)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `local_dict`.", "question_id": 12866},
{"snippet": "pandas.eval(expr, global_dict=None)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `global_dict`.", "question_id": 12867},
{"snippet": "pandas.eval(expr, resolvers=())", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `resolvers`.", "question_id": 12868},
{"snippet": "pandas.eval(expr, level=0)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `level`.", "question_id": 12869},
{"snippet": "pandas.eval(expr, target=None)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `target`.", "question_id": 12870},
{"snippet": "pandas.eval(expr, inplace=False)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `inplace`.", "question_id": 12871},
{"snippet": "pandas.eval(expr)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`.", "question_id": 12872},
{"snippet": "pandas.eval(expr, parser='pandas')", "intent": "Evaluate a Python expression as a string using various backends . Additionally , the 'pandas ' `parser` allows the use of and , or , and not with the same semantics as the corresponding bitwise operators . With arguments `expr`.", "question_id": 12873},
{"snippet": "pandas.eval(expr, engine=None)", "intent": "Evaluate a Python expression as a string using various backends . The following arithmetic operations are supported : + , - , * , / , * * , % , // ( python `engine` only ) along with the following boolean operations : | ( or ) , & ( and ) , and ~ ( not ) . With arguments `expr`.", "question_id": 12874},
{"snippet": "pandas.eval(expr, truediv=NoDefault.no_default)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `truediv`.", "question_id": 12875},
{"snippet": "pandas.eval(expr, local_dict=None)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `local_dict`.", "question_id": 12876},
{"snippet": "pandas.eval(expr, global_dict=None)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `global_dict`.", "question_id": 12877},
{"snippet": "pandas.eval(expr, resolvers=())", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `resolvers`.", "question_id": 12878},
{"snippet": "pandas.eval(expr, level=0)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `level`.", "question_id": 12879},
{"snippet": "pandas.eval(expr, target=None)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `target`.", "question_id": 12880},
{"snippet": "pandas.eval(expr, inplace=False)", "intent": "Evaluate a Python expression as a string using various backends . With arguments `expr`, `inplace`.", "question_id": 12881},
{"snippet": "pandas.factorize(values)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` .", "question_id": 12882},
{"snippet": "pandas.factorize(values, sort=False)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . With arguments `sort`.", "question_id": 12883},
{"snippet": "pandas.factorize(values, na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) .", "question_id": 12884},
{"snippet": "pandas.factorize(values, size_hint=None)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . With arguments `size_hint`.", "question_id": 12885},
{"snippet": "pandas.factorize(values, sort=False, na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `sort`.", "question_id": 12886},
{"snippet": "pandas.factorize(values, sort=False, size_hint=None)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . With arguments `sort`, `size_hint`.", "question_id": 12887},
{"snippet": "pandas.factorize(values, na_sentinel=- 1, size_hint=None)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `size_hint`.", "question_id": 12888},
{"snippet": "pandas.factorize(values, sort=False, na_sentinel=- 1, size_hint=None)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `sort`, `size_hint`.", "question_id": 12889},
{"snippet": "pandas.factorize(values)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` .", "question_id": 12890},
{"snippet": "pandas.factorize(values, sort=False)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . With arguments `sort`.", "question_id": 12891},
{"snippet": "pandas.factorize(values, na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) .", "question_id": 12892},
{"snippet": "pandas.factorize(values, size_hint=None)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . With arguments `size_hint`.", "question_id": 12893},
{"snippet": "pandas.factorize(values, sort=False, na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `sort`.", "question_id": 12894},
{"snippet": "pandas.factorize(values, sort=False, size_hint=None)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . With arguments `sort`, `size_hint`.", "question_id": 12895},
{"snippet": "pandas.factorize(values, na_sentinel=- 1, size_hint=None)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `size_hint`.", "question_id": 12896},
{"snippet": "pandas.factorize(values, sort=False, na_sentinel=- 1, size_hint=None)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `sort`, `size_hint`.", "question_id": 12897},
{"snippet": "pandas.factorize(values)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` .", "question_id": 12898},
{"snippet": "pandas.factorize(values, sort=False)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . With arguments `sort`.", "question_id": 12899},
{"snippet": "pandas.factorize(values, na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) .", "question_id": 12900},
{"snippet": "pandas.factorize(values, size_hint=None)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . With arguments `size_hint`.", "question_id": 12901},
{"snippet": "pandas.factorize(values, sort=False, na_sentinel=- 1)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `sort`.", "question_id": 12902},
{"snippet": "pandas.factorize(values, sort=False, size_hint=None)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . With arguments `sort`, `size_hint`.", "question_id": 12903},
{"snippet": "pandas.factorize(values, na_sentinel=- 1, size_hint=None)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `size_hint`.", "question_id": 12904},
{"snippet": "pandas.factorize(values, sort=False, na_sentinel=- 1, size_hint=None)", "intent": "Encode the object as an enumerated type or categorical variable . This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct `values` . Missing values are indicated in codes with `na_sentinel` ( -1 by default ) . With arguments `sort`, `size_hint`.", "question_id": 12905},
{"snippet": "pandas.get_dummies(data)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`.", "question_id": 12906},
{"snippet": "pandas.get_dummies(data, prefix=None)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `prefix`.", "question_id": 12907},
{"snippet": "pandas.get_dummies(data, prefix_sep='_')", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `prefix_sep`.", "question_id": 12908},
{"snippet": "pandas.get_dummies(data, dummy_na=False)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `dummy_na`.", "question_id": 12909},
{"snippet": "pandas.get_dummies(data, columns=None)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `columns`.", "question_id": 12910},
{"snippet": "pandas.get_dummies(data, sparse=False)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `sparse`.", "question_id": 12911},
{"snippet": "pandas.get_dummies(data, drop_first=False)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `drop_first`.", "question_id": 12912},
{"snippet": "pandas.get_dummies(data, dtype=None)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `dtype`.", "question_id": 12913},
{"snippet": "pandas.get_dummies(data, prefix=None, prefix_sep='_')", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `prefix`, `prefix_sep`.", "question_id": 12914},
{"snippet": "pandas.get_dummies(data, prefix=None, dummy_na=False)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `prefix`, `dummy_na`.", "question_id": 12915},
{"snippet": "pandas.get_dummies(data)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`.", "question_id": 12916},
{"snippet": "pandas.get_dummies(data, prefix=None)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `prefix`.", "question_id": 12917},
{"snippet": "pandas.get_dummies(data, prefix_sep='_')", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `prefix_sep`.", "question_id": 12918},
{"snippet": "pandas.get_dummies(data, dummy_na=False)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `dummy_na`.", "question_id": 12919},
{"snippet": "pandas.get_dummies(data, columns=None)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `columns`.", "question_id": 12920},
{"snippet": "pandas.get_dummies(data, sparse=False)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `sparse`.", "question_id": 12921},
{"snippet": "pandas.get_dummies(data, drop_first=False)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `drop_first`.", "question_id": 12922},
{"snippet": "pandas.get_dummies(data, dtype=None)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `dtype`.", "question_id": 12923},
{"snippet": "pandas.get_dummies(data, prefix=None, prefix_sep='_')", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `prefix`, `prefix_sep`.", "question_id": 12924},
{"snippet": "pandas.get_dummies(data, prefix=None, dummy_na=False)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `prefix`, `dummy_na`.", "question_id": 12925},
{"snippet": "pandas.get_dummies(data)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`.", "question_id": 12926},
{"snippet": "pandas.get_dummies(data, prefix=None)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `prefix`.", "question_id": 12927},
{"snippet": "pandas.get_dummies(data, prefix_sep='_')", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `prefix_sep`.", "question_id": 12928},
{"snippet": "pandas.get_dummies(data, dummy_na=False)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `dummy_na`.", "question_id": 12929},
{"snippet": "pandas.get_dummies(data, columns=None)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `columns`.", "question_id": 12930},
{"snippet": "pandas.get_dummies(data, sparse=False)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `sparse`.", "question_id": 12931},
{"snippet": "pandas.get_dummies(data, drop_first=False)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `drop_first`.", "question_id": 12932},
{"snippet": "pandas.get_dummies(data, dtype=None)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `dtype`.", "question_id": 12933},
{"snippet": "pandas.get_dummies(data, prefix=None, prefix_sep='_')", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `prefix`, `prefix_sep`.", "question_id": 12934},
{"snippet": "pandas.get_dummies(data, prefix=None, dummy_na=False)", "intent": "Convert categorical variable into dummy/indicator variables . With arguments `data`, `prefix`, `dummy_na`.", "question_id": 12935},
{"snippet": "pandas.get_option(pat)", "intent": "Retrieves the value of the specified option . With arguments `pat`.", "question_id": 12936},
{"snippet": "pandas.get_option(pat)", "intent": "Retrieves the value of the specified option . With arguments `pat`.", "question_id": 12937},
{"snippet": "pandas.get_option(pat)", "intent": "Retrieves the value of the specified option . With arguments `pat`.", "question_id": 12938},
{"snippet": "pandas.infer_freq(index)", "intent": "Infer the most likely frequency given the input `index` .", "question_id": 12939},
{"snippet": "pandas.infer_freq(index, warn=True)", "intent": "Infer the most likely frequency given the input `index` . With arguments `warn`.", "question_id": 12940},
{"snippet": "pandas.infer_freq(index)", "intent": "Infer the most likely frequency given the input `index` .", "question_id": 12941},
{"snippet": "pandas.infer_freq(index, warn=True)", "intent": "Infer the most likely frequency given the input `index` . With arguments `warn`.", "question_id": 12942},
{"snippet": "pandas.infer_freq(index)", "intent": "Infer the most likely frequency given the input `index` .", "question_id": 12943},
{"snippet": "pandas.infer_freq(index, warn=True)", "intent": "Infer the most likely frequency given the input `index` . With arguments `warn`.", "question_id": 12944},
{"snippet": "pandas.interval_range()", "intent": "Return a fixed frequency IntervalIndex .", "question_id": 12945},
{"snippet": "pandas.interval_range(start=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12946},
{"snippet": "pandas.interval_range(end=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12947},
{"snippet": "pandas.interval_range(periods=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12948},
{"snippet": "pandas.interval_range(freq=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12949},
{"snippet": "pandas.interval_range(name=None)", "intent": "Return a fixed frequency IntervalIndex . With arguments `name`.", "question_id": 12950},
{"snippet": "pandas.interval_range(closed='right')", "intent": "Return a fixed frequency IntervalIndex . The `closed` parameter specifies which endpoints of the individual intervals within the IntervalIndex are closed .", "question_id": 12951},
{"snippet": "pandas.interval_range(start=None, end=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12952},
{"snippet": "pandas.interval_range(start=None, periods=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12953},
{"snippet": "pandas.interval_range(start=None, freq=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12954},
{"snippet": "pandas.interval_range()", "intent": "Return a fixed frequency IntervalIndex .", "question_id": 12955},
{"snippet": "pandas.interval_range(start=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12956},
{"snippet": "pandas.interval_range(end=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12957},
{"snippet": "pandas.interval_range(periods=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12958},
{"snippet": "pandas.interval_range(freq=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12959},
{"snippet": "pandas.interval_range(name=None)", "intent": "Return a fixed frequency IntervalIndex . With arguments `name`.", "question_id": 12960},
{"snippet": "pandas.interval_range(closed='right')", "intent": "Return a fixed frequency IntervalIndex . The `closed` parameter specifies which endpoints of the individual intervals within the IntervalIndex are closed .", "question_id": 12961},
{"snippet": "pandas.interval_range(start=None, end=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12962},
{"snippet": "pandas.interval_range(start=None, periods=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12963},
{"snippet": "pandas.interval_range(start=None, freq=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12964},
{"snippet": "pandas.interval_range()", "intent": "Return a fixed frequency IntervalIndex .", "question_id": 12965},
{"snippet": "pandas.interval_range(start=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12966},
{"snippet": "pandas.interval_range(end=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12967},
{"snippet": "pandas.interval_range(periods=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12968},
{"snippet": "pandas.interval_range(freq=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12969},
{"snippet": "pandas.interval_range(name=None)", "intent": "Return a fixed frequency IntervalIndex . With arguments `name`.", "question_id": 12970},
{"snippet": "pandas.interval_range(closed='right')", "intent": "Return a fixed frequency IntervalIndex . The `closed` parameter specifies which endpoints of the individual intervals within the IntervalIndex are closed .", "question_id": 12971},
{"snippet": "pandas.interval_range(start=None, end=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12972},
{"snippet": "pandas.interval_range(start=None, periods=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12973},
{"snippet": "pandas.interval_range(start=None, freq=None)", "intent": "Return a fixed frequency IntervalIndex . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 12974},
{"snippet": "Styler.apply(func, **kwargs)", "intent": "Apply a CSS-styling function column-wise , row-wise , or table-wise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . With arguments `**kwargs`.", "question_id": 12975},
{"snippet": "Styler.apply(func, **kwargs, axis=0)", "intent": "Apply a CSS-styling function column-wise , row-wise , or table-wise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . With arguments `**kwargs`, `axis`.", "question_id": 12976},
{"snippet": "Styler.apply(func, **kwargs, subset=None)", "intent": "Apply a CSS-styling function column-wise , row-wise , or table-wise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . Using `subset` to restrict application to a single column or multiple columns With arguments `**kwargs`.", "question_id": 12977},
{"snippet": "Styler.apply(func, **kwargs, axis=0, subset=None)", "intent": "Apply a CSS-styling function column-wise , row-wise , or table-wise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . Using `subset` to restrict application to a single column or multiple columns With arguments `**kwargs`, `axis`.", "question_id": 12978},
{"snippet": "Styler.apply(func, **kwargs)", "intent": "Apply a CSS-styling function column-wise , row-wise , or table-wise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . With arguments `**kwargs`.", "question_id": 12979},
{"snippet": "Styler.apply(func, **kwargs, axis=0)", "intent": "Apply a CSS-styling function column-wise , row-wise , or table-wise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . With arguments `**kwargs`, `axis`.", "question_id": 12980},
{"snippet": "Styler.apply(func, **kwargs, subset=None)", "intent": "Apply a CSS-styling function column-wise , row-wise , or table-wise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . Using `subset` to restrict application to a single column or multiple columns With arguments `**kwargs`.", "question_id": 12981},
{"snippet": "Styler.apply(func, **kwargs, axis=0, subset=None)", "intent": "Apply a CSS-styling function column-wise , row-wise , or table-wise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . Using `subset` to restrict application to a single column or multiple columns With arguments `**kwargs`, `axis`.", "question_id": 12982},
{"snippet": "Styler.apply(func, **kwargs)", "intent": "Apply a CSS-styling function column-wise , row-wise , or table-wise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . With arguments `**kwargs`.", "question_id": 12983},
{"snippet": "Styler.apply(func, **kwargs, axis=0)", "intent": "Apply a CSS-styling function column-wise , row-wise , or table-wise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . With arguments `**kwargs`, `axis`.", "question_id": 12984},
{"snippet": "Styler.apply(func, **kwargs, subset=None)", "intent": "Apply a CSS-styling function column-wise , row-wise , or table-wise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . Using `subset` to restrict application to a single column or multiple columns With arguments `**kwargs`.", "question_id": 12985},
{"snippet": "Styler.apply(func, **kwargs, axis=0, subset=None)", "intent": "Apply a CSS-styling function column-wise , row-wise , or table-wise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . Using `subset` to restrict application to a single column or multiple columns With arguments `**kwargs`, `axis`.", "question_id": 12986},
{"snippet": "Styler.applymap(func, **kwargs)", "intent": "Apply a CSS-styling function elementwise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . With arguments `**kwargs`.", "question_id": 12987},
{"snippet": "Styler.applymap(func, **kwargs, subset=None)", "intent": "Apply a CSS-styling function elementwise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . Using `subset` to restrict application to a single column or multiple columns With arguments `**kwargs`.", "question_id": 12988},
{"snippet": "Styler.applymap(func, **kwargs)", "intent": "Apply a CSS-styling function elementwise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . With arguments `**kwargs`.", "question_id": 12989},
{"snippet": "Styler.applymap(func, **kwargs, subset=None)", "intent": "Apply a CSS-styling function elementwise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . Using `subset` to restrict application to a single column or multiple columns With arguments `**kwargs`.", "question_id": 12990},
{"snippet": "Styler.applymap(func, **kwargs)", "intent": "Apply a CSS-styling function elementwise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . With arguments `**kwargs`.", "question_id": 12991},
{"snippet": "Styler.applymap(func, **kwargs, subset=None)", "intent": "Apply a CSS-styling function elementwise . The elements of the output of `func` should be CSS styles as strings , in the format \u2018 attribute : value ; attribute2 : value2 ; \u2026 \u2019 or , if nothing is to be applied to that element , an empty string or None . Using `subset` to restrict application to a single column or multiple columns With arguments `**kwargs`.", "question_id": 12992},
{"snippet": "Styler.background_gradient()", "intent": "Color the background in a gradient style .", "question_id": 12993},
{"snippet": "Styler.background_gradient(cmap='PuBu')", "intent": "Color the background in a gradient style . Setting a gmap and applying to all columns with another `cmap`", "question_id": 12994},
{"snippet": "Styler.background_gradient(low=0)", "intent": "Color the background in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 12995},
{"snippet": "Styler.background_gradient(high=0)", "intent": "Color the background in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 12996},
{"snippet": "Styler.background_gradient(axis=0)", "intent": "Color the background in a gradient style . With arguments `axis`.", "question_id": 12997},
{"snippet": "Styler.background_gradient(subset=None)", "intent": "Color the background in a gradient style . axis=None ) , we need to explicitly state `subset` to match the gmap shape", "question_id": 12998},
{"snippet": "Styler.background_gradient(text_color_threshold=0.408)", "intent": "Color the background in a gradient style . With arguments `text_color_threshold`.", "question_id": 12999},
{"snippet": "Styler.background_gradient(vmin=None)", "intent": "Color the background in a gradient style . If combining with `vmin` and `vmax` the map.min , map.max and map.range are replaced by values according to the values derived from vmin and vmax .", "question_id": 13000},
{"snippet": "Styler.background_gradient(vmax=None)", "intent": "Color the background in a gradient style . If combining with `vmin` and `vmax` the map.min , map.max and map.range are replaced by values according to the values derived from vmin and vmax .", "question_id": 13001},
{"snippet": "Styler.background_gradient(gmap=None)", "intent": "Color the background in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13002},
{"snippet": "Styler.background_gradient()", "intent": "Color the background in a gradient style .", "question_id": 13003},
{"snippet": "Styler.background_gradient(cmap='PuBu')", "intent": "Color the background in a gradient style . Setting a gmap and applying to all columns with another `cmap`", "question_id": 13004},
{"snippet": "Styler.background_gradient(low=0)", "intent": "Color the background in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13005},
{"snippet": "Styler.background_gradient(high=0)", "intent": "Color the background in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13006},
{"snippet": "Styler.background_gradient(axis=0)", "intent": "Color the background in a gradient style . With arguments `axis`.", "question_id": 13007},
{"snippet": "Styler.background_gradient(subset=None)", "intent": "Color the background in a gradient style . axis=None ) , we need to explicitly state `subset` to match the gmap shape", "question_id": 13008},
{"snippet": "Styler.background_gradient(text_color_threshold=0.408)", "intent": "Color the background in a gradient style . With arguments `text_color_threshold`.", "question_id": 13009},
{"snippet": "Styler.background_gradient(vmin=None)", "intent": "Color the background in a gradient style . If combining with `vmin` and `vmax` the map.min , map.max and map.range are replaced by values according to the values derived from vmin and vmax .", "question_id": 13010},
{"snippet": "Styler.background_gradient(vmax=None)", "intent": "Color the background in a gradient style . If combining with `vmin` and `vmax` the map.min , map.max and map.range are replaced by values according to the values derived from vmin and vmax .", "question_id": 13011},
{"snippet": "Styler.background_gradient(gmap=None)", "intent": "Color the background in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13012},
{"snippet": "Styler.background_gradient()", "intent": "Color the background in a gradient style .", "question_id": 13013},
{"snippet": "Styler.background_gradient(cmap='PuBu')", "intent": "Color the background in a gradient style . Setting a gmap and applying to all columns with another `cmap`", "question_id": 13014},
{"snippet": "Styler.background_gradient(low=0)", "intent": "Color the background in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13015},
{"snippet": "Styler.background_gradient(high=0)", "intent": "Color the background in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13016},
{"snippet": "Styler.background_gradient(axis=0)", "intent": "Color the background in a gradient style . With arguments `axis`.", "question_id": 13017},
{"snippet": "Styler.background_gradient(subset=None)", "intent": "Color the background in a gradient style . axis=None ) , we need to explicitly state `subset` to match the gmap shape", "question_id": 13018},
{"snippet": "Styler.background_gradient(text_color_threshold=0.408)", "intent": "Color the background in a gradient style . With arguments `text_color_threshold`.", "question_id": 13019},
{"snippet": "Styler.background_gradient(vmin=None)", "intent": "Color the background in a gradient style . If combining with `vmin` and `vmax` the map.min , map.max and map.range are replaced by values according to the values derived from vmin and vmax .", "question_id": 13020},
{"snippet": "Styler.background_gradient(vmax=None)", "intent": "Color the background in a gradient style . If combining with `vmin` and `vmax` the map.min , map.max and map.range are replaced by values according to the values derived from vmin and vmax .", "question_id": 13021},
{"snippet": "Styler.background_gradient(gmap=None)", "intent": "Color the background in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13022},
{"snippet": "Styler.bar()", "intent": "Draw bar chart in the cell backgrounds .", "question_id": 13023},
{"snippet": "Styler.bar(subset=None)", "intent": "Draw bar chart in the cell backgrounds . With arguments `subset`.", "question_id": 13024},
{"snippet": "Styler.bar(axis=0)", "intent": "Draw bar chart in the cell backgrounds . With arguments `axis`.", "question_id": 13025},
{"snippet": "Styler.bar(color='#d65f5f')", "intent": "Draw bar chart in the cell backgrounds . With arguments `color`.", "question_id": 13026},
{"snippet": "Styler.bar(width=100)", "intent": "Draw bar chart in the cell backgrounds . With arguments `width`.", "question_id": 13027},
{"snippet": "Styler.bar(align='left')", "intent": "Draw bar chart in the cell backgrounds . With arguments `align`.", "question_id": 13028},
{"snippet": "Styler.bar(vmin=None)", "intent": "Draw bar chart in the cell backgrounds . With arguments `vmin`.", "question_id": 13029},
{"snippet": "Styler.bar(vmax=None)", "intent": "Draw bar chart in the cell backgrounds . With arguments `vmax`.", "question_id": 13030},
{"snippet": "Styler.bar(subset=None, axis=0)", "intent": "Draw bar chart in the cell backgrounds . With arguments `subset`, `axis`.", "question_id": 13031},
{"snippet": "Styler.bar(subset=None, color='#d65f5f')", "intent": "Draw bar chart in the cell backgrounds . With arguments `subset`, `color`.", "question_id": 13032},
{"snippet": "Styler.bar()", "intent": "Draw bar chart in the cell backgrounds .", "question_id": 13033},
{"snippet": "Styler.bar(subset=None)", "intent": "Draw bar chart in the cell backgrounds . With arguments `subset`.", "question_id": 13034},
{"snippet": "Styler.bar(axis=0)", "intent": "Draw bar chart in the cell backgrounds . With arguments `axis`.", "question_id": 13035},
{"snippet": "Styler.bar(color='#d65f5f')", "intent": "Draw bar chart in the cell backgrounds . With arguments `color`.", "question_id": 13036},
{"snippet": "Styler.bar(width=100)", "intent": "Draw bar chart in the cell backgrounds . With arguments `width`.", "question_id": 13037},
{"snippet": "Styler.bar(align='left')", "intent": "Draw bar chart in the cell backgrounds . With arguments `align`.", "question_id": 13038},
{"snippet": "Styler.bar(vmin=None)", "intent": "Draw bar chart in the cell backgrounds . With arguments `vmin`.", "question_id": 13039},
{"snippet": "Styler.bar(vmax=None)", "intent": "Draw bar chart in the cell backgrounds . With arguments `vmax`.", "question_id": 13040},
{"snippet": "Styler.bar(subset=None, axis=0)", "intent": "Draw bar chart in the cell backgrounds . With arguments `subset`, `axis`.", "question_id": 13041},
{"snippet": "Styler.bar(subset=None, color='#d65f5f')", "intent": "Draw bar chart in the cell backgrounds . With arguments `subset`, `color`.", "question_id": 13042},
{"snippet": "Styler.bar()", "intent": "Draw bar chart in the cell backgrounds .", "question_id": 13043},
{"snippet": "Styler.bar(subset=None)", "intent": "Draw bar chart in the cell backgrounds . With arguments `subset`.", "question_id": 13044},
{"snippet": "Styler.bar(axis=0)", "intent": "Draw bar chart in the cell backgrounds . With arguments `axis`.", "question_id": 13045},
{"snippet": "Styler.bar(color='#d65f5f')", "intent": "Draw bar chart in the cell backgrounds . With arguments `color`.", "question_id": 13046},
{"snippet": "Styler.bar(width=100)", "intent": "Draw bar chart in the cell backgrounds . With arguments `width`.", "question_id": 13047},
{"snippet": "Styler.bar(align='left')", "intent": "Draw bar chart in the cell backgrounds . With arguments `align`.", "question_id": 13048},
{"snippet": "Styler.bar(vmin=None)", "intent": "Draw bar chart in the cell backgrounds . With arguments `vmin`.", "question_id": 13049},
{"snippet": "Styler.bar(vmax=None)", "intent": "Draw bar chart in the cell backgrounds . With arguments `vmax`.", "question_id": 13050},
{"snippet": "Styler.bar(subset=None, axis=0)", "intent": "Draw bar chart in the cell backgrounds . With arguments `subset`, `axis`.", "question_id": 13051},
{"snippet": "Styler.bar(subset=None, color='#d65f5f')", "intent": "Draw bar chart in the cell backgrounds . With arguments `subset`, `color`.", "question_id": 13052},
{"snippet": "Styler.clear()", "intent": "Reset the Styler , removing any previously applied styles .", "question_id": 13053},
{"snippet": "Styler.clear()", "intent": "Reset the Styler , removing any previously applied styles .", "question_id": 13054},
{"snippet": "Styler.clear()", "intent": "Reset the Styler , removing any previously applied styles .", "question_id": 13055},
{"snippet": "Styler.export()", "intent": "Export the styles applied to the current Styler .", "question_id": 13056},
{"snippet": "Styler.export()", "intent": "Export the styles applied to the current Styler .", "question_id": 13057},
{"snippet": "Styler.export()", "intent": "Export the styles applied to the current Styler .", "question_id": 13058},
{"snippet": "Styler.format()", "intent": "Format the text display value of cells .", "question_id": 13059},
{"snippet": "Styler.format(formatter=None)", "intent": "Format the text display value of cells . This method assigns a formatting function , `formatter` , to each cell in the DataFrame .", "question_id": 13060},
{"snippet": "Styler.format(subset=None)", "intent": "Format the text display value of cells . The `subset` argument defines which region to apply the formatting function to .", "question_id": 13061},
{"snippet": "Styler.format(na_rep=None)", "intent": "Format the text display value of cells . The default formatter does not adjust the representation of missing values unless the `na_rep` argument is used .", "question_id": 13062},
{"snippet": "Styler.format(precision=None)", "intent": "Format the text display value of cells . The default formatter currently expresses floats and complex numbers with the pandas display `precision` unless using the precision argument here .", "question_id": 13063},
{"snippet": "Styler.format(decimal='.')", "intent": "Format the text display value of cells . With arguments `decimal`.", "question_id": 13064},
{"snippet": "Styler.format(thousands=None)", "intent": "Format the text display value of cells . With arguments `thousands`.", "question_id": 13065},
{"snippet": "Styler.format(escape=None)", "intent": "Format the text display value of cells . Using a formatter with HTML `escape` and na_rep .", "question_id": 13066},
{"snippet": "Styler.format(formatter=None, subset=None)", "intent": "Format the text display value of cells . This method assigns a formatting function , `formatter` , to each cell in the DataFrame . The `subset` argument defines which region to apply the formatting function to .", "question_id": 13067},
{"snippet": "Styler.format(formatter=None, na_rep=None)", "intent": "Format the text display value of cells . This method assigns a formatting function , `formatter` , to each cell in the DataFrame . The default formatter does not adjust the representation of missing values unless the `na_rep` argument is used .", "question_id": 13068},
{"snippet": "Styler.format()", "intent": "Format the text display value of cells .", "question_id": 13069},
{"snippet": "Styler.format(formatter=None)", "intent": "Format the text display value of cells . This method assigns a formatting function , `formatter` , to each cell in the DataFrame .", "question_id": 13070},
{"snippet": "Styler.format(subset=None)", "intent": "Format the text display value of cells . The `subset` argument defines which region to apply the formatting function to .", "question_id": 13071},
{"snippet": "Styler.format(na_rep=None)", "intent": "Format the text display value of cells . The default formatter does not adjust the representation of missing values unless the `na_rep` argument is used .", "question_id": 13072},
{"snippet": "Styler.format(precision=None)", "intent": "Format the text display value of cells . The default formatter currently expresses floats and complex numbers with the pandas display `precision` unless using the precision argument here .", "question_id": 13073},
{"snippet": "Styler.format(decimal='.')", "intent": "Format the text display value of cells . With arguments `decimal`.", "question_id": 13074},
{"snippet": "Styler.format(thousands=None)", "intent": "Format the text display value of cells . With arguments `thousands`.", "question_id": 13075},
{"snippet": "Styler.format(escape=None)", "intent": "Format the text display value of cells . Using a formatter with HTML `escape` and na_rep .", "question_id": 13076},
{"snippet": "Styler.format(formatter=None, subset=None)", "intent": "Format the text display value of cells . This method assigns a formatting function , `formatter` , to each cell in the DataFrame . The `subset` argument defines which region to apply the formatting function to .", "question_id": 13077},
{"snippet": "Styler.format(formatter=None, na_rep=None)", "intent": "Format the text display value of cells . This method assigns a formatting function , `formatter` , to each cell in the DataFrame . The default formatter does not adjust the representation of missing values unless the `na_rep` argument is used .", "question_id": 13078},
{"snippet": "Styler.format()", "intent": "Format the text display value of cells .", "question_id": 13079},
{"snippet": "Styler.format(formatter=None)", "intent": "Format the text display value of cells . This method assigns a formatting function , `formatter` , to each cell in the DataFrame .", "question_id": 13080},
{"snippet": "Styler.format(subset=None)", "intent": "Format the text display value of cells . The `subset` argument defines which region to apply the formatting function to .", "question_id": 13081},
{"snippet": "Styler.format(na_rep=None)", "intent": "Format the text display value of cells . The default formatter does not adjust the representation of missing values unless the `na_rep` argument is used .", "question_id": 13082},
{"snippet": "Styler.format(precision=None)", "intent": "Format the text display value of cells . The default formatter currently expresses floats and complex numbers with the pandas display `precision` unless using the precision argument here .", "question_id": 13083},
{"snippet": "Styler.format(decimal='.')", "intent": "Format the text display value of cells . With arguments `decimal`.", "question_id": 13084},
{"snippet": "Styler.format(thousands=None)", "intent": "Format the text display value of cells . With arguments `thousands`.", "question_id": 13085},
{"snippet": "Styler.format(escape=None)", "intent": "Format the text display value of cells . Using a formatter with HTML `escape` and na_rep .", "question_id": 13086},
{"snippet": "Styler.format(formatter=None, subset=None)", "intent": "Format the text display value of cells . This method assigns a formatting function , `formatter` , to each cell in the DataFrame . The `subset` argument defines which region to apply the formatting function to .", "question_id": 13087},
{"snippet": "Styler.format(formatter=None, na_rep=None)", "intent": "Format the text display value of cells . This method assigns a formatting function , `formatter` , to each cell in the DataFrame . The default formatter does not adjust the representation of missing values unless the `na_rep` argument is used .", "question_id": 13088},
{"snippet": "Styler.from_custom_template(searchpath)", "intent": "Factory function for creating a subclass of Styler . With arguments `searchpath`.", "question_id": 13089},
{"snippet": "Styler.from_custom_template(searchpath, html_table=None)", "intent": "Factory function for creating a subclass of Styler . With arguments `searchpath`, `html_table`.", "question_id": 13090},
{"snippet": "Styler.from_custom_template(searchpath, html_style=None)", "intent": "Factory function for creating a subclass of Styler . With arguments `searchpath`, `html_style`.", "question_id": 13091},
{"snippet": "Styler.from_custom_template(searchpath, html_table=None, html_style=None)", "intent": "Factory function for creating a subclass of Styler . With arguments `searchpath`, `html_table`, `html_style`.", "question_id": 13092},
{"snippet": "Styler.from_custom_template(searchpath)", "intent": "Factory function for creating a subclass of Styler . With arguments `searchpath`.", "question_id": 13093},
{"snippet": "Styler.from_custom_template(searchpath, html_table=None)", "intent": "Factory function for creating a subclass of Styler . With arguments `searchpath`, `html_table`.", "question_id": 13094},
{"snippet": "Styler.from_custom_template(searchpath, html_style=None)", "intent": "Factory function for creating a subclass of Styler . With arguments `searchpath`, `html_style`.", "question_id": 13095},
{"snippet": "Styler.from_custom_template(searchpath, html_table=None, html_style=None)", "intent": "Factory function for creating a subclass of Styler . With arguments `searchpath`, `html_table`, `html_style`.", "question_id": 13096},
{"snippet": "Styler.from_custom_template(searchpath)", "intent": "Factory function for creating a subclass of Styler . With arguments `searchpath`.", "question_id": 13097},
{"snippet": "Styler.from_custom_template(searchpath, html_table=None)", "intent": "Factory function for creating a subclass of Styler . With arguments `searchpath`, `html_table`.", "question_id": 13098},
{"snippet": "Styler.from_custom_template(searchpath, html_style=None)", "intent": "Factory function for creating a subclass of Styler . With arguments `searchpath`, `html_style`.", "question_id": 13099},
{"snippet": "Styler.from_custom_template(searchpath, html_table=None, html_style=None)", "intent": "Factory function for creating a subclass of Styler . With arguments `searchpath`, `html_table`, `html_style`.", "question_id": 13100},
{"snippet": "Styler.hide_columns()", "intent": "Hide the column headers or specific keys in the columns from rendering .", "question_id": 13101},
{"snippet": "Styler.hide_columns(subset=None)", "intent": "Hide the column headers or specific keys in the columns from rendering . With arguments `subset`.", "question_id": 13102},
{"snippet": "Styler.hide_columns()", "intent": "Hide the column headers or specific keys in the columns from rendering .", "question_id": 13103},
{"snippet": "Styler.hide_columns(subset=None)", "intent": "Hide the column headers or specific keys in the columns from rendering . With arguments `subset`.", "question_id": 13104},
{"snippet": "Styler.hide_columns()", "intent": "Hide the column headers or specific keys in the columns from rendering .", "question_id": 13105},
{"snippet": "Styler.hide_columns(subset=None)", "intent": "Hide the column headers or specific keys in the columns from rendering . With arguments `subset`.", "question_id": 13106},
{"snippet": "Styler.hide_index()", "intent": "Hide the entire index , or specific keys in the index from rendering .", "question_id": 13107},
{"snippet": "Styler.hide_index(subset=None)", "intent": "Hide the entire index , or specific keys in the index from rendering . With arguments `subset`.", "question_id": 13108},
{"snippet": "Styler.hide_index()", "intent": "Hide the entire index , or specific keys in the index from rendering .", "question_id": 13109},
{"snippet": "Styler.hide_index(subset=None)", "intent": "Hide the entire index , or specific keys in the index from rendering . With arguments `subset`.", "question_id": 13110},
{"snippet": "Styler.hide_index()", "intent": "Hide the entire index , or specific keys in the index from rendering .", "question_id": 13111},
{"snippet": "Styler.hide_index(subset=None)", "intent": "Hide the entire index , or specific keys in the index from rendering . With arguments `subset`.", "question_id": 13112},
{"snippet": "Styler.highlight_between()", "intent": "Highlight a defined range with a style .", "question_id": 13113},
{"snippet": "Styler.highlight_between(subset=None)", "intent": "Highlight a defined range with a style . Use `subset` to control regions which have multiple dtypes .", "question_id": 13114},
{"snippet": "Styler.highlight_between(color='yellow')", "intent": "Highlight a defined range with a style . With arguments `color`.", "question_id": 13115},
{"snippet": "Styler.highlight_between(axis=0)", "intent": "Highlight a defined range with a style . `axis` is only needed if left or right are provided as a sequence or an array-like object for aligning the shapes .", "question_id": 13116},
{"snippet": "Styler.highlight_between(left=None)", "intent": "Highlight a defined range with a style . If `left` is None only the `right` bound is applied .", "question_id": 13117},
{"snippet": "Styler.highlight_between(right=None)", "intent": "Highlight a defined range with a style . If `left` is None only the `right` bound is applied .", "question_id": 13118},
{"snippet": "Styler.highlight_between(inclusive='both')", "intent": "Highlight a defined range with a style . With arguments `inclusive`.", "question_id": 13119},
{"snippet": "Styler.highlight_between(props=None)", "intent": "Highlight a defined range with a style . Using `props` instead of default background coloring", "question_id": 13120},
{"snippet": "Styler.highlight_between(subset=None, color='yellow')", "intent": "Highlight a defined range with a style . Use `subset` to control regions which have multiple dtypes . With arguments `color`.", "question_id": 13121},
{"snippet": "Styler.highlight_between(subset=None, axis=0)", "intent": "Highlight a defined range with a style . Use `subset` to control regions which have multiple dtypes . `axis` is only needed if left or right are provided as a sequence or an array-like object for aligning the shapes .", "question_id": 13122},
{"snippet": "Styler.highlight_between()", "intent": "Highlight a defined range with a style .", "question_id": 13123},
{"snippet": "Styler.highlight_between(subset=None)", "intent": "Highlight a defined range with a style . Use `subset` to control regions which have multiple dtypes .", "question_id": 13124},
{"snippet": "Styler.highlight_between(color='yellow')", "intent": "Highlight a defined range with a style . With arguments `color`.", "question_id": 13125},
{"snippet": "Styler.highlight_between(axis=0)", "intent": "Highlight a defined range with a style . `axis` is only needed if left or right are provided as a sequence or an array-like object for aligning the shapes .", "question_id": 13126},
{"snippet": "Styler.highlight_between(left=None)", "intent": "Highlight a defined range with a style . If `left` is None only the `right` bound is applied .", "question_id": 13127},
{"snippet": "Styler.highlight_between(right=None)", "intent": "Highlight a defined range with a style . If `left` is None only the `right` bound is applied .", "question_id": 13128},
{"snippet": "Styler.highlight_between(inclusive='both')", "intent": "Highlight a defined range with a style . With arguments `inclusive`.", "question_id": 13129},
{"snippet": "Styler.highlight_between(props=None)", "intent": "Highlight a defined range with a style . Using `props` instead of default background coloring", "question_id": 13130},
{"snippet": "Styler.highlight_between(subset=None, color='yellow')", "intent": "Highlight a defined range with a style . Use `subset` to control regions which have multiple dtypes . With arguments `color`.", "question_id": 13131},
{"snippet": "Styler.highlight_between(subset=None, axis=0)", "intent": "Highlight a defined range with a style . Use `subset` to control regions which have multiple dtypes . `axis` is only needed if left or right are provided as a sequence or an array-like object for aligning the shapes .", "question_id": 13132},
{"snippet": "Styler.highlight_between()", "intent": "Highlight a defined range with a style .", "question_id": 13133},
{"snippet": "Styler.highlight_between(subset=None)", "intent": "Highlight a defined range with a style . Use `subset` to control regions which have multiple dtypes .", "question_id": 13134},
{"snippet": "Styler.highlight_between(color='yellow')", "intent": "Highlight a defined range with a style . With arguments `color`.", "question_id": 13135},
{"snippet": "Styler.highlight_between(axis=0)", "intent": "Highlight a defined range with a style . `axis` is only needed if left or right are provided as a sequence or an array-like object for aligning the shapes .", "question_id": 13136},
{"snippet": "Styler.highlight_between(left=None)", "intent": "Highlight a defined range with a style . If `left` is None only the `right` bound is applied .", "question_id": 13137},
{"snippet": "Styler.highlight_between(right=None)", "intent": "Highlight a defined range with a style . If `left` is None only the `right` bound is applied .", "question_id": 13138},
{"snippet": "Styler.highlight_between(inclusive='both')", "intent": "Highlight a defined range with a style . With arguments `inclusive`.", "question_id": 13139},
{"snippet": "Styler.highlight_between(props=None)", "intent": "Highlight a defined range with a style . Using `props` instead of default background coloring", "question_id": 13140},
{"snippet": "Styler.highlight_between(subset=None, color='yellow')", "intent": "Highlight a defined range with a style . Use `subset` to control regions which have multiple dtypes . With arguments `color`.", "question_id": 13141},
{"snippet": "Styler.highlight_between(subset=None, axis=0)", "intent": "Highlight a defined range with a style . Use `subset` to control regions which have multiple dtypes . `axis` is only needed if left or right are provided as a sequence or an array-like object for aligning the shapes .", "question_id": 13142},
{"snippet": "Styler.highlight_max()", "intent": "Highlight the maximum with a style .", "question_id": 13143},
{"snippet": "Styler.highlight_max(subset=None)", "intent": "Highlight the maximum with a style . With arguments `subset`.", "question_id": 13144},
{"snippet": "Styler.highlight_max(color='yellow')", "intent": "Highlight the maximum with a style . With arguments `color`.", "question_id": 13145},
{"snippet": "Styler.highlight_max(axis=0)", "intent": "Highlight the maximum with a style . With arguments `axis`.", "question_id": 13146},
{"snippet": "Styler.highlight_max(props=None)", "intent": "Highlight the maximum with a style . With arguments `props`.", "question_id": 13147},
{"snippet": "Styler.highlight_max(subset=None, color='yellow')", "intent": "Highlight the maximum with a style . With arguments `subset`, `color`.", "question_id": 13148},
{"snippet": "Styler.highlight_max(subset=None, axis=0)", "intent": "Highlight the maximum with a style . With arguments `subset`, `axis`.", "question_id": 13149},
{"snippet": "Styler.highlight_max(subset=None, props=None)", "intent": "Highlight the maximum with a style . With arguments `subset`, `props`.", "question_id": 13150},
{"snippet": "Styler.highlight_max(color='yellow', axis=0)", "intent": "Highlight the maximum with a style . With arguments `color`, `axis`.", "question_id": 13151},
{"snippet": "Styler.highlight_max(color='yellow', props=None)", "intent": "Highlight the maximum with a style . With arguments `color`, `props`.", "question_id": 13152},
{"snippet": "Styler.highlight_max()", "intent": "Highlight the maximum with a style .", "question_id": 13153},
{"snippet": "Styler.highlight_max(subset=None)", "intent": "Highlight the maximum with a style . With arguments `subset`.", "question_id": 13154},
{"snippet": "Styler.highlight_max(color='yellow')", "intent": "Highlight the maximum with a style . With arguments `color`.", "question_id": 13155},
{"snippet": "Styler.highlight_max(axis=0)", "intent": "Highlight the maximum with a style . With arguments `axis`.", "question_id": 13156},
{"snippet": "Styler.highlight_max(props=None)", "intent": "Highlight the maximum with a style . With arguments `props`.", "question_id": 13157},
{"snippet": "Styler.highlight_max(subset=None, color='yellow')", "intent": "Highlight the maximum with a style . With arguments `subset`, `color`.", "question_id": 13158},
{"snippet": "Styler.highlight_max(subset=None, axis=0)", "intent": "Highlight the maximum with a style . With arguments `subset`, `axis`.", "question_id": 13159},
{"snippet": "Styler.highlight_max(subset=None, props=None)", "intent": "Highlight the maximum with a style . With arguments `subset`, `props`.", "question_id": 13160},
{"snippet": "Styler.highlight_max(color='yellow', axis=0)", "intent": "Highlight the maximum with a style . With arguments `color`, `axis`.", "question_id": 13161},
{"snippet": "Styler.highlight_max(color='yellow', props=None)", "intent": "Highlight the maximum with a style . With arguments `color`, `props`.", "question_id": 13162},
{"snippet": "Styler.highlight_max()", "intent": "Highlight the maximum with a style .", "question_id": 13163},
{"snippet": "Styler.highlight_max(subset=None)", "intent": "Highlight the maximum with a style . With arguments `subset`.", "question_id": 13164},
{"snippet": "Styler.highlight_max(color='yellow')", "intent": "Highlight the maximum with a style . With arguments `color`.", "question_id": 13165},
{"snippet": "Styler.highlight_max(axis=0)", "intent": "Highlight the maximum with a style . With arguments `axis`.", "question_id": 13166},
{"snippet": "Styler.highlight_max(props=None)", "intent": "Highlight the maximum with a style . With arguments `props`.", "question_id": 13167},
{"snippet": "Styler.highlight_max(subset=None, color='yellow')", "intent": "Highlight the maximum with a style . With arguments `subset`, `color`.", "question_id": 13168},
{"snippet": "Styler.highlight_max(subset=None, axis=0)", "intent": "Highlight the maximum with a style . With arguments `subset`, `axis`.", "question_id": 13169},
{"snippet": "Styler.highlight_max(subset=None, props=None)", "intent": "Highlight the maximum with a style . With arguments `subset`, `props`.", "question_id": 13170},
{"snippet": "Styler.highlight_max(color='yellow', axis=0)", "intent": "Highlight the maximum with a style . With arguments `color`, `axis`.", "question_id": 13171},
{"snippet": "Styler.highlight_max(color='yellow', props=None)", "intent": "Highlight the maximum with a style . With arguments `color`, `props`.", "question_id": 13172},
{"snippet": "Styler.highlight_min()", "intent": "Highlight the minimum with a style .", "question_id": 13173},
{"snippet": "Styler.highlight_min(subset=None)", "intent": "Highlight the minimum with a style . With arguments `subset`.", "question_id": 13174},
{"snippet": "Styler.highlight_min(color='yellow')", "intent": "Highlight the minimum with a style . With arguments `color`.", "question_id": 13175},
{"snippet": "Styler.highlight_min(axis=0)", "intent": "Highlight the minimum with a style . With arguments `axis`.", "question_id": 13176},
{"snippet": "Styler.highlight_min(props=None)", "intent": "Highlight the minimum with a style . With arguments `props`.", "question_id": 13177},
{"snippet": "Styler.highlight_min(subset=None, color='yellow')", "intent": "Highlight the minimum with a style . With arguments `subset`, `color`.", "question_id": 13178},
{"snippet": "Styler.highlight_min(subset=None, axis=0)", "intent": "Highlight the minimum with a style . With arguments `subset`, `axis`.", "question_id": 13179},
{"snippet": "Styler.highlight_min(subset=None, props=None)", "intent": "Highlight the minimum with a style . With arguments `subset`, `props`.", "question_id": 13180},
{"snippet": "Styler.highlight_min(color='yellow', axis=0)", "intent": "Highlight the minimum with a style . With arguments `color`, `axis`.", "question_id": 13181},
{"snippet": "Styler.highlight_min(color='yellow', props=None)", "intent": "Highlight the minimum with a style . With arguments `color`, `props`.", "question_id": 13182},
{"snippet": "Styler.highlight_min()", "intent": "Highlight the minimum with a style .", "question_id": 13183},
{"snippet": "Styler.highlight_min(subset=None)", "intent": "Highlight the minimum with a style . With arguments `subset`.", "question_id": 13184},
{"snippet": "Styler.highlight_min(color='yellow')", "intent": "Highlight the minimum with a style . With arguments `color`.", "question_id": 13185},
{"snippet": "Styler.highlight_min(axis=0)", "intent": "Highlight the minimum with a style . With arguments `axis`.", "question_id": 13186},
{"snippet": "Styler.highlight_min(props=None)", "intent": "Highlight the minimum with a style . With arguments `props`.", "question_id": 13187},
{"snippet": "Styler.highlight_min(subset=None, color='yellow')", "intent": "Highlight the minimum with a style . With arguments `subset`, `color`.", "question_id": 13188},
{"snippet": "Styler.highlight_min(subset=None, axis=0)", "intent": "Highlight the minimum with a style . With arguments `subset`, `axis`.", "question_id": 13189},
{"snippet": "Styler.highlight_min(subset=None, props=None)", "intent": "Highlight the minimum with a style . With arguments `subset`, `props`.", "question_id": 13190},
{"snippet": "Styler.highlight_min(color='yellow', axis=0)", "intent": "Highlight the minimum with a style . With arguments `color`, `axis`.", "question_id": 13191},
{"snippet": "Styler.highlight_min(color='yellow', props=None)", "intent": "Highlight the minimum with a style . With arguments `color`, `props`.", "question_id": 13192},
{"snippet": "Styler.highlight_min()", "intent": "Highlight the minimum with a style .", "question_id": 13193},
{"snippet": "Styler.highlight_min(subset=None)", "intent": "Highlight the minimum with a style . With arguments `subset`.", "question_id": 13194},
{"snippet": "Styler.highlight_min(color='yellow')", "intent": "Highlight the minimum with a style . With arguments `color`.", "question_id": 13195},
{"snippet": "Styler.highlight_min(axis=0)", "intent": "Highlight the minimum with a style . With arguments `axis`.", "question_id": 13196},
{"snippet": "Styler.highlight_min(props=None)", "intent": "Highlight the minimum with a style . With arguments `props`.", "question_id": 13197},
{"snippet": "Styler.highlight_min(subset=None, color='yellow')", "intent": "Highlight the minimum with a style . With arguments `subset`, `color`.", "question_id": 13198},
{"snippet": "Styler.highlight_min(subset=None, axis=0)", "intent": "Highlight the minimum with a style . With arguments `subset`, `axis`.", "question_id": 13199},
{"snippet": "Styler.highlight_min(subset=None, props=None)", "intent": "Highlight the minimum with a style . With arguments `subset`, `props`.", "question_id": 13200},
{"snippet": "Styler.highlight_min(color='yellow', axis=0)", "intent": "Highlight the minimum with a style . With arguments `color`, `axis`.", "question_id": 13201},
{"snippet": "Styler.highlight_min(color='yellow', props=None)", "intent": "Highlight the minimum with a style . With arguments `color`, `props`.", "question_id": 13202},
{"snippet": "Styler.highlight_null()", "intent": "Highlight missing values with a style .", "question_id": 13203},
{"snippet": "Styler.highlight_null(null_color='red')", "intent": "Highlight missing values with a style . With arguments `null_color`.", "question_id": 13204},
{"snippet": "Styler.highlight_null(subset=None)", "intent": "Highlight missing values with a style . With arguments `subset`.", "question_id": 13205},
{"snippet": "Styler.highlight_null(props=None)", "intent": "Highlight missing values with a style . With arguments `props`.", "question_id": 13206},
{"snippet": "Styler.highlight_null(null_color='red', subset=None)", "intent": "Highlight missing values with a style . With arguments `null_color`, `subset`.", "question_id": 13207},
{"snippet": "Styler.highlight_null(null_color='red', props=None)", "intent": "Highlight missing values with a style . With arguments `null_color`, `props`.", "question_id": 13208},
{"snippet": "Styler.highlight_null(subset=None, props=None)", "intent": "Highlight missing values with a style . With arguments `subset`, `props`.", "question_id": 13209},
{"snippet": "Styler.highlight_null(null_color='red', subset=None, props=None)", "intent": "Highlight missing values with a style . With arguments `null_color`, `subset`, `props`.", "question_id": 13210},
{"snippet": "Styler.highlight_null()", "intent": "Highlight missing values with a style .", "question_id": 13211},
{"snippet": "Styler.highlight_null(null_color='red')", "intent": "Highlight missing values with a style . With arguments `null_color`.", "question_id": 13212},
{"snippet": "Styler.highlight_null(subset=None)", "intent": "Highlight missing values with a style . With arguments `subset`.", "question_id": 13213},
{"snippet": "Styler.highlight_null(props=None)", "intent": "Highlight missing values with a style . With arguments `props`.", "question_id": 13214},
{"snippet": "Styler.highlight_null(null_color='red', subset=None)", "intent": "Highlight missing values with a style . With arguments `null_color`, `subset`.", "question_id": 13215},
{"snippet": "Styler.highlight_null(null_color='red', props=None)", "intent": "Highlight missing values with a style . With arguments `null_color`, `props`.", "question_id": 13216},
{"snippet": "Styler.highlight_null(subset=None, props=None)", "intent": "Highlight missing values with a style . With arguments `subset`, `props`.", "question_id": 13217},
{"snippet": "Styler.highlight_null(null_color='red', subset=None, props=None)", "intent": "Highlight missing values with a style . With arguments `null_color`, `subset`, `props`.", "question_id": 13218},
{"snippet": "Styler.highlight_null()", "intent": "Highlight missing values with a style .", "question_id": 13219},
{"snippet": "Styler.highlight_null(null_color='red')", "intent": "Highlight missing values with a style . With arguments `null_color`.", "question_id": 13220},
{"snippet": "Styler.highlight_null(subset=None)", "intent": "Highlight missing values with a style . With arguments `subset`.", "question_id": 13221},
{"snippet": "Styler.highlight_null(props=None)", "intent": "Highlight missing values with a style . With arguments `props`.", "question_id": 13222},
{"snippet": "Styler.highlight_null(null_color='red', subset=None)", "intent": "Highlight missing values with a style . With arguments `null_color`, `subset`.", "question_id": 13223},
{"snippet": "Styler.highlight_null(null_color='red', props=None)", "intent": "Highlight missing values with a style . With arguments `null_color`, `props`.", "question_id": 13224},
{"snippet": "Styler.highlight_null(subset=None, props=None)", "intent": "Highlight missing values with a style . With arguments `subset`, `props`.", "question_id": 13225},
{"snippet": "Styler.highlight_null(null_color='red', subset=None, props=None)", "intent": "Highlight missing values with a style . With arguments `null_color`, `subset`, `props`.", "question_id": 13226},
{"snippet": "Styler.highlight_quantile()", "intent": "Highlight values defined by a quantile with a style .", "question_id": 13227},
{"snippet": "Styler.highlight_quantile(subset=None)", "intent": "Highlight values defined by a quantile with a style . With arguments `subset`.", "question_id": 13228},
{"snippet": "Styler.highlight_quantile(color='yellow')", "intent": "Highlight values defined by a quantile with a style . With arguments `color`.", "question_id": 13229},
{"snippet": "Styler.highlight_quantile(axis=0)", "intent": "Highlight values defined by a quantile with a style . With arguments `axis`.", "question_id": 13230},
{"snippet": "Styler.highlight_quantile(q_left=0.0)", "intent": "Highlight values defined by a quantile with a style . With arguments `q_left`.", "question_id": 13231},
{"snippet": "Styler.highlight_quantile(q_right=1.0)", "intent": "Highlight values defined by a quantile with a style . With arguments `q_right`.", "question_id": 13232},
{"snippet": "Styler.highlight_quantile(interpolation='linear')", "intent": "Highlight values defined by a quantile with a style . With arguments `interpolation`.", "question_id": 13233},
{"snippet": "Styler.highlight_quantile(inclusive='both')", "intent": "Highlight values defined by a quantile with a style . With arguments `inclusive`.", "question_id": 13234},
{"snippet": "Styler.highlight_quantile(props=None)", "intent": "Highlight values defined by a quantile with a style . Use `props` instead of default background coloring", "question_id": 13235},
{"snippet": "Styler.highlight_quantile(subset=None, color='yellow')", "intent": "Highlight values defined by a quantile with a style . With arguments `subset`, `color`.", "question_id": 13236},
{"snippet": "Styler.highlight_quantile()", "intent": "Highlight values defined by a quantile with a style .", "question_id": 13237},
{"snippet": "Styler.highlight_quantile(subset=None)", "intent": "Highlight values defined by a quantile with a style . With arguments `subset`.", "question_id": 13238},
{"snippet": "Styler.highlight_quantile(color='yellow')", "intent": "Highlight values defined by a quantile with a style . With arguments `color`.", "question_id": 13239},
{"snippet": "Styler.highlight_quantile(axis=0)", "intent": "Highlight values defined by a quantile with a style . With arguments `axis`.", "question_id": 13240},
{"snippet": "Styler.highlight_quantile(q_left=0.0)", "intent": "Highlight values defined by a quantile with a style . With arguments `q_left`.", "question_id": 13241},
{"snippet": "Styler.highlight_quantile(q_right=1.0)", "intent": "Highlight values defined by a quantile with a style . With arguments `q_right`.", "question_id": 13242},
{"snippet": "Styler.highlight_quantile(interpolation='linear')", "intent": "Highlight values defined by a quantile with a style . With arguments `interpolation`.", "question_id": 13243},
{"snippet": "Styler.highlight_quantile(inclusive='both')", "intent": "Highlight values defined by a quantile with a style . With arguments `inclusive`.", "question_id": 13244},
{"snippet": "Styler.highlight_quantile(props=None)", "intent": "Highlight values defined by a quantile with a style . Use `props` instead of default background coloring", "question_id": 13245},
{"snippet": "Styler.highlight_quantile(subset=None, color='yellow')", "intent": "Highlight values defined by a quantile with a style . With arguments `subset`, `color`.", "question_id": 13246},
{"snippet": "Styler.highlight_quantile()", "intent": "Highlight values defined by a quantile with a style .", "question_id": 13247},
{"snippet": "Styler.highlight_quantile(subset=None)", "intent": "Highlight values defined by a quantile with a style . With arguments `subset`.", "question_id": 13248},
{"snippet": "Styler.highlight_quantile(color='yellow')", "intent": "Highlight values defined by a quantile with a style . With arguments `color`.", "question_id": 13249},
{"snippet": "Styler.highlight_quantile(axis=0)", "intent": "Highlight values defined by a quantile with a style . With arguments `axis`.", "question_id": 13250},
{"snippet": "Styler.highlight_quantile(q_left=0.0)", "intent": "Highlight values defined by a quantile with a style . With arguments `q_left`.", "question_id": 13251},
{"snippet": "Styler.highlight_quantile(q_right=1.0)", "intent": "Highlight values defined by a quantile with a style . With arguments `q_right`.", "question_id": 13252},
{"snippet": "Styler.highlight_quantile(interpolation='linear')", "intent": "Highlight values defined by a quantile with a style . With arguments `interpolation`.", "question_id": 13253},
{"snippet": "Styler.highlight_quantile(inclusive='both')", "intent": "Highlight values defined by a quantile with a style . With arguments `inclusive`.", "question_id": 13254},
{"snippet": "Styler.highlight_quantile(props=None)", "intent": "Highlight values defined by a quantile with a style . Use `props` instead of default background coloring", "question_id": 13255},
{"snippet": "Styler.highlight_quantile(subset=None, color='yellow')", "intent": "Highlight values defined by a quantile with a style . With arguments `subset`, `color`.", "question_id": 13256},
{"snippet": "pandas.io.formats.style.Styler(data)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS .", "question_id": 13257},
{"snippet": "pandas.io.formats.style.Styler(data, precision=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `precision`.", "question_id": 13258},
{"snippet": "pandas.io.formats.style.Styler(data, table_styles=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `table_styles`.", "question_id": 13259},
{"snippet": "pandas.io.formats.style.Styler(data, uuid=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `uuid`.", "question_id": 13260},
{"snippet": "pandas.io.formats.style.Styler(data, caption=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `caption`.", "question_id": 13261},
{"snippet": "pandas.io.formats.style.Styler(data, table_attributes=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `table_attributes`.", "question_id": 13262},
{"snippet": "pandas.io.formats.style.Styler(data, cell_ids=True)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `cell_ids`.", "question_id": 13263},
{"snippet": "pandas.io.formats.style.Styler(data, na_rep=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `na_rep`.", "question_id": 13264},
{"snippet": "pandas.io.formats.style.Styler(data, uuid_len=5)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `uuid_len`.", "question_id": 13265},
{"snippet": "pandas.io.formats.style.Styler(data, decimal='.')", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `decimal`.", "question_id": 13266},
{"snippet": "pandas.io.formats.style.Styler(data)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS .", "question_id": 13267},
{"snippet": "pandas.io.formats.style.Styler(data, precision=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `precision`.", "question_id": 13268},
{"snippet": "pandas.io.formats.style.Styler(data, table_styles=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `table_styles`.", "question_id": 13269},
{"snippet": "pandas.io.formats.style.Styler(data, uuid=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `uuid`.", "question_id": 13270},
{"snippet": "pandas.io.formats.style.Styler(data, caption=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `caption`.", "question_id": 13271},
{"snippet": "pandas.io.formats.style.Styler(data, table_attributes=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `table_attributes`.", "question_id": 13272},
{"snippet": "pandas.io.formats.style.Styler(data, cell_ids=True)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `cell_ids`.", "question_id": 13273},
{"snippet": "pandas.io.formats.style.Styler(data, na_rep=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `na_rep`.", "question_id": 13274},
{"snippet": "pandas.io.formats.style.Styler(data, uuid_len=5)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `uuid_len`.", "question_id": 13275},
{"snippet": "pandas.io.formats.style.Styler(data, decimal='.')", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `decimal`.", "question_id": 13276},
{"snippet": "pandas.io.formats.style.Styler(data)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS .", "question_id": 13277},
{"snippet": "pandas.io.formats.style.Styler(data, precision=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `precision`.", "question_id": 13278},
{"snippet": "pandas.io.formats.style.Styler(data, table_styles=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `table_styles`.", "question_id": 13279},
{"snippet": "pandas.io.formats.style.Styler(data, uuid=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `uuid`.", "question_id": 13280},
{"snippet": "pandas.io.formats.style.Styler(data, caption=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `caption`.", "question_id": 13281},
{"snippet": "pandas.io.formats.style.Styler(data, table_attributes=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `table_attributes`.", "question_id": 13282},
{"snippet": "pandas.io.formats.style.Styler(data, cell_ids=True)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `cell_ids`.", "question_id": 13283},
{"snippet": "pandas.io.formats.style.Styler(data, na_rep=None)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `na_rep`.", "question_id": 13284},
{"snippet": "pandas.io.formats.style.Styler(data, uuid_len=5)", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `uuid_len`.", "question_id": 13285},
{"snippet": "pandas.io.formats.style.Styler(data, decimal='.')", "intent": "Helps style a DataFrame or Series according to the `data` with HTML and CSS . With arguments `decimal`.", "question_id": 13286},
{"snippet": "Styler.pipe(func, *args, **kwargs)", "intent": "Apply `func` ( self , * args , * * kwargs ) , and return the result . With arguments `*args`, `**kwargs`.", "question_id": 13287},
{"snippet": "Styler.pipe(func, *args, **kwargs)", "intent": "Apply `func` ( self , * args , * * kwargs ) , and return the result . With arguments `*args`, `**kwargs`.", "question_id": 13288},
{"snippet": "Styler.pipe(func, *args, **kwargs)", "intent": "Apply `func` ( self , * args , * * kwargs ) , and return the result . With arguments `*args`, `**kwargs`.", "question_id": 13289},
{"snippet": "Styler.render(**kwargs)", "intent": "Render the Styler including all applied styles to HTML . With arguments `**kwargs`.", "question_id": 13290},
{"snippet": "Styler.render(**kwargs, sparse_index=None)", "intent": "Render the Styler including all applied styles to HTML . With arguments `**kwargs`, `sparse_index`.", "question_id": 13291},
{"snippet": "Styler.render(**kwargs, sparse_columns=None)", "intent": "Render the Styler including all applied styles to HTML . With arguments `**kwargs`, `sparse_columns`.", "question_id": 13292},
{"snippet": "Styler.render(**kwargs, sparse_index=None, sparse_columns=None)", "intent": "Render the Styler including all applied styles to HTML . With arguments `**kwargs`, `sparse_index`, `sparse_columns`.", "question_id": 13293},
{"snippet": "Styler.render(**kwargs)", "intent": "Render the Styler including all applied styles to HTML . With arguments `**kwargs`.", "question_id": 13294},
{"snippet": "Styler.render(**kwargs, sparse_index=None)", "intent": "Render the Styler including all applied styles to HTML . With arguments `**kwargs`, `sparse_index`.", "question_id": 13295},
{"snippet": "Styler.render(**kwargs, sparse_columns=None)", "intent": "Render the Styler including all applied styles to HTML . With arguments `**kwargs`, `sparse_columns`.", "question_id": 13296},
{"snippet": "Styler.render(**kwargs, sparse_index=None, sparse_columns=None)", "intent": "Render the Styler including all applied styles to HTML . With arguments `**kwargs`, `sparse_index`, `sparse_columns`.", "question_id": 13297},
{"snippet": "Styler.render(**kwargs)", "intent": "Render the Styler including all applied styles to HTML . With arguments `**kwargs`.", "question_id": 13298},
{"snippet": "Styler.render(**kwargs, sparse_index=None)", "intent": "Render the Styler including all applied styles to HTML . With arguments `**kwargs`, `sparse_index`.", "question_id": 13299},
{"snippet": "Styler.render(**kwargs, sparse_columns=None)", "intent": "Render the Styler including all applied styles to HTML . With arguments `**kwargs`, `sparse_columns`.", "question_id": 13300},
{"snippet": "Styler.render(**kwargs, sparse_index=None, sparse_columns=None)", "intent": "Render the Styler including all applied styles to HTML . With arguments `**kwargs`, `sparse_index`, `sparse_columns`.", "question_id": 13301},
{"snippet": "Styler.set_caption(caption)", "intent": "Set the text added to a < `caption` > HTML element .", "question_id": 13302},
{"snippet": "Styler.set_caption(caption)", "intent": "Set the text added to a < `caption` > HTML element .", "question_id": 13303},
{"snippet": "Styler.set_caption(caption)", "intent": "Set the text added to a < `caption` > HTML element .", "question_id": 13304},
{"snippet": "Styler.set_na_rep(na_rep)", "intent": "Set the missing data representation on a Styler . With arguments `na_rep`.", "question_id": 13305},
{"snippet": "Styler.set_na_rep(na_rep)", "intent": "Set the missing data representation on a Styler . With arguments `na_rep`.", "question_id": 13306},
{"snippet": "Styler.set_na_rep(na_rep)", "intent": "Set the missing data representation on a Styler . With arguments `na_rep`.", "question_id": 13307},
{"snippet": "Styler.set_precision(precision)", "intent": "Set the `precision` used to display values .", "question_id": 13308},
{"snippet": "Styler.set_precision(precision)", "intent": "Set the `precision` used to display values .", "question_id": 13309},
{"snippet": "Styler.set_precision(precision)", "intent": "Set the `precision` used to display values .", "question_id": 13310},
{"snippet": "Styler.set_properties(**kwargs)", "intent": "Set defined CSS-properties to each < td > HTML element within the given `subset` . With arguments `**kwargs`.", "question_id": 13311},
{"snippet": "Styler.set_properties(**kwargs, subset=None)", "intent": "Set defined CSS-properties to each < td > HTML element within the given `subset` . With arguments `**kwargs`.", "question_id": 13312},
{"snippet": "Styler.set_properties(**kwargs)", "intent": "Set defined CSS-properties to each < td > HTML element within the given `subset` . With arguments `**kwargs`.", "question_id": 13313},
{"snippet": "Styler.set_properties(**kwargs, subset=None)", "intent": "Set defined CSS-properties to each < td > HTML element within the given `subset` . With arguments `**kwargs`.", "question_id": 13314},
{"snippet": "Styler.set_properties(**kwargs)", "intent": "Set defined CSS-properties to each < td > HTML element within the given `subset` . With arguments `**kwargs`.", "question_id": 13315},
{"snippet": "Styler.set_properties(**kwargs, subset=None)", "intent": "Set defined CSS-properties to each < td > HTML element within the given `subset` . With arguments `**kwargs`.", "question_id": 13316},
{"snippet": "Styler.set_sticky()", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame .", "question_id": 13317},
{"snippet": "Styler.set_sticky(axis=0)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `axis`.", "question_id": 13318},
{"snippet": "Styler.set_sticky(pixel_size=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `pixel_size`.", "question_id": 13319},
{"snippet": "Styler.set_sticky(levels=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `levels`.", "question_id": 13320},
{"snippet": "Styler.set_sticky(axis=0, pixel_size=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `axis`, `pixel_size`.", "question_id": 13321},
{"snippet": "Styler.set_sticky(axis=0, levels=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `axis`, `levels`.", "question_id": 13322},
{"snippet": "Styler.set_sticky(pixel_size=None, levels=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `pixel_size`, `levels`.", "question_id": 13323},
{"snippet": "Styler.set_sticky(axis=0, pixel_size=None, levels=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `axis`, `pixel_size`, `levels`.", "question_id": 13324},
{"snippet": "Styler.set_sticky()", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame .", "question_id": 13325},
{"snippet": "Styler.set_sticky(axis=0)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `axis`.", "question_id": 13326},
{"snippet": "Styler.set_sticky(pixel_size=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `pixel_size`.", "question_id": 13327},
{"snippet": "Styler.set_sticky(levels=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `levels`.", "question_id": 13328},
{"snippet": "Styler.set_sticky(axis=0, pixel_size=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `axis`, `pixel_size`.", "question_id": 13329},
{"snippet": "Styler.set_sticky(axis=0, levels=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `axis`, `levels`.", "question_id": 13330},
{"snippet": "Styler.set_sticky(pixel_size=None, levels=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `pixel_size`, `levels`.", "question_id": 13331},
{"snippet": "Styler.set_sticky(axis=0, pixel_size=None, levels=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `axis`, `pixel_size`, `levels`.", "question_id": 13332},
{"snippet": "Styler.set_sticky()", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame .", "question_id": 13333},
{"snippet": "Styler.set_sticky(axis=0)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `axis`.", "question_id": 13334},
{"snippet": "Styler.set_sticky(pixel_size=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `pixel_size`.", "question_id": 13335},
{"snippet": "Styler.set_sticky(levels=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `levels`.", "question_id": 13336},
{"snippet": "Styler.set_sticky(axis=0, pixel_size=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `axis`, `pixel_size`.", "question_id": 13337},
{"snippet": "Styler.set_sticky(axis=0, levels=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `axis`, `levels`.", "question_id": 13338},
{"snippet": "Styler.set_sticky(pixel_size=None, levels=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `pixel_size`, `levels`.", "question_id": 13339},
{"snippet": "Styler.set_sticky(axis=0, pixel_size=None, levels=None)", "intent": "Add CSS to permanently display the index or column headers in a scrolling frame . With arguments `axis`, `pixel_size`, `levels`.", "question_id": 13340},
{"snippet": "Styler.set_table_attributes(attributes)", "intent": "Set the table `attributes` added to the < table > HTML element .", "question_id": 13341},
{"snippet": "Styler.set_table_attributes(attributes)", "intent": "Set the table `attributes` added to the < table > HTML element .", "question_id": 13342},
{"snippet": "Styler.set_table_attributes(attributes)", "intent": "Set the table `attributes` added to the < table > HTML element .", "question_id": 13343},
{"snippet": "Styler.set_table_styles(table_styles)", "intent": "Set the table styles included within the < style > HTML element . With arguments `table_styles`.", "question_id": 13344},
{"snippet": "Styler.set_table_styles(table_styles, axis=0)", "intent": "Set the table styles included within the < style > HTML element . With arguments `table_styles`, `axis`.", "question_id": 13345},
{"snippet": "Styler.set_table_styles(table_styles, overwrite=True)", "intent": "Set the table styles included within the < style > HTML element . With arguments `table_styles`, `overwrite`.", "question_id": 13346},
{"snippet": "Styler.set_table_styles(table_styles, axis=0, overwrite=True)", "intent": "Set the table styles included within the < style > HTML element . With arguments `table_styles`, `axis`, `overwrite`.", "question_id": 13347},
{"snippet": "Styler.set_table_styles(table_styles)", "intent": "Set the table styles included within the < style > HTML element . With arguments `table_styles`.", "question_id": 13348},
{"snippet": "Styler.set_table_styles(table_styles, axis=0)", "intent": "Set the table styles included within the < style > HTML element . With arguments `table_styles`, `axis`.", "question_id": 13349},
{"snippet": "Styler.set_table_styles(table_styles, overwrite=True)", "intent": "Set the table styles included within the < style > HTML element . With arguments `table_styles`, `overwrite`.", "question_id": 13350},
{"snippet": "Styler.set_table_styles(table_styles, axis=0, overwrite=True)", "intent": "Set the table styles included within the < style > HTML element . With arguments `table_styles`, `axis`, `overwrite`.", "question_id": 13351},
{"snippet": "Styler.set_table_styles(table_styles)", "intent": "Set the table styles included within the < style > HTML element . With arguments `table_styles`.", "question_id": 13352},
{"snippet": "Styler.set_table_styles(table_styles, axis=0)", "intent": "Set the table styles included within the < style > HTML element . With arguments `table_styles`, `axis`.", "question_id": 13353},
{"snippet": "Styler.set_table_styles(table_styles, overwrite=True)", "intent": "Set the table styles included within the < style > HTML element . With arguments `table_styles`, `overwrite`.", "question_id": 13354},
{"snippet": "Styler.set_table_styles(table_styles, axis=0, overwrite=True)", "intent": "Set the table styles included within the < style > HTML element . With arguments `table_styles`, `axis`, `overwrite`.", "question_id": 13355},
{"snippet": "Styler.set_td_classes(classes)", "intent": "Set the DataFrame of strings added to the class attribute of < td > HTML elements . Using MultiIndex columns and a `classes` DataFrame as a subset of the underlying ,", "question_id": 13356},
{"snippet": "Styler.set_td_classes(classes)", "intent": "Set the DataFrame of strings added to the class attribute of < td > HTML elements . Using MultiIndex columns and a `classes` DataFrame as a subset of the underlying ,", "question_id": 13357},
{"snippet": "Styler.set_td_classes(classes)", "intent": "Set the DataFrame of strings added to the class attribute of < td > HTML elements . Using MultiIndex columns and a `classes` DataFrame as a subset of the underlying ,", "question_id": 13358},
{"snippet": "Styler.set_tooltips(ttips)", "intent": "Set the DataFrame of strings on Styler generating : hover tooltips . With arguments `ttips`.", "question_id": 13359},
{"snippet": "Styler.set_tooltips(ttips, props=None)", "intent": "Set the DataFrame of strings on Styler generating : hover tooltips . The property \u2018 visibility : hidden ; \u2019 is a key prerequisite to the hover functionality , and should always be included in any manual properties specification , using the `props` argument . With arguments `ttips`.", "question_id": 13360},
{"snippet": "Styler.set_tooltips(ttips, css_class=None)", "intent": "Set the DataFrame of strings on Styler generating : hover tooltips . With arguments `ttips`, `css_class`.", "question_id": 13361},
{"snippet": "Styler.set_tooltips(ttips, props=None, css_class=None)", "intent": "Set the DataFrame of strings on Styler generating : hover tooltips . The property \u2018 visibility : hidden ; \u2019 is a key prerequisite to the hover functionality , and should always be included in any manual properties specification , using the `props` argument . With arguments `ttips`, `css_class`.", "question_id": 13362},
{"snippet": "Styler.set_tooltips(ttips)", "intent": "Set the DataFrame of strings on Styler generating : hover tooltips . With arguments `ttips`.", "question_id": 13363},
{"snippet": "Styler.set_tooltips(ttips, props=None)", "intent": "Set the DataFrame of strings on Styler generating : hover tooltips . The property \u2018 visibility : hidden ; \u2019 is a key prerequisite to the hover functionality , and should always be included in any manual properties specification , using the `props` argument . With arguments `ttips`.", "question_id": 13364},
{"snippet": "Styler.set_tooltips(ttips, css_class=None)", "intent": "Set the DataFrame of strings on Styler generating : hover tooltips . With arguments `ttips`, `css_class`.", "question_id": 13365},
{"snippet": "Styler.set_tooltips(ttips, props=None, css_class=None)", "intent": "Set the DataFrame of strings on Styler generating : hover tooltips . The property \u2018 visibility : hidden ; \u2019 is a key prerequisite to the hover functionality , and should always be included in any manual properties specification , using the `props` argument . With arguments `ttips`, `css_class`.", "question_id": 13366},
{"snippet": "Styler.set_tooltips(ttips)", "intent": "Set the DataFrame of strings on Styler generating : hover tooltips . With arguments `ttips`.", "question_id": 13367},
{"snippet": "Styler.set_tooltips(ttips, props=None)", "intent": "Set the DataFrame of strings on Styler generating : hover tooltips . The property \u2018 visibility : hidden ; \u2019 is a key prerequisite to the hover functionality , and should always be included in any manual properties specification , using the `props` argument . With arguments `ttips`.", "question_id": 13368},
{"snippet": "Styler.set_tooltips(ttips, css_class=None)", "intent": "Set the DataFrame of strings on Styler generating : hover tooltips . With arguments `ttips`, `css_class`.", "question_id": 13369},
{"snippet": "Styler.set_tooltips(ttips, props=None, css_class=None)", "intent": "Set the DataFrame of strings on Styler generating : hover tooltips . The property \u2018 visibility : hidden ; \u2019 is a key prerequisite to the hover functionality , and should always be included in any manual properties specification , using the `props` argument . With arguments `ttips`, `css_class`.", "question_id": 13370},
{"snippet": "Styler.set_uuid(uuid)", "intent": "Set the `uuid` applied to id attributes of HTML elements .", "question_id": 13371},
{"snippet": "Styler.set_uuid(uuid)", "intent": "Set the `uuid` applied to id attributes of HTML elements .", "question_id": 13372},
{"snippet": "Styler.set_uuid(uuid)", "intent": "Set the `uuid` applied to id attributes of HTML elements .", "question_id": 13373},
{"snippet": "Styler.text_gradient()", "intent": "Color the text in a gradient style .", "question_id": 13374},
{"snippet": "Styler.text_gradient(cmap='PuBu')", "intent": "Color the text in a gradient style . Setting a gmap and applying to all columns with another `cmap`", "question_id": 13375},
{"snippet": "Styler.text_gradient(low=0)", "intent": "Color the text in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13376},
{"snippet": "Styler.text_gradient(high=0)", "intent": "Color the text in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13377},
{"snippet": "Styler.text_gradient(axis=0)", "intent": "Color the text in a gradient style . With arguments `axis`.", "question_id": 13378},
{"snippet": "Styler.text_gradient(subset=None)", "intent": "Color the text in a gradient style . axis=None ) , we need to explicitly state `subset` to match the gmap shape", "question_id": 13379},
{"snippet": "Styler.text_gradient(vmin=None)", "intent": "Color the text in a gradient style . If combining with `vmin` and `vmax` the map.min , map.max and map.range are replaced by values according to the values derived from vmin and vmax .", "question_id": 13380},
{"snippet": "Styler.text_gradient(vmax=None)", "intent": "Color the text in a gradient style . If combining with `vmin` and `vmax` the map.min , map.max and map.range are replaced by values according to the values derived from vmin and vmax .", "question_id": 13381},
{"snippet": "Styler.text_gradient(gmap=None)", "intent": "Color the text in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13382},
{"snippet": "Styler.text_gradient(cmap='PuBu', low=0)", "intent": "Color the text in a gradient style . Setting a gmap and applying to all columns with another `cmap` When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13383},
{"snippet": "Styler.text_gradient()", "intent": "Color the text in a gradient style .", "question_id": 13384},
{"snippet": "Styler.text_gradient(cmap='PuBu')", "intent": "Color the text in a gradient style . Setting a gmap and applying to all columns with another `cmap`", "question_id": 13385},
{"snippet": "Styler.text_gradient(low=0)", "intent": "Color the text in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13386},
{"snippet": "Styler.text_gradient(high=0)", "intent": "Color the text in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13387},
{"snippet": "Styler.text_gradient(axis=0)", "intent": "Color the text in a gradient style . With arguments `axis`.", "question_id": 13388},
{"snippet": "Styler.text_gradient(subset=None)", "intent": "Color the text in a gradient style . axis=None ) , we need to explicitly state `subset` to match the gmap shape", "question_id": 13389},
{"snippet": "Styler.text_gradient(vmin=None)", "intent": "Color the text in a gradient style . If combining with `vmin` and `vmax` the map.min , map.max and map.range are replaced by values according to the values derived from vmin and vmax .", "question_id": 13390},
{"snippet": "Styler.text_gradient(vmax=None)", "intent": "Color the text in a gradient style . If combining with `vmin` and `vmax` the map.min , map.max and map.range are replaced by values according to the values derived from vmin and vmax .", "question_id": 13391},
{"snippet": "Styler.text_gradient(gmap=None)", "intent": "Color the text in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13392},
{"snippet": "Styler.text_gradient(cmap='PuBu', low=0)", "intent": "Color the text in a gradient style . Setting a gmap and applying to all columns with another `cmap` When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13393},
{"snippet": "Styler.text_gradient()", "intent": "Color the text in a gradient style .", "question_id": 13394},
{"snippet": "Styler.text_gradient(cmap='PuBu')", "intent": "Color the text in a gradient style . Setting a gmap and applying to all columns with another `cmap`", "question_id": 13395},
{"snippet": "Styler.text_gradient(low=0)", "intent": "Color the text in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13396},
{"snippet": "Styler.text_gradient(high=0)", "intent": "Color the text in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13397},
{"snippet": "Styler.text_gradient(axis=0)", "intent": "Color the text in a gradient style . With arguments `axis`.", "question_id": 13398},
{"snippet": "Styler.text_gradient(subset=None)", "intent": "Color the text in a gradient style . axis=None ) , we need to explicitly state `subset` to match the gmap shape", "question_id": 13399},
{"snippet": "Styler.text_gradient(vmin=None)", "intent": "Color the text in a gradient style . If combining with `vmin` and `vmax` the map.min , map.max and map.range are replaced by values according to the values derived from vmin and vmax .", "question_id": 13400},
{"snippet": "Styler.text_gradient(vmax=None)", "intent": "Color the text in a gradient style . If combining with `vmin` and `vmax` the map.min , map.max and map.range are replaced by values according to the values derived from vmin and vmax .", "question_id": 13401},
{"snippet": "Styler.text_gradient(gmap=None)", "intent": "Color the text in a gradient style . When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13402},
{"snippet": "Styler.text_gradient(cmap='PuBu', low=0)", "intent": "Color the text in a gradient style . Setting a gmap and applying to all columns with another `cmap` When using `low` and `high` the range of the gradient , given by the data if `gmap` is not given or by gmap , is extended at the low end effectively by map.min - low * map.range and at the high end by map.max + high * map.range before the colors are normalized and determined .", "question_id": 13403},
{"snippet": "Styler.to_excel(excel_writer)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`.", "question_id": 13404},
{"snippet": "Styler.to_excel(excel_writer, sheet_name='Sheet1')", "intent": "Write Styler to an Excel sheet . Multiple sheets may be written to by specifying unique `sheet_name` . With arguments `excel_writer`.", "question_id": 13405},
{"snippet": "Styler.to_excel(excel_writer, na_rep='')", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `na_rep`.", "question_id": 13406},
{"snippet": "Styler.to_excel(excel_writer, float_format=None)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `float_format`.", "question_id": 13407},
{"snippet": "Styler.to_excel(excel_writer, columns=None)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `columns`.", "question_id": 13408},
{"snippet": "Styler.to_excel(excel_writer, header=True)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `header`.", "question_id": 13409},
{"snippet": "Styler.to_excel(excel_writer, index=True)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `index`.", "question_id": 13410},
{"snippet": "Styler.to_excel(excel_writer, index_label=None)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `index_label`.", "question_id": 13411},
{"snippet": "Styler.to_excel(excel_writer, startrow=0)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `startrow`.", "question_id": 13412},
{"snippet": "Styler.to_excel(excel_writer, startcol=0)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `startcol`.", "question_id": 13413},
{"snippet": "Styler.to_excel(excel_writer)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`.", "question_id": 13414},
{"snippet": "Styler.to_excel(excel_writer, sheet_name='Sheet1')", "intent": "Write Styler to an Excel sheet . Multiple sheets may be written to by specifying unique `sheet_name` . With arguments `excel_writer`.", "question_id": 13415},
{"snippet": "Styler.to_excel(excel_writer, na_rep='')", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `na_rep`.", "question_id": 13416},
{"snippet": "Styler.to_excel(excel_writer, float_format=None)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `float_format`.", "question_id": 13417},
{"snippet": "Styler.to_excel(excel_writer, columns=None)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `columns`.", "question_id": 13418},
{"snippet": "Styler.to_excel(excel_writer, header=True)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `header`.", "question_id": 13419},
{"snippet": "Styler.to_excel(excel_writer, index=True)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `index`.", "question_id": 13420},
{"snippet": "Styler.to_excel(excel_writer, index_label=None)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `index_label`.", "question_id": 13421},
{"snippet": "Styler.to_excel(excel_writer, startrow=0)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `startrow`.", "question_id": 13422},
{"snippet": "Styler.to_excel(excel_writer, startcol=0)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `startcol`.", "question_id": 13423},
{"snippet": "Styler.to_excel(excel_writer)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`.", "question_id": 13424},
{"snippet": "Styler.to_excel(excel_writer, sheet_name='Sheet1')", "intent": "Write Styler to an Excel sheet . Multiple sheets may be written to by specifying unique `sheet_name` . With arguments `excel_writer`.", "question_id": 13425},
{"snippet": "Styler.to_excel(excel_writer, na_rep='')", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `na_rep`.", "question_id": 13426},
{"snippet": "Styler.to_excel(excel_writer, float_format=None)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `float_format`.", "question_id": 13427},
{"snippet": "Styler.to_excel(excel_writer, columns=None)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `columns`.", "question_id": 13428},
{"snippet": "Styler.to_excel(excel_writer, header=True)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `header`.", "question_id": 13429},
{"snippet": "Styler.to_excel(excel_writer, index=True)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `index`.", "question_id": 13430},
{"snippet": "Styler.to_excel(excel_writer, index_label=None)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `index_label`.", "question_id": 13431},
{"snippet": "Styler.to_excel(excel_writer, startrow=0)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `startrow`.", "question_id": 13432},
{"snippet": "Styler.to_excel(excel_writer, startcol=0)", "intent": "Write Styler to an Excel sheet . With arguments `excel_writer`, `startcol`.", "question_id": 13433},
{"snippet": "Styler.to_html()", "intent": "Write Styler to a file , buffer or string in HTML-CSS format .", "question_id": 13434},
{"snippet": "Styler.to_html(buf=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `buf`.", "question_id": 13435},
{"snippet": "Styler.to_html(table_uuid=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `table_uuid`.", "question_id": 13436},
{"snippet": "Styler.to_html(table_attributes=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `table_attributes`.", "question_id": 13437},
{"snippet": "Styler.to_html(encoding=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `encoding`.", "question_id": 13438},
{"snippet": "Styler.to_html(doctype_html=False)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `doctype_html`.", "question_id": 13439},
{"snippet": "Styler.to_html(exclude_styles=False)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `exclude_styles`.", "question_id": 13440},
{"snippet": "Styler.to_html(buf=None, table_uuid=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `buf`, `table_uuid`.", "question_id": 13441},
{"snippet": "Styler.to_html(buf=None, table_attributes=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `buf`, `table_attributes`.", "question_id": 13442},
{"snippet": "Styler.to_html(buf=None, encoding=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `buf`, `encoding`.", "question_id": 13443},
{"snippet": "Styler.to_html()", "intent": "Write Styler to a file , buffer or string in HTML-CSS format .", "question_id": 13444},
{"snippet": "Styler.to_html(buf=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `buf`.", "question_id": 13445},
{"snippet": "Styler.to_html(table_uuid=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `table_uuid`.", "question_id": 13446},
{"snippet": "Styler.to_html(table_attributes=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `table_attributes`.", "question_id": 13447},
{"snippet": "Styler.to_html(encoding=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `encoding`.", "question_id": 13448},
{"snippet": "Styler.to_html(doctype_html=False)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `doctype_html`.", "question_id": 13449},
{"snippet": "Styler.to_html(exclude_styles=False)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `exclude_styles`.", "question_id": 13450},
{"snippet": "Styler.to_html(buf=None, table_uuid=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `buf`, `table_uuid`.", "question_id": 13451},
{"snippet": "Styler.to_html(buf=None, table_attributes=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `buf`, `table_attributes`.", "question_id": 13452},
{"snippet": "Styler.to_html(buf=None, encoding=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `buf`, `encoding`.", "question_id": 13453},
{"snippet": "Styler.to_html()", "intent": "Write Styler to a file , buffer or string in HTML-CSS format .", "question_id": 13454},
{"snippet": "Styler.to_html(buf=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `buf`.", "question_id": 13455},
{"snippet": "Styler.to_html(table_uuid=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `table_uuid`.", "question_id": 13456},
{"snippet": "Styler.to_html(table_attributes=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `table_attributes`.", "question_id": 13457},
{"snippet": "Styler.to_html(encoding=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `encoding`.", "question_id": 13458},
{"snippet": "Styler.to_html(doctype_html=False)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `doctype_html`.", "question_id": 13459},
{"snippet": "Styler.to_html(exclude_styles=False)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `exclude_styles`.", "question_id": 13460},
{"snippet": "Styler.to_html(buf=None, table_uuid=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `buf`, `table_uuid`.", "question_id": 13461},
{"snippet": "Styler.to_html(buf=None, table_attributes=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `buf`, `table_attributes`.", "question_id": 13462},
{"snippet": "Styler.to_html(buf=None, encoding=None)", "intent": "Write Styler to a file , buffer or string in HTML-CSS format . With arguments `buf`, `encoding`.", "question_id": 13463},
{"snippet": "Styler.to_latex()", "intent": "Write Styler to a file , buffer or string in LaTeX format .", "question_id": 13464},
{"snippet": "Styler.to_latex(buf=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . With arguments `buf`.", "question_id": 13465},
{"snippet": "Styler.to_latex(column_format=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Internally Styler uses its table_styles object to parse the `column_format` , `position` , `position_float` , and `label` input arguments .", "question_id": 13466},
{"snippet": "Styler.to_latex(position=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Internally Styler uses its table_styles object to parse the `column_format` , `position` , `position_float` , and `label` input arguments .", "question_id": 13467},
{"snippet": "Styler.to_latex(position_float=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Internally Styler uses its table_styles object to parse the `column_format` , `position` , `position_float` , and `label` input arguments .", "question_id": 13468},
{"snippet": "Styler.to_latex(hrules=False)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Exception is made for the `hrules` argument which , in fact , controls all three commands : toprule , bottomrule and midrule simultaneously .", "question_id": 13469},
{"snippet": "Styler.to_latex(label=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Internally Styler uses its table_styles object to parse the `column_format` , `position` , `position_float` , and `label` input arguments .", "question_id": 13470},
{"snippet": "Styler.to_latex(caption=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . With arguments `caption`.", "question_id": 13471},
{"snippet": "Styler.to_latex(sparse_index=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . With arguments `sparse_index`.", "question_id": 13472},
{"snippet": "Styler.to_latex(sparse_columns=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . With arguments `sparse_columns`.", "question_id": 13473},
{"snippet": "Styler.to_latex()", "intent": "Write Styler to a file , buffer or string in LaTeX format .", "question_id": 13474},
{"snippet": "Styler.to_latex(buf=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . With arguments `buf`.", "question_id": 13475},
{"snippet": "Styler.to_latex(column_format=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Internally Styler uses its table_styles object to parse the `column_format` , `position` , `position_float` , and `label` input arguments .", "question_id": 13476},
{"snippet": "Styler.to_latex(position=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Internally Styler uses its table_styles object to parse the `column_format` , `position` , `position_float` , and `label` input arguments .", "question_id": 13477},
{"snippet": "Styler.to_latex(position_float=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Internally Styler uses its table_styles object to parse the `column_format` , `position` , `position_float` , and `label` input arguments .", "question_id": 13478},
{"snippet": "Styler.to_latex(hrules=False)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Exception is made for the `hrules` argument which , in fact , controls all three commands : toprule , bottomrule and midrule simultaneously .", "question_id": 13479},
{"snippet": "Styler.to_latex(label=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Internally Styler uses its table_styles object to parse the `column_format` , `position` , `position_float` , and `label` input arguments .", "question_id": 13480},
{"snippet": "Styler.to_latex(caption=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . With arguments `caption`.", "question_id": 13481},
{"snippet": "Styler.to_latex(sparse_index=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . With arguments `sparse_index`.", "question_id": 13482},
{"snippet": "Styler.to_latex(sparse_columns=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . With arguments `sparse_columns`.", "question_id": 13483},
{"snippet": "Styler.to_latex()", "intent": "Write Styler to a file , buffer or string in LaTeX format .", "question_id": 13484},
{"snippet": "Styler.to_latex(buf=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . With arguments `buf`.", "question_id": 13485},
{"snippet": "Styler.to_latex(column_format=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Internally Styler uses its table_styles object to parse the `column_format` , `position` , `position_float` , and `label` input arguments .", "question_id": 13486},
{"snippet": "Styler.to_latex(position=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Internally Styler uses its table_styles object to parse the `column_format` , `position` , `position_float` , and `label` input arguments .", "question_id": 13487},
{"snippet": "Styler.to_latex(position_float=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Internally Styler uses its table_styles object to parse the `column_format` , `position` , `position_float` , and `label` input arguments .", "question_id": 13488},
{"snippet": "Styler.to_latex(hrules=False)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Exception is made for the `hrules` argument which , in fact , controls all three commands : toprule , bottomrule and midrule simultaneously .", "question_id": 13489},
{"snippet": "Styler.to_latex(label=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . Internally Styler uses its table_styles object to parse the `column_format` , `position` , `position_float` , and `label` input arguments .", "question_id": 13490},
{"snippet": "Styler.to_latex(caption=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . With arguments `caption`.", "question_id": 13491},
{"snippet": "Styler.to_latex(sparse_index=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . With arguments `sparse_index`.", "question_id": 13492},
{"snippet": "Styler.to_latex(sparse_columns=None)", "intent": "Write Styler to a file , buffer or string in LaTeX format . With arguments `sparse_columns`.", "question_id": 13493},
{"snippet": "Styler.use(styles)", "intent": "Set the `styles` on the current Styler .", "question_id": 13494},
{"snippet": "Styler.use(styles)", "intent": "Set the `styles` on the current Styler .", "question_id": 13495},
{"snippet": "Styler.use(styles)", "intent": "Set the `styles` on the current Styler .", "question_id": 13496},
{"snippet": "Styler.where(cond, value, **kwargs)", "intent": "Apply CSS-styles based on a conditional function elementwise . Updates the HTML representation with a style which is selected in accordance with the return `value` of a function . With arguments `cond`, `**kwargs`.", "question_id": 13497},
{"snippet": "Styler.where(cond, value, **kwargs, other=None)", "intent": "Apply CSS-styles based on a conditional function elementwise . Updates the HTML representation with a style which is selected in accordance with the return `value` of a function . With arguments `cond`, `**kwargs`, `other`.", "question_id": 13498},
{"snippet": "Styler.where(cond, value, **kwargs, subset=None)", "intent": "Apply CSS-styles based on a conditional function elementwise . Updates the HTML representation with a style which is selected in accordance with the return `value` of a function . With arguments `cond`, `**kwargs`, `subset`.", "question_id": 13499},
{"snippet": "Styler.where(cond, value, **kwargs, other=None, subset=None)", "intent": "Apply CSS-styles based on a conditional function elementwise . Updates the HTML representation with a style which is selected in accordance with the return `value` of a function . With arguments `cond`, `**kwargs`, `other`, `subset`.", "question_id": 13500},
{"snippet": "Styler.where(cond, value, **kwargs)", "intent": "Apply CSS-styles based on a conditional function elementwise . Updates the HTML representation with a style which is selected in accordance with the return `value` of a function . With arguments `cond`, `**kwargs`.", "question_id": 13501},
{"snippet": "Styler.where(cond, value, **kwargs, other=None)", "intent": "Apply CSS-styles based on a conditional function elementwise . Updates the HTML representation with a style which is selected in accordance with the return `value` of a function . With arguments `cond`, `**kwargs`, `other`.", "question_id": 13502},
{"snippet": "Styler.where(cond, value, **kwargs, subset=None)", "intent": "Apply CSS-styles based on a conditional function elementwise . Updates the HTML representation with a style which is selected in accordance with the return `value` of a function . With arguments `cond`, `**kwargs`, `subset`.", "question_id": 13503},
{"snippet": "Styler.where(cond, value, **kwargs, other=None, subset=None)", "intent": "Apply CSS-styles based on a conditional function elementwise . Updates the HTML representation with a style which is selected in accordance with the return `value` of a function . With arguments `cond`, `**kwargs`, `other`, `subset`.", "question_id": 13504},
{"snippet": "Styler.where(cond, value, **kwargs)", "intent": "Apply CSS-styles based on a conditional function elementwise . Updates the HTML representation with a style which is selected in accordance with the return `value` of a function . With arguments `cond`, `**kwargs`.", "question_id": 13505},
{"snippet": "Styler.where(cond, value, **kwargs, other=None)", "intent": "Apply CSS-styles based on a conditional function elementwise . Updates the HTML representation with a style which is selected in accordance with the return `value` of a function . With arguments `cond`, `**kwargs`, `other`.", "question_id": 13506},
{"snippet": "Styler.where(cond, value, **kwargs, subset=None)", "intent": "Apply CSS-styles based on a conditional function elementwise . Updates the HTML representation with a style which is selected in accordance with the return `value` of a function . With arguments `cond`, `**kwargs`, `subset`.", "question_id": 13507},
{"snippet": "Styler.where(cond, value, **kwargs, other=None, subset=None)", "intent": "Apply CSS-styles based on a conditional function elementwise . Updates the HTML representation with a style which is selected in accordance with the return `value` of a function . With arguments `cond`, `**kwargs`, `other`, `subset`.", "question_id": 13508},
{"snippet": "pandas.io.json.build_table_schema(data)", "intent": "Create a Table schema from `data` .", "question_id": 13509},
{"snippet": "pandas.io.json.build_table_schema(data, index=True)", "intent": "Create a Table schema from `data` . With arguments `index`.", "question_id": 13510},
{"snippet": "pandas.io.json.build_table_schema(data, primary_key=None)", "intent": "Create a Table schema from `data` . With arguments `primary_key`.", "question_id": 13511},
{"snippet": "pandas.io.json.build_table_schema(data, version=True)", "intent": "Create a Table schema from `data` . With arguments `version`.", "question_id": 13512},
{"snippet": "pandas.io.json.build_table_schema(data, index=True, primary_key=None)", "intent": "Create a Table schema from `data` . With arguments `index`, `primary_key`.", "question_id": 13513},
{"snippet": "pandas.io.json.build_table_schema(data, index=True, version=True)", "intent": "Create a Table schema from `data` . With arguments `index`, `version`.", "question_id": 13514},
{"snippet": "pandas.io.json.build_table_schema(data, primary_key=None, version=True)", "intent": "Create a Table schema from `data` . With arguments `primary_key`, `version`.", "question_id": 13515},
{"snippet": "pandas.io.json.build_table_schema(data, index=True, primary_key=None, version=True)", "intent": "Create a Table schema from `data` . With arguments `index`, `primary_key`, `version`.", "question_id": 13516},
{"snippet": "pandas.io.json.build_table_schema(data)", "intent": "Create a Table schema from `data` .", "question_id": 13517},
{"snippet": "pandas.io.json.build_table_schema(data, index=True)", "intent": "Create a Table schema from `data` . With arguments `index`.", "question_id": 13518},
{"snippet": "pandas.io.json.build_table_schema(data, primary_key=None)", "intent": "Create a Table schema from `data` . With arguments `primary_key`.", "question_id": 13519},
{"snippet": "pandas.io.json.build_table_schema(data, version=True)", "intent": "Create a Table schema from `data` . With arguments `version`.", "question_id": 13520},
{"snippet": "pandas.io.json.build_table_schema(data, index=True, primary_key=None)", "intent": "Create a Table schema from `data` . With arguments `index`, `primary_key`.", "question_id": 13521},
{"snippet": "pandas.io.json.build_table_schema(data, index=True, version=True)", "intent": "Create a Table schema from `data` . With arguments `index`, `version`.", "question_id": 13522},
{"snippet": "pandas.io.json.build_table_schema(data, primary_key=None, version=True)", "intent": "Create a Table schema from `data` . With arguments `primary_key`, `version`.", "question_id": 13523},
{"snippet": "pandas.io.json.build_table_schema(data, index=True, primary_key=None, version=True)", "intent": "Create a Table schema from `data` . With arguments `index`, `primary_key`, `version`.", "question_id": 13524},
{"snippet": "pandas.io.json.build_table_schema(data)", "intent": "Create a Table schema from `data` .", "question_id": 13525},
{"snippet": "pandas.io.json.build_table_schema(data, index=True)", "intent": "Create a Table schema from `data` . With arguments `index`.", "question_id": 13526},
{"snippet": "pandas.io.json.build_table_schema(data, primary_key=None)", "intent": "Create a Table schema from `data` . With arguments `primary_key`.", "question_id": 13527},
{"snippet": "pandas.io.json.build_table_schema(data, version=True)", "intent": "Create a Table schema from `data` . With arguments `version`.", "question_id": 13528},
{"snippet": "pandas.io.json.build_table_schema(data, index=True, primary_key=None)", "intent": "Create a Table schema from `data` . With arguments `index`, `primary_key`.", "question_id": 13529},
{"snippet": "pandas.io.json.build_table_schema(data, index=True, version=True)", "intent": "Create a Table schema from `data` . With arguments `index`, `version`.", "question_id": 13530},
{"snippet": "pandas.io.json.build_table_schema(data, primary_key=None, version=True)", "intent": "Create a Table schema from `data` . With arguments `primary_key`, `version`.", "question_id": 13531},
{"snippet": "pandas.io.json.build_table_schema(data, index=True, primary_key=None, version=True)", "intent": "Create a Table schema from `data` . With arguments `index`, `primary_key`, `version`.", "question_id": 13532},
{"snippet": "pandas.io.json.read_json()", "intent": "Convert a JSON string to pandas object .", "question_id": 13533},
{"snippet": "pandas.io.json.read_json(path_or_buf=None)", "intent": "Convert a JSON string to pandas object . With arguments `path_or_buf`.", "question_id": 13534},
{"snippet": "pandas.io.json.read_json(orient=None)", "intent": "Convert a JSON string to pandas object . With arguments `orient`.", "question_id": 13535},
{"snippet": "pandas.io.json.read_json(typ='frame')", "intent": "Convert a JSON string to pandas object . With arguments `typ`.", "question_id": 13536},
{"snippet": "pandas.io.json.read_json(dtype=None)", "intent": "Convert a JSON string to pandas object . With arguments `dtype`.", "question_id": 13537},
{"snippet": "pandas.io.json.read_json(convert_axes=None)", "intent": "Convert a JSON string to pandas object . With arguments `convert_axes`.", "question_id": 13538},
{"snippet": "pandas.io.json.read_json(convert_dates=True)", "intent": "Convert a JSON string to pandas object . With arguments `convert_dates`.", "question_id": 13539},
{"snippet": "pandas.io.json.read_json(keep_default_dates=True)", "intent": "Convert a JSON string to pandas object . With arguments `keep_default_dates`.", "question_id": 13540},
{"snippet": "pandas.io.json.read_json(numpy=False)", "intent": "Convert a JSON string to pandas object . With arguments `numpy`.", "question_id": 13541},
{"snippet": "pandas.io.json.read_json(precise_float=False)", "intent": "Convert a JSON string to pandas object . With arguments `precise_float`.", "question_id": 13542},
{"snippet": "pandas.io.json.read_json()", "intent": "Convert a JSON string to pandas object .", "question_id": 13543},
{"snippet": "pandas.io.json.read_json(path_or_buf=None)", "intent": "Convert a JSON string to pandas object . With arguments `path_or_buf`.", "question_id": 13544},
{"snippet": "pandas.io.json.read_json(orient=None)", "intent": "Convert a JSON string to pandas object . With arguments `orient`.", "question_id": 13545},
{"snippet": "pandas.io.json.read_json(typ='frame')", "intent": "Convert a JSON string to pandas object . With arguments `typ`.", "question_id": 13546},
{"snippet": "pandas.io.json.read_json(dtype=None)", "intent": "Convert a JSON string to pandas object . With arguments `dtype`.", "question_id": 13547},
{"snippet": "pandas.io.json.read_json(convert_axes=None)", "intent": "Convert a JSON string to pandas object . With arguments `convert_axes`.", "question_id": 13548},
{"snippet": "pandas.io.json.read_json(convert_dates=True)", "intent": "Convert a JSON string to pandas object . With arguments `convert_dates`.", "question_id": 13549},
{"snippet": "pandas.io.json.read_json(keep_default_dates=True)", "intent": "Convert a JSON string to pandas object . With arguments `keep_default_dates`.", "question_id": 13550},
{"snippet": "pandas.io.json.read_json(numpy=False)", "intent": "Convert a JSON string to pandas object . With arguments `numpy`.", "question_id": 13551},
{"snippet": "pandas.io.json.read_json(precise_float=False)", "intent": "Convert a JSON string to pandas object . With arguments `precise_float`.", "question_id": 13552},
{"snippet": "pandas.io.json.read_json()", "intent": "Convert a JSON string to pandas object .", "question_id": 13553},
{"snippet": "pandas.io.json.read_json(path_or_buf=None)", "intent": "Convert a JSON string to pandas object . With arguments `path_or_buf`.", "question_id": 13554},
{"snippet": "pandas.io.json.read_json(orient=None)", "intent": "Convert a JSON string to pandas object . With arguments `orient`.", "question_id": 13555},
{"snippet": "pandas.io.json.read_json(typ='frame')", "intent": "Convert a JSON string to pandas object . With arguments `typ`.", "question_id": 13556},
{"snippet": "pandas.io.json.read_json(dtype=None)", "intent": "Convert a JSON string to pandas object . With arguments `dtype`.", "question_id": 13557},
{"snippet": "pandas.io.json.read_json(convert_axes=None)", "intent": "Convert a JSON string to pandas object . With arguments `convert_axes`.", "question_id": 13558},
{"snippet": "pandas.io.json.read_json(convert_dates=True)", "intent": "Convert a JSON string to pandas object . With arguments `convert_dates`.", "question_id": 13559},
{"snippet": "pandas.io.json.read_json(keep_default_dates=True)", "intent": "Convert a JSON string to pandas object . With arguments `keep_default_dates`.", "question_id": 13560},
{"snippet": "pandas.io.json.read_json(numpy=False)", "intent": "Convert a JSON string to pandas object . With arguments `numpy`.", "question_id": 13561},
{"snippet": "pandas.io.json.read_json(precise_float=False)", "intent": "Convert a JSON string to pandas object . With arguments `precise_float`.", "question_id": 13562},
{"snippet": "StataReader.value_labels()", "intent": "Return a dict , associating each variable name a dict , associating each value its corresponding label .", "question_id": 13563},
{"snippet": "StataReader.value_labels()", "intent": "Return a dict , associating each variable name a dict , associating each value its corresponding label .", "question_id": 13564},
{"snippet": "StataReader.value_labels()", "intent": "Return a dict , associating each variable name a dict , associating each value its corresponding label .", "question_id": 13565},
{"snippet": "StataReader.variable_labels()", "intent": "Return variable labels as a dict , associating each variable name with corresponding label .", "question_id": 13566},
{"snippet": "StataReader.variable_labels()", "intent": "Return variable labels as a dict , associating each variable name with corresponding label .", "question_id": 13567},
{"snippet": "StataReader.variable_labels()", "intent": "Return variable labels as a dict , associating each variable name with corresponding label .", "question_id": 13568},
{"snippet": "pandas.isna(obj)", "intent": "Detect missing values for an array-like object . With arguments `obj`.", "question_id": 13569},
{"snippet": "pandas.isna(obj)", "intent": "Detect missing values for an array-like object . With arguments `obj`.", "question_id": 13570},
{"snippet": "pandas.isna(obj)", "intent": "Detect missing values for an array-like object . With arguments `obj`.", "question_id": 13571},
{"snippet": "pandas.isnull(obj)", "intent": "Detect missing values for an array-like object . With arguments `obj`.", "question_id": 13572},
{"snippet": "pandas.isnull(obj)", "intent": "Detect missing values for an array-like object . With arguments `obj`.", "question_id": 13573},
{"snippet": "pandas.isnull(obj)", "intent": "Detect missing values for an array-like object . With arguments `obj`.", "question_id": 13574},
{"snippet": "pandas.melt(frame)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`.", "question_id": 13575},
{"snippet": "pandas.melt(frame, id_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`.", "question_id": 13576},
{"snippet": "pandas.melt(frame, value_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`.", "question_id": 13577},
{"snippet": "pandas.melt(frame, var_name=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`, `var_name`.", "question_id": 13578},
{"snippet": "pandas.melt(frame, value_name='value')", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`, `value_name`.", "question_id": 13579},
{"snippet": "pandas.melt(frame, col_level=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`, `col_level`.", "question_id": 13580},
{"snippet": "pandas.melt(frame, ignore_index=True)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`, `ignore_index`.", "question_id": 13581},
{"snippet": "pandas.melt(frame, id_vars=None, value_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`.", "question_id": 13582},
{"snippet": "pandas.melt(frame, id_vars=None, var_name=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`, `var_name`.", "question_id": 13583},
{"snippet": "pandas.melt(frame, id_vars=None, value_name='value')", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`, `value_name`.", "question_id": 13584},
{"snippet": "pandas.melt(frame)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`.", "question_id": 13585},
{"snippet": "pandas.melt(frame, id_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`.", "question_id": 13586},
{"snippet": "pandas.melt(frame, value_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`.", "question_id": 13587},
{"snippet": "pandas.melt(frame, var_name=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`, `var_name`.", "question_id": 13588},
{"snippet": "pandas.melt(frame, value_name='value')", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`, `value_name`.", "question_id": 13589},
{"snippet": "pandas.melt(frame, col_level=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`, `col_level`.", "question_id": 13590},
{"snippet": "pandas.melt(frame, ignore_index=True)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`, `ignore_index`.", "question_id": 13591},
{"snippet": "pandas.melt(frame, id_vars=None, value_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`.", "question_id": 13592},
{"snippet": "pandas.melt(frame, id_vars=None, var_name=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`, `var_name`.", "question_id": 13593},
{"snippet": "pandas.melt(frame, id_vars=None, value_name='value')", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`, `value_name`.", "question_id": 13594},
{"snippet": "pandas.melt(frame)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`.", "question_id": 13595},
{"snippet": "pandas.melt(frame, id_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`.", "question_id": 13596},
{"snippet": "pandas.melt(frame, value_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`.", "question_id": 13597},
{"snippet": "pandas.melt(frame, var_name=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`, `var_name`.", "question_id": 13598},
{"snippet": "pandas.melt(frame, value_name='value')", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`, `value_name`.", "question_id": 13599},
{"snippet": "pandas.melt(frame, col_level=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`, `col_level`.", "question_id": 13600},
{"snippet": "pandas.melt(frame, ignore_index=True)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . With arguments `frame`, `ignore_index`.", "question_id": 13601},
{"snippet": "pandas.melt(frame, id_vars=None, value_vars=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`.", "question_id": 13602},
{"snippet": "pandas.melt(frame, id_vars=None, var_name=None)", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`, `var_name`.", "question_id": 13603},
{"snippet": "pandas.melt(frame, id_vars=None, value_name='value')", "intent": "Unpivot a DataFrame from wide to long format , optionally leaving identifiers set . This function is useful to massage a DataFrame into a format where one or more columns are identifier variables ( `id_vars` ) , while all other columns , considered measured variables ( `value_vars` ) , are \u201c unpivoted \u201d to the row axis , leaving just two non-identifier columns , \u2018 variable \u2019 and \u2018 value \u2019 . With arguments `frame`, `value_name`.", "question_id": 13604},
{"snippet": "pandas.merge(left, right, '_y'))", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`.", "question_id": 13605},
{"snippet": "pandas.merge(left, right, '_y'), how='inner')", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `how`.", "question_id": 13606},
{"snippet": "pandas.merge(left, right, '_y'), on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . The join is done `on` columns or indexes . With arguments `'_y')`.", "question_id": 13607},
{"snippet": "pandas.merge(left, right, '_y'), left_on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . Support for specifying index levels as the on , `left_on` , and `right_on` parameters was added in version 0.23.0 Support for merging named Series objects was added in version 0.24.0 With arguments `'_y')`.", "question_id": 13608},
{"snippet": "pandas.merge(left, right, '_y'), right_on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . Support for specifying index levels as the on , `left_on` , and `right_on` parameters was added in version 0.23.0 Support for merging named Series objects was added in version 0.24.0 With arguments `'_y')`.", "question_id": 13609},
{"snippet": "pandas.merge(left, right, '_y'), left_index=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `left_index`.", "question_id": 13610},
{"snippet": "pandas.merge(left, right, '_y'), right_index=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `right_index`.", "question_id": 13611},
{"snippet": "pandas.merge(left, right, '_y'), sort=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `sort`.", "question_id": 13612},
{"snippet": "pandas.merge(left, right, '_y'), suffixes=('_x')", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . The value columns have the default `suffixes` , _x and _y , appended . With arguments `'_y')`.", "question_id": 13613},
{"snippet": "pandas.merge(left, right, '_y'), copy=True)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `copy`.", "question_id": 13614},
{"snippet": "pandas.merge(left, right, '_y'))", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`.", "question_id": 13615},
{"snippet": "pandas.merge(left, right, '_y'), how='inner')", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `how`.", "question_id": 13616},
{"snippet": "pandas.merge(left, right, '_y'), on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . The join is done `on` columns or indexes . With arguments `'_y')`.", "question_id": 13617},
{"snippet": "pandas.merge(left, right, '_y'), left_on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . Support for specifying index levels as the on , `left_on` , and `right_on` parameters was added in version 0.23.0 Support for merging named Series objects was added in version 0.24.0 With arguments `'_y')`.", "question_id": 13618},
{"snippet": "pandas.merge(left, right, '_y'), right_on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . Support for specifying index levels as the on , `left_on` , and `right_on` parameters was added in version 0.23.0 Support for merging named Series objects was added in version 0.24.0 With arguments `'_y')`.", "question_id": 13619},
{"snippet": "pandas.merge(left, right, '_y'), left_index=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `left_index`.", "question_id": 13620},
{"snippet": "pandas.merge(left, right, '_y'), right_index=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `right_index`.", "question_id": 13621},
{"snippet": "pandas.merge(left, right, '_y'), sort=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `sort`.", "question_id": 13622},
{"snippet": "pandas.merge(left, right, '_y'), suffixes=('_x')", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . The value columns have the default `suffixes` , _x and _y , appended . With arguments `'_y')`.", "question_id": 13623},
{"snippet": "pandas.merge(left, right, '_y'), copy=True)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `copy`.", "question_id": 13624},
{"snippet": "pandas.merge(left, right, '_y'))", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`.", "question_id": 13625},
{"snippet": "pandas.merge(left, right, '_y'), how='inner')", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `how`.", "question_id": 13626},
{"snippet": "pandas.merge(left, right, '_y'), on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . The join is done `on` columns or indexes . With arguments `'_y')`.", "question_id": 13627},
{"snippet": "pandas.merge(left, right, '_y'), left_on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . Support for specifying index levels as the on , `left_on` , and `right_on` parameters was added in version 0.23.0 Support for merging named Series objects was added in version 0.24.0 With arguments `'_y')`.", "question_id": 13628},
{"snippet": "pandas.merge(left, right, '_y'), right_on=None)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . Support for specifying index levels as the on , `left_on` , and `right_on` parameters was added in version 0.23.0 Support for merging named Series objects was added in version 0.24.0 With arguments `'_y')`.", "question_id": 13629},
{"snippet": "pandas.merge(left, right, '_y'), left_index=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `left_index`.", "question_id": 13630},
{"snippet": "pandas.merge(left, right, '_y'), right_index=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `right_index`.", "question_id": 13631},
{"snippet": "pandas.merge(left, right, '_y'), sort=False)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `sort`.", "question_id": 13632},
{"snippet": "pandas.merge(left, right, '_y'), suffixes=('_x')", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . The value columns have the default `suffixes` , _x and _y , appended . With arguments `'_y')`.", "question_id": 13633},
{"snippet": "pandas.merge(left, right, '_y'), copy=True)", "intent": "Merge DataFrame or named Series objects with a database-style join . Merge DataFrames df1 and df2 with specified `left` and `right` suffixes appended to any overlapping columns . With arguments `'_y')`, `copy`.", "question_id": 13634},
{"snippet": "pandas.merge_asof(left, right, '_y'))", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`.", "question_id": 13635},
{"snippet": "pandas.merge_asof(left, right, '_y'), on=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : This is similar to a left-join except that we match `on` nearest key rather than equal keys . With arguments `right`, `'_y')`.", "question_id": 13636},
{"snippet": "pandas.merge_asof(left, right, '_y'), left_on=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `left_on`.", "question_id": 13637},
{"snippet": "pandas.merge_asof(left, right, '_y'), right_on=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `right_on`.", "question_id": 13638},
{"snippet": "pandas.merge_asof(left, right, '_y'), left_index=False)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `left_index`.", "question_id": 13639},
{"snippet": "pandas.merge_asof(left, right, '_y'), right_index=False)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `right_index`.", "question_id": 13640},
{"snippet": "pandas.merge_asof(left, right, '_y'), by=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : Both DataFrames must be sorted `by` the key . With arguments `right`, `'_y')`.", "question_id": 13641},
{"snippet": "pandas.merge_asof(left, right, '_y'), left_by=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `left_by`.", "question_id": 13642},
{"snippet": "pandas.merge_asof(left, right, '_y'), right_by=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `right_by`.", "question_id": 13643},
{"snippet": "pandas.merge_asof(left, right, '_y'), suffixes=('_x')", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `suffixes`.", "question_id": 13644},
{"snippet": "pandas.merge_asof(left, right, '_y'))", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`.", "question_id": 13645},
{"snippet": "pandas.merge_asof(left, right, '_y'), on=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : This is similar to a left-join except that we match `on` nearest key rather than equal keys . With arguments `right`, `'_y')`.", "question_id": 13646},
{"snippet": "pandas.merge_asof(left, right, '_y'), left_on=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `left_on`.", "question_id": 13647},
{"snippet": "pandas.merge_asof(left, right, '_y'), right_on=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `right_on`.", "question_id": 13648},
{"snippet": "pandas.merge_asof(left, right, '_y'), left_index=False)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `left_index`.", "question_id": 13649},
{"snippet": "pandas.merge_asof(left, right, '_y'), right_index=False)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `right_index`.", "question_id": 13650},
{"snippet": "pandas.merge_asof(left, right, '_y'), by=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : Both DataFrames must be sorted `by` the key . With arguments `right`, `'_y')`.", "question_id": 13651},
{"snippet": "pandas.merge_asof(left, right, '_y'), left_by=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `left_by`.", "question_id": 13652},
{"snippet": "pandas.merge_asof(left, right, '_y'), right_by=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `right_by`.", "question_id": 13653},
{"snippet": "pandas.merge_asof(left, right, '_y'), suffixes=('_x')", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `suffixes`.", "question_id": 13654},
{"snippet": "pandas.merge_asof(left, right, '_y'))", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`.", "question_id": 13655},
{"snippet": "pandas.merge_asof(left, right, '_y'), on=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : This is similar to a left-join except that we match `on` nearest key rather than equal keys . With arguments `right`, `'_y')`.", "question_id": 13656},
{"snippet": "pandas.merge_asof(left, right, '_y'), left_on=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `left_on`.", "question_id": 13657},
{"snippet": "pandas.merge_asof(left, right, '_y'), right_on=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `right_on`.", "question_id": 13658},
{"snippet": "pandas.merge_asof(left, right, '_y'), left_index=False)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `left_index`.", "question_id": 13659},
{"snippet": "pandas.merge_asof(left, right, '_y'), right_index=False)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `right_index`.", "question_id": 13660},
{"snippet": "pandas.merge_asof(left, right, '_y'), by=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : Both DataFrames must be sorted `by` the key . With arguments `right`, `'_y')`.", "question_id": 13661},
{"snippet": "pandas.merge_asof(left, right, '_y'), left_by=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `left_by`.", "question_id": 13662},
{"snippet": "pandas.merge_asof(left, right, '_y'), right_by=None)", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `right_by`.", "question_id": 13663},
{"snippet": "pandas.merge_asof(left, right, '_y'), suffixes=('_x')", "intent": "Perform an asof merge . For each row in the `left` DataFrame : With arguments `right`, `'_y')`, `suffixes`.", "question_id": 13664},
{"snippet": "pandas.merge_ordered(left, right, '_y'))", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`.", "question_id": 13665},
{"snippet": "pandas.merge_ordered(left, right, '_y'), on=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `on`.", "question_id": 13666},
{"snippet": "pandas.merge_ordered(left, right, '_y'), left_on=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `left_on`.", "question_id": 13667},
{"snippet": "pandas.merge_ordered(left, right, '_y'), right_on=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `right_on`.", "question_id": 13668},
{"snippet": "pandas.merge_ordered(left, right, '_y'), left_by=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `left_by`.", "question_id": 13669},
{"snippet": "pandas.merge_ordered(left, right, '_y'), right_by=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `right_by`.", "question_id": 13670},
{"snippet": "pandas.merge_ordered(left, right, '_y'), fill_method=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `fill_method`.", "question_id": 13671},
{"snippet": "pandas.merge_ordered(left, right, '_y'), suffixes=('_x')", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `suffixes`.", "question_id": 13672},
{"snippet": "pandas.merge_ordered(left, right, '_y'), how='outer')", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `how`.", "question_id": 13673},
{"snippet": "pandas.merge_ordered(left, right, '_y'), on=None, left_on=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `on`, `left_on`.", "question_id": 13674},
{"snippet": "pandas.merge_ordered(left, right, '_y'))", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`.", "question_id": 13675},
{"snippet": "pandas.merge_ordered(left, right, '_y'), on=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `on`.", "question_id": 13676},
{"snippet": "pandas.merge_ordered(left, right, '_y'), left_on=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `left_on`.", "question_id": 13677},
{"snippet": "pandas.merge_ordered(left, right, '_y'), right_on=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `right_on`.", "question_id": 13678},
{"snippet": "pandas.merge_ordered(left, right, '_y'), left_by=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `left_by`.", "question_id": 13679},
{"snippet": "pandas.merge_ordered(left, right, '_y'), right_by=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `right_by`.", "question_id": 13680},
{"snippet": "pandas.merge_ordered(left, right, '_y'), fill_method=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `fill_method`.", "question_id": 13681},
{"snippet": "pandas.merge_ordered(left, right, '_y'), suffixes=('_x')", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `suffixes`.", "question_id": 13682},
{"snippet": "pandas.merge_ordered(left, right, '_y'), how='outer')", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `how`.", "question_id": 13683},
{"snippet": "pandas.merge_ordered(left, right, '_y'), on=None, left_on=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `on`, `left_on`.", "question_id": 13684},
{"snippet": "pandas.merge_ordered(left, right, '_y'))", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`.", "question_id": 13685},
{"snippet": "pandas.merge_ordered(left, right, '_y'), on=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `on`.", "question_id": 13686},
{"snippet": "pandas.merge_ordered(left, right, '_y'), left_on=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `left_on`.", "question_id": 13687},
{"snippet": "pandas.merge_ordered(left, right, '_y'), right_on=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `right_on`.", "question_id": 13688},
{"snippet": "pandas.merge_ordered(left, right, '_y'), left_by=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `left_by`.", "question_id": 13689},
{"snippet": "pandas.merge_ordered(left, right, '_y'), right_by=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `right_by`.", "question_id": 13690},
{"snippet": "pandas.merge_ordered(left, right, '_y'), fill_method=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `fill_method`.", "question_id": 13691},
{"snippet": "pandas.merge_ordered(left, right, '_y'), suffixes=('_x')", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `suffixes`.", "question_id": 13692},
{"snippet": "pandas.merge_ordered(left, right, '_y'), how='outer')", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `how`.", "question_id": 13693},
{"snippet": "pandas.merge_ordered(left, right, '_y'), on=None, left_on=None)", "intent": "Perform merge with optional filling/interpolation . With arguments `left`, `right`, `'_y')`, `on`, `left_on`.", "question_id": 13694},
{"snippet": "pandas.notna(obj)", "intent": "Detect non-missing values for an array-like object . With arguments `obj`.", "question_id": 13695},
{"snippet": "pandas.notna(obj)", "intent": "Detect non-missing values for an array-like object . With arguments `obj`.", "question_id": 13696},
{"snippet": "pandas.notna(obj)", "intent": "Detect non-missing values for an array-like object . With arguments `obj`.", "question_id": 13697},
{"snippet": "pandas.notnull(obj)", "intent": "Detect non-missing values for an array-like object . With arguments `obj`.", "question_id": 13698},
{"snippet": "pandas.notnull(obj)", "intent": "Detect non-missing values for an array-like object . With arguments `obj`.", "question_id": 13699},
{"snippet": "pandas.notnull(obj)", "intent": "Detect non-missing values for an array-like object . With arguments `obj`.", "question_id": 13700},
{"snippet": "option_context.__call__(func)", "intent": "Call self as a function . With arguments `func`.", "question_id": 13701},
{"snippet": "option_context.__call__(func)", "intent": "Call self as a function . With arguments `func`.", "question_id": 13702},
{"snippet": "option_context.__call__(func)", "intent": "Call self as a function . With arguments `func`.", "question_id": 13703},
{"snippet": "pandas.option_context(*args)", "intent": "Context manager to temporarily set options in the with statement context . With arguments `*args`.", "question_id": 13704},
{"snippet": "pandas.option_context(*args)", "intent": "Context manager to temporarily set options in the with statement context . With arguments `*args`.", "question_id": 13705},
{"snippet": "pandas.option_context(*args)", "intent": "Context manager to temporarily set options in the with statement context . With arguments `*args`.", "question_id": 13706},
{"snippet": "pandas.period_range()", "intent": "Return a fixed frequency PeriodIndex .", "question_id": 13707},
{"snippet": "pandas.period_range(start=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13708},
{"snippet": "pandas.period_range(end=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13709},
{"snippet": "pandas.period_range(periods=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13710},
{"snippet": "pandas.period_range(freq=None)", "intent": "Return a fixed frequency PeriodIndex . With arguments `freq`.", "question_id": 13711},
{"snippet": "pandas.period_range(name=None)", "intent": "Return a fixed frequency PeriodIndex . With arguments `name`.", "question_id": 13712},
{"snippet": "pandas.period_range(start=None, end=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13713},
{"snippet": "pandas.period_range(start=None, periods=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13714},
{"snippet": "pandas.period_range(start=None, freq=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified . With arguments `freq`.", "question_id": 13715},
{"snippet": "pandas.period_range(start=None, name=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified . With arguments `name`.", "question_id": 13716},
{"snippet": "pandas.period_range()", "intent": "Return a fixed frequency PeriodIndex .", "question_id": 13717},
{"snippet": "pandas.period_range(start=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13718},
{"snippet": "pandas.period_range(end=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13719},
{"snippet": "pandas.period_range(periods=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13720},
{"snippet": "pandas.period_range(freq=None)", "intent": "Return a fixed frequency PeriodIndex . With arguments `freq`.", "question_id": 13721},
{"snippet": "pandas.period_range(name=None)", "intent": "Return a fixed frequency PeriodIndex . With arguments `name`.", "question_id": 13722},
{"snippet": "pandas.period_range(start=None, end=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13723},
{"snippet": "pandas.period_range(start=None, periods=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13724},
{"snippet": "pandas.period_range(start=None, freq=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified . With arguments `freq`.", "question_id": 13725},
{"snippet": "pandas.period_range(start=None, name=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified . With arguments `name`.", "question_id": 13726},
{"snippet": "pandas.period_range()", "intent": "Return a fixed frequency PeriodIndex .", "question_id": 13727},
{"snippet": "pandas.period_range(start=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13728},
{"snippet": "pandas.period_range(end=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13729},
{"snippet": "pandas.period_range(periods=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13730},
{"snippet": "pandas.period_range(freq=None)", "intent": "Return a fixed frequency PeriodIndex . With arguments `freq`.", "question_id": 13731},
{"snippet": "pandas.period_range(name=None)", "intent": "Return a fixed frequency PeriodIndex . With arguments `name`.", "question_id": 13732},
{"snippet": "pandas.period_range(start=None, end=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13733},
{"snippet": "pandas.period_range(start=None, periods=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified .", "question_id": 13734},
{"snippet": "pandas.period_range(start=None, freq=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified . With arguments `freq`.", "question_id": 13735},
{"snippet": "pandas.period_range(start=None, name=None)", "intent": "Return a fixed frequency PeriodIndex . Of the three parameters : `start` , `end` , and `periods` , exactly two must be specified . With arguments `name`.", "question_id": 13736},
{"snippet": "pandas.pivot(data)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values .", "question_id": 13737},
{"snippet": "pandas.pivot(data, index=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values .", "question_id": 13738},
{"snippet": "pandas.pivot(data, columns=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 13739},
{"snippet": "pandas.pivot(data, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values .", "question_id": 13740},
{"snippet": "pandas.pivot(data, index=None, columns=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 13741},
{"snippet": "pandas.pivot(data, index=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values .", "question_id": 13742},
{"snippet": "pandas.pivot(data, columns=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 13743},
{"snippet": "pandas.pivot(data, index=None, columns=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 13744},
{"snippet": "pandas.pivot(data)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values .", "question_id": 13745},
{"snippet": "pandas.pivot(data, index=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values .", "question_id": 13746},
{"snippet": "pandas.pivot(data, columns=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 13747},
{"snippet": "pandas.pivot(data, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values .", "question_id": 13748},
{"snippet": "pandas.pivot(data, index=None, columns=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 13749},
{"snippet": "pandas.pivot(data, index=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values .", "question_id": 13750},
{"snippet": "pandas.pivot(data, columns=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 13751},
{"snippet": "pandas.pivot(data, index=None, columns=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 13752},
{"snippet": "pandas.pivot(data)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values .", "question_id": 13753},
{"snippet": "pandas.pivot(data, index=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values .", "question_id": 13754},
{"snippet": "pandas.pivot(data, columns=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 13755},
{"snippet": "pandas.pivot(data, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values .", "question_id": 13756},
{"snippet": "pandas.pivot(data, index=None, columns=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 13757},
{"snippet": "pandas.pivot(data, index=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values .", "question_id": 13758},
{"snippet": "pandas.pivot(data, columns=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 13759},
{"snippet": "pandas.pivot(data, index=None, columns=None, values=None)", "intent": "Return reshaped DataFrame organized by given `index` / column `values` . Reshape `data` ( produce a \u201c pivot \u201d table ) based on column values . Uses unique values from specified index / `columns` to form axes of the resulting DataFrame .", "question_id": 13760},
{"snippet": "pandas.pivot_table(data)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`.", "question_id": 13761},
{"snippet": "pandas.pivot_table(data, values=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . This first example aggregates `values` by taking the sum . With arguments `data`.", "question_id": 13762},
{"snippet": "pandas.pivot_table(data, index=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . The levels in the pivot table will be stored in MultiIndex objects ( hierarchical indexes ) on the `index` and `columns` of the result DataFrame . With arguments `data`.", "question_id": 13763},
{"snippet": "pandas.pivot_table(data, columns=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . The levels in the pivot table will be stored in MultiIndex objects ( hierarchical indexes ) on the `index` and `columns` of the result DataFrame . With arguments `data`.", "question_id": 13764},
{"snippet": "pandas.pivot_table(data, aggfunc='mean')", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `aggfunc`.", "question_id": 13765},
{"snippet": "pandas.pivot_table(data, fill_value=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . We can also fill missing values using the `fill_value` parameter . With arguments `data`.", "question_id": 13766},
{"snippet": "pandas.pivot_table(data, margins=False)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `margins`.", "question_id": 13767},
{"snippet": "pandas.pivot_table(data, dropna=True)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `dropna`.", "question_id": 13768},
{"snippet": "pandas.pivot_table(data, margins_name='All')", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `margins_name`.", "question_id": 13769},
{"snippet": "pandas.pivot_table(data, observed=False)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `observed`.", "question_id": 13770},
{"snippet": "pandas.pivot_table(data)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`.", "question_id": 13771},
{"snippet": "pandas.pivot_table(data, values=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . This first example aggregates `values` by taking the sum . With arguments `data`.", "question_id": 13772},
{"snippet": "pandas.pivot_table(data, index=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . The levels in the pivot table will be stored in MultiIndex objects ( hierarchical indexes ) on the `index` and `columns` of the result DataFrame . With arguments `data`.", "question_id": 13773},
{"snippet": "pandas.pivot_table(data, columns=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . The levels in the pivot table will be stored in MultiIndex objects ( hierarchical indexes ) on the `index` and `columns` of the result DataFrame . With arguments `data`.", "question_id": 13774},
{"snippet": "pandas.pivot_table(data, aggfunc='mean')", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `aggfunc`.", "question_id": 13775},
{"snippet": "pandas.pivot_table(data, fill_value=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . We can also fill missing values using the `fill_value` parameter . With arguments `data`.", "question_id": 13776},
{"snippet": "pandas.pivot_table(data, margins=False)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `margins`.", "question_id": 13777},
{"snippet": "pandas.pivot_table(data, dropna=True)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `dropna`.", "question_id": 13778},
{"snippet": "pandas.pivot_table(data, margins_name='All')", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `margins_name`.", "question_id": 13779},
{"snippet": "pandas.pivot_table(data, observed=False)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `observed`.", "question_id": 13780},
{"snippet": "pandas.pivot_table(data)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`.", "question_id": 13781},
{"snippet": "pandas.pivot_table(data, values=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . This first example aggregates `values` by taking the sum . With arguments `data`.", "question_id": 13782},
{"snippet": "pandas.pivot_table(data, index=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . The levels in the pivot table will be stored in MultiIndex objects ( hierarchical indexes ) on the `index` and `columns` of the result DataFrame . With arguments `data`.", "question_id": 13783},
{"snippet": "pandas.pivot_table(data, columns=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . The levels in the pivot table will be stored in MultiIndex objects ( hierarchical indexes ) on the `index` and `columns` of the result DataFrame . With arguments `data`.", "question_id": 13784},
{"snippet": "pandas.pivot_table(data, aggfunc='mean')", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `aggfunc`.", "question_id": 13785},
{"snippet": "pandas.pivot_table(data, fill_value=None)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . We can also fill missing values using the `fill_value` parameter . With arguments `data`.", "question_id": 13786},
{"snippet": "pandas.pivot_table(data, margins=False)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `margins`.", "question_id": 13787},
{"snippet": "pandas.pivot_table(data, dropna=True)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `dropna`.", "question_id": 13788},
{"snippet": "pandas.pivot_table(data, margins_name='All')", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `margins_name`.", "question_id": 13789},
{"snippet": "pandas.pivot_table(data, observed=False)", "intent": "Create a spreadsheet-style pivot table as a DataFrame . With arguments `data`, `observed`.", "question_id": 13790},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`.", "question_id": 13791},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, ax=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `ax`.", "question_id": 13792},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, samples=200)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `samples`.", "question_id": 13793},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, color=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `color`.", "question_id": 13794},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, colormap=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `colormap`.", "question_id": 13795},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, ax=None, samples=200)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `ax`, `samples`.", "question_id": 13796},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, ax=None, color=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `ax`, `color`.", "question_id": 13797},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, ax=None, colormap=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `ax`, `colormap`.", "question_id": 13798},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, samples=200, color=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `samples`, `color`.", "question_id": 13799},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, samples=200, colormap=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `samples`, `colormap`.", "question_id": 13800},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`.", "question_id": 13801},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, ax=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `ax`.", "question_id": 13802},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, samples=200)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `samples`.", "question_id": 13803},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, color=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `color`.", "question_id": 13804},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, colormap=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `colormap`.", "question_id": 13805},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, ax=None, samples=200)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `ax`, `samples`.", "question_id": 13806},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, ax=None, color=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `ax`, `color`.", "question_id": 13807},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, ax=None, colormap=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `ax`, `colormap`.", "question_id": 13808},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, samples=200, color=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `samples`, `color`.", "question_id": 13809},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, samples=200, colormap=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `samples`, `colormap`.", "question_id": 13810},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`.", "question_id": 13811},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, ax=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `ax`.", "question_id": 13812},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, samples=200)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `samples`.", "question_id": 13813},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, color=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `color`.", "question_id": 13814},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, colormap=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `colormap`.", "question_id": 13815},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, ax=None, samples=200)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `ax`, `samples`.", "question_id": 13816},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, ax=None, color=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `ax`, `color`.", "question_id": 13817},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, ax=None, colormap=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `ax`, `colormap`.", "question_id": 13818},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, samples=200, color=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `samples`, `color`.", "question_id": 13819},
{"snippet": "pandas.plotting.andrews_curves(frame, class_column, **kwargs, samples=200, colormap=None)", "intent": "Generate a matplotlib plot of Andrews curves , for visualising clusters of multivariate data . Each row of `frame` then corresponds to a single curve . With arguments `class_column`, `**kwargs`, `samples`, `colormap`.", "question_id": 13820},
{"snippet": "pandas.plotting.autocorrelation_plot(series, **kwargs)", "intent": "Autocorrelation plot for time `series` . With arguments `**kwargs`.", "question_id": 13821},
{"snippet": "pandas.plotting.autocorrelation_plot(series, **kwargs, ax=None)", "intent": "Autocorrelation plot for time `series` . With arguments `**kwargs`, `ax`.", "question_id": 13822},
{"snippet": "pandas.plotting.autocorrelation_plot(series, **kwargs)", "intent": "Autocorrelation plot for time `series` . With arguments `**kwargs`.", "question_id": 13823},
{"snippet": "pandas.plotting.autocorrelation_plot(series, **kwargs, ax=None)", "intent": "Autocorrelation plot for time `series` . With arguments `**kwargs`, `ax`.", "question_id": 13824},
{"snippet": "pandas.plotting.autocorrelation_plot(series, **kwargs)", "intent": "Autocorrelation plot for time `series` . With arguments `**kwargs`.", "question_id": 13825},
{"snippet": "pandas.plotting.autocorrelation_plot(series, **kwargs, ax=None)", "intent": "Autocorrelation plot for time `series` . With arguments `**kwargs`, `ax`.", "question_id": 13826},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds)", "intent": "Bootstrap plot on mean , median and mid-range statistics . With arguments `series`, `**kwds`.", "question_id": 13827},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, fig=None)", "intent": "Bootstrap plot on mean , median and mid-range statistics . With arguments `series`, `**kwds`, `fig`.", "question_id": 13828},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, size=50)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`.", "question_id": 13829},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, samples=500)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`.", "question_id": 13830},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, fig=None, size=50)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`, `fig`.", "question_id": 13831},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, fig=None, samples=500)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`, `fig`.", "question_id": 13832},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, size=50, samples=500)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`.", "question_id": 13833},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, fig=None, size=50, samples=500)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`, `fig`.", "question_id": 13834},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds)", "intent": "Bootstrap plot on mean , median and mid-range statistics . With arguments `series`, `**kwds`.", "question_id": 13835},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, fig=None)", "intent": "Bootstrap plot on mean , median and mid-range statistics . With arguments `series`, `**kwds`, `fig`.", "question_id": 13836},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, size=50)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`.", "question_id": 13837},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, samples=500)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`.", "question_id": 13838},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, fig=None, size=50)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`, `fig`.", "question_id": 13839},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, fig=None, samples=500)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`, `fig`.", "question_id": 13840},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, size=50, samples=500)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`.", "question_id": 13841},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, fig=None, size=50, samples=500)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`, `fig`.", "question_id": 13842},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds)", "intent": "Bootstrap plot on mean , median and mid-range statistics . With arguments `series`, `**kwds`.", "question_id": 13843},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, fig=None)", "intent": "Bootstrap plot on mean , median and mid-range statistics . With arguments `series`, `**kwds`, `fig`.", "question_id": 13844},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, size=50)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`.", "question_id": 13845},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, samples=500)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`.", "question_id": 13846},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, fig=None, size=50)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`, `fig`.", "question_id": 13847},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, fig=None, samples=500)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`, `fig`.", "question_id": 13848},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, size=50, samples=500)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`.", "question_id": 13849},
{"snippet": "pandas.plotting.bootstrap_plot(series, **kwds, fig=None, size=50, samples=500)", "intent": "Bootstrap plot on mean , median and mid-range statistics . This function will generate bootstrapping plots for mean , median and mid-range statistics for the given number of `samples` of the given `size` . With arguments `series`, `**kwds`, `fig`.", "question_id": 13850},
{"snippet": "pandas.plotting.boxplot(data, **kwargs)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . With arguments `**kwargs`.", "question_id": 13851},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, column=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . Boxplots can be created for every `column` in the dataframe by df.boxplot ( ) or indicating the columns to be used : With arguments `**kwargs`.", "question_id": 13852},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, by=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . Make a box-and-whisker plot from DataFrame columns , optionally grouped `by` some other columns . With arguments `**kwargs`.", "question_id": 13853},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, ax=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . With arguments `**kwargs`, `ax`.", "question_id": 13854},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, fontsize=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . rot=45 ) or changing the `fontsize` ( i.e . With arguments `**kwargs`.", "question_id": 13855},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, rot=0)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . With arguments `**kwargs`, `rot`.", "question_id": 13856},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, grid=True)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . Additional formatting can be done to the boxplot , like suppressing the `grid` ( grid=False ) , rotating the labels in the x-axis ( i.e . With arguments `**kwargs`.", "question_id": 13857},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, figsize=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . With arguments `**kwargs`, `figsize`.", "question_id": 13858},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, layout=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . The `layout` of boxplot can be adjusted giving a tuple to layout : With arguments `**kwargs`.", "question_id": 13859},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, return_type=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . The return type depends on the `return_type` parameter : With arguments `**kwargs`.", "question_id": 13860},
{"snippet": "pandas.plotting.boxplot(data, **kwargs)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . With arguments `**kwargs`.", "question_id": 13861},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, column=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . Boxplots can be created for every `column` in the dataframe by df.boxplot ( ) or indicating the columns to be used : With arguments `**kwargs`.", "question_id": 13862},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, by=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . Make a box-and-whisker plot from DataFrame columns , optionally grouped `by` some other columns . With arguments `**kwargs`.", "question_id": 13863},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, ax=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . With arguments `**kwargs`, `ax`.", "question_id": 13864},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, fontsize=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . rot=45 ) or changing the `fontsize` ( i.e . With arguments `**kwargs`.", "question_id": 13865},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, rot=0)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . With arguments `**kwargs`, `rot`.", "question_id": 13866},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, grid=True)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . Additional formatting can be done to the boxplot , like suppressing the `grid` ( grid=False ) , rotating the labels in the x-axis ( i.e . With arguments `**kwargs`.", "question_id": 13867},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, figsize=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . With arguments `**kwargs`, `figsize`.", "question_id": 13868},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, layout=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . The `layout` of boxplot can be adjusted giving a tuple to layout : With arguments `**kwargs`.", "question_id": 13869},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, return_type=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . The return type depends on the `return_type` parameter : With arguments `**kwargs`.", "question_id": 13870},
{"snippet": "pandas.plotting.boxplot(data, **kwargs)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . With arguments `**kwargs`.", "question_id": 13871},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, column=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . Boxplots can be created for every `column` in the dataframe by df.boxplot ( ) or indicating the columns to be used : With arguments `**kwargs`.", "question_id": 13872},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, by=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . Make a box-and-whisker plot from DataFrame columns , optionally grouped `by` some other columns . With arguments `**kwargs`.", "question_id": 13873},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, ax=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . With arguments `**kwargs`, `ax`.", "question_id": 13874},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, fontsize=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . rot=45 ) or changing the `fontsize` ( i.e . With arguments `**kwargs`.", "question_id": 13875},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, rot=0)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . With arguments `**kwargs`, `rot`.", "question_id": 13876},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, grid=True)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . Additional formatting can be done to the boxplot , like suppressing the `grid` ( grid=False ) , rotating the labels in the x-axis ( i.e . With arguments `**kwargs`.", "question_id": 13877},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, figsize=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . With arguments `**kwargs`, `figsize`.", "question_id": 13878},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, layout=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . The `layout` of boxplot can be adjusted giving a tuple to layout : With arguments `**kwargs`.", "question_id": 13879},
{"snippet": "pandas.plotting.boxplot(data, **kwargs, return_type=None)", "intent": "Make a box plot from DataFrame columns . A box plot is a method for graphically depicting groups of numerical `data` through their quartiles . The return type depends on the `return_type` parameter : With arguments `**kwargs`.", "question_id": 13880},
{"snippet": "pandas.plotting.deregister_matplotlib_converters()", "intent": "Remove pandas formatters and converters .", "question_id": 13881},
{"snippet": "pandas.plotting.deregister_matplotlib_converters()", "intent": "Remove pandas formatters and converters .", "question_id": 13882},
{"snippet": "pandas.plotting.deregister_matplotlib_converters()", "intent": "Remove pandas formatters and converters .", "question_id": 13883},
{"snippet": "pandas.plotting.lag_plot(series, **kwds)", "intent": "Lag plot for time `series` . With arguments `**kwds`.", "question_id": 13884},
{"snippet": "pandas.plotting.lag_plot(series, **kwds, lag=1)", "intent": "Lag plot for time `series` . A `lag` plot with lag=1 returns With arguments `**kwds`.", "question_id": 13885},
{"snippet": "pandas.plotting.lag_plot(series, **kwds, ax=None)", "intent": "Lag plot for time `series` . With arguments `**kwds`, `ax`.", "question_id": 13886},
{"snippet": "pandas.plotting.lag_plot(series, **kwds, lag=1, ax=None)", "intent": "Lag plot for time `series` . A `lag` plot with lag=1 returns With arguments `**kwds`, `ax`.", "question_id": 13887},
{"snippet": "pandas.plotting.lag_plot(series, **kwds)", "intent": "Lag plot for time `series` . With arguments `**kwds`.", "question_id": 13888},
{"snippet": "pandas.plotting.lag_plot(series, **kwds, lag=1)", "intent": "Lag plot for time `series` . A `lag` plot with lag=1 returns With arguments `**kwds`.", "question_id": 13889},
{"snippet": "pandas.plotting.lag_plot(series, **kwds, ax=None)", "intent": "Lag plot for time `series` . With arguments `**kwds`, `ax`.", "question_id": 13890},
{"snippet": "pandas.plotting.lag_plot(series, **kwds, lag=1, ax=None)", "intent": "Lag plot for time `series` . A `lag` plot with lag=1 returns With arguments `**kwds`, `ax`.", "question_id": 13891},
{"snippet": "pandas.plotting.lag_plot(series, **kwds)", "intent": "Lag plot for time `series` . With arguments `**kwds`.", "question_id": 13892},
{"snippet": "pandas.plotting.lag_plot(series, **kwds, lag=1)", "intent": "Lag plot for time `series` . A `lag` plot with lag=1 returns With arguments `**kwds`.", "question_id": 13893},
{"snippet": "pandas.plotting.lag_plot(series, **kwds, ax=None)", "intent": "Lag plot for time `series` . With arguments `**kwds`, `ax`.", "question_id": 13894},
{"snippet": "pandas.plotting.lag_plot(series, **kwds, lag=1, ax=None)", "intent": "Lag plot for time `series` . A `lag` plot with lag=1 returns With arguments `**kwds`, `ax`.", "question_id": 13895},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`.", "question_id": 13896},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, cols=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `cols`.", "question_id": 13897},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, ax=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `ax`.", "question_id": 13898},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, color=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `color`.", "question_id": 13899},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, use_columns=False)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `use_columns`.", "question_id": 13900},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, xticks=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `xticks`.", "question_id": 13901},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, colormap=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `colormap`.", "question_id": 13902},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, axvlines=True)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `axvlines`.", "question_id": 13903},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, axvlines_kwds=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `axvlines_kwds`.", "question_id": 13904},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, sort_labels=False)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `sort_labels`.", "question_id": 13905},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`.", "question_id": 13906},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, cols=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `cols`.", "question_id": 13907},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, ax=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `ax`.", "question_id": 13908},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, color=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `color`.", "question_id": 13909},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, use_columns=False)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `use_columns`.", "question_id": 13910},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, xticks=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `xticks`.", "question_id": 13911},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, colormap=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `colormap`.", "question_id": 13912},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, axvlines=True)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `axvlines`.", "question_id": 13913},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, axvlines_kwds=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `axvlines_kwds`.", "question_id": 13914},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, sort_labels=False)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `sort_labels`.", "question_id": 13915},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`.", "question_id": 13916},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, cols=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `cols`.", "question_id": 13917},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, ax=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `ax`.", "question_id": 13918},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, color=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `color`.", "question_id": 13919},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, use_columns=False)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `use_columns`.", "question_id": 13920},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, xticks=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `xticks`.", "question_id": 13921},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, colormap=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `colormap`.", "question_id": 13922},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, axvlines=True)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `axvlines`.", "question_id": 13923},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, axvlines_kwds=None)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `axvlines_kwds`.", "question_id": 13924},
{"snippet": "pandas.plotting.parallel_coordinates(frame, class_column, **kwargs, sort_labels=False)", "intent": "Parallel coordinates plotting . With arguments `frame`, `class_column`, `**kwargs`, `sort_labels`.", "question_id": 13925},
{"snippet": "pandas.plotting.plot_params", "intent": "Stores pandas plotting options.", "question_id": 13926},
{"snippet": "pandas.plotting.plot_params", "intent": "Stores pandas plotting options.", "question_id": 13927},
{"snippet": "pandas.plotting.plot_params", "intent": "Stores pandas plotting options.", "question_id": 13928},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`.", "question_id": 13929},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, ax=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `ax`.", "question_id": 13930},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, color=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `color`.", "question_id": 13931},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, colormap=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `colormap`.", "question_id": 13932},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, ax=None, color=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `ax`, `color`.", "question_id": 13933},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, ax=None, colormap=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `ax`, `colormap`.", "question_id": 13934},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, color=None, colormap=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `color`, `colormap`.", "question_id": 13935},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, ax=None, color=None, colormap=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `ax`, `color`, `colormap`.", "question_id": 13936},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`.", "question_id": 13937},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, ax=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `ax`.", "question_id": 13938},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, color=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `color`.", "question_id": 13939},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, colormap=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `colormap`.", "question_id": 13940},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, ax=None, color=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `ax`, `color`.", "question_id": 13941},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, ax=None, colormap=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `ax`, `colormap`.", "question_id": 13942},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, color=None, colormap=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `color`, `colormap`.", "question_id": 13943},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, ax=None, color=None, colormap=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `ax`, `color`, `colormap`.", "question_id": 13944},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`.", "question_id": 13945},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, ax=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `ax`.", "question_id": 13946},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, color=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `color`.", "question_id": 13947},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, colormap=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `colormap`.", "question_id": 13948},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, ax=None, color=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `ax`, `color`.", "question_id": 13949},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, ax=None, colormap=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `ax`, `colormap`.", "question_id": 13950},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, color=None, colormap=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `color`, `colormap`.", "question_id": 13951},
{"snippet": "pandas.plotting.radviz(frame, class_column, **kwds, ax=None, color=None, colormap=None)", "intent": "Plot a multidimensional dataset in 2D . With arguments `frame`, `class_column`, `**kwds`, `ax`, `color`, `colormap`.", "question_id": 13952},
{"snippet": "pandas.plotting.register_matplotlib_converters()", "intent": "Register pandas formatters and converters with matplotlib .", "question_id": 13953},
{"snippet": "pandas.plotting.register_matplotlib_converters()", "intent": "Register pandas formatters and converters with matplotlib .", "question_id": 13954},
{"snippet": "pandas.plotting.register_matplotlib_converters()", "intent": "Register pandas formatters and converters with matplotlib .", "question_id": 13955},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`.", "question_id": 13956},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, alpha=0.5)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `alpha`.", "question_id": 13957},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, figsize=None)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `figsize`.", "question_id": 13958},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, ax=None)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `ax`.", "question_id": 13959},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, grid=False)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `grid`.", "question_id": 13960},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, diagonal='hist')", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `diagonal`.", "question_id": 13961},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, marker='.')", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `marker`.", "question_id": 13962},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, density_kwds=None)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `density_kwds`.", "question_id": 13963},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, hist_kwds=None)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `hist_kwds`.", "question_id": 13964},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, range_padding=0.05)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `range_padding`.", "question_id": 13965},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`.", "question_id": 13966},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, alpha=0.5)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `alpha`.", "question_id": 13967},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, figsize=None)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `figsize`.", "question_id": 13968},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, ax=None)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `ax`.", "question_id": 13969},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, grid=False)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `grid`.", "question_id": 13970},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, diagonal='hist')", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `diagonal`.", "question_id": 13971},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, marker='.')", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `marker`.", "question_id": 13972},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, density_kwds=None)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `density_kwds`.", "question_id": 13973},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, hist_kwds=None)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `hist_kwds`.", "question_id": 13974},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, range_padding=0.05)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `range_padding`.", "question_id": 13975},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`.", "question_id": 13976},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, alpha=0.5)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `alpha`.", "question_id": 13977},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, figsize=None)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `figsize`.", "question_id": 13978},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, ax=None)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `ax`.", "question_id": 13979},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, grid=False)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `grid`.", "question_id": 13980},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, diagonal='hist')", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `diagonal`.", "question_id": 13981},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, marker='.')", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `marker`.", "question_id": 13982},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, density_kwds=None)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `density_kwds`.", "question_id": 13983},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, hist_kwds=None)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `hist_kwds`.", "question_id": 13984},
{"snippet": "pandas.plotting.scatter_matrix(frame, **kwargs, range_padding=0.05)", "intent": "Draw a matrix of scatter plots . With arguments `frame`, `**kwargs`, `range_padding`.", "question_id": 13985},
{"snippet": "pandas.plotting.table(ax, data, **kwargs)", "intent": "Helper function to convert DataFrame and Series to matplotlib.table . With arguments `ax`, `data`, `**kwargs`.", "question_id": 13986},
{"snippet": "pandas.plotting.table(ax, data, **kwargs, rowLabels=None)", "intent": "Helper function to convert DataFrame and Series to matplotlib.table . With arguments `ax`, `data`, `**kwargs`, `rowLabels`.", "question_id": 13987},
{"snippet": "pandas.plotting.table(ax, data, **kwargs, colLabels=None)", "intent": "Helper function to convert DataFrame and Series to matplotlib.table . With arguments `ax`, `data`, `**kwargs`, `colLabels`.", "question_id": 13988},
{"snippet": "pandas.plotting.table(ax, data, **kwargs, rowLabels=None, colLabels=None)", "intent": "Helper function to convert DataFrame and Series to matplotlib.table . With arguments `ax`, `data`, `**kwargs`, `rowLabels`, `colLabels`.", "question_id": 13989},
{"snippet": "pandas.plotting.table(ax, data, **kwargs)", "intent": "Helper function to convert DataFrame and Series to matplotlib.table . With arguments `ax`, `data`, `**kwargs`.", "question_id": 13990},
{"snippet": "pandas.plotting.table(ax, data, **kwargs, rowLabels=None)", "intent": "Helper function to convert DataFrame and Series to matplotlib.table . With arguments `ax`, `data`, `**kwargs`, `rowLabels`.", "question_id": 13991},
{"snippet": "pandas.plotting.table(ax, data, **kwargs, colLabels=None)", "intent": "Helper function to convert DataFrame and Series to matplotlib.table . With arguments `ax`, `data`, `**kwargs`, `colLabels`.", "question_id": 13992},
{"snippet": "pandas.plotting.table(ax, data, **kwargs, rowLabels=None, colLabels=None)", "intent": "Helper function to convert DataFrame and Series to matplotlib.table . With arguments `ax`, `data`, `**kwargs`, `rowLabels`, `colLabels`.", "question_id": 13993},
{"snippet": "pandas.plotting.table(ax, data, **kwargs)", "intent": "Helper function to convert DataFrame and Series to matplotlib.table . With arguments `ax`, `data`, `**kwargs`.", "question_id": 13994},
{"snippet": "pandas.plotting.table(ax, data, **kwargs, rowLabels=None)", "intent": "Helper function to convert DataFrame and Series to matplotlib.table . With arguments `ax`, `data`, `**kwargs`, `rowLabels`.", "question_id": 13995},
{"snippet": "pandas.plotting.table(ax, data, **kwargs, colLabels=None)", "intent": "Helper function to convert DataFrame and Series to matplotlib.table . With arguments `ax`, `data`, `**kwargs`, `colLabels`.", "question_id": 13996},
{"snippet": "pandas.plotting.table(ax, data, **kwargs, rowLabels=None, colLabels=None)", "intent": "Helper function to convert DataFrame and Series to matplotlib.table . With arguments `ax`, `data`, `**kwargs`, `rowLabels`, `colLabels`.", "question_id": 13997},
{"snippet": "pandas.qcut(x, q)", "intent": "Quantile-based discretization function . With arguments `x`, `q`.", "question_id": 13998},
{"snippet": "pandas.qcut(x, q, labels=None)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `labels`.", "question_id": 13999},
{"snippet": "pandas.qcut(x, q, retbins=False)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `retbins`.", "question_id": 14000},
{"snippet": "pandas.qcut(x, q, precision=3)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `precision`.", "question_id": 14001},
{"snippet": "pandas.qcut(x, q, duplicates='raise')", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `duplicates`.", "question_id": 14002},
{"snippet": "pandas.qcut(x, q, labels=None, retbins=False)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `labels`, `retbins`.", "question_id": 14003},
{"snippet": "pandas.qcut(x, q, labels=None, precision=3)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `labels`, `precision`.", "question_id": 14004},
{"snippet": "pandas.qcut(x, q, labels=None, duplicates='raise')", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `labels`, `duplicates`.", "question_id": 14005},
{"snippet": "pandas.qcut(x, q, retbins=False, precision=3)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `retbins`, `precision`.", "question_id": 14006},
{"snippet": "pandas.qcut(x, q, retbins=False, duplicates='raise')", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `retbins`, `duplicates`.", "question_id": 14007},
{"snippet": "pandas.qcut(x, q)", "intent": "Quantile-based discretization function . With arguments `x`, `q`.", "question_id": 14008},
{"snippet": "pandas.qcut(x, q, labels=None)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `labels`.", "question_id": 14009},
{"snippet": "pandas.qcut(x, q, retbins=False)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `retbins`.", "question_id": 14010},
{"snippet": "pandas.qcut(x, q, precision=3)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `precision`.", "question_id": 14011},
{"snippet": "pandas.qcut(x, q, duplicates='raise')", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `duplicates`.", "question_id": 14012},
{"snippet": "pandas.qcut(x, q, labels=None, retbins=False)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `labels`, `retbins`.", "question_id": 14013},
{"snippet": "pandas.qcut(x, q, labels=None, precision=3)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `labels`, `precision`.", "question_id": 14014},
{"snippet": "pandas.qcut(x, q, labels=None, duplicates='raise')", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `labels`, `duplicates`.", "question_id": 14015},
{"snippet": "pandas.qcut(x, q, retbins=False, precision=3)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `retbins`, `precision`.", "question_id": 14016},
{"snippet": "pandas.qcut(x, q, retbins=False, duplicates='raise')", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `retbins`, `duplicates`.", "question_id": 14017},
{"snippet": "pandas.qcut(x, q)", "intent": "Quantile-based discretization function . With arguments `x`, `q`.", "question_id": 14018},
{"snippet": "pandas.qcut(x, q, labels=None)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `labels`.", "question_id": 14019},
{"snippet": "pandas.qcut(x, q, retbins=False)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `retbins`.", "question_id": 14020},
{"snippet": "pandas.qcut(x, q, precision=3)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `precision`.", "question_id": 14021},
{"snippet": "pandas.qcut(x, q, duplicates='raise')", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `duplicates`.", "question_id": 14022},
{"snippet": "pandas.qcut(x, q, labels=None, retbins=False)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `labels`, `retbins`.", "question_id": 14023},
{"snippet": "pandas.qcut(x, q, labels=None, precision=3)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `labels`, `precision`.", "question_id": 14024},
{"snippet": "pandas.qcut(x, q, labels=None, duplicates='raise')", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `labels`, `duplicates`.", "question_id": 14025},
{"snippet": "pandas.qcut(x, q, retbins=False, precision=3)", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `retbins`, `precision`.", "question_id": 14026},
{"snippet": "pandas.qcut(x, q, retbins=False, duplicates='raise')", "intent": "Quantile-based discretization function . With arguments `x`, `q`, `retbins`, `duplicates`.", "question_id": 14027},
{"snippet": "pandas.read_clipboard(**kwargs)", "intent": "Read text from clipboard and pass to read_csv . With arguments `**kwargs`.", "question_id": 14028},
{"snippet": "pandas.read_clipboard(**kwargs, sep='\\\\s+')", "intent": "Read text from clipboard and pass to read_csv . With arguments `**kwargs`, `sep`.", "question_id": 14029},
{"snippet": "pandas.read_clipboard(**kwargs)", "intent": "Read text from clipboard and pass to read_csv . With arguments `**kwargs`.", "question_id": 14030},
{"snippet": "pandas.read_clipboard(**kwargs, sep='\\\\s+')", "intent": "Read text from clipboard and pass to read_csv . With arguments `**kwargs`, `sep`.", "question_id": 14031},
{"snippet": "pandas.read_clipboard(**kwargs)", "intent": "Read text from clipboard and pass to read_csv . With arguments `**kwargs`.", "question_id": 14032},
{"snippet": "pandas.read_clipboard(**kwargs, sep='\\\\s+')", "intent": "Read text from clipboard and pass to read_csv . With arguments `**kwargs`, `sep`.", "question_id": 14033},
{"snippet": "pandas.read_csv(filepath_or_buffer)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`.", "question_id": 14034},
{"snippet": "pandas.read_csv(filepath_or_buffer, sep=NoDefault.no_default)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `sep`.", "question_id": 14035},
{"snippet": "pandas.read_csv(filepath_or_buffer, delimiter=None)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `delimiter`.", "question_id": 14036},
{"snippet": "pandas.read_csv(filepath_or_buffer, header='infer')", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `header`.", "question_id": 14037},
{"snippet": "pandas.read_csv(filepath_or_buffer, names=NoDefault.no_default)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `names`.", "question_id": 14038},
{"snippet": "pandas.read_csv(filepath_or_buffer, index_col=None)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `index_col`.", "question_id": 14039},
{"snippet": "pandas.read_csv(filepath_or_buffer, usecols=None)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `usecols`.", "question_id": 14040},
{"snippet": "pandas.read_csv(filepath_or_buffer, squeeze=False)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `squeeze`.", "question_id": 14041},
{"snippet": "pandas.read_csv(filepath_or_buffer, prefix=NoDefault.no_default)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `prefix`.", "question_id": 14042},
{"snippet": "pandas.read_csv(filepath_or_buffer, mangle_dupe_cols=True)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `mangle_dupe_cols`.", "question_id": 14043},
{"snippet": "pandas.read_csv(filepath_or_buffer)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`.", "question_id": 14044},
{"snippet": "pandas.read_csv(filepath_or_buffer, sep=NoDefault.no_default)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `sep`.", "question_id": 14045},
{"snippet": "pandas.read_csv(filepath_or_buffer, delimiter=None)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `delimiter`.", "question_id": 14046},
{"snippet": "pandas.read_csv(filepath_or_buffer, header='infer')", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `header`.", "question_id": 14047},
{"snippet": "pandas.read_csv(filepath_or_buffer, names=NoDefault.no_default)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `names`.", "question_id": 14048},
{"snippet": "pandas.read_csv(filepath_or_buffer, index_col=None)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `index_col`.", "question_id": 14049},
{"snippet": "pandas.read_csv(filepath_or_buffer, usecols=None)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `usecols`.", "question_id": 14050},
{"snippet": "pandas.read_csv(filepath_or_buffer, squeeze=False)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `squeeze`.", "question_id": 14051},
{"snippet": "pandas.read_csv(filepath_or_buffer, prefix=NoDefault.no_default)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `prefix`.", "question_id": 14052},
{"snippet": "pandas.read_csv(filepath_or_buffer, mangle_dupe_cols=True)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `mangle_dupe_cols`.", "question_id": 14053},
{"snippet": "pandas.read_csv(filepath_or_buffer)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`.", "question_id": 14054},
{"snippet": "pandas.read_csv(filepath_or_buffer, sep=NoDefault.no_default)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `sep`.", "question_id": 14055},
{"snippet": "pandas.read_csv(filepath_or_buffer, delimiter=None)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `delimiter`.", "question_id": 14056},
{"snippet": "pandas.read_csv(filepath_or_buffer, header='infer')", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `header`.", "question_id": 14057},
{"snippet": "pandas.read_csv(filepath_or_buffer, names=NoDefault.no_default)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `names`.", "question_id": 14058},
{"snippet": "pandas.read_csv(filepath_or_buffer, index_col=None)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `index_col`.", "question_id": 14059},
{"snippet": "pandas.read_csv(filepath_or_buffer, usecols=None)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `usecols`.", "question_id": 14060},
{"snippet": "pandas.read_csv(filepath_or_buffer, squeeze=False)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `squeeze`.", "question_id": 14061},
{"snippet": "pandas.read_csv(filepath_or_buffer, prefix=NoDefault.no_default)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `prefix`.", "question_id": 14062},
{"snippet": "pandas.read_csv(filepath_or_buffer, mangle_dupe_cols=True)", "intent": "Read a comma-separated values ( csv ) file into DataFrame . With arguments `filepath_or_buffer`, `mangle_dupe_cols`.", "question_id": 14063},
{"snippet": "pandas.read_excel(io)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`.", "question_id": 14064},
{"snippet": "pandas.read_excel(io, sheet_name=0)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `sheet_name`.", "question_id": 14065},
{"snippet": "pandas.read_excel(io, header=0)", "intent": "Read an Excel file into a pandas DataFrame . Index and `header` can be specified via the `index_col` and header arguments With arguments `io`.", "question_id": 14066},
{"snippet": "pandas.read_excel(io, names=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `names`.", "question_id": 14067},
{"snippet": "pandas.read_excel(io, index_col=None)", "intent": "Read an Excel file into a pandas DataFrame . Index and `header` can be specified via the `index_col` and header arguments With arguments `io`.", "question_id": 14068},
{"snippet": "pandas.read_excel(io, usecols=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `usecols`.", "question_id": 14069},
{"snippet": "pandas.read_excel(io, squeeze=False)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `squeeze`.", "question_id": 14070},
{"snippet": "pandas.read_excel(io, dtype=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `dtype`.", "question_id": 14071},
{"snippet": "pandas.read_excel(io, engine=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `engine`.", "question_id": 14072},
{"snippet": "pandas.read_excel(io, converters=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `converters`.", "question_id": 14073},
{"snippet": "pandas.read_excel(io)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`.", "question_id": 14074},
{"snippet": "pandas.read_excel(io, sheet_name=0)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `sheet_name`.", "question_id": 14075},
{"snippet": "pandas.read_excel(io, header=0)", "intent": "Read an Excel file into a pandas DataFrame . Index and `header` can be specified via the `index_col` and header arguments With arguments `io`.", "question_id": 14076},
{"snippet": "pandas.read_excel(io, names=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `names`.", "question_id": 14077},
{"snippet": "pandas.read_excel(io, index_col=None)", "intent": "Read an Excel file into a pandas DataFrame . Index and `header` can be specified via the `index_col` and header arguments With arguments `io`.", "question_id": 14078},
{"snippet": "pandas.read_excel(io, usecols=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `usecols`.", "question_id": 14079},
{"snippet": "pandas.read_excel(io, squeeze=False)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `squeeze`.", "question_id": 14080},
{"snippet": "pandas.read_excel(io, dtype=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `dtype`.", "question_id": 14081},
{"snippet": "pandas.read_excel(io, engine=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `engine`.", "question_id": 14082},
{"snippet": "pandas.read_excel(io, converters=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `converters`.", "question_id": 14083},
{"snippet": "pandas.read_excel(io)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`.", "question_id": 14084},
{"snippet": "pandas.read_excel(io, sheet_name=0)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `sheet_name`.", "question_id": 14085},
{"snippet": "pandas.read_excel(io, header=0)", "intent": "Read an Excel file into a pandas DataFrame . Index and `header` can be specified via the `index_col` and header arguments With arguments `io`.", "question_id": 14086},
{"snippet": "pandas.read_excel(io, names=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `names`.", "question_id": 14087},
{"snippet": "pandas.read_excel(io, index_col=None)", "intent": "Read an Excel file into a pandas DataFrame . Index and `header` can be specified via the `index_col` and header arguments With arguments `io`.", "question_id": 14088},
{"snippet": "pandas.read_excel(io, usecols=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `usecols`.", "question_id": 14089},
{"snippet": "pandas.read_excel(io, squeeze=False)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `squeeze`.", "question_id": 14090},
{"snippet": "pandas.read_excel(io, dtype=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `dtype`.", "question_id": 14091},
{"snippet": "pandas.read_excel(io, engine=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `engine`.", "question_id": 14092},
{"snippet": "pandas.read_excel(io, converters=None)", "intent": "Read an Excel file into a pandas DataFrame . With arguments `io`, `converters`.", "question_id": 14093},
{"snippet": "pandas.read_feather(path)", "intent": "Load a feather-format object from the file `path` .", "question_id": 14094},
{"snippet": "pandas.read_feather(path, columns=None)", "intent": "Load a feather-format object from the file `path` . With arguments `columns`.", "question_id": 14095},
{"snippet": "pandas.read_feather(path, use_threads=True)", "intent": "Load a feather-format object from the file `path` . With arguments `use_threads`.", "question_id": 14096},
{"snippet": "pandas.read_feather(path, storage_options=None)", "intent": "Load a feather-format object from the file `path` . With arguments `storage_options`.", "question_id": 14097},
{"snippet": "pandas.read_feather(path, columns=None, use_threads=True)", "intent": "Load a feather-format object from the file `path` . With arguments `columns`, `use_threads`.", "question_id": 14098},
{"snippet": "pandas.read_feather(path, columns=None, storage_options=None)", "intent": "Load a feather-format object from the file `path` . With arguments `columns`, `storage_options`.", "question_id": 14099},
{"snippet": "pandas.read_feather(path, use_threads=True, storage_options=None)", "intent": "Load a feather-format object from the file `path` . With arguments `use_threads`, `storage_options`.", "question_id": 14100},
{"snippet": "pandas.read_feather(path, columns=None, use_threads=True, storage_options=None)", "intent": "Load a feather-format object from the file `path` . With arguments `columns`, `use_threads`, `storage_options`.", "question_id": 14101},
{"snippet": "pandas.read_feather(path)", "intent": "Load a feather-format object from the file `path` .", "question_id": 14102},
{"snippet": "pandas.read_feather(path, columns=None)", "intent": "Load a feather-format object from the file `path` . With arguments `columns`.", "question_id": 14103},
{"snippet": "pandas.read_feather(path, use_threads=True)", "intent": "Load a feather-format object from the file `path` . With arguments `use_threads`.", "question_id": 14104},
{"snippet": "pandas.read_feather(path, storage_options=None)", "intent": "Load a feather-format object from the file `path` . With arguments `storage_options`.", "question_id": 14105},
{"snippet": "pandas.read_feather(path, columns=None, use_threads=True)", "intent": "Load a feather-format object from the file `path` . With arguments `columns`, `use_threads`.", "question_id": 14106},
{"snippet": "pandas.read_feather(path, columns=None, storage_options=None)", "intent": "Load a feather-format object from the file `path` . With arguments `columns`, `storage_options`.", "question_id": 14107},
{"snippet": "pandas.read_feather(path, use_threads=True, storage_options=None)", "intent": "Load a feather-format object from the file `path` . With arguments `use_threads`, `storage_options`.", "question_id": 14108},
{"snippet": "pandas.read_feather(path, columns=None, use_threads=True, storage_options=None)", "intent": "Load a feather-format object from the file `path` . With arguments `columns`, `use_threads`, `storage_options`.", "question_id": 14109},
{"snippet": "pandas.read_feather(path)", "intent": "Load a feather-format object from the file `path` .", "question_id": 14110},
{"snippet": "pandas.read_feather(path, columns=None)", "intent": "Load a feather-format object from the file `path` . With arguments `columns`.", "question_id": 14111},
{"snippet": "pandas.read_feather(path, use_threads=True)", "intent": "Load a feather-format object from the file `path` . With arguments `use_threads`.", "question_id": 14112},
{"snippet": "pandas.read_feather(path, storage_options=None)", "intent": "Load a feather-format object from the file `path` . With arguments `storage_options`.", "question_id": 14113},
{"snippet": "pandas.read_feather(path, columns=None, use_threads=True)", "intent": "Load a feather-format object from the file `path` . With arguments `columns`, `use_threads`.", "question_id": 14114},
{"snippet": "pandas.read_feather(path, columns=None, storage_options=None)", "intent": "Load a feather-format object from the file `path` . With arguments `columns`, `storage_options`.", "question_id": 14115},
{"snippet": "pandas.read_feather(path, use_threads=True, storage_options=None)", "intent": "Load a feather-format object from the file `path` . With arguments `use_threads`, `storage_options`.", "question_id": 14116},
{"snippet": "pandas.read_feather(path, columns=None, use_threads=True, storage_options=None)", "intent": "Load a feather-format object from the file `path` . With arguments `columns`, `use_threads`, `storage_options`.", "question_id": 14117},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`.", "question_id": 14118},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, colspecs='infer')", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `colspecs`.", "question_id": 14119},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, widths=None)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `widths`.", "question_id": 14120},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, infer_nrows=100)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `infer_nrows`.", "question_id": 14121},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, colspecs='infer', widths=None)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `colspecs`, `widths`.", "question_id": 14122},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, colspecs='infer', infer_nrows=100)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `colspecs`, `infer_nrows`.", "question_id": 14123},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, widths=None, infer_nrows=100)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `widths`, `infer_nrows`.", "question_id": 14124},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, colspecs='infer', widths=None, infer_nrows=100)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `colspecs`, `widths`, `infer_nrows`.", "question_id": 14125},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`.", "question_id": 14126},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, colspecs='infer')", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `colspecs`.", "question_id": 14127},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, widths=None)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `widths`.", "question_id": 14128},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, infer_nrows=100)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `infer_nrows`.", "question_id": 14129},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, colspecs='infer', widths=None)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `colspecs`, `widths`.", "question_id": 14130},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, colspecs='infer', infer_nrows=100)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `colspecs`, `infer_nrows`.", "question_id": 14131},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, widths=None, infer_nrows=100)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `widths`, `infer_nrows`.", "question_id": 14132},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, colspecs='infer', widths=None, infer_nrows=100)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `colspecs`, `widths`, `infer_nrows`.", "question_id": 14133},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`.", "question_id": 14134},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, colspecs='infer')", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `colspecs`.", "question_id": 14135},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, widths=None)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `widths`.", "question_id": 14136},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, infer_nrows=100)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `infer_nrows`.", "question_id": 14137},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, colspecs='infer', widths=None)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `colspecs`, `widths`.", "question_id": 14138},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, colspecs='infer', infer_nrows=100)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `colspecs`, `infer_nrows`.", "question_id": 14139},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, widths=None, infer_nrows=100)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `widths`, `infer_nrows`.", "question_id": 14140},
{"snippet": "pandas.read_fwf(filepath_or_buffer, **kwds, colspecs='infer', widths=None, infer_nrows=100)", "intent": "Read a table of fixed-width formatted lines into DataFrame . With arguments `filepath_or_buffer`, `**kwds`, `colspecs`, `widths`, `infer_nrows`.", "question_id": 14141},
{"snippet": "pandas.read_gbq(query)", "intent": "Load data from Google BigQuery . With arguments `query`.", "question_id": 14142},
{"snippet": "pandas.read_gbq(query, project_id=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `project_id`.", "question_id": 14143},
{"snippet": "pandas.read_gbq(query, index_col=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `index_col`.", "question_id": 14144},
{"snippet": "pandas.read_gbq(query, col_order=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `col_order`.", "question_id": 14145},
{"snippet": "pandas.read_gbq(query, reauth=False)", "intent": "Load data from Google BigQuery . With arguments `query`, `reauth`.", "question_id": 14146},
{"snippet": "pandas.read_gbq(query, auth_local_webserver=False)", "intent": "Load data from Google BigQuery . With arguments `query`, `auth_local_webserver`.", "question_id": 14147},
{"snippet": "pandas.read_gbq(query, dialect=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `dialect`.", "question_id": 14148},
{"snippet": "pandas.read_gbq(query, location=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `location`.", "question_id": 14149},
{"snippet": "pandas.read_gbq(query, configuration=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `configuration`.", "question_id": 14150},
{"snippet": "pandas.read_gbq(query, credentials=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `credentials`.", "question_id": 14151},
{"snippet": "pandas.read_gbq(query)", "intent": "Load data from Google BigQuery . With arguments `query`.", "question_id": 14152},
{"snippet": "pandas.read_gbq(query, project_id=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `project_id`.", "question_id": 14153},
{"snippet": "pandas.read_gbq(query, index_col=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `index_col`.", "question_id": 14154},
{"snippet": "pandas.read_gbq(query, col_order=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `col_order`.", "question_id": 14155},
{"snippet": "pandas.read_gbq(query, reauth=False)", "intent": "Load data from Google BigQuery . With arguments `query`, `reauth`.", "question_id": 14156},
{"snippet": "pandas.read_gbq(query, auth_local_webserver=False)", "intent": "Load data from Google BigQuery . With arguments `query`, `auth_local_webserver`.", "question_id": 14157},
{"snippet": "pandas.read_gbq(query, dialect=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `dialect`.", "question_id": 14158},
{"snippet": "pandas.read_gbq(query, location=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `location`.", "question_id": 14159},
{"snippet": "pandas.read_gbq(query, configuration=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `configuration`.", "question_id": 14160},
{"snippet": "pandas.read_gbq(query, credentials=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `credentials`.", "question_id": 14161},
{"snippet": "pandas.read_gbq(query)", "intent": "Load data from Google BigQuery . With arguments `query`.", "question_id": 14162},
{"snippet": "pandas.read_gbq(query, project_id=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `project_id`.", "question_id": 14163},
{"snippet": "pandas.read_gbq(query, index_col=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `index_col`.", "question_id": 14164},
{"snippet": "pandas.read_gbq(query, col_order=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `col_order`.", "question_id": 14165},
{"snippet": "pandas.read_gbq(query, reauth=False)", "intent": "Load data from Google BigQuery . With arguments `query`, `reauth`.", "question_id": 14166},
{"snippet": "pandas.read_gbq(query, auth_local_webserver=False)", "intent": "Load data from Google BigQuery . With arguments `query`, `auth_local_webserver`.", "question_id": 14167},
{"snippet": "pandas.read_gbq(query, dialect=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `dialect`.", "question_id": 14168},
{"snippet": "pandas.read_gbq(query, location=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `location`.", "question_id": 14169},
{"snippet": "pandas.read_gbq(query, configuration=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `configuration`.", "question_id": 14170},
{"snippet": "pandas.read_gbq(query, credentials=None)", "intent": "Load data from Google BigQuery . With arguments `query`, `credentials`.", "question_id": 14171},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`.", "question_id": 14172},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, key=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `key`.", "question_id": 14173},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, mode='r')", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `mode`.", "question_id": 14174},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, errors='strict')", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `errors`.", "question_id": 14175},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, where=None)", "intent": "Read from the store , close it if we opened it . Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `path_or_buf`, `**kwargs`.", "question_id": 14176},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, start=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `start`.", "question_id": 14177},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, stop=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `stop`.", "question_id": 14178},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, columns=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `columns`.", "question_id": 14179},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, iterator=False)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `iterator`.", "question_id": 14180},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, chunksize=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `chunksize`.", "question_id": 14181},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`.", "question_id": 14182},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, key=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `key`.", "question_id": 14183},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, mode='r')", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `mode`.", "question_id": 14184},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, errors='strict')", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `errors`.", "question_id": 14185},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, where=None)", "intent": "Read from the store , close it if we opened it . Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `path_or_buf`, `**kwargs`.", "question_id": 14186},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, start=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `start`.", "question_id": 14187},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, stop=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `stop`.", "question_id": 14188},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, columns=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `columns`.", "question_id": 14189},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, iterator=False)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `iterator`.", "question_id": 14190},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, chunksize=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `chunksize`.", "question_id": 14191},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`.", "question_id": 14192},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, key=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `key`.", "question_id": 14193},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, mode='r')", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `mode`.", "question_id": 14194},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, errors='strict')", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `errors`.", "question_id": 14195},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, where=None)", "intent": "Read from the store , close it if we opened it . Retrieve pandas object stored in file , optionally based on `where` criteria . With arguments `path_or_buf`, `**kwargs`.", "question_id": 14196},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, start=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `start`.", "question_id": 14197},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, stop=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `stop`.", "question_id": 14198},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, columns=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `columns`.", "question_id": 14199},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, iterator=False)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `iterator`.", "question_id": 14200},
{"snippet": "pandas.read_hdf(path_or_buf, **kwargs, chunksize=None)", "intent": "Read from the store , close it if we opened it . With arguments `path_or_buf`, `**kwargs`, `chunksize`.", "question_id": 14201},
{"snippet": "pandas.read_html(io)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`.", "question_id": 14202},
{"snippet": "pandas.read_html(io, match='.+')", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `match`.", "question_id": 14203},
{"snippet": "pandas.read_html(io, flavor=None)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `flavor`.", "question_id": 14204},
{"snippet": "pandas.read_html(io, header=None)", "intent": "Read HTML tables into a list of DataFrame objects . If the function has a < thead > argument , it is used to construct the `header` , otherwise the function attempts to find the header within the body ( by putting rows with only < th > elements into the header ) . With arguments `io`.", "question_id": 14205},
{"snippet": "pandas.read_html(io, index_col=None)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `index_col`.", "question_id": 14206},
{"snippet": "pandas.read_html(io, skiprows=None)", "intent": "Read HTML tables into a list of DataFrame objects . Similar to read_csv ( ) the header argument is applied after `skiprows` is applied . With arguments `io`.", "question_id": 14207},
{"snippet": "pandas.read_html(io, attrs=None)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `attrs`.", "question_id": 14208},
{"snippet": "pandas.read_html(io, parse_dates=False)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `parse_dates`.", "question_id": 14209},
{"snippet": "pandas.read_html(io, thousands=',')", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `thousands`.", "question_id": 14210},
{"snippet": "pandas.read_html(io, encoding=None)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `encoding`.", "question_id": 14211},
{"snippet": "pandas.read_html(io)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`.", "question_id": 14212},
{"snippet": "pandas.read_html(io, match='.+')", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `match`.", "question_id": 14213},
{"snippet": "pandas.read_html(io, flavor=None)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `flavor`.", "question_id": 14214},
{"snippet": "pandas.read_html(io, header=None)", "intent": "Read HTML tables into a list of DataFrame objects . If the function has a < thead > argument , it is used to construct the `header` , otherwise the function attempts to find the header within the body ( by putting rows with only < th > elements into the header ) . With arguments `io`.", "question_id": 14215},
{"snippet": "pandas.read_html(io, index_col=None)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `index_col`.", "question_id": 14216},
{"snippet": "pandas.read_html(io, skiprows=None)", "intent": "Read HTML tables into a list of DataFrame objects . Similar to read_csv ( ) the header argument is applied after `skiprows` is applied . With arguments `io`.", "question_id": 14217},
{"snippet": "pandas.read_html(io, attrs=None)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `attrs`.", "question_id": 14218},
{"snippet": "pandas.read_html(io, parse_dates=False)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `parse_dates`.", "question_id": 14219},
{"snippet": "pandas.read_html(io, thousands=',')", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `thousands`.", "question_id": 14220},
{"snippet": "pandas.read_html(io, encoding=None)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `encoding`.", "question_id": 14221},
{"snippet": "pandas.read_html(io)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`.", "question_id": 14222},
{"snippet": "pandas.read_html(io, match='.+')", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `match`.", "question_id": 14223},
{"snippet": "pandas.read_html(io, flavor=None)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `flavor`.", "question_id": 14224},
{"snippet": "pandas.read_html(io, header=None)", "intent": "Read HTML tables into a list of DataFrame objects . If the function has a < thead > argument , it is used to construct the `header` , otherwise the function attempts to find the header within the body ( by putting rows with only < th > elements into the header ) . With arguments `io`.", "question_id": 14225},
{"snippet": "pandas.read_html(io, index_col=None)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `index_col`.", "question_id": 14226},
{"snippet": "pandas.read_html(io, skiprows=None)", "intent": "Read HTML tables into a list of DataFrame objects . Similar to read_csv ( ) the header argument is applied after `skiprows` is applied . With arguments `io`.", "question_id": 14227},
{"snippet": "pandas.read_html(io, attrs=None)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `attrs`.", "question_id": 14228},
{"snippet": "pandas.read_html(io, parse_dates=False)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `parse_dates`.", "question_id": 14229},
{"snippet": "pandas.read_html(io, thousands=',')", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `thousands`.", "question_id": 14230},
{"snippet": "pandas.read_html(io, encoding=None)", "intent": "Read HTML tables into a list of DataFrame objects . With arguments `io`, `encoding`.", "question_id": 14231},
{"snippet": "pandas.read_orc(path, **kwargs)", "intent": "Load an ORC object from the file `path` , returning a DataFrame . With arguments `**kwargs`.", "question_id": 14232},
{"snippet": "pandas.read_orc(path, **kwargs, columns=None)", "intent": "Load an ORC object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `columns`.", "question_id": 14233},
{"snippet": "pandas.read_orc(path, **kwargs)", "intent": "Load an ORC object from the file `path` , returning a DataFrame . With arguments `**kwargs`.", "question_id": 14234},
{"snippet": "pandas.read_orc(path, **kwargs, columns=None)", "intent": "Load an ORC object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `columns`.", "question_id": 14235},
{"snippet": "pandas.read_orc(path, **kwargs)", "intent": "Load an ORC object from the file `path` , returning a DataFrame . With arguments `**kwargs`.", "question_id": 14236},
{"snippet": "pandas.read_orc(path, **kwargs, columns=None)", "intent": "Load an ORC object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `columns`.", "question_id": 14237},
{"snippet": "pandas.read_parquet(path, **kwargs)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`.", "question_id": 14238},
{"snippet": "pandas.read_parquet(path, **kwargs, engine='auto')", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `engine`.", "question_id": 14239},
{"snippet": "pandas.read_parquet(path, **kwargs, columns=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `columns`.", "question_id": 14240},
{"snippet": "pandas.read_parquet(path, **kwargs, storage_options=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `storage_options`.", "question_id": 14241},
{"snippet": "pandas.read_parquet(path, **kwargs, use_nullable_dtypes=False)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `use_nullable_dtypes`.", "question_id": 14242},
{"snippet": "pandas.read_parquet(path, **kwargs, engine='auto', columns=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `engine`, `columns`.", "question_id": 14243},
{"snippet": "pandas.read_parquet(path, **kwargs, engine='auto', storage_options=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `engine`, `storage_options`.", "question_id": 14244},
{"snippet": "pandas.read_parquet(path, **kwargs, engine='auto', use_nullable_dtypes=False)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `engine`, `use_nullable_dtypes`.", "question_id": 14245},
{"snippet": "pandas.read_parquet(path, **kwargs, columns=None, storage_options=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `columns`, `storage_options`.", "question_id": 14246},
{"snippet": "pandas.read_parquet(path, **kwargs, columns=None, use_nullable_dtypes=False)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `columns`, `use_nullable_dtypes`.", "question_id": 14247},
{"snippet": "pandas.read_parquet(path, **kwargs)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`.", "question_id": 14248},
{"snippet": "pandas.read_parquet(path, **kwargs, engine='auto')", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `engine`.", "question_id": 14249},
{"snippet": "pandas.read_parquet(path, **kwargs, columns=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `columns`.", "question_id": 14250},
{"snippet": "pandas.read_parquet(path, **kwargs, storage_options=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `storage_options`.", "question_id": 14251},
{"snippet": "pandas.read_parquet(path, **kwargs, use_nullable_dtypes=False)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `use_nullable_dtypes`.", "question_id": 14252},
{"snippet": "pandas.read_parquet(path, **kwargs, engine='auto', columns=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `engine`, `columns`.", "question_id": 14253},
{"snippet": "pandas.read_parquet(path, **kwargs, engine='auto', storage_options=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `engine`, `storage_options`.", "question_id": 14254},
{"snippet": "pandas.read_parquet(path, **kwargs, engine='auto', use_nullable_dtypes=False)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `engine`, `use_nullable_dtypes`.", "question_id": 14255},
{"snippet": "pandas.read_parquet(path, **kwargs, columns=None, storage_options=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `columns`, `storage_options`.", "question_id": 14256},
{"snippet": "pandas.read_parquet(path, **kwargs, columns=None, use_nullable_dtypes=False)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `columns`, `use_nullable_dtypes`.", "question_id": 14257},
{"snippet": "pandas.read_parquet(path, **kwargs)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`.", "question_id": 14258},
{"snippet": "pandas.read_parquet(path, **kwargs, engine='auto')", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `engine`.", "question_id": 14259},
{"snippet": "pandas.read_parquet(path, **kwargs, columns=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `columns`.", "question_id": 14260},
{"snippet": "pandas.read_parquet(path, **kwargs, storage_options=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `storage_options`.", "question_id": 14261},
{"snippet": "pandas.read_parquet(path, **kwargs, use_nullable_dtypes=False)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `use_nullable_dtypes`.", "question_id": 14262},
{"snippet": "pandas.read_parquet(path, **kwargs, engine='auto', columns=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `engine`, `columns`.", "question_id": 14263},
{"snippet": "pandas.read_parquet(path, **kwargs, engine='auto', storage_options=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `engine`, `storage_options`.", "question_id": 14264},
{"snippet": "pandas.read_parquet(path, **kwargs, engine='auto', use_nullable_dtypes=False)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `engine`, `use_nullable_dtypes`.", "question_id": 14265},
{"snippet": "pandas.read_parquet(path, **kwargs, columns=None, storage_options=None)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `columns`, `storage_options`.", "question_id": 14266},
{"snippet": "pandas.read_parquet(path, **kwargs, columns=None, use_nullable_dtypes=False)", "intent": "Load a parquet object from the file `path` , returning a DataFrame . With arguments `**kwargs`, `columns`, `use_nullable_dtypes`.", "question_id": 14267},
{"snippet": "pandas.read_pickle(filepath_or_buffer)", "intent": "Load pickled pandas object ( or any object ) from file . With arguments `filepath_or_buffer`.", "question_id": 14268},
{"snippet": "pandas.read_pickle(filepath_or_buffer, compression='infer')", "intent": "Load pickled pandas object ( or any object ) from file . With arguments `filepath_or_buffer`, `compression`.", "question_id": 14269},
{"snippet": "pandas.read_pickle(filepath_or_buffer, storage_options=None)", "intent": "Load pickled pandas object ( or any object ) from file . With arguments `filepath_or_buffer`, `storage_options`.", "question_id": 14270},
{"snippet": "pandas.read_pickle(filepath_or_buffer, compression='infer', storage_options=None)", "intent": "Load pickled pandas object ( or any object ) from file . With arguments `filepath_or_buffer`, `compression`, `storage_options`.", "question_id": 14271},
{"snippet": "pandas.read_pickle(filepath_or_buffer)", "intent": "Load pickled pandas object ( or any object ) from file . With arguments `filepath_or_buffer`.", "question_id": 14272},
{"snippet": "pandas.read_pickle(filepath_or_buffer, compression='infer')", "intent": "Load pickled pandas object ( or any object ) from file . With arguments `filepath_or_buffer`, `compression`.", "question_id": 14273},
{"snippet": "pandas.read_pickle(filepath_or_buffer, storage_options=None)", "intent": "Load pickled pandas object ( or any object ) from file . With arguments `filepath_or_buffer`, `storage_options`.", "question_id": 14274},
{"snippet": "pandas.read_pickle(filepath_or_buffer, compression='infer', storage_options=None)", "intent": "Load pickled pandas object ( or any object ) from file . With arguments `filepath_or_buffer`, `compression`, `storage_options`.", "question_id": 14275},
{"snippet": "pandas.read_pickle(filepath_or_buffer)", "intent": "Load pickled pandas object ( or any object ) from file . With arguments `filepath_or_buffer`.", "question_id": 14276},
{"snippet": "pandas.read_pickle(filepath_or_buffer, compression='infer')", "intent": "Load pickled pandas object ( or any object ) from file . With arguments `filepath_or_buffer`, `compression`.", "question_id": 14277},
{"snippet": "pandas.read_pickle(filepath_or_buffer, storage_options=None)", "intent": "Load pickled pandas object ( or any object ) from file . With arguments `filepath_or_buffer`, `storage_options`.", "question_id": 14278},
{"snippet": "pandas.read_pickle(filepath_or_buffer, compression='infer', storage_options=None)", "intent": "Load pickled pandas object ( or any object ) from file . With arguments `filepath_or_buffer`, `compression`, `storage_options`.", "question_id": 14279},
{"snippet": "pandas.read_sas(filepath_or_buffer)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`.", "question_id": 14280},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`.", "question_id": 14281},
{"snippet": "pandas.read_sas(filepath_or_buffer, index=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `index`.", "question_id": 14282},
{"snippet": "pandas.read_sas(filepath_or_buffer, encoding=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `encoding`.", "question_id": 14283},
{"snippet": "pandas.read_sas(filepath_or_buffer, chunksize=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `chunksize`.", "question_id": 14284},
{"snippet": "pandas.read_sas(filepath_or_buffer, iterator=False)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `iterator`.", "question_id": 14285},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None, index=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `index`.", "question_id": 14286},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None, encoding=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `encoding`.", "question_id": 14287},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None, chunksize=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `chunksize`.", "question_id": 14288},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None, iterator=False)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `iterator`.", "question_id": 14289},
{"snippet": "pandas.read_sas(filepath_or_buffer)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`.", "question_id": 14290},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`.", "question_id": 14291},
{"snippet": "pandas.read_sas(filepath_or_buffer, index=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `index`.", "question_id": 14292},
{"snippet": "pandas.read_sas(filepath_or_buffer, encoding=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `encoding`.", "question_id": 14293},
{"snippet": "pandas.read_sas(filepath_or_buffer, chunksize=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `chunksize`.", "question_id": 14294},
{"snippet": "pandas.read_sas(filepath_or_buffer, iterator=False)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `iterator`.", "question_id": 14295},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None, index=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `index`.", "question_id": 14296},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None, encoding=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `encoding`.", "question_id": 14297},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None, chunksize=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `chunksize`.", "question_id": 14298},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None, iterator=False)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `iterator`.", "question_id": 14299},
{"snippet": "pandas.read_sas(filepath_or_buffer)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`.", "question_id": 14300},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`.", "question_id": 14301},
{"snippet": "pandas.read_sas(filepath_or_buffer, index=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `index`.", "question_id": 14302},
{"snippet": "pandas.read_sas(filepath_or_buffer, encoding=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `encoding`.", "question_id": 14303},
{"snippet": "pandas.read_sas(filepath_or_buffer, chunksize=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `chunksize`.", "question_id": 14304},
{"snippet": "pandas.read_sas(filepath_or_buffer, iterator=False)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `iterator`.", "question_id": 14305},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None, index=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `index`.", "question_id": 14306},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None, encoding=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `encoding`.", "question_id": 14307},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None, chunksize=None)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `chunksize`.", "question_id": 14308},
{"snippet": "pandas.read_sas(filepath_or_buffer, format=None, iterator=False)", "intent": "Read SAS files stored as either XPORT or SAS7BDAT `format` files . With arguments `filepath_or_buffer`, `iterator`.", "question_id": 14309},
{"snippet": "pandas.read_spss(path)", "intent": "Load an SPSS file from the file `path` , returning a DataFrame .", "question_id": 14310},
{"snippet": "pandas.read_spss(path, usecols=None)", "intent": "Load an SPSS file from the file `path` , returning a DataFrame . With arguments `usecols`.", "question_id": 14311},
{"snippet": "pandas.read_spss(path, convert_categoricals=True)", "intent": "Load an SPSS file from the file `path` , returning a DataFrame . With arguments `convert_categoricals`.", "question_id": 14312},
{"snippet": "pandas.read_spss(path, usecols=None, convert_categoricals=True)", "intent": "Load an SPSS file from the file `path` , returning a DataFrame . With arguments `usecols`, `convert_categoricals`.", "question_id": 14313},
{"snippet": "pandas.read_spss(path)", "intent": "Load an SPSS file from the file `path` , returning a DataFrame .", "question_id": 14314},
{"snippet": "pandas.read_spss(path, usecols=None)", "intent": "Load an SPSS file from the file `path` , returning a DataFrame . With arguments `usecols`.", "question_id": 14315},
{"snippet": "pandas.read_spss(path, convert_categoricals=True)", "intent": "Load an SPSS file from the file `path` , returning a DataFrame . With arguments `convert_categoricals`.", "question_id": 14316},
{"snippet": "pandas.read_spss(path, usecols=None, convert_categoricals=True)", "intent": "Load an SPSS file from the file `path` , returning a DataFrame . With arguments `usecols`, `convert_categoricals`.", "question_id": 14317},
{"snippet": "pandas.read_spss(path)", "intent": "Load an SPSS file from the file `path` , returning a DataFrame .", "question_id": 14318},
{"snippet": "pandas.read_spss(path, usecols=None)", "intent": "Load an SPSS file from the file `path` , returning a DataFrame . With arguments `usecols`.", "question_id": 14319},
{"snippet": "pandas.read_spss(path, convert_categoricals=True)", "intent": "Load an SPSS file from the file `path` , returning a DataFrame . With arguments `convert_categoricals`.", "question_id": 14320},
{"snippet": "pandas.read_spss(path, usecols=None, convert_categoricals=True)", "intent": "Load an SPSS file from the file `path` , returning a DataFrame . With arguments `usecols`, `convert_categoricals`.", "question_id": 14321},
{"snippet": "pandas.read_sql(sql, con)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`.", "question_id": 14322},
{"snippet": "pandas.read_sql(sql, con, index_col=None)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `index_col`.", "question_id": 14323},
{"snippet": "pandas.read_sql(sql, con, coerce_float=True)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `coerce_float`.", "question_id": 14324},
{"snippet": "pandas.read_sql(sql, con, params=None)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `params`.", "question_id": 14325},
{"snippet": "pandas.read_sql(sql, con, parse_dates=None)", "intent": "Read SQL query or database table into a DataFrame . Apply date parsing to `columns` through the `parse_dates` argument With arguments `sql`, `con`.", "question_id": 14326},
{"snippet": "pandas.read_sql(sql, con, columns=None)", "intent": "Read SQL query or database table into a DataFrame . Apply date parsing to `columns` through the `parse_dates` argument With arguments `sql`, `con`.", "question_id": 14327},
{"snippet": "pandas.read_sql(sql, con, chunksize=None)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `chunksize`.", "question_id": 14328},
{"snippet": "pandas.read_sql(sql, con, index_col=None, coerce_float=True)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `index_col`, `coerce_float`.", "question_id": 14329},
{"snippet": "pandas.read_sql(sql, con, index_col=None, params=None)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `index_col`, `params`.", "question_id": 14330},
{"snippet": "pandas.read_sql(sql, con, index_col=None, parse_dates=None)", "intent": "Read SQL query or database table into a DataFrame . Apply date parsing to `columns` through the `parse_dates` argument With arguments `sql`, `con`, `index_col`.", "question_id": 14331},
{"snippet": "pandas.read_sql(sql, con)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`.", "question_id": 14332},
{"snippet": "pandas.read_sql(sql, con, index_col=None)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `index_col`.", "question_id": 14333},
{"snippet": "pandas.read_sql(sql, con, coerce_float=True)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `coerce_float`.", "question_id": 14334},
{"snippet": "pandas.read_sql(sql, con, params=None)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `params`.", "question_id": 14335},
{"snippet": "pandas.read_sql(sql, con, parse_dates=None)", "intent": "Read SQL query or database table into a DataFrame . Apply date parsing to `columns` through the `parse_dates` argument With arguments `sql`, `con`.", "question_id": 14336},
{"snippet": "pandas.read_sql(sql, con, columns=None)", "intent": "Read SQL query or database table into a DataFrame . Apply date parsing to `columns` through the `parse_dates` argument With arguments `sql`, `con`.", "question_id": 14337},
{"snippet": "pandas.read_sql(sql, con, chunksize=None)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `chunksize`.", "question_id": 14338},
{"snippet": "pandas.read_sql(sql, con, index_col=None, coerce_float=True)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `index_col`, `coerce_float`.", "question_id": 14339},
{"snippet": "pandas.read_sql(sql, con, index_col=None, params=None)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `index_col`, `params`.", "question_id": 14340},
{"snippet": "pandas.read_sql(sql, con, index_col=None, parse_dates=None)", "intent": "Read SQL query or database table into a DataFrame . Apply date parsing to `columns` through the `parse_dates` argument With arguments `sql`, `con`, `index_col`.", "question_id": 14341},
{"snippet": "pandas.read_sql(sql, con)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`.", "question_id": 14342},
{"snippet": "pandas.read_sql(sql, con, index_col=None)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `index_col`.", "question_id": 14343},
{"snippet": "pandas.read_sql(sql, con, coerce_float=True)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `coerce_float`.", "question_id": 14344},
{"snippet": "pandas.read_sql(sql, con, params=None)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `params`.", "question_id": 14345},
{"snippet": "pandas.read_sql(sql, con, parse_dates=None)", "intent": "Read SQL query or database table into a DataFrame . Apply date parsing to `columns` through the `parse_dates` argument With arguments `sql`, `con`.", "question_id": 14346},
{"snippet": "pandas.read_sql(sql, con, columns=None)", "intent": "Read SQL query or database table into a DataFrame . Apply date parsing to `columns` through the `parse_dates` argument With arguments `sql`, `con`.", "question_id": 14347},
{"snippet": "pandas.read_sql(sql, con, chunksize=None)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `chunksize`.", "question_id": 14348},
{"snippet": "pandas.read_sql(sql, con, index_col=None, coerce_float=True)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `index_col`, `coerce_float`.", "question_id": 14349},
{"snippet": "pandas.read_sql(sql, con, index_col=None, params=None)", "intent": "Read SQL query or database table into a DataFrame . With arguments `sql`, `con`, `index_col`, `params`.", "question_id": 14350},
{"snippet": "pandas.read_sql(sql, con, index_col=None, parse_dates=None)", "intent": "Read SQL query or database table into a DataFrame . Apply date parsing to `columns` through the `parse_dates` argument With arguments `sql`, `con`, `index_col`.", "question_id": 14351},
{"snippet": "pandas.read_sql_query(sql, con)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`.", "question_id": 14352},
{"snippet": "pandas.read_sql_query(sql, con, index_col=None)", "intent": "Read SQL query into a DataFrame . Optionally provide an `index_col` parameter to use one of the columns as the index , otherwise default integer index will be used . With arguments `sql`, `con`.", "question_id": 14353},
{"snippet": "pandas.read_sql_query(sql, con, coerce_float=True)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`, `coerce_float`.", "question_id": 14354},
{"snippet": "pandas.read_sql_query(sql, con, params=None)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`, `params`.", "question_id": 14355},
{"snippet": "pandas.read_sql_query(sql, con, parse_dates=None)", "intent": "Read SQL query into a DataFrame . Any datetime values with time zone information parsed via the `parse_dates` parameter will be converted to UTC . With arguments `sql`, `con`.", "question_id": 14356},
{"snippet": "pandas.read_sql_query(sql, con, chunksize=None)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`, `chunksize`.", "question_id": 14357},
{"snippet": "pandas.read_sql_query(sql, con, dtype=None)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`, `dtype`.", "question_id": 14358},
{"snippet": "pandas.read_sql_query(sql, con, index_col=None, coerce_float=True)", "intent": "Read SQL query into a DataFrame . Optionally provide an `index_col` parameter to use one of the columns as the index , otherwise default integer index will be used . With arguments `sql`, `con`, `coerce_float`.", "question_id": 14359},
{"snippet": "pandas.read_sql_query(sql, con, index_col=None, params=None)", "intent": "Read SQL query into a DataFrame . Optionally provide an `index_col` parameter to use one of the columns as the index , otherwise default integer index will be used . With arguments `sql`, `con`, `params`.", "question_id": 14360},
{"snippet": "pandas.read_sql_query(sql, con, index_col=None, parse_dates=None)", "intent": "Read SQL query into a DataFrame . Optionally provide an `index_col` parameter to use one of the columns as the index , otherwise default integer index will be used . Any datetime values with time zone information parsed via the `parse_dates` parameter will be converted to UTC . With arguments `sql`, `con`.", "question_id": 14361},
{"snippet": "pandas.read_sql_query(sql, con)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`.", "question_id": 14362},
{"snippet": "pandas.read_sql_query(sql, con, index_col=None)", "intent": "Read SQL query into a DataFrame . Optionally provide an `index_col` parameter to use one of the columns as the index , otherwise default integer index will be used . With arguments `sql`, `con`.", "question_id": 14363},
{"snippet": "pandas.read_sql_query(sql, con, coerce_float=True)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`, `coerce_float`.", "question_id": 14364},
{"snippet": "pandas.read_sql_query(sql, con, params=None)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`, `params`.", "question_id": 14365},
{"snippet": "pandas.read_sql_query(sql, con, parse_dates=None)", "intent": "Read SQL query into a DataFrame . Any datetime values with time zone information parsed via the `parse_dates` parameter will be converted to UTC . With arguments `sql`, `con`.", "question_id": 14366},
{"snippet": "pandas.read_sql_query(sql, con, chunksize=None)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`, `chunksize`.", "question_id": 14367},
{"snippet": "pandas.read_sql_query(sql, con, dtype=None)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`, `dtype`.", "question_id": 14368},
{"snippet": "pandas.read_sql_query(sql, con, index_col=None, coerce_float=True)", "intent": "Read SQL query into a DataFrame . Optionally provide an `index_col` parameter to use one of the columns as the index , otherwise default integer index will be used . With arguments `sql`, `con`, `coerce_float`.", "question_id": 14369},
{"snippet": "pandas.read_sql_query(sql, con, index_col=None, params=None)", "intent": "Read SQL query into a DataFrame . Optionally provide an `index_col` parameter to use one of the columns as the index , otherwise default integer index will be used . With arguments `sql`, `con`, `params`.", "question_id": 14370},
{"snippet": "pandas.read_sql_query(sql, con, index_col=None, parse_dates=None)", "intent": "Read SQL query into a DataFrame . Optionally provide an `index_col` parameter to use one of the columns as the index , otherwise default integer index will be used . Any datetime values with time zone information parsed via the `parse_dates` parameter will be converted to UTC . With arguments `sql`, `con`.", "question_id": 14371},
{"snippet": "pandas.read_sql_query(sql, con)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`.", "question_id": 14372},
{"snippet": "pandas.read_sql_query(sql, con, index_col=None)", "intent": "Read SQL query into a DataFrame . Optionally provide an `index_col` parameter to use one of the columns as the index , otherwise default integer index will be used . With arguments `sql`, `con`.", "question_id": 14373},
{"snippet": "pandas.read_sql_query(sql, con, coerce_float=True)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`, `coerce_float`.", "question_id": 14374},
{"snippet": "pandas.read_sql_query(sql, con, params=None)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`, `params`.", "question_id": 14375},
{"snippet": "pandas.read_sql_query(sql, con, parse_dates=None)", "intent": "Read SQL query into a DataFrame . Any datetime values with time zone information parsed via the `parse_dates` parameter will be converted to UTC . With arguments `sql`, `con`.", "question_id": 14376},
{"snippet": "pandas.read_sql_query(sql, con, chunksize=None)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`, `chunksize`.", "question_id": 14377},
{"snippet": "pandas.read_sql_query(sql, con, dtype=None)", "intent": "Read SQL query into a DataFrame . With arguments `sql`, `con`, `dtype`.", "question_id": 14378},
{"snippet": "pandas.read_sql_query(sql, con, index_col=None, coerce_float=True)", "intent": "Read SQL query into a DataFrame . Optionally provide an `index_col` parameter to use one of the columns as the index , otherwise default integer index will be used . With arguments `sql`, `con`, `coerce_float`.", "question_id": 14379},
{"snippet": "pandas.read_sql_query(sql, con, index_col=None, params=None)", "intent": "Read SQL query into a DataFrame . Optionally provide an `index_col` parameter to use one of the columns as the index , otherwise default integer index will be used . With arguments `sql`, `con`, `params`.", "question_id": 14380},
{"snippet": "pandas.read_sql_query(sql, con, index_col=None, parse_dates=None)", "intent": "Read SQL query into a DataFrame . Optionally provide an `index_col` parameter to use one of the columns as the index , otherwise default integer index will be used . Any datetime values with time zone information parsed via the `parse_dates` parameter will be converted to UTC . With arguments `sql`, `con`.", "question_id": 14381},
{"snippet": "pandas.read_sql_table(table_name, con)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`.", "question_id": 14382},
{"snippet": "pandas.read_sql_table(table_name, con, schema=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `schema`.", "question_id": 14383},
{"snippet": "pandas.read_sql_table(table_name, con, index_col=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `index_col`.", "question_id": 14384},
{"snippet": "pandas.read_sql_table(table_name, con, coerce_float=True)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `coerce_float`.", "question_id": 14385},
{"snippet": "pandas.read_sql_table(table_name, con, parse_dates=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `parse_dates`.", "question_id": 14386},
{"snippet": "pandas.read_sql_table(table_name, con, columns=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `columns`.", "question_id": 14387},
{"snippet": "pandas.read_sql_table(table_name, con, chunksize=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `chunksize`.", "question_id": 14388},
{"snippet": "pandas.read_sql_table(table_name, con, schema=None, index_col=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `schema`, `index_col`.", "question_id": 14389},
{"snippet": "pandas.read_sql_table(table_name, con, schema=None, coerce_float=True)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `schema`, `coerce_float`.", "question_id": 14390},
{"snippet": "pandas.read_sql_table(table_name, con, schema=None, parse_dates=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `schema`, `parse_dates`.", "question_id": 14391},
{"snippet": "pandas.read_sql_table(table_name, con)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`.", "question_id": 14392},
{"snippet": "pandas.read_sql_table(table_name, con, schema=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `schema`.", "question_id": 14393},
{"snippet": "pandas.read_sql_table(table_name, con, index_col=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `index_col`.", "question_id": 14394},
{"snippet": "pandas.read_sql_table(table_name, con, coerce_float=True)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `coerce_float`.", "question_id": 14395},
{"snippet": "pandas.read_sql_table(table_name, con, parse_dates=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `parse_dates`.", "question_id": 14396},
{"snippet": "pandas.read_sql_table(table_name, con, columns=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `columns`.", "question_id": 14397},
{"snippet": "pandas.read_sql_table(table_name, con, chunksize=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `chunksize`.", "question_id": 14398},
{"snippet": "pandas.read_sql_table(table_name, con, schema=None, index_col=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `schema`, `index_col`.", "question_id": 14399},
{"snippet": "pandas.read_sql_table(table_name, con, schema=None, coerce_float=True)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `schema`, `coerce_float`.", "question_id": 14400},
{"snippet": "pandas.read_sql_table(table_name, con, schema=None, parse_dates=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `schema`, `parse_dates`.", "question_id": 14401},
{"snippet": "pandas.read_sql_table(table_name, con)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`.", "question_id": 14402},
{"snippet": "pandas.read_sql_table(table_name, con, schema=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `schema`.", "question_id": 14403},
{"snippet": "pandas.read_sql_table(table_name, con, index_col=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `index_col`.", "question_id": 14404},
{"snippet": "pandas.read_sql_table(table_name, con, coerce_float=True)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `coerce_float`.", "question_id": 14405},
{"snippet": "pandas.read_sql_table(table_name, con, parse_dates=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `parse_dates`.", "question_id": 14406},
{"snippet": "pandas.read_sql_table(table_name, con, columns=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `columns`.", "question_id": 14407},
{"snippet": "pandas.read_sql_table(table_name, con, chunksize=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `chunksize`.", "question_id": 14408},
{"snippet": "pandas.read_sql_table(table_name, con, schema=None, index_col=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `schema`, `index_col`.", "question_id": 14409},
{"snippet": "pandas.read_sql_table(table_name, con, schema=None, coerce_float=True)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `schema`, `coerce_float`.", "question_id": 14410},
{"snippet": "pandas.read_sql_table(table_name, con, schema=None, parse_dates=None)", "intent": "Read SQL database table into a DataFrame . With arguments `table_name`, `con`, `schema`, `parse_dates`.", "question_id": 14411},
{"snippet": "pandas.read_stata(filepath_or_buffer)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`.", "question_id": 14412},
{"snippet": "pandas.read_stata(filepath_or_buffer, convert_dates=True)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `convert_dates`.", "question_id": 14413},
{"snippet": "pandas.read_stata(filepath_or_buffer, convert_categoricals=True)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `convert_categoricals`.", "question_id": 14414},
{"snippet": "pandas.read_stata(filepath_or_buffer, index_col=None)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `index_col`.", "question_id": 14415},
{"snippet": "pandas.read_stata(filepath_or_buffer, convert_missing=False)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `convert_missing`.", "question_id": 14416},
{"snippet": "pandas.read_stata(filepath_or_buffer, preserve_dtypes=True)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `preserve_dtypes`.", "question_id": 14417},
{"snippet": "pandas.read_stata(filepath_or_buffer, columns=None)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `columns`.", "question_id": 14418},
{"snippet": "pandas.read_stata(filepath_or_buffer, order_categoricals=True)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `order_categoricals`.", "question_id": 14419},
{"snippet": "pandas.read_stata(filepath_or_buffer, chunksize=None)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `chunksize`.", "question_id": 14420},
{"snippet": "pandas.read_stata(filepath_or_buffer, iterator=False)", "intent": "Read Stata file into DataFrame . Categorical variables read through an `iterator` may not have the same categories and dtype . With arguments `filepath_or_buffer`.", "question_id": 14421},
{"snippet": "pandas.read_stata(filepath_or_buffer)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`.", "question_id": 14422},
{"snippet": "pandas.read_stata(filepath_or_buffer, convert_dates=True)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `convert_dates`.", "question_id": 14423},
{"snippet": "pandas.read_stata(filepath_or_buffer, convert_categoricals=True)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `convert_categoricals`.", "question_id": 14424},
{"snippet": "pandas.read_stata(filepath_or_buffer, index_col=None)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `index_col`.", "question_id": 14425},
{"snippet": "pandas.read_stata(filepath_or_buffer, convert_missing=False)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `convert_missing`.", "question_id": 14426},
{"snippet": "pandas.read_stata(filepath_or_buffer, preserve_dtypes=True)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `preserve_dtypes`.", "question_id": 14427},
{"snippet": "pandas.read_stata(filepath_or_buffer, columns=None)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `columns`.", "question_id": 14428},
{"snippet": "pandas.read_stata(filepath_or_buffer, order_categoricals=True)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `order_categoricals`.", "question_id": 14429},
{"snippet": "pandas.read_stata(filepath_or_buffer, chunksize=None)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `chunksize`.", "question_id": 14430},
{"snippet": "pandas.read_stata(filepath_or_buffer, iterator=False)", "intent": "Read Stata file into DataFrame . Categorical variables read through an `iterator` may not have the same categories and dtype . With arguments `filepath_or_buffer`.", "question_id": 14431},
{"snippet": "pandas.read_stata(filepath_or_buffer)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`.", "question_id": 14432},
{"snippet": "pandas.read_stata(filepath_or_buffer, convert_dates=True)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `convert_dates`.", "question_id": 14433},
{"snippet": "pandas.read_stata(filepath_or_buffer, convert_categoricals=True)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `convert_categoricals`.", "question_id": 14434},
{"snippet": "pandas.read_stata(filepath_or_buffer, index_col=None)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `index_col`.", "question_id": 14435},
{"snippet": "pandas.read_stata(filepath_or_buffer, convert_missing=False)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `convert_missing`.", "question_id": 14436},
{"snippet": "pandas.read_stata(filepath_or_buffer, preserve_dtypes=True)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `preserve_dtypes`.", "question_id": 14437},
{"snippet": "pandas.read_stata(filepath_or_buffer, columns=None)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `columns`.", "question_id": 14438},
{"snippet": "pandas.read_stata(filepath_or_buffer, order_categoricals=True)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `order_categoricals`.", "question_id": 14439},
{"snippet": "pandas.read_stata(filepath_or_buffer, chunksize=None)", "intent": "Read Stata file into DataFrame . With arguments `filepath_or_buffer`, `chunksize`.", "question_id": 14440},
{"snippet": "pandas.read_stata(filepath_or_buffer, iterator=False)", "intent": "Read Stata file into DataFrame . Categorical variables read through an `iterator` may not have the same categories and dtype . With arguments `filepath_or_buffer`.", "question_id": 14441},
{"snippet": "pandas.read_table(filepath_or_buffer)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`.", "question_id": 14442},
{"snippet": "pandas.read_table(filepath_or_buffer, sep=NoDefault.no_default)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `sep`.", "question_id": 14443},
{"snippet": "pandas.read_table(filepath_or_buffer, delimiter=None)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `delimiter`.", "question_id": 14444},
{"snippet": "pandas.read_table(filepath_or_buffer, header='infer')", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `header`.", "question_id": 14445},
{"snippet": "pandas.read_table(filepath_or_buffer, names=NoDefault.no_default)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `names`.", "question_id": 14446},
{"snippet": "pandas.read_table(filepath_or_buffer, index_col=None)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `index_col`.", "question_id": 14447},
{"snippet": "pandas.read_table(filepath_or_buffer, usecols=None)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `usecols`.", "question_id": 14448},
{"snippet": "pandas.read_table(filepath_or_buffer, squeeze=False)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `squeeze`.", "question_id": 14449},
{"snippet": "pandas.read_table(filepath_or_buffer, prefix=NoDefault.no_default)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `prefix`.", "question_id": 14450},
{"snippet": "pandas.read_table(filepath_or_buffer, mangle_dupe_cols=True)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `mangle_dupe_cols`.", "question_id": 14451},
{"snippet": "pandas.read_table(filepath_or_buffer)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`.", "question_id": 14452},
{"snippet": "pandas.read_table(filepath_or_buffer, sep=NoDefault.no_default)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `sep`.", "question_id": 14453},
{"snippet": "pandas.read_table(filepath_or_buffer, delimiter=None)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `delimiter`.", "question_id": 14454},
{"snippet": "pandas.read_table(filepath_or_buffer, header='infer')", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `header`.", "question_id": 14455},
{"snippet": "pandas.read_table(filepath_or_buffer, names=NoDefault.no_default)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `names`.", "question_id": 14456},
{"snippet": "pandas.read_table(filepath_or_buffer, index_col=None)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `index_col`.", "question_id": 14457},
{"snippet": "pandas.read_table(filepath_or_buffer, usecols=None)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `usecols`.", "question_id": 14458},
{"snippet": "pandas.read_table(filepath_or_buffer, squeeze=False)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `squeeze`.", "question_id": 14459},
{"snippet": "pandas.read_table(filepath_or_buffer, prefix=NoDefault.no_default)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `prefix`.", "question_id": 14460},
{"snippet": "pandas.read_table(filepath_or_buffer, mangle_dupe_cols=True)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `mangle_dupe_cols`.", "question_id": 14461},
{"snippet": "pandas.read_table(filepath_or_buffer)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`.", "question_id": 14462},
{"snippet": "pandas.read_table(filepath_or_buffer, sep=NoDefault.no_default)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `sep`.", "question_id": 14463},
{"snippet": "pandas.read_table(filepath_or_buffer, delimiter=None)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `delimiter`.", "question_id": 14464},
{"snippet": "pandas.read_table(filepath_or_buffer, header='infer')", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `header`.", "question_id": 14465},
{"snippet": "pandas.read_table(filepath_or_buffer, names=NoDefault.no_default)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `names`.", "question_id": 14466},
{"snippet": "pandas.read_table(filepath_or_buffer, index_col=None)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `index_col`.", "question_id": 14467},
{"snippet": "pandas.read_table(filepath_or_buffer, usecols=None)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `usecols`.", "question_id": 14468},
{"snippet": "pandas.read_table(filepath_or_buffer, squeeze=False)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `squeeze`.", "question_id": 14469},
{"snippet": "pandas.read_table(filepath_or_buffer, prefix=NoDefault.no_default)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `prefix`.", "question_id": 14470},
{"snippet": "pandas.read_table(filepath_or_buffer, mangle_dupe_cols=True)", "intent": "Read general delimited file into DataFrame . With arguments `filepath_or_buffer`, `mangle_dupe_cols`.", "question_id": 14471},
{"snippet": "pandas.read_xml(path_or_buffer)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`.", "question_id": 14472},
{"snippet": "pandas.read_xml(path_or_buffer, xpath='./*')", "intent": "Read XML document into a DataFrame object . This function will always return a single DataFrame or raise exceptions due to issues with XML document , `xpath` , or other parameters . With arguments `path_or_buffer`.", "question_id": 14473},
{"snippet": "pandas.read_xml(path_or_buffer, namespaces=None)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `namespaces`.", "question_id": 14474},
{"snippet": "pandas.read_xml(path_or_buffer, elems_only=False)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `elems_only`.", "question_id": 14475},
{"snippet": "pandas.read_xml(path_or_buffer, attrs_only=False)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `attrs_only`.", "question_id": 14476},
{"snippet": "pandas.read_xml(path_or_buffer, names=None)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `names`.", "question_id": 14477},
{"snippet": "pandas.read_xml(path_or_buffer, encoding='utf-8')", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `encoding`.", "question_id": 14478},
{"snippet": "pandas.read_xml(path_or_buffer, parser='lxml')", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `parser`.", "question_id": 14479},
{"snippet": "pandas.read_xml(path_or_buffer, stylesheet=None)", "intent": "Read XML document into a DataFrame object . However , for more complex XML documents , `stylesheet` allows you to temporarily redesign original document with XSLT ( a special purpose language ) for a flatter version for migration to a DataFrame . With arguments `path_or_buffer`.", "question_id": 14480},
{"snippet": "pandas.read_xml(path_or_buffer, compression='infer')", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `compression`.", "question_id": 14481},
{"snippet": "pandas.read_xml(path_or_buffer)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`.", "question_id": 14482},
{"snippet": "pandas.read_xml(path_or_buffer, xpath='./*')", "intent": "Read XML document into a DataFrame object . This function will always return a single DataFrame or raise exceptions due to issues with XML document , `xpath` , or other parameters . With arguments `path_or_buffer`.", "question_id": 14483},
{"snippet": "pandas.read_xml(path_or_buffer, namespaces=None)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `namespaces`.", "question_id": 14484},
{"snippet": "pandas.read_xml(path_or_buffer, elems_only=False)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `elems_only`.", "question_id": 14485},
{"snippet": "pandas.read_xml(path_or_buffer, attrs_only=False)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `attrs_only`.", "question_id": 14486},
{"snippet": "pandas.read_xml(path_or_buffer, names=None)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `names`.", "question_id": 14487},
{"snippet": "pandas.read_xml(path_or_buffer, encoding='utf-8')", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `encoding`.", "question_id": 14488},
{"snippet": "pandas.read_xml(path_or_buffer, parser='lxml')", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `parser`.", "question_id": 14489},
{"snippet": "pandas.read_xml(path_or_buffer, stylesheet=None)", "intent": "Read XML document into a DataFrame object . However , for more complex XML documents , `stylesheet` allows you to temporarily redesign original document with XSLT ( a special purpose language ) for a flatter version for migration to a DataFrame . With arguments `path_or_buffer`.", "question_id": 14490},
{"snippet": "pandas.read_xml(path_or_buffer, compression='infer')", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `compression`.", "question_id": 14491},
{"snippet": "pandas.read_xml(path_or_buffer)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`.", "question_id": 14492},
{"snippet": "pandas.read_xml(path_or_buffer, xpath='./*')", "intent": "Read XML document into a DataFrame object . This function will always return a single DataFrame or raise exceptions due to issues with XML document , `xpath` , or other parameters . With arguments `path_or_buffer`.", "question_id": 14493},
{"snippet": "pandas.read_xml(path_or_buffer, namespaces=None)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `namespaces`.", "question_id": 14494},
{"snippet": "pandas.read_xml(path_or_buffer, elems_only=False)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `elems_only`.", "question_id": 14495},
{"snippet": "pandas.read_xml(path_or_buffer, attrs_only=False)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `attrs_only`.", "question_id": 14496},
{"snippet": "pandas.read_xml(path_or_buffer, names=None)", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `names`.", "question_id": 14497},
{"snippet": "pandas.read_xml(path_or_buffer, encoding='utf-8')", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `encoding`.", "question_id": 14498},
{"snippet": "pandas.read_xml(path_or_buffer, parser='lxml')", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `parser`.", "question_id": 14499},
{"snippet": "pandas.read_xml(path_or_buffer, stylesheet=None)", "intent": "Read XML document into a DataFrame object . However , for more complex XML documents , `stylesheet` allows you to temporarily redesign original document with XSLT ( a special purpose language ) for a flatter version for migration to a DataFrame . With arguments `path_or_buffer`.", "question_id": 14500},
{"snippet": "pandas.read_xml(path_or_buffer, compression='infer')", "intent": "Read XML document into a DataFrame object . With arguments `path_or_buffer`, `compression`.", "question_id": 14501},
{"snippet": "pandas.reset_option(pat)", "intent": "Reset one or more options to their default value . With arguments `pat`.", "question_id": 14502},
{"snippet": "pandas.reset_option(pat)", "intent": "Reset one or more options to their default value . With arguments `pat`.", "question_id": 14503},
{"snippet": "pandas.reset_option(pat)", "intent": "Reset one or more options to their default value . With arguments `pat`.", "question_id": 14504},
{"snippet": "pandas.set_option(pat, value)", "intent": "Sets the `value` of the specified option . With arguments `pat`.", "question_id": 14505},
{"snippet": "pandas.set_option(pat, value)", "intent": "Sets the `value` of the specified option . With arguments `pat`.", "question_id": 14506},
{"snippet": "pandas.set_option(pat, value)", "intent": "Sets the `value` of the specified option . With arguments `pat`.", "question_id": 14507},
{"snippet": "pandas.show_versions()", "intent": "Provide useful information , important for bug reports .", "question_id": 14508},
{"snippet": "pandas.show_versions(as_json=False)", "intent": "Provide useful information , important for bug reports . With arguments `as_json`.", "question_id": 14509},
{"snippet": "pandas.show_versions()", "intent": "Provide useful information , important for bug reports .", "question_id": 14510},
{"snippet": "pandas.show_versions(as_json=False)", "intent": "Provide useful information , important for bug reports . With arguments `as_json`.", "question_id": 14511},
{"snippet": "pandas.show_versions()", "intent": "Provide useful information , important for bug reports .", "question_id": 14512},
{"snippet": "pandas.show_versions(as_json=False)", "intent": "Provide useful information , important for bug reports . With arguments `as_json`.", "question_id": 14513},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right)", "intent": "Check that `left` and `right` ExtensionArrays are equal .", "question_id": 14514},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_dtype=True)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_dtype`.", "question_id": 14515},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, index_values=None)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `index_values`.", "question_id": 14516},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_less_precise`.", "question_id": 14517},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_exact=False)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_exact`.", "question_id": 14518},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, rtol=1e-05)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `rtol`.", "question_id": 14519},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, atol=1e-08)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `atol`.", "question_id": 14520},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_dtype=True, index_values=None)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_dtype`, `index_values`.", "question_id": 14521},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_dtype=True, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_dtype`, `check_less_precise`.", "question_id": 14522},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_dtype=True, check_exact=False)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_dtype`, `check_exact`.", "question_id": 14523},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right)", "intent": "Check that `left` and `right` ExtensionArrays are equal .", "question_id": 14524},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_dtype=True)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_dtype`.", "question_id": 14525},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, index_values=None)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `index_values`.", "question_id": 14526},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_less_precise`.", "question_id": 14527},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_exact=False)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_exact`.", "question_id": 14528},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, rtol=1e-05)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `rtol`.", "question_id": 14529},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, atol=1e-08)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `atol`.", "question_id": 14530},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_dtype=True, index_values=None)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_dtype`, `index_values`.", "question_id": 14531},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_dtype=True, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_dtype`, `check_less_precise`.", "question_id": 14532},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_dtype=True, check_exact=False)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_dtype`, `check_exact`.", "question_id": 14533},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right)", "intent": "Check that `left` and `right` ExtensionArrays are equal .", "question_id": 14534},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_dtype=True)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_dtype`.", "question_id": 14535},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, index_values=None)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `index_values`.", "question_id": 14536},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_less_precise`.", "question_id": 14537},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_exact=False)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_exact`.", "question_id": 14538},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, rtol=1e-05)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `rtol`.", "question_id": 14539},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, atol=1e-08)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `atol`.", "question_id": 14540},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_dtype=True, index_values=None)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_dtype`, `index_values`.", "question_id": 14541},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_dtype=True, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_dtype`, `check_less_precise`.", "question_id": 14542},
{"snippet": "pandas.testing.assert_extension_array_equal(left, right, check_dtype=True, check_exact=False)", "intent": "Check that `left` and `right` ExtensionArrays are equal . With arguments `check_dtype`, `check_exact`.", "question_id": 14543},
{"snippet": "pandas.testing.assert_frame_equal(left, right)", "intent": "Check that `left` and `right` DataFrame are equal .", "question_id": 14544},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_dtype=True)", "intent": "Check that `left` and `right` DataFrame are equal . Ignore differing dtypes in columns with `check_dtype` .", "question_id": 14545},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_index_type='equiv')", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_index_type`.", "question_id": 14546},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_column_type='equiv')", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_column_type`.", "question_id": 14547},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_frame_type=True)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_frame_type`.", "question_id": 14548},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_less_precise`.", "question_id": 14549},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_names=True)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_names`.", "question_id": 14550},
{"snippet": "pandas.testing.assert_frame_equal(left, right, by_blocks=False)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `by_blocks`.", "question_id": 14551},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_exact=False)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_exact`.", "question_id": 14552},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_datetimelike_compat=False)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_datetimelike_compat`.", "question_id": 14553},
{"snippet": "pandas.testing.assert_frame_equal(left, right)", "intent": "Check that `left` and `right` DataFrame are equal .", "question_id": 14554},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_dtype=True)", "intent": "Check that `left` and `right` DataFrame are equal . Ignore differing dtypes in columns with `check_dtype` .", "question_id": 14555},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_index_type='equiv')", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_index_type`.", "question_id": 14556},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_column_type='equiv')", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_column_type`.", "question_id": 14557},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_frame_type=True)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_frame_type`.", "question_id": 14558},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_less_precise`.", "question_id": 14559},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_names=True)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_names`.", "question_id": 14560},
{"snippet": "pandas.testing.assert_frame_equal(left, right, by_blocks=False)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `by_blocks`.", "question_id": 14561},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_exact=False)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_exact`.", "question_id": 14562},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_datetimelike_compat=False)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_datetimelike_compat`.", "question_id": 14563},
{"snippet": "pandas.testing.assert_frame_equal(left, right)", "intent": "Check that `left` and `right` DataFrame are equal .", "question_id": 14564},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_dtype=True)", "intent": "Check that `left` and `right` DataFrame are equal . Ignore differing dtypes in columns with `check_dtype` .", "question_id": 14565},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_index_type='equiv')", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_index_type`.", "question_id": 14566},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_column_type='equiv')", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_column_type`.", "question_id": 14567},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_frame_type=True)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_frame_type`.", "question_id": 14568},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_less_precise`.", "question_id": 14569},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_names=True)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_names`.", "question_id": 14570},
{"snippet": "pandas.testing.assert_frame_equal(left, right, by_blocks=False)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `by_blocks`.", "question_id": 14571},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_exact=False)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_exact`.", "question_id": 14572},
{"snippet": "pandas.testing.assert_frame_equal(left, right, check_datetimelike_compat=False)", "intent": "Check that `left` and `right` DataFrame are equal . With arguments `check_datetimelike_compat`.", "question_id": 14573},
{"snippet": "pandas.testing.assert_index_equal(left, right)", "intent": "Check that `left` and `right` Index are equal .", "question_id": 14574},
{"snippet": "pandas.testing.assert_index_equal(left, right, exact='equiv')", "intent": "Check that `left` and `right` Index are equal . With arguments `exact`.", "question_id": 14575},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_names=True)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_names`.", "question_id": 14576},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_less_precise`.", "question_id": 14577},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_exact=True)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_exact`.", "question_id": 14578},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_categorical=True)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_categorical`.", "question_id": 14579},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_order=True)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_order`.", "question_id": 14580},
{"snippet": "pandas.testing.assert_index_equal(left, right, rtol=1e-05)", "intent": "Check that `left` and `right` Index are equal . With arguments `rtol`.", "question_id": 14581},
{"snippet": "pandas.testing.assert_index_equal(left, right, atol=1e-08)", "intent": "Check that `left` and `right` Index are equal . With arguments `atol`.", "question_id": 14582},
{"snippet": "pandas.testing.assert_index_equal(left, right, obj='Index')", "intent": "Check that `left` and `right` Index are equal . With arguments `obj`.", "question_id": 14583},
{"snippet": "pandas.testing.assert_index_equal(left, right)", "intent": "Check that `left` and `right` Index are equal .", "question_id": 14584},
{"snippet": "pandas.testing.assert_index_equal(left, right, exact='equiv')", "intent": "Check that `left` and `right` Index are equal . With arguments `exact`.", "question_id": 14585},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_names=True)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_names`.", "question_id": 14586},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_less_precise`.", "question_id": 14587},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_exact=True)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_exact`.", "question_id": 14588},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_categorical=True)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_categorical`.", "question_id": 14589},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_order=True)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_order`.", "question_id": 14590},
{"snippet": "pandas.testing.assert_index_equal(left, right, rtol=1e-05)", "intent": "Check that `left` and `right` Index are equal . With arguments `rtol`.", "question_id": 14591},
{"snippet": "pandas.testing.assert_index_equal(left, right, atol=1e-08)", "intent": "Check that `left` and `right` Index are equal . With arguments `atol`.", "question_id": 14592},
{"snippet": "pandas.testing.assert_index_equal(left, right, obj='Index')", "intent": "Check that `left` and `right` Index are equal . With arguments `obj`.", "question_id": 14593},
{"snippet": "pandas.testing.assert_index_equal(left, right)", "intent": "Check that `left` and `right` Index are equal .", "question_id": 14594},
{"snippet": "pandas.testing.assert_index_equal(left, right, exact='equiv')", "intent": "Check that `left` and `right` Index are equal . With arguments `exact`.", "question_id": 14595},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_names=True)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_names`.", "question_id": 14596},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_less_precise`.", "question_id": 14597},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_exact=True)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_exact`.", "question_id": 14598},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_categorical=True)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_categorical`.", "question_id": 14599},
{"snippet": "pandas.testing.assert_index_equal(left, right, check_order=True)", "intent": "Check that `left` and `right` Index are equal . With arguments `check_order`.", "question_id": 14600},
{"snippet": "pandas.testing.assert_index_equal(left, right, rtol=1e-05)", "intent": "Check that `left` and `right` Index are equal . With arguments `rtol`.", "question_id": 14601},
{"snippet": "pandas.testing.assert_index_equal(left, right, atol=1e-08)", "intent": "Check that `left` and `right` Index are equal . With arguments `atol`.", "question_id": 14602},
{"snippet": "pandas.testing.assert_index_equal(left, right, obj='Index')", "intent": "Check that `left` and `right` Index are equal . With arguments `obj`.", "question_id": 14603},
{"snippet": "pandas.testing.assert_series_equal(left, right)", "intent": "Check that `left` and `right` Series are equal .", "question_id": 14604},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_dtype=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_dtype`.", "question_id": 14605},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_index_type='equiv')", "intent": "Check that `left` and `right` Series are equal . With arguments `check_index_type`.", "question_id": 14606},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_series_type=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_series_type`.", "question_id": 14607},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_less_precise`.", "question_id": 14608},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_names=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_names`.", "question_id": 14609},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_exact=False)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_exact`.", "question_id": 14610},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_datetimelike_compat=False)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_datetimelike_compat`.", "question_id": 14611},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_categorical=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_categorical`.", "question_id": 14612},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_category_order=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_category_order`.", "question_id": 14613},
{"snippet": "pandas.testing.assert_series_equal(left, right)", "intent": "Check that `left` and `right` Series are equal .", "question_id": 14614},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_dtype=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_dtype`.", "question_id": 14615},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_index_type='equiv')", "intent": "Check that `left` and `right` Series are equal . With arguments `check_index_type`.", "question_id": 14616},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_series_type=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_series_type`.", "question_id": 14617},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_less_precise`.", "question_id": 14618},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_names=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_names`.", "question_id": 14619},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_exact=False)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_exact`.", "question_id": 14620},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_datetimelike_compat=False)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_datetimelike_compat`.", "question_id": 14621},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_categorical=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_categorical`.", "question_id": 14622},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_category_order=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_category_order`.", "question_id": 14623},
{"snippet": "pandas.testing.assert_series_equal(left, right)", "intent": "Check that `left` and `right` Series are equal .", "question_id": 14624},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_dtype=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_dtype`.", "question_id": 14625},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_index_type='equiv')", "intent": "Check that `left` and `right` Series are equal . With arguments `check_index_type`.", "question_id": 14626},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_series_type=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_series_type`.", "question_id": 14627},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_less_precise=NoDefault.no_default)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_less_precise`.", "question_id": 14628},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_names=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_names`.", "question_id": 14629},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_exact=False)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_exact`.", "question_id": 14630},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_datetimelike_compat=False)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_datetimelike_compat`.", "question_id": 14631},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_categorical=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_categorical`.", "question_id": 14632},
{"snippet": "pandas.testing.assert_series_equal(left, right, check_category_order=True)", "intent": "Check that `left` and `right` Series are equal . With arguments `check_category_order`.", "question_id": 14633},
{"snippet": "pandas.timedelta_range()", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency .", "question_id": 14634},
{"snippet": "pandas.timedelta_range(start=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14635},
{"snippet": "pandas.timedelta_range(end=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14636},
{"snippet": "pandas.timedelta_range(periods=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14637},
{"snippet": "pandas.timedelta_range(freq=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14638},
{"snippet": "pandas.timedelta_range(name=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . With arguments `name`.", "question_id": 14639},
{"snippet": "pandas.timedelta_range(closed=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . If freq is omitted , the resulting TimedeltaIndex will have periods linearly spaced elements between start and end ( `closed` on both sides ) .", "question_id": 14640},
{"snippet": "pandas.timedelta_range(start=None, end=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14641},
{"snippet": "pandas.timedelta_range(start=None, periods=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14642},
{"snippet": "pandas.timedelta_range(start=None, freq=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14643},
{"snippet": "pandas.timedelta_range()", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency .", "question_id": 14644},
{"snippet": "pandas.timedelta_range(start=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14645},
{"snippet": "pandas.timedelta_range(end=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14646},
{"snippet": "pandas.timedelta_range(periods=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14647},
{"snippet": "pandas.timedelta_range(freq=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14648},
{"snippet": "pandas.timedelta_range(name=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . With arguments `name`.", "question_id": 14649},
{"snippet": "pandas.timedelta_range(closed=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . If freq is omitted , the resulting TimedeltaIndex will have periods linearly spaced elements between start and end ( `closed` on both sides ) .", "question_id": 14650},
{"snippet": "pandas.timedelta_range(start=None, end=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14651},
{"snippet": "pandas.timedelta_range(start=None, periods=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14652},
{"snippet": "pandas.timedelta_range(start=None, freq=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14653},
{"snippet": "pandas.timedelta_range()", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency .", "question_id": 14654},
{"snippet": "pandas.timedelta_range(start=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14655},
{"snippet": "pandas.timedelta_range(end=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14656},
{"snippet": "pandas.timedelta_range(periods=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14657},
{"snippet": "pandas.timedelta_range(freq=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14658},
{"snippet": "pandas.timedelta_range(name=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . With arguments `name`.", "question_id": 14659},
{"snippet": "pandas.timedelta_range(closed=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . If freq is omitted , the resulting TimedeltaIndex will have periods linearly spaced elements between start and end ( `closed` on both sides ) .", "question_id": 14660},
{"snippet": "pandas.timedelta_range(start=None, end=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14661},
{"snippet": "pandas.timedelta_range(start=None, periods=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14662},
{"snippet": "pandas.timedelta_range(start=None, freq=None)", "intent": "Return a fixed frequency TimedeltaIndex , with day as the default frequency . Of the four parameters `start` , `end` , `periods` , and `freq` , exactly three must be specified .", "question_id": 14663},
{"snippet": "pandas.to_datetime(arg)", "intent": "Convert argument to datetime . With arguments `arg`.", "question_id": 14664},
{"snippet": "pandas.to_datetime(arg, errors='raise')", "intent": "Convert argument to datetime . With arguments `arg`, `errors`.", "question_id": 14665},
{"snippet": "pandas.to_datetime(arg, dayfirst=False)", "intent": "Convert argument to datetime . With arguments `arg`, `dayfirst`.", "question_id": 14666},
{"snippet": "pandas.to_datetime(arg, yearfirst=False)", "intent": "Convert argument to datetime . With arguments `arg`, `yearfirst`.", "question_id": 14667},
{"snippet": "pandas.to_datetime(arg, utc=None)", "intent": "Convert argument to datetime . With arguments `arg`, `utc`.", "question_id": 14668},
{"snippet": "pandas.to_datetime(arg, format=None)", "intent": "Convert argument to datetime . Passing infer_datetime_format=True can often-times speedup a parsing if its not an ISO8601 `format` exactly , but in a regular format . With arguments `arg`.", "question_id": 14669},
{"snippet": "pandas.to_datetime(arg, exact=True)", "intent": "Convert argument to datetime . With arguments `arg`, `exact`.", "question_id": 14670},
{"snippet": "pandas.to_datetime(arg, unit=None)", "intent": "Convert argument to datetime . With arguments `arg`, `unit`.", "question_id": 14671},
{"snippet": "pandas.to_datetime(arg, infer_datetime_format=False)", "intent": "Convert argument to datetime . With arguments `arg`, `infer_datetime_format`.", "question_id": 14672},
{"snippet": "pandas.to_datetime(arg, origin='unix')", "intent": "Convert argument to datetime . Using a non-unix epoch `origin` With arguments `arg`.", "question_id": 14673},
{"snippet": "pandas.to_datetime(arg)", "intent": "Convert argument to datetime . With arguments `arg`.", "question_id": 14674},
{"snippet": "pandas.to_datetime(arg, errors='raise')", "intent": "Convert argument to datetime . With arguments `arg`, `errors`.", "question_id": 14675},
{"snippet": "pandas.to_datetime(arg, dayfirst=False)", "intent": "Convert argument to datetime . With arguments `arg`, `dayfirst`.", "question_id": 14676},
{"snippet": "pandas.to_datetime(arg, yearfirst=False)", "intent": "Convert argument to datetime . With arguments `arg`, `yearfirst`.", "question_id": 14677},
{"snippet": "pandas.to_datetime(arg, utc=None)", "intent": "Convert argument to datetime . With arguments `arg`, `utc`.", "question_id": 14678},
{"snippet": "pandas.to_datetime(arg, format=None)", "intent": "Convert argument to datetime . Passing infer_datetime_format=True can often-times speedup a parsing if its not an ISO8601 `format` exactly , but in a regular format . With arguments `arg`.", "question_id": 14679},
{"snippet": "pandas.to_datetime(arg, exact=True)", "intent": "Convert argument to datetime . With arguments `arg`, `exact`.", "question_id": 14680},
{"snippet": "pandas.to_datetime(arg, unit=None)", "intent": "Convert argument to datetime . With arguments `arg`, `unit`.", "question_id": 14681},
{"snippet": "pandas.to_datetime(arg, infer_datetime_format=False)", "intent": "Convert argument to datetime . With arguments `arg`, `infer_datetime_format`.", "question_id": 14682},
{"snippet": "pandas.to_datetime(arg, origin='unix')", "intent": "Convert argument to datetime . Using a non-unix epoch `origin` With arguments `arg`.", "question_id": 14683},
{"snippet": "pandas.to_datetime(arg)", "intent": "Convert argument to datetime . With arguments `arg`.", "question_id": 14684},
{"snippet": "pandas.to_datetime(arg, errors='raise')", "intent": "Convert argument to datetime . With arguments `arg`, `errors`.", "question_id": 14685},
{"snippet": "pandas.to_datetime(arg, dayfirst=False)", "intent": "Convert argument to datetime . With arguments `arg`, `dayfirst`.", "question_id": 14686},
{"snippet": "pandas.to_datetime(arg, yearfirst=False)", "intent": "Convert argument to datetime . With arguments `arg`, `yearfirst`.", "question_id": 14687},
{"snippet": "pandas.to_datetime(arg, utc=None)", "intent": "Convert argument to datetime . With arguments `arg`, `utc`.", "question_id": 14688},
{"snippet": "pandas.to_datetime(arg, format=None)", "intent": "Convert argument to datetime . Passing infer_datetime_format=True can often-times speedup a parsing if its not an ISO8601 `format` exactly , but in a regular format . With arguments `arg`.", "question_id": 14689},
{"snippet": "pandas.to_datetime(arg, exact=True)", "intent": "Convert argument to datetime . With arguments `arg`, `exact`.", "question_id": 14690},
{"snippet": "pandas.to_datetime(arg, unit=None)", "intent": "Convert argument to datetime . With arguments `arg`, `unit`.", "question_id": 14691},
{"snippet": "pandas.to_datetime(arg, infer_datetime_format=False)", "intent": "Convert argument to datetime . With arguments `arg`, `infer_datetime_format`.", "question_id": 14692},
{"snippet": "pandas.to_datetime(arg, origin='unix')", "intent": "Convert argument to datetime . Using a non-unix epoch `origin` With arguments `arg`.", "question_id": 14693},
{"snippet": "pandas.to_numeric(arg)", "intent": "Convert argument to a numeric type . With arguments `arg`.", "question_id": 14694},
{"snippet": "pandas.to_numeric(arg, errors='raise')", "intent": "Convert argument to a numeric type . With arguments `arg`, `errors`.", "question_id": 14695},
{"snippet": "pandas.to_numeric(arg, downcast=None)", "intent": "Convert argument to a numeric type . Use the `downcast` parameter to obtain other dtypes . With arguments `arg`.", "question_id": 14696},
{"snippet": "pandas.to_numeric(arg, errors='raise', downcast=None)", "intent": "Convert argument to a numeric type . Use the `downcast` parameter to obtain other dtypes . With arguments `arg`, `errors`.", "question_id": 14697},
{"snippet": "pandas.to_numeric(arg)", "intent": "Convert argument to a numeric type . With arguments `arg`.", "question_id": 14698},
{"snippet": "pandas.to_numeric(arg, errors='raise')", "intent": "Convert argument to a numeric type . With arguments `arg`, `errors`.", "question_id": 14699},
{"snippet": "pandas.to_numeric(arg, downcast=None)", "intent": "Convert argument to a numeric type . Use the `downcast` parameter to obtain other dtypes . With arguments `arg`.", "question_id": 14700},
{"snippet": "pandas.to_numeric(arg, errors='raise', downcast=None)", "intent": "Convert argument to a numeric type . Use the `downcast` parameter to obtain other dtypes . With arguments `arg`, `errors`.", "question_id": 14701},
{"snippet": "pandas.to_numeric(arg)", "intent": "Convert argument to a numeric type . With arguments `arg`.", "question_id": 14702},
{"snippet": "pandas.to_numeric(arg, errors='raise')", "intent": "Convert argument to a numeric type . With arguments `arg`, `errors`.", "question_id": 14703},
{"snippet": "pandas.to_numeric(arg, downcast=None)", "intent": "Convert argument to a numeric type . Use the `downcast` parameter to obtain other dtypes . With arguments `arg`.", "question_id": 14704},
{"snippet": "pandas.to_numeric(arg, errors='raise', downcast=None)", "intent": "Convert argument to a numeric type . Use the `downcast` parameter to obtain other dtypes . With arguments `arg`, `errors`.", "question_id": 14705},
{"snippet": "pandas.to_timedelta(arg)", "intent": "Convert argument to timedelta . With arguments `arg`.", "question_id": 14706},
{"snippet": "pandas.to_timedelta(arg, unit=None)", "intent": "Convert argument to timedelta . Converting numbers by specifying the `unit` keyword argument : With arguments `arg`.", "question_id": 14707},
{"snippet": "pandas.to_timedelta(arg, errors='raise')", "intent": "Convert argument to timedelta . With arguments `arg`, `errors`.", "question_id": 14708},
{"snippet": "pandas.to_timedelta(arg, unit=None, errors='raise')", "intent": "Convert argument to timedelta . Converting numbers by specifying the `unit` keyword argument : With arguments `arg`, `errors`.", "question_id": 14709},
{"snippet": "pandas.to_timedelta(arg)", "intent": "Convert argument to timedelta . With arguments `arg`.", "question_id": 14710},
{"snippet": "pandas.to_timedelta(arg, unit=None)", "intent": "Convert argument to timedelta . Converting numbers by specifying the `unit` keyword argument : With arguments `arg`.", "question_id": 14711},
{"snippet": "pandas.to_timedelta(arg, errors='raise')", "intent": "Convert argument to timedelta . With arguments `arg`, `errors`.", "question_id": 14712},
{"snippet": "pandas.to_timedelta(arg, unit=None, errors='raise')", "intent": "Convert argument to timedelta . Converting numbers by specifying the `unit` keyword argument : With arguments `arg`, `errors`.", "question_id": 14713},
{"snippet": "pandas.to_timedelta(arg)", "intent": "Convert argument to timedelta . With arguments `arg`.", "question_id": 14714},
{"snippet": "pandas.to_timedelta(arg, unit=None)", "intent": "Convert argument to timedelta . Converting numbers by specifying the `unit` keyword argument : With arguments `arg`.", "question_id": 14715},
{"snippet": "pandas.to_timedelta(arg, errors='raise')", "intent": "Convert argument to timedelta . With arguments `arg`, `errors`.", "question_id": 14716},
{"snippet": "pandas.to_timedelta(arg, unit=None, errors='raise')", "intent": "Convert argument to timedelta . Converting numbers by specifying the `unit` keyword argument : With arguments `arg`, `errors`.", "question_id": 14717},
{"snippet": "pandas.tseries.frequencies.to_offset()", "intent": "Return DateOffset object from string or tuple representation or datetime.timedelta object .", "question_id": 14718},
{"snippet": "pandas.tseries.frequencies.to_offset()", "intent": "Return DateOffset object from string or tuple representation or datetime.timedelta object .", "question_id": 14719},
{"snippet": "pandas.tseries.frequencies.to_offset()", "intent": "Return DateOffset object from string or tuple representation or datetime.timedelta object .", "question_id": 14720},
{"snippet": "pandas.tseries.offsets.BDay", "intent": "alias of pandas._libs.tslibs.offsets.BusinessDay", "question_id": 14721},
{"snippet": "pandas.tseries.offsets.BDay", "intent": "alias of pandas._libs.tslibs.offsets.BusinessDay", "question_id": 14722},
{"snippet": "pandas.tseries.offsets.BDay", "intent": "alias of pandas._libs.tslibs.offsets.BusinessDay", "question_id": 14723},
{"snippet": "pandas.tseries.offsets.BMonthBegin", "intent": "alias of pandas._libs.tslibs.offsets.BusinessMonthBegin", "question_id": 14724},
{"snippet": "pandas.tseries.offsets.BMonthBegin", "intent": "alias of pandas._libs.tslibs.offsets.BusinessMonthBegin", "question_id": 14725},
{"snippet": "pandas.tseries.offsets.BMonthBegin", "intent": "alias of pandas._libs.tslibs.offsets.BusinessMonthBegin", "question_id": 14726},
{"snippet": "pandas.tseries.offsets.BMonthEnd", "intent": "alias of pandas._libs.tslibs.offsets.BusinessMonthEnd", "question_id": 14727},
{"snippet": "pandas.tseries.offsets.BMonthEnd", "intent": "alias of pandas._libs.tslibs.offsets.BusinessMonthEnd", "question_id": 14728},
{"snippet": "pandas.tseries.offsets.BMonthEnd", "intent": "alias of pandas._libs.tslibs.offsets.BusinessMonthEnd", "question_id": 14729},
{"snippet": "BQuarterBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14730},
{"snippet": "BQuarterBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14731},
{"snippet": "BQuarterBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14732},
{"snippet": "BQuarterBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14733},
{"snippet": "BQuarterBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14734},
{"snippet": "BQuarterBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14735},
{"snippet": "pandas.tseries.offsets.BQuarterBegin", "intent": "DateOffset increments between the first business day of each Quarter.", "question_id": 14736},
{"snippet": "pandas.tseries.offsets.BQuarterBegin", "intent": "DateOffset increments between the first business day of each Quarter.", "question_id": 14737},
{"snippet": "pandas.tseries.offsets.BQuarterBegin", "intent": "DateOffset increments between the first business day of each Quarter.", "question_id": 14738},
{"snippet": "BQuarterBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14739},
{"snippet": "BQuarterBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14740},
{"snippet": "BQuarterBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14741},
{"snippet": "BQuarterBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14742},
{"snippet": "BQuarterBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14743},
{"snippet": "BQuarterBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14744},
{"snippet": "BQuarterEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14745},
{"snippet": "BQuarterEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14746},
{"snippet": "BQuarterEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14747},
{"snippet": "BQuarterEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14748},
{"snippet": "BQuarterEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14749},
{"snippet": "BQuarterEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14750},
{"snippet": "pandas.tseries.offsets.BQuarterEnd", "intent": "DateOffset increments between the last business day of each Quarter.", "question_id": 14751},
{"snippet": "pandas.tseries.offsets.BQuarterEnd", "intent": "DateOffset increments between the last business day of each Quarter.", "question_id": 14752},
{"snippet": "pandas.tseries.offsets.BQuarterEnd", "intent": "DateOffset increments between the last business day of each Quarter.", "question_id": 14753},
{"snippet": "BQuarterEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14754},
{"snippet": "BQuarterEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14755},
{"snippet": "BQuarterEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14756},
{"snippet": "BQuarterEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14757},
{"snippet": "BQuarterEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14758},
{"snippet": "BQuarterEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14759},
{"snippet": "BYearBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14760},
{"snippet": "BYearBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14761},
{"snippet": "BYearBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14762},
{"snippet": "BYearBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14763},
{"snippet": "BYearBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14764},
{"snippet": "BYearBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14765},
{"snippet": "pandas.tseries.offsets.BYearBegin", "intent": "DateOffset increments between the first business day of the year.", "question_id": 14766},
{"snippet": "pandas.tseries.offsets.BYearBegin", "intent": "DateOffset increments between the first business day of the year.", "question_id": 14767},
{"snippet": "pandas.tseries.offsets.BYearBegin", "intent": "DateOffset increments between the first business day of the year.", "question_id": 14768},
{"snippet": "BYearBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14769},
{"snippet": "BYearBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14770},
{"snippet": "BYearBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14771},
{"snippet": "BYearBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14772},
{"snippet": "BYearBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14773},
{"snippet": "BYearBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14774},
{"snippet": "BYearEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14775},
{"snippet": "BYearEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14776},
{"snippet": "BYearEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14777},
{"snippet": "BYearEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14778},
{"snippet": "BYearEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14779},
{"snippet": "BYearEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14780},
{"snippet": "pandas.tseries.offsets.BYearEnd", "intent": "DateOffset increments between the last business day of the year.", "question_id": 14781},
{"snippet": "pandas.tseries.offsets.BYearEnd", "intent": "DateOffset increments between the last business day of the year.", "question_id": 14782},
{"snippet": "pandas.tseries.offsets.BYearEnd", "intent": "DateOffset increments between the last business day of the year.", "question_id": 14783},
{"snippet": "BYearEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14784},
{"snippet": "BYearEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14785},
{"snippet": "BYearEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14786},
{"snippet": "BYearEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14787},
{"snippet": "BYearEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14788},
{"snippet": "BYearEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14789},
{"snippet": "BusinessDay.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14790},
{"snippet": "BusinessDay.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14791},
{"snippet": "BusinessDay.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14792},
{"snippet": "BusinessDay.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14793},
{"snippet": "BusinessDay.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14794},
{"snippet": "BusinessDay.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14795},
{"snippet": "pandas.tseries.offsets.BusinessDay", "intent": "DateOffset subclass representing possibly n business days.", "question_id": 14796},
{"snippet": "pandas.tseries.offsets.BusinessDay", "intent": "DateOffset subclass representing possibly n business days.", "question_id": 14797},
{"snippet": "pandas.tseries.offsets.BusinessDay", "intent": "DateOffset subclass representing possibly n business days.", "question_id": 14798},
{"snippet": "BusinessDay.offset", "intent": "Alias for self._offset.", "question_id": 14799},
{"snippet": "BusinessDay.offset", "intent": "Alias for self._offset.", "question_id": 14800},
{"snippet": "BusinessDay.offset", "intent": "Alias for self._offset.", "question_id": 14801},
{"snippet": "BusinessDay.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14802},
{"snippet": "BusinessDay.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14803},
{"snippet": "BusinessDay.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14804},
{"snippet": "BusinessDay.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14805},
{"snippet": "BusinessDay.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14806},
{"snippet": "BusinessDay.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14807},
{"snippet": "BusinessHour.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14808},
{"snippet": "BusinessHour.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14809},
{"snippet": "BusinessHour.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14810},
{"snippet": "BusinessHour.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14811},
{"snippet": "BusinessHour.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14812},
{"snippet": "BusinessHour.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14813},
{"snippet": "pandas.tseries.offsets.BusinessHour", "intent": "DateOffset subclass representing possibly n business hours.", "question_id": 14814},
{"snippet": "pandas.tseries.offsets.BusinessHour", "intent": "DateOffset subclass representing possibly n business hours.", "question_id": 14815},
{"snippet": "pandas.tseries.offsets.BusinessHour", "intent": "DateOffset subclass representing possibly n business hours.", "question_id": 14816},
{"snippet": "BusinessHour.next_bday", "intent": "Used for moving to next business day.", "question_id": 14817},
{"snippet": "BusinessHour.next_bday", "intent": "Used for moving to next business day.", "question_id": 14818},
{"snippet": "BusinessHour.next_bday", "intent": "Used for moving to next business day.", "question_id": 14819},
{"snippet": "BusinessHour.offset", "intent": "Alias for self._offset.", "question_id": 14820},
{"snippet": "BusinessHour.offset", "intent": "Alias for self._offset.", "question_id": 14821},
{"snippet": "BusinessHour.offset", "intent": "Alias for self._offset.", "question_id": 14822},
{"snippet": "BusinessHour.rollback(other)", "intent": "Roll provided date backward to next offset only if not on offset . With arguments `other`.", "question_id": 14823},
{"snippet": "BusinessHour.rollback(other)", "intent": "Roll provided date backward to next offset only if not on offset . With arguments `other`.", "question_id": 14824},
{"snippet": "BusinessHour.rollback(other)", "intent": "Roll provided date backward to next offset only if not on offset . With arguments `other`.", "question_id": 14825},
{"snippet": "BusinessHour.rollforward(other)", "intent": "Roll provided date forward to next offset only if not on offset . With arguments `other`.", "question_id": 14826},
{"snippet": "BusinessHour.rollforward(other)", "intent": "Roll provided date forward to next offset only if not on offset . With arguments `other`.", "question_id": 14827},
{"snippet": "BusinessHour.rollforward(other)", "intent": "Roll provided date forward to next offset only if not on offset . With arguments `other`.", "question_id": 14828},
{"snippet": "BusinessMonthBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14829},
{"snippet": "BusinessMonthBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14830},
{"snippet": "BusinessMonthBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14831},
{"snippet": "BusinessMonthBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14832},
{"snippet": "BusinessMonthBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14833},
{"snippet": "BusinessMonthBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14834},
{"snippet": "pandas.tseries.offsets.BusinessMonthBegin", "intent": "DateOffset of one month at the first business day.", "question_id": 14835},
{"snippet": "pandas.tseries.offsets.BusinessMonthBegin", "intent": "DateOffset of one month at the first business day.", "question_id": 14836},
{"snippet": "pandas.tseries.offsets.BusinessMonthBegin", "intent": "DateOffset of one month at the first business day.", "question_id": 14837},
{"snippet": "BusinessMonthBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14838},
{"snippet": "BusinessMonthBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14839},
{"snippet": "BusinessMonthBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14840},
{"snippet": "BusinessMonthBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14841},
{"snippet": "BusinessMonthBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14842},
{"snippet": "BusinessMonthBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14843},
{"snippet": "BusinessMonthEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14844},
{"snippet": "BusinessMonthEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14845},
{"snippet": "BusinessMonthEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14846},
{"snippet": "BusinessMonthEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14847},
{"snippet": "BusinessMonthEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14848},
{"snippet": "BusinessMonthEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14849},
{"snippet": "pandas.tseries.offsets.BusinessMonthEnd", "intent": "DateOffset increments between the last business day of the month", "question_id": 14850},
{"snippet": "pandas.tseries.offsets.BusinessMonthEnd", "intent": "DateOffset increments between the last business day of the month", "question_id": 14851},
{"snippet": "pandas.tseries.offsets.BusinessMonthEnd", "intent": "DateOffset increments between the last business day of the month", "question_id": 14852},
{"snippet": "BusinessMonthEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14853},
{"snippet": "BusinessMonthEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14854},
{"snippet": "BusinessMonthEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14855},
{"snippet": "BusinessMonthEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14856},
{"snippet": "BusinessMonthEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14857},
{"snippet": "BusinessMonthEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14858},
{"snippet": "pandas.tseries.offsets.CBMonthBegin", "intent": "alias of pandas._libs.tslibs.offsets.CustomBusinessMonthBegin", "question_id": 14859},
{"snippet": "pandas.tseries.offsets.CBMonthBegin", "intent": "alias of pandas._libs.tslibs.offsets.CustomBusinessMonthBegin", "question_id": 14860},
{"snippet": "pandas.tseries.offsets.CBMonthBegin", "intent": "alias of pandas._libs.tslibs.offsets.CustomBusinessMonthBegin", "question_id": 14861},
{"snippet": "pandas.tseries.offsets.CBMonthEnd", "intent": "alias of pandas._libs.tslibs.offsets.CustomBusinessMonthEnd", "question_id": 14862},
{"snippet": "pandas.tseries.offsets.CBMonthEnd", "intent": "alias of pandas._libs.tslibs.offsets.CustomBusinessMonthEnd", "question_id": 14863},
{"snippet": "pandas.tseries.offsets.CBMonthEnd", "intent": "alias of pandas._libs.tslibs.offsets.CustomBusinessMonthEnd", "question_id": 14864},
{"snippet": "pandas.tseries.offsets.CDay", "intent": "alias of pandas._libs.tslibs.offsets.CustomBusinessDay", "question_id": 14865},
{"snippet": "pandas.tseries.offsets.CDay", "intent": "alias of pandas._libs.tslibs.offsets.CustomBusinessDay", "question_id": 14866},
{"snippet": "pandas.tseries.offsets.CDay", "intent": "alias of pandas._libs.tslibs.offsets.CustomBusinessDay", "question_id": 14867},
{"snippet": "CustomBusinessDay.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14868},
{"snippet": "CustomBusinessDay.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14869},
{"snippet": "CustomBusinessDay.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14870},
{"snippet": "CustomBusinessDay.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14871},
{"snippet": "CustomBusinessDay.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14872},
{"snippet": "CustomBusinessDay.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14873},
{"snippet": "pandas.tseries.offsets.CustomBusinessDay", "intent": "DateOffset subclass representing custom business days excluding holidays.", "question_id": 14874},
{"snippet": "pandas.tseries.offsets.CustomBusinessDay", "intent": "DateOffset subclass representing custom business days excluding holidays.", "question_id": 14875},
{"snippet": "pandas.tseries.offsets.CustomBusinessDay", "intent": "DateOffset subclass representing custom business days excluding holidays.", "question_id": 14876},
{"snippet": "CustomBusinessDay.offset", "intent": "Alias for self._offset.", "question_id": 14877},
{"snippet": "CustomBusinessDay.offset", "intent": "Alias for self._offset.", "question_id": 14878},
{"snippet": "CustomBusinessDay.offset", "intent": "Alias for self._offset.", "question_id": 14879},
{"snippet": "CustomBusinessDay.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14880},
{"snippet": "CustomBusinessDay.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14881},
{"snippet": "CustomBusinessDay.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14882},
{"snippet": "CustomBusinessDay.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14883},
{"snippet": "CustomBusinessDay.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14884},
{"snippet": "CustomBusinessDay.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14885},
{"snippet": "CustomBusinessHour.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14886},
{"snippet": "CustomBusinessHour.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14887},
{"snippet": "CustomBusinessHour.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14888},
{"snippet": "CustomBusinessHour.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14889},
{"snippet": "CustomBusinessHour.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14890},
{"snippet": "CustomBusinessHour.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14891},
{"snippet": "pandas.tseries.offsets.CustomBusinessHour", "intent": "DateOffset subclass representing possibly n custom business days.", "question_id": 14892},
{"snippet": "pandas.tseries.offsets.CustomBusinessHour", "intent": "DateOffset subclass representing possibly n custom business days.", "question_id": 14893},
{"snippet": "pandas.tseries.offsets.CustomBusinessHour", "intent": "DateOffset subclass representing possibly n custom business days.", "question_id": 14894},
{"snippet": "CustomBusinessHour.next_bday", "intent": "Used for moving to next business day.", "question_id": 14895},
{"snippet": "CustomBusinessHour.next_bday", "intent": "Used for moving to next business day.", "question_id": 14896},
{"snippet": "CustomBusinessHour.next_bday", "intent": "Used for moving to next business day.", "question_id": 14897},
{"snippet": "CustomBusinessHour.offset", "intent": "Alias for self._offset.", "question_id": 14898},
{"snippet": "CustomBusinessHour.offset", "intent": "Alias for self._offset.", "question_id": 14899},
{"snippet": "CustomBusinessHour.offset", "intent": "Alias for self._offset.", "question_id": 14900},
{"snippet": "CustomBusinessHour.rollback(other)", "intent": "Roll provided date backward to next offset only if not on offset . With arguments `other`.", "question_id": 14901},
{"snippet": "CustomBusinessHour.rollback(other)", "intent": "Roll provided date backward to next offset only if not on offset . With arguments `other`.", "question_id": 14902},
{"snippet": "CustomBusinessHour.rollback(other)", "intent": "Roll provided date backward to next offset only if not on offset . With arguments `other`.", "question_id": 14903},
{"snippet": "CustomBusinessHour.rollforward(other)", "intent": "Roll provided date forward to next offset only if not on offset . With arguments `other`.", "question_id": 14904},
{"snippet": "CustomBusinessHour.rollforward(other)", "intent": "Roll provided date forward to next offset only if not on offset . With arguments `other`.", "question_id": 14905},
{"snippet": "CustomBusinessHour.rollforward(other)", "intent": "Roll provided date forward to next offset only if not on offset . With arguments `other`.", "question_id": 14906},
{"snippet": "CustomBusinessMonthBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14907},
{"snippet": "CustomBusinessMonthBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14908},
{"snippet": "CustomBusinessMonthBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14909},
{"snippet": "CustomBusinessMonthBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14910},
{"snippet": "CustomBusinessMonthBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14911},
{"snippet": "CustomBusinessMonthBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14912},
{"snippet": "CustomBusinessMonthBegin.cbday_roll", "intent": "Define default roll function to be called in apply method.", "question_id": 14913},
{"snippet": "CustomBusinessMonthBegin.cbday_roll", "intent": "Define default roll function to be called in apply method.", "question_id": 14914},
{"snippet": "CustomBusinessMonthBegin.cbday_roll", "intent": "Define default roll function to be called in apply method.", "question_id": 14915},
{"snippet": "pandas.tseries.offsets.CustomBusinessMonthBegin", "intent": "Attributes", "question_id": 14916},
{"snippet": "pandas.tseries.offsets.CustomBusinessMonthBegin", "intent": "Attributes", "question_id": 14917},
{"snippet": "pandas.tseries.offsets.CustomBusinessMonthBegin", "intent": "Attributes", "question_id": 14918},
{"snippet": "CustomBusinessMonthBegin.month_roll", "intent": "Define default roll function to be called in apply method.", "question_id": 14919},
{"snippet": "CustomBusinessMonthBegin.month_roll", "intent": "Define default roll function to be called in apply method.", "question_id": 14920},
{"snippet": "CustomBusinessMonthBegin.month_roll", "intent": "Define default roll function to be called in apply method.", "question_id": 14921},
{"snippet": "CustomBusinessMonthBegin.offset", "intent": "Alias for self._offset.", "question_id": 14922},
{"snippet": "CustomBusinessMonthBegin.offset", "intent": "Alias for self._offset.", "question_id": 14923},
{"snippet": "CustomBusinessMonthBegin.offset", "intent": "Alias for self._offset.", "question_id": 14924},
{"snippet": "CustomBusinessMonthBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14925},
{"snippet": "CustomBusinessMonthBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14926},
{"snippet": "CustomBusinessMonthBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14927},
{"snippet": "CustomBusinessMonthBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14928},
{"snippet": "CustomBusinessMonthBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14929},
{"snippet": "CustomBusinessMonthBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14930},
{"snippet": "CustomBusinessMonthEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14931},
{"snippet": "CustomBusinessMonthEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14932},
{"snippet": "CustomBusinessMonthEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14933},
{"snippet": "CustomBusinessMonthEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14934},
{"snippet": "CustomBusinessMonthEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14935},
{"snippet": "CustomBusinessMonthEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14936},
{"snippet": "CustomBusinessMonthEnd.cbday_roll", "intent": "Define default roll function to be called in apply method.", "question_id": 14937},
{"snippet": "CustomBusinessMonthEnd.cbday_roll", "intent": "Define default roll function to be called in apply method.", "question_id": 14938},
{"snippet": "CustomBusinessMonthEnd.cbday_roll", "intent": "Define default roll function to be called in apply method.", "question_id": 14939},
{"snippet": "pandas.tseries.offsets.CustomBusinessMonthEnd", "intent": "Attributes", "question_id": 14940},
{"snippet": "pandas.tseries.offsets.CustomBusinessMonthEnd", "intent": "Attributes", "question_id": 14941},
{"snippet": "pandas.tseries.offsets.CustomBusinessMonthEnd", "intent": "Attributes", "question_id": 14942},
{"snippet": "CustomBusinessMonthEnd.month_roll", "intent": "Define default roll function to be called in apply method.", "question_id": 14943},
{"snippet": "CustomBusinessMonthEnd.month_roll", "intent": "Define default roll function to be called in apply method.", "question_id": 14944},
{"snippet": "CustomBusinessMonthEnd.month_roll", "intent": "Define default roll function to be called in apply method.", "question_id": 14945},
{"snippet": "CustomBusinessMonthEnd.offset", "intent": "Alias for self._offset.", "question_id": 14946},
{"snippet": "CustomBusinessMonthEnd.offset", "intent": "Alias for self._offset.", "question_id": 14947},
{"snippet": "CustomBusinessMonthEnd.offset", "intent": "Alias for self._offset.", "question_id": 14948},
{"snippet": "CustomBusinessMonthEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14949},
{"snippet": "CustomBusinessMonthEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14950},
{"snippet": "CustomBusinessMonthEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14951},
{"snippet": "CustomBusinessMonthEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14952},
{"snippet": "CustomBusinessMonthEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14953},
{"snippet": "CustomBusinessMonthEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14954},
{"snippet": "DateOffset.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14955},
{"snippet": "DateOffset.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14956},
{"snippet": "DateOffset.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14957},
{"snippet": "DateOffset.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14958},
{"snippet": "DateOffset.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14959},
{"snippet": "DateOffset.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14960},
{"snippet": "pandas.tseries.offsets.DateOffset", "intent": "Standard kind of date increment used for a date range.", "question_id": 14961},
{"snippet": "pandas.tseries.offsets.DateOffset", "intent": "Standard kind of date increment used for a date range.", "question_id": 14962},
{"snippet": "pandas.tseries.offsets.DateOffset", "intent": "Standard kind of date increment used for a date range.", "question_id": 14963},
{"snippet": "DateOffset.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14964},
{"snippet": "DateOffset.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14965},
{"snippet": "DateOffset.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14966},
{"snippet": "DateOffset.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14967},
{"snippet": "DateOffset.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14968},
{"snippet": "DateOffset.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14969},
{"snippet": "Day.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14970},
{"snippet": "Day.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14971},
{"snippet": "Day.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14972},
{"snippet": "Day.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14973},
{"snippet": "Day.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14974},
{"snippet": "Day.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14975},
{"snippet": "pandas.tseries.offsets.Day", "intent": "Attributes", "question_id": 14976},
{"snippet": "pandas.tseries.offsets.Day", "intent": "Attributes", "question_id": 14977},
{"snippet": "pandas.tseries.offsets.Day", "intent": "Attributes", "question_id": 14978},
{"snippet": "Day.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14979},
{"snippet": "Day.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14980},
{"snippet": "Day.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14981},
{"snippet": "Day.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14982},
{"snippet": "Day.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14983},
{"snippet": "Day.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14984},
{"snippet": "Easter.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14985},
{"snippet": "Easter.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14986},
{"snippet": "Easter.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 14987},
{"snippet": "Easter.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14988},
{"snippet": "Easter.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14989},
{"snippet": "Easter.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 14990},
{"snippet": "pandas.tseries.offsets.Easter", "intent": "DateOffset for the Easter holiday using logic defined in dateutil.", "question_id": 14991},
{"snippet": "pandas.tseries.offsets.Easter", "intent": "DateOffset for the Easter holiday using logic defined in dateutil.", "question_id": 14992},
{"snippet": "pandas.tseries.offsets.Easter", "intent": "DateOffset for the Easter holiday using logic defined in dateutil.", "question_id": 14993},
{"snippet": "Easter.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14994},
{"snippet": "Easter.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14995},
{"snippet": "Easter.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 14996},
{"snippet": "Easter.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14997},
{"snippet": "Easter.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14998},
{"snippet": "Easter.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 14999},
{"snippet": "FY5253.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15000},
{"snippet": "FY5253.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15001},
{"snippet": "FY5253.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15002},
{"snippet": "FY5253.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15003},
{"snippet": "FY5253.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15004},
{"snippet": "FY5253.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15005},
{"snippet": "pandas.tseries.offsets.FY5253", "intent": "Describes 52-53 week fiscal year.", "question_id": 15006},
{"snippet": "pandas.tseries.offsets.FY5253", "intent": "Describes 52-53 week fiscal year.", "question_id": 15007},
{"snippet": "pandas.tseries.offsets.FY5253", "intent": "Describes 52-53 week fiscal year.", "question_id": 15008},
{"snippet": "FY5253.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15009},
{"snippet": "FY5253.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15010},
{"snippet": "FY5253.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15011},
{"snippet": "FY5253.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15012},
{"snippet": "FY5253.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15013},
{"snippet": "FY5253.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15014},
{"snippet": "FY5253Quarter.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15015},
{"snippet": "FY5253Quarter.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15016},
{"snippet": "FY5253Quarter.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15017},
{"snippet": "FY5253Quarter.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15018},
{"snippet": "FY5253Quarter.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15019},
{"snippet": "FY5253Quarter.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15020},
{"snippet": "pandas.tseries.offsets.FY5253Quarter", "intent": "DateOffset increments between business quarter dates for 52-53 week fiscal year (also known as a 4-4-5 calendar).", "question_id": 15021},
{"snippet": "pandas.tseries.offsets.FY5253Quarter", "intent": "DateOffset increments between business quarter dates for 52-53 week fiscal year (also known as a 4-4-5 calendar).", "question_id": 15022},
{"snippet": "pandas.tseries.offsets.FY5253Quarter", "intent": "DateOffset increments between business quarter dates for 52-53 week fiscal year (also known as a 4-4-5 calendar).", "question_id": 15023},
{"snippet": "FY5253Quarter.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15024},
{"snippet": "FY5253Quarter.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15025},
{"snippet": "FY5253Quarter.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15026},
{"snippet": "FY5253Quarter.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15027},
{"snippet": "FY5253Quarter.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15028},
{"snippet": "FY5253Quarter.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15029},
{"snippet": "Hour.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15030},
{"snippet": "Hour.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15031},
{"snippet": "Hour.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15032},
{"snippet": "Hour.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15033},
{"snippet": "Hour.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15034},
{"snippet": "Hour.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15035},
{"snippet": "pandas.tseries.offsets.Hour", "intent": "Attributes", "question_id": 15036},
{"snippet": "pandas.tseries.offsets.Hour", "intent": "Attributes", "question_id": 15037},
{"snippet": "pandas.tseries.offsets.Hour", "intent": "Attributes", "question_id": 15038},
{"snippet": "Hour.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15039},
{"snippet": "Hour.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15040},
{"snippet": "Hour.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15041},
{"snippet": "Hour.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15042},
{"snippet": "Hour.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15043},
{"snippet": "Hour.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15044},
{"snippet": "LastWeekOfMonth.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15045},
{"snippet": "LastWeekOfMonth.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15046},
{"snippet": "LastWeekOfMonth.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15047},
{"snippet": "LastWeekOfMonth.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15048},
{"snippet": "LastWeekOfMonth.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15049},
{"snippet": "LastWeekOfMonth.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15050},
{"snippet": "pandas.tseries.offsets.LastWeekOfMonth", "intent": "Describes monthly dates in last week of month like \u201cthe last Tuesday of each month\u201d.", "question_id": 15051},
{"snippet": "pandas.tseries.offsets.LastWeekOfMonth", "intent": "Describes monthly dates in last week of month like \u201cthe last Tuesday of each month\u201d.", "question_id": 15052},
{"snippet": "pandas.tseries.offsets.LastWeekOfMonth", "intent": "Describes monthly dates in last week of month like \u201cthe last Tuesday of each month\u201d.", "question_id": 15053},
{"snippet": "LastWeekOfMonth.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15054},
{"snippet": "LastWeekOfMonth.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15055},
{"snippet": "LastWeekOfMonth.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15056},
{"snippet": "LastWeekOfMonth.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15057},
{"snippet": "LastWeekOfMonth.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15058},
{"snippet": "LastWeekOfMonth.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15059},
{"snippet": "Micro.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15060},
{"snippet": "Micro.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15061},
{"snippet": "Micro.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15062},
{"snippet": "Micro.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15063},
{"snippet": "Micro.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15064},
{"snippet": "Micro.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15065},
{"snippet": "pandas.tseries.offsets.Micro", "intent": "Attributes", "question_id": 15066},
{"snippet": "pandas.tseries.offsets.Micro", "intent": "Attributes", "question_id": 15067},
{"snippet": "pandas.tseries.offsets.Micro", "intent": "Attributes", "question_id": 15068},
{"snippet": "Micro.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15069},
{"snippet": "Micro.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15070},
{"snippet": "Micro.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15071},
{"snippet": "Micro.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15072},
{"snippet": "Micro.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15073},
{"snippet": "Micro.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15074},
{"snippet": "Milli.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15075},
{"snippet": "Milli.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15076},
{"snippet": "Milli.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15077},
{"snippet": "Milli.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15078},
{"snippet": "Milli.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15079},
{"snippet": "Milli.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15080},
{"snippet": "pandas.tseries.offsets.Milli", "intent": "Attributes", "question_id": 15081},
{"snippet": "pandas.tseries.offsets.Milli", "intent": "Attributes", "question_id": 15082},
{"snippet": "pandas.tseries.offsets.Milli", "intent": "Attributes", "question_id": 15083},
{"snippet": "Milli.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15084},
{"snippet": "Milli.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15085},
{"snippet": "Milli.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15086},
{"snippet": "Milli.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15087},
{"snippet": "Milli.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15088},
{"snippet": "Milli.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15089},
{"snippet": "Minute.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15090},
{"snippet": "Minute.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15091},
{"snippet": "Minute.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15092},
{"snippet": "Minute.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15093},
{"snippet": "Minute.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15094},
{"snippet": "Minute.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15095},
{"snippet": "pandas.tseries.offsets.Minute", "intent": "Attributes", "question_id": 15096},
{"snippet": "pandas.tseries.offsets.Minute", "intent": "Attributes", "question_id": 15097},
{"snippet": "pandas.tseries.offsets.Minute", "intent": "Attributes", "question_id": 15098},
{"snippet": "Minute.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15099},
{"snippet": "Minute.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15100},
{"snippet": "Minute.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15101},
{"snippet": "Minute.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15102},
{"snippet": "Minute.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15103},
{"snippet": "Minute.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15104},
{"snippet": "MonthBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15105},
{"snippet": "MonthBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15106},
{"snippet": "MonthBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15107},
{"snippet": "MonthBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15108},
{"snippet": "MonthBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15109},
{"snippet": "MonthBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15110},
{"snippet": "pandas.tseries.offsets.MonthBegin", "intent": "DateOffset of one month at beginning.", "question_id": 15111},
{"snippet": "pandas.tseries.offsets.MonthBegin", "intent": "DateOffset of one month at beginning.", "question_id": 15112},
{"snippet": "pandas.tseries.offsets.MonthBegin", "intent": "DateOffset of one month at beginning.", "question_id": 15113},
{"snippet": "MonthBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15114},
{"snippet": "MonthBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15115},
{"snippet": "MonthBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15116},
{"snippet": "MonthBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15117},
{"snippet": "MonthBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15118},
{"snippet": "MonthBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15119},
{"snippet": "MonthEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15120},
{"snippet": "MonthEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15121},
{"snippet": "MonthEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15122},
{"snippet": "MonthEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15123},
{"snippet": "MonthEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15124},
{"snippet": "MonthEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15125},
{"snippet": "pandas.tseries.offsets.MonthEnd", "intent": "DateOffset of one month end.", "question_id": 15126},
{"snippet": "pandas.tseries.offsets.MonthEnd", "intent": "DateOffset of one month end.", "question_id": 15127},
{"snippet": "pandas.tseries.offsets.MonthEnd", "intent": "DateOffset of one month end.", "question_id": 15128},
{"snippet": "MonthEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15129},
{"snippet": "MonthEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15130},
{"snippet": "MonthEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15131},
{"snippet": "MonthEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15132},
{"snippet": "MonthEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15133},
{"snippet": "MonthEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15134},
{"snippet": "Nano.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15135},
{"snippet": "Nano.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15136},
{"snippet": "Nano.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15137},
{"snippet": "Nano.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15138},
{"snippet": "Nano.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15139},
{"snippet": "Nano.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15140},
{"snippet": "pandas.tseries.offsets.Nano", "intent": "Attributes", "question_id": 15141},
{"snippet": "pandas.tseries.offsets.Nano", "intent": "Attributes", "question_id": 15142},
{"snippet": "pandas.tseries.offsets.Nano", "intent": "Attributes", "question_id": 15143},
{"snippet": "Nano.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15144},
{"snippet": "Nano.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15145},
{"snippet": "Nano.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15146},
{"snippet": "Nano.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15147},
{"snippet": "Nano.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15148},
{"snippet": "Nano.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15149},
{"snippet": "QuarterBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15150},
{"snippet": "QuarterBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15151},
{"snippet": "QuarterBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15152},
{"snippet": "QuarterBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15153},
{"snippet": "QuarterBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15154},
{"snippet": "QuarterBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15155},
{"snippet": "pandas.tseries.offsets.QuarterBegin", "intent": "DateOffset increments between Quarter start dates.", "question_id": 15156},
{"snippet": "pandas.tseries.offsets.QuarterBegin", "intent": "DateOffset increments between Quarter start dates.", "question_id": 15157},
{"snippet": "pandas.tseries.offsets.QuarterBegin", "intent": "DateOffset increments between Quarter start dates.", "question_id": 15158},
{"snippet": "QuarterBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15159},
{"snippet": "QuarterBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15160},
{"snippet": "QuarterBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15161},
{"snippet": "QuarterBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15162},
{"snippet": "QuarterBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15163},
{"snippet": "QuarterBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15164},
{"snippet": "QuarterEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15165},
{"snippet": "QuarterEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15166},
{"snippet": "QuarterEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15167},
{"snippet": "QuarterEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15168},
{"snippet": "QuarterEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15169},
{"snippet": "QuarterEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15170},
{"snippet": "pandas.tseries.offsets.QuarterEnd", "intent": "DateOffset increments between Quarter end dates.", "question_id": 15171},
{"snippet": "pandas.tseries.offsets.QuarterEnd", "intent": "DateOffset increments between Quarter end dates.", "question_id": 15172},
{"snippet": "pandas.tseries.offsets.QuarterEnd", "intent": "DateOffset increments between Quarter end dates.", "question_id": 15173},
{"snippet": "QuarterEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15174},
{"snippet": "QuarterEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15175},
{"snippet": "QuarterEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15176},
{"snippet": "QuarterEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15177},
{"snippet": "QuarterEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15178},
{"snippet": "QuarterEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15179},
{"snippet": "Second.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15180},
{"snippet": "Second.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15181},
{"snippet": "Second.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15182},
{"snippet": "Second.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15183},
{"snippet": "Second.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15184},
{"snippet": "Second.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15185},
{"snippet": "pandas.tseries.offsets.Second", "intent": "Attributes", "question_id": 15186},
{"snippet": "pandas.tseries.offsets.Second", "intent": "Attributes", "question_id": 15187},
{"snippet": "pandas.tseries.offsets.Second", "intent": "Attributes", "question_id": 15188},
{"snippet": "Second.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15189},
{"snippet": "Second.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15190},
{"snippet": "Second.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15191},
{"snippet": "Second.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15192},
{"snippet": "Second.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15193},
{"snippet": "Second.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15194},
{"snippet": "SemiMonthBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15195},
{"snippet": "SemiMonthBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15196},
{"snippet": "SemiMonthBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15197},
{"snippet": "SemiMonthBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15198},
{"snippet": "SemiMonthBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15199},
{"snippet": "SemiMonthBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15200},
{"snippet": "pandas.tseries.offsets.SemiMonthBegin", "intent": "Two DateOffset\u2019s per month repeating on the first day of the month and day_of_month.", "question_id": 15201},
{"snippet": "pandas.tseries.offsets.SemiMonthBegin", "intent": "Two DateOffset\u2019s per month repeating on the first day of the month and day_of_month.", "question_id": 15202},
{"snippet": "pandas.tseries.offsets.SemiMonthBegin", "intent": "Two DateOffset\u2019s per month repeating on the first day of the month and day_of_month.", "question_id": 15203},
{"snippet": "SemiMonthBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15204},
{"snippet": "SemiMonthBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15205},
{"snippet": "SemiMonthBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15206},
{"snippet": "SemiMonthBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15207},
{"snippet": "SemiMonthBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15208},
{"snippet": "SemiMonthBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15209},
{"snippet": "SemiMonthEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15210},
{"snippet": "SemiMonthEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15211},
{"snippet": "SemiMonthEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15212},
{"snippet": "SemiMonthEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15213},
{"snippet": "SemiMonthEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15214},
{"snippet": "SemiMonthEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15215},
{"snippet": "pandas.tseries.offsets.SemiMonthEnd", "intent": "Two DateOffset\u2019s per month repeating on the last day of the month and day_of_month.", "question_id": 15216},
{"snippet": "pandas.tseries.offsets.SemiMonthEnd", "intent": "Two DateOffset\u2019s per month repeating on the last day of the month and day_of_month.", "question_id": 15217},
{"snippet": "pandas.tseries.offsets.SemiMonthEnd", "intent": "Two DateOffset\u2019s per month repeating on the last day of the month and day_of_month.", "question_id": 15218},
{"snippet": "SemiMonthEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15219},
{"snippet": "SemiMonthEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15220},
{"snippet": "SemiMonthEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15221},
{"snippet": "SemiMonthEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15222},
{"snippet": "SemiMonthEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15223},
{"snippet": "SemiMonthEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15224},
{"snippet": "Tick.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15225},
{"snippet": "Tick.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15226},
{"snippet": "Tick.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15227},
{"snippet": "Tick.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15228},
{"snippet": "Tick.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15229},
{"snippet": "Tick.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15230},
{"snippet": "pandas.tseries.offsets.Tick", "intent": "Attributes", "question_id": 15231},
{"snippet": "pandas.tseries.offsets.Tick", "intent": "Attributes", "question_id": 15232},
{"snippet": "pandas.tseries.offsets.Tick", "intent": "Attributes", "question_id": 15233},
{"snippet": "Tick.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15234},
{"snippet": "Tick.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15235},
{"snippet": "Tick.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15236},
{"snippet": "Tick.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15237},
{"snippet": "Tick.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15238},
{"snippet": "Tick.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15239},
{"snippet": "Week.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15240},
{"snippet": "Week.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15241},
{"snippet": "Week.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15242},
{"snippet": "Week.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15243},
{"snippet": "Week.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15244},
{"snippet": "Week.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15245},
{"snippet": "pandas.tseries.offsets.Week", "intent": "Weekly offset.", "question_id": 15246},
{"snippet": "pandas.tseries.offsets.Week", "intent": "Weekly offset.", "question_id": 15247},
{"snippet": "pandas.tseries.offsets.Week", "intent": "Weekly offset.", "question_id": 15248},
{"snippet": "Week.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15249},
{"snippet": "Week.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15250},
{"snippet": "Week.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15251},
{"snippet": "Week.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15252},
{"snippet": "Week.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15253},
{"snippet": "Week.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15254},
{"snippet": "WeekOfMonth.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15255},
{"snippet": "WeekOfMonth.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15256},
{"snippet": "WeekOfMonth.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15257},
{"snippet": "WeekOfMonth.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15258},
{"snippet": "WeekOfMonth.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15259},
{"snippet": "WeekOfMonth.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15260},
{"snippet": "pandas.tseries.offsets.WeekOfMonth", "intent": "Describes monthly dates like \u201cthe Tuesday of the 2nd week of each month\u201d.", "question_id": 15261},
{"snippet": "pandas.tseries.offsets.WeekOfMonth", "intent": "Describes monthly dates like \u201cthe Tuesday of the 2nd week of each month\u201d.", "question_id": 15262},
{"snippet": "pandas.tseries.offsets.WeekOfMonth", "intent": "Describes monthly dates like \u201cthe Tuesday of the 2nd week of each month\u201d.", "question_id": 15263},
{"snippet": "WeekOfMonth.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15264},
{"snippet": "WeekOfMonth.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15265},
{"snippet": "WeekOfMonth.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15266},
{"snippet": "WeekOfMonth.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15267},
{"snippet": "WeekOfMonth.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15268},
{"snippet": "WeekOfMonth.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15269},
{"snippet": "YearBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15270},
{"snippet": "YearBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15271},
{"snippet": "YearBegin.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15272},
{"snippet": "YearBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15273},
{"snippet": "YearBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15274},
{"snippet": "YearBegin.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15275},
{"snippet": "pandas.tseries.offsets.YearBegin", "intent": "DateOffset increments between calendar year begin dates.", "question_id": 15276},
{"snippet": "pandas.tseries.offsets.YearBegin", "intent": "DateOffset increments between calendar year begin dates.", "question_id": 15277},
{"snippet": "pandas.tseries.offsets.YearBegin", "intent": "DateOffset increments between calendar year begin dates.", "question_id": 15278},
{"snippet": "YearBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15279},
{"snippet": "YearBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15280},
{"snippet": "YearBegin.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15281},
{"snippet": "YearBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15282},
{"snippet": "YearBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15283},
{"snippet": "YearBegin.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15284},
{"snippet": "YearEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15285},
{"snippet": "YearEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15286},
{"snippet": "YearEnd.__call__(*args, **kwargs)", "intent": "Call self as a function . With arguments `*args`, `**kwargs`.", "question_id": 15287},
{"snippet": "YearEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15288},
{"snippet": "YearEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15289},
{"snippet": "YearEnd.base", "intent": "Returns a copy of the calling offset object with n=1 and all other attributes equal.", "question_id": 15290},
{"snippet": "pandas.tseries.offsets.YearEnd", "intent": "DateOffset increments between calendar year ends.", "question_id": 15291},
{"snippet": "pandas.tseries.offsets.YearEnd", "intent": "DateOffset increments between calendar year ends.", "question_id": 15292},
{"snippet": "pandas.tseries.offsets.YearEnd", "intent": "DateOffset increments between calendar year ends.", "question_id": 15293},
{"snippet": "YearEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15294},
{"snippet": "YearEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15295},
{"snippet": "YearEnd.rollback()", "intent": "Roll provided date backward to next offset only if not on offset .", "question_id": 15296},
{"snippet": "YearEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15297},
{"snippet": "YearEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15298},
{"snippet": "YearEnd.rollforward()", "intent": "Roll provided date forward to next offset only if not on offset .", "question_id": 15299},
{"snippet": "pandas.unique(values)", "intent": "Hash table-based unique . Includes NA `values` .", "question_id": 15300},
{"snippet": "pandas.unique(values)", "intent": "Hash table-based unique . Includes NA `values` .", "question_id": 15301},
{"snippet": "pandas.unique(values)", "intent": "Hash table-based unique . Includes NA `values` .", "question_id": 15302},
{"snippet": "pandas.util.hash_array(vals)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`.", "question_id": 15303},
{"snippet": "pandas.util.hash_array(vals, encoding='utf8')", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `encoding`.", "question_id": 15304},
{"snippet": "pandas.util.hash_array(vals, hash_key='0123456789123456')", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `hash_key`.", "question_id": 15305},
{"snippet": "pandas.util.hash_array(vals, categorize=True)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `categorize`.", "question_id": 15306},
{"snippet": "pandas.util.hash_array(vals, encoding='utf8', hash_key='0123456789123456')", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `encoding`, `hash_key`.", "question_id": 15307},
{"snippet": "pandas.util.hash_array(vals, encoding='utf8', categorize=True)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `encoding`, `categorize`.", "question_id": 15308},
{"snippet": "pandas.util.hash_array(vals, hash_key='0123456789123456', categorize=True)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `hash_key`, `categorize`.", "question_id": 15309},
{"snippet": "pandas.util.hash_array(vals, encoding='utf8', hash_key='0123456789123456', categorize=True)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `encoding`, `hash_key`, `categorize`.", "question_id": 15310},
{"snippet": "pandas.util.hash_array(vals)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`.", "question_id": 15311},
{"snippet": "pandas.util.hash_array(vals, encoding='utf8')", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `encoding`.", "question_id": 15312},
{"snippet": "pandas.util.hash_array(vals, hash_key='0123456789123456')", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `hash_key`.", "question_id": 15313},
{"snippet": "pandas.util.hash_array(vals, categorize=True)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `categorize`.", "question_id": 15314},
{"snippet": "pandas.util.hash_array(vals, encoding='utf8', hash_key='0123456789123456')", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `encoding`, `hash_key`.", "question_id": 15315},
{"snippet": "pandas.util.hash_array(vals, encoding='utf8', categorize=True)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `encoding`, `categorize`.", "question_id": 15316},
{"snippet": "pandas.util.hash_array(vals, hash_key='0123456789123456', categorize=True)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `hash_key`, `categorize`.", "question_id": 15317},
{"snippet": "pandas.util.hash_array(vals, encoding='utf8', hash_key='0123456789123456', categorize=True)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `encoding`, `hash_key`, `categorize`.", "question_id": 15318},
{"snippet": "pandas.util.hash_array(vals)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`.", "question_id": 15319},
{"snippet": "pandas.util.hash_array(vals, encoding='utf8')", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `encoding`.", "question_id": 15320},
{"snippet": "pandas.util.hash_array(vals, hash_key='0123456789123456')", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `hash_key`.", "question_id": 15321},
{"snippet": "pandas.util.hash_array(vals, categorize=True)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `categorize`.", "question_id": 15322},
{"snippet": "pandas.util.hash_array(vals, encoding='utf8', hash_key='0123456789123456')", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `encoding`, `hash_key`.", "question_id": 15323},
{"snippet": "pandas.util.hash_array(vals, encoding='utf8', categorize=True)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `encoding`, `categorize`.", "question_id": 15324},
{"snippet": "pandas.util.hash_array(vals, hash_key='0123456789123456', categorize=True)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `hash_key`, `categorize`.", "question_id": 15325},
{"snippet": "pandas.util.hash_array(vals, encoding='utf8', hash_key='0123456789123456', categorize=True)", "intent": "Given a 1d array , return an array of deterministic integers . With arguments `vals`, `encoding`, `hash_key`, `categorize`.", "question_id": 15326},
{"snippet": "pandas.util.hash_pandas_object(obj)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`.", "question_id": 15327},
{"snippet": "pandas.util.hash_pandas_object(obj, index=True)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `index`.", "question_id": 15328},
{"snippet": "pandas.util.hash_pandas_object(obj, encoding='utf8')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `encoding`.", "question_id": 15329},
{"snippet": "pandas.util.hash_pandas_object(obj, hash_key='0123456789123456')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `hash_key`.", "question_id": 15330},
{"snippet": "pandas.util.hash_pandas_object(obj, categorize=True)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `categorize`.", "question_id": 15331},
{"snippet": "pandas.util.hash_pandas_object(obj, index=True, encoding='utf8')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `index`, `encoding`.", "question_id": 15332},
{"snippet": "pandas.util.hash_pandas_object(obj, index=True, hash_key='0123456789123456')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `index`, `hash_key`.", "question_id": 15333},
{"snippet": "pandas.util.hash_pandas_object(obj, index=True, categorize=True)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `index`, `categorize`.", "question_id": 15334},
{"snippet": "pandas.util.hash_pandas_object(obj, encoding='utf8', hash_key='0123456789123456')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `encoding`, `hash_key`.", "question_id": 15335},
{"snippet": "pandas.util.hash_pandas_object(obj, encoding='utf8', categorize=True)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `encoding`, `categorize`.", "question_id": 15336},
{"snippet": "pandas.util.hash_pandas_object(obj)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`.", "question_id": 15337},
{"snippet": "pandas.util.hash_pandas_object(obj, index=True)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `index`.", "question_id": 15338},
{"snippet": "pandas.util.hash_pandas_object(obj, encoding='utf8')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `encoding`.", "question_id": 15339},
{"snippet": "pandas.util.hash_pandas_object(obj, hash_key='0123456789123456')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `hash_key`.", "question_id": 15340},
{"snippet": "pandas.util.hash_pandas_object(obj, categorize=True)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `categorize`.", "question_id": 15341},
{"snippet": "pandas.util.hash_pandas_object(obj, index=True, encoding='utf8')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `index`, `encoding`.", "question_id": 15342},
{"snippet": "pandas.util.hash_pandas_object(obj, index=True, hash_key='0123456789123456')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `index`, `hash_key`.", "question_id": 15343},
{"snippet": "pandas.util.hash_pandas_object(obj, index=True, categorize=True)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `index`, `categorize`.", "question_id": 15344},
{"snippet": "pandas.util.hash_pandas_object(obj, encoding='utf8', hash_key='0123456789123456')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `encoding`, `hash_key`.", "question_id": 15345},
{"snippet": "pandas.util.hash_pandas_object(obj, encoding='utf8', categorize=True)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `encoding`, `categorize`.", "question_id": 15346},
{"snippet": "pandas.util.hash_pandas_object(obj)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`.", "question_id": 15347},
{"snippet": "pandas.util.hash_pandas_object(obj, index=True)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `index`.", "question_id": 15348},
{"snippet": "pandas.util.hash_pandas_object(obj, encoding='utf8')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `encoding`.", "question_id": 15349},
{"snippet": "pandas.util.hash_pandas_object(obj, hash_key='0123456789123456')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `hash_key`.", "question_id": 15350},
{"snippet": "pandas.util.hash_pandas_object(obj, categorize=True)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `categorize`.", "question_id": 15351},
{"snippet": "pandas.util.hash_pandas_object(obj, index=True, encoding='utf8')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `index`, `encoding`.", "question_id": 15352},
{"snippet": "pandas.util.hash_pandas_object(obj, index=True, hash_key='0123456789123456')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `index`, `hash_key`.", "question_id": 15353},
{"snippet": "pandas.util.hash_pandas_object(obj, index=True, categorize=True)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `index`, `categorize`.", "question_id": 15354},
{"snippet": "pandas.util.hash_pandas_object(obj, encoding='utf8', hash_key='0123456789123456')", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `encoding`, `hash_key`.", "question_id": 15355},
{"snippet": "pandas.util.hash_pandas_object(obj, encoding='utf8', categorize=True)", "intent": "Return a data hash of the Index/Series/DataFrame . With arguments `obj`, `encoding`, `categorize`.", "question_id": 15356},
{"snippet": "pandas.wide_to_long(df, stubnames, i, j)", "intent": "Wide panel to long format . With `stubnames` [ \u2018 A \u2019 , \u2018 B \u2019 ] , this function expects to find one or more group of columns with format A-suffix1 , A-suffix2 , \u2026 , B-suffix1 , B-suffix2 , \u2026 You specify what you want to call this `suffix` in the resulting long format with `j` ( for example j= \u2019 year \u2019 ) Each row of these wide variables are assumed to be uniquely identified by `i` ( can be a single column name or a list of column names ) With arguments `df`.", "question_id": 15357},
{"snippet": "pandas.wide_to_long(df, stubnames, i, j, sep='')", "intent": "Wide panel to long format . With `stubnames` [ \u2018 A \u2019 , \u2018 B \u2019 ] , this function expects to find one or more group of columns with format A-suffix1 , A-suffix2 , \u2026 , B-suffix1 , B-suffix2 , \u2026 You specify what you want to call this `suffix` in the resulting long format with `j` ( for example j= \u2019 year \u2019 ) Each row of these wide variables are assumed to be uniquely identified by `i` ( can be a single column name or a list of column names ) With arguments `df`, `sep`.", "question_id": 15358},
{"snippet": "pandas.wide_to_long(df, stubnames, i, j, suffix='\\\\d+')", "intent": "Wide panel to long format . With `stubnames` [ \u2018 A \u2019 , \u2018 B \u2019 ] , this function expects to find one or more group of columns with format A-suffix1 , A-suffix2 , \u2026 , B-suffix1 , B-suffix2 , \u2026 You specify what you want to call this `suffix` in the resulting long format with `j` ( for example j= \u2019 year \u2019 ) Each row of these wide variables are assumed to be uniquely identified by `i` ( can be a single column name or a list of column names ) With arguments `df`.", "question_id": 15359},
{"snippet": "pandas.wide_to_long(df, stubnames, i, j, sep='', suffix='\\\\d+')", "intent": "Wide panel to long format . With `stubnames` [ \u2018 A \u2019 , \u2018 B \u2019 ] , this function expects to find one or more group of columns with format A-suffix1 , A-suffix2 , \u2026 , B-suffix1 , B-suffix2 , \u2026 You specify what you want to call this `suffix` in the resulting long format with `j` ( for example j= \u2019 year \u2019 ) Each row of these wide variables are assumed to be uniquely identified by `i` ( can be a single column name or a list of column names ) With arguments `df`, `sep`.", "question_id": 15360},
{"snippet": "pandas.wide_to_long(df, stubnames, i, j)", "intent": "Wide panel to long format . With `stubnames` [ \u2018 A \u2019 , \u2018 B \u2019 ] , this function expects to find one or more group of columns with format A-suffix1 , A-suffix2 , \u2026 , B-suffix1 , B-suffix2 , \u2026 You specify what you want to call this `suffix` in the resulting long format with `j` ( for example j= \u2019 year \u2019 ) Each row of these wide variables are assumed to be uniquely identified by `i` ( can be a single column name or a list of column names ) With arguments `df`.", "question_id": 15361},
{"snippet": "pandas.wide_to_long(df, stubnames, i, j, sep='')", "intent": "Wide panel to long format . With `stubnames` [ \u2018 A \u2019 , \u2018 B \u2019 ] , this function expects to find one or more group of columns with format A-suffix1 , A-suffix2 , \u2026 , B-suffix1 , B-suffix2 , \u2026 You specify what you want to call this `suffix` in the resulting long format with `j` ( for example j= \u2019 year \u2019 ) Each row of these wide variables are assumed to be uniquely identified by `i` ( can be a single column name or a list of column names ) With arguments `df`, `sep`.", "question_id": 15362},
{"snippet": "pandas.wide_to_long(df, stubnames, i, j, suffix='\\\\d+')", "intent": "Wide panel to long format . With `stubnames` [ \u2018 A \u2019 , \u2018 B \u2019 ] , this function expects to find one or more group of columns with format A-suffix1 , A-suffix2 , \u2026 , B-suffix1 , B-suffix2 , \u2026 You specify what you want to call this `suffix` in the resulting long format with `j` ( for example j= \u2019 year \u2019 ) Each row of these wide variables are assumed to be uniquely identified by `i` ( can be a single column name or a list of column names ) With arguments `df`.", "question_id": 15363},
{"snippet": "pandas.wide_to_long(df, stubnames, i, j, sep='', suffix='\\\\d+')", "intent": "Wide panel to long format . With `stubnames` [ \u2018 A \u2019 , \u2018 B \u2019 ] , this function expects to find one or more group of columns with format A-suffix1 , A-suffix2 , \u2026 , B-suffix1 , B-suffix2 , \u2026 You specify what you want to call this `suffix` in the resulting long format with `j` ( for example j= \u2019 year \u2019 ) Each row of these wide variables are assumed to be uniquely identified by `i` ( can be a single column name or a list of column names ) With arguments `df`, `sep`.", "question_id": 15364},
{"snippet": "pandas.wide_to_long(df, stubnames, i, j)", "intent": "Wide panel to long format . With `stubnames` [ \u2018 A \u2019 , \u2018 B \u2019 ] , this function expects to find one or more group of columns with format A-suffix1 , A-suffix2 , \u2026 , B-suffix1 , B-suffix2 , \u2026 You specify what you want to call this `suffix` in the resulting long format with `j` ( for example j= \u2019 year \u2019 ) Each row of these wide variables are assumed to be uniquely identified by `i` ( can be a single column name or a list of column names ) With arguments `df`.", "question_id": 15365},
{"snippet": "pandas.wide_to_long(df, stubnames, i, j, sep='')", "intent": "Wide panel to long format . With `stubnames` [ \u2018 A \u2019 , \u2018 B \u2019 ] , this function expects to find one or more group of columns with format A-suffix1 , A-suffix2 , \u2026 , B-suffix1 , B-suffix2 , \u2026 You specify what you want to call this `suffix` in the resulting long format with `j` ( for example j= \u2019 year \u2019 ) Each row of these wide variables are assumed to be uniquely identified by `i` ( can be a single column name or a list of column names ) With arguments `df`, `sep`.", "question_id": 15366},
{"snippet": "pandas.wide_to_long(df, stubnames, i, j, suffix='\\\\d+')", "intent": "Wide panel to long format . With `stubnames` [ \u2018 A \u2019 , \u2018 B \u2019 ] , this function expects to find one or more group of columns with format A-suffix1 , A-suffix2 , \u2026 , B-suffix1 , B-suffix2 , \u2026 You specify what you want to call this `suffix` in the resulting long format with `j` ( for example j= \u2019 year \u2019 ) Each row of these wide variables are assumed to be uniquely identified by `i` ( can be a single column name or a list of column names ) With arguments `df`.", "question_id": 15367},
{"snippet": "pandas.wide_to_long(df, stubnames, i, j, sep='', suffix='\\\\d+')", "intent": "Wide panel to long format . With `stubnames` [ \u2018 A \u2019 , \u2018 B \u2019 ] , this function expects to find one or more group of columns with format A-suffix1 , A-suffix2 , \u2026 , B-suffix1 , B-suffix2 , \u2026 You specify what you want to call this `suffix` in the resulting long format with `j` ( for example j= \u2019 year \u2019 ) Each row of these wide variables are assumed to be uniquely identified by `i` ( can be a single column name or a list of column names ) With arguments `df`, `sep`.", "question_id": 15368},
